{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Establish Node Graph State Management",
        "description": "Design the minimal Zustand-backed graph state slice for nodes, pins, and params while matching the undo/redo plus autosave conventions seen in `studio/src/stores/project.ts` (temporal + markDirty/touch) and the leaner `studio/src/stores/timeline.ts` patterns. Extend scope to include NodeDefinitions-based validation and standalone graph selectors. Use zundo temporal with limit 50, partialized to `graph`, and revision-based equality; export a `withHistoryBatch` helper for gesture grouping.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "Codebase alignment and targets (based on repo scan):\n- Stores: `studio/src/stores/project.ts`, `studio/src/stores/device.ts`, and `studio/src/stores/timeline.ts` compose `devtools` + `immer`; `project.ts`/`device.ts` use `zundo` temporal with `limit: 50`, partialized history, and identity equality; exports undo/redo via `useXxxStore.temporal.getState()` (see device export names `deviceUndo/deviceRedo/deviceHistoryClear`).\n- Persistence: `studio/src/lib/projectSchema.ts` currently has no `graph` field; `createEmptyProject` lives here; `serializeProject`/`deserializeProject` are in `studio/src/stores/project.ts`.\n- Vitest setup: `studio/vitest.config.ts` uses `happy-dom`; test files match `src/**/*.test.{ts,tsx}`; see patterns in `studio/src/stores/{project,device}.test.ts`.\n\nStore implementation (zustand + immer + zundo temporal):\n- Add `studio/src/stores/graph.ts` using `create`, `devtools`, `immer`, and `temporal`, mirroring composition in `project.ts`/`device.ts`.\n- Types and shape:\n  - `type NodeKind = 'Noise2D' | 'Gradient' | 'Solid' | 'Rotate' | 'Scale' | 'Mirror' | 'Add' | 'Multiply' | 'PaletteMap' | 'HueShift' | 'Brightness' | 'ToK1'`.\n  - `type ParamValue = number | string`.\n  - `interface GraphNode { id: string; kind: NodeKind; params: Record<string, ParamValue>; inputs: Record<string, string | null>; }`.\n  - `type Graph = { nodes: Record<string, GraphNode>; order: string[]; revision: number; outputGeometry?: { width: number; height: number } }`.\n  - UI slice excluded from history/persistence: `{ layout: Record<string, { x: number; y: number }>; selection: string[] }`.\n- Temporal configuration (update vs. earlier referential plan):\n  - `temporal(immer(...), { limit: 50, partialize: (s) => ({ graph: s.graph }), equality: (a, b) => (a as any).graph?.revision === (b as any).graph?.revision })`.\n  - Rationale: revision-based equality drops redundant frames and formalizes gesture grouping; keep UI-only edits out of history by default.\n- Autosave coupling: do NOT add autosave in graph store; for each mutating action, call `useProjectStore.getState().touch()` (see `studio/src/stores/project.ts` for the hybrid throttle pattern with idle flush and edit thresholds).\n- Actions (all increment `graph.revision` and call `touch()`):\n  - `addNode(node, pos?)`, `removeNode(id)` (clean inbound references), `updateNodeParams(id, key, value)`, `connectPins(toNodeId, toPin, fromNodeId)`, `setOutputGeometry(geometry)`.\n  - `connectPins` must validate nodes and pins, prevent self-loops, and reject cycles via a cheap dependsOn DFS over `inputs`.\n- Exports:\n  - Undo/redo/clear (and pause/resume): `export const { undo: graphUndo, redo: graphRedo, clear: graphHistoryClear, pause: graphHistoryPause, resume: graphHistoryResume } = (useGraphStore as any).temporal.getState();` (matches style in `studio/src/stores/device.ts`).\n  - `withHistoryBatch(fn)`: helper that `pause()`/`resume()` around a function body to coalesce multi-step gestures into one history frame.\n\nNodeDefinitions & validation (new):\n- Add `studio/src/lib/graph/nodeDefinitions.ts` exporting per-`NodeKind` definitions:\n  - For each kind specify: `inputs: Record<string, { required?: boolean; arity?: 1 | 'many' }>` and `params: Record<string, { type: 'number' | 'string' | 'color'; min?: number; max?: number; enum?: string[] }>`.\n- Enforce in graph actions:\n  - `connectPins`: check target node exists; check `toPin` exists per definition; ensure arity constraints; prevent self-connect; run cycle precheck; error codes: `NODE_NOT_FOUND`, `PIN_NOT_FOUND`, `CYCLE`.\n  - `updateNodeParams`: verify param key exists and value matches type/range; error codes: `TYPE_INVALID`, `RANGE_INVALID`.\n  - Emit errors as `throw new Error(<CODE>)` (consistent with `NO_DEVICE` error usage in `studio/src/stores/device.ts`).\n\nSelectors & topology (new):\n- Add `studio/src/stores/graph.selectors.ts` exporting pure utilities that operate on `{ nodes, order }`:\n  - `orderedNodes(graph): GraphNode[]` (map `order` to nodes).\n  - `getEdges(graph): Array<{ from: string; to: string; pin: string }>` (from each node.inputs mapping).\n  - `topoSort(graph): string[]` (throws on cycles; second backstop to `connectPins` precheck).\n  - `canConnect(state, toNodeId, toPin, fromNodeId): { ok: true } | { ok: false; code: 'NODE_NOT_FOUND' | 'PIN_NOT_FOUND' | 'CYCLE' }` (uses NodeDefinitions + DFS).\n- Document gesture grouping policy: UI-only actions (`setNodePosition`, `setSelection`) are excluded from history; for drag gestures that should record once, use `withHistoryBatch` or temporal `pause()` on pointerdown and `resume()` on pointerup.\n\nProject schema and persistence:\n- Extend `studio/src/lib/projectSchema.ts` with a `GraphSchema` matching the Graph shape above, and add `graph: GraphSchema.default(/* Solid → ToK1 seed */)` to `ProjectSchema`.\n- Update `createEmptyProject` to include a seeded graph default: nodes `{ nSolid: { kind: 'Solid', params: { color: '#ffffff' }, inputs: {} }, nToK1: { kind: 'ToK1', params: {}, inputs: { input: 'nSolid' } } }`, `order: ['nSolid','nToK1']`, `revision: 0`.\n- `serializeProject`/`deserializeProject` in `studio/src/stores/project.ts` already round-trip arbitrary fields; older projects parse via GraphSchema defaults.\n\nBenchmarks:\n- Add `studio/src/stores/graph.bench.test.ts` to run ~1,000 mixed ops across graph sizes 25/100/500; mix ~600 param edits, ~200 connect/disconnects, ~200 add/remove pairs; measure total apply/undo/redo times with autosave stubbed (spy on `useProjectStore.getState().touch()`); initial targets ≤2.5s for apply/undo/redo each on typical dev hardware; memory delta ~20–40 MB for N≈100 with limit 50.\n\nAcceptance and risks:\n- Composition matches stores; history partialized to `graph` with `limit: 50` and revision-based equality; required actions exist and call `touch()`; undo/redo work; UI-only edits excluded from history; project schema persists a seeded Solid → ToK1 graph; older projects load with defaults. Risks (snapshot memory/latency, history flooding) mitigated via partialize, modest limit, and grouping; cycle checks via DFS and `topoSort` backstop; autosave duplication avoided by relying on `project.ts` autosave.\n",
        "testStrategy": "- Unit tests: add `studio/src/stores/graph.test.ts` (mirroring `project.test.ts`/`device.test.ts`) covering:\n  - Default seeding (Solid → ToK1 graph) from `createEmptyProject` in `studio/src/lib/projectSchema.ts`.\n  - CRUD flows with guards (duplicate id, not found); `removeNode` cleans inbound references.\n  - Pin wiring with cycle prevention; `canConnect` error-paths.\n  - NodeDefinitions validation: invalid connect emits `NODE_NOT_FOUND`/`PIN_NOT_FOUND`/`CYCLE`; invalid params emit `TYPE_INVALID`/`RANGE_INVALID`.\n  - Undo/redo via `useGraphStore.temporal.getState().undo/redo` and ensure UI-only actions are not recorded.\n  - Autosave coupling: spy on `useProjectStore.getState().touch()` in each mutating action.\n  - Serialization round-trip through `serializeProject`/`deserializeProject` with graph preserved.\n  - Selectors exported from `studio/src/stores/graph.selectors.ts` (`topoSort`, `getEdges`, `canConnect`) and behave as expected.\n- Benchmarks: `studio/src/stores/graph.bench.test.ts` executes the 1k mixed-op suite; set thresholds (apply/undo/redo ≤ 2.5s); stub autosave to avoid I/O skew.\n- Equality policy: a small test asserts history frames advance only when `graph.revision` increments; UI-only edits do not increment revision and therefore do not produce frames.\n",
        "subtasks": [
          {
            "id": 1,
            "title": "Review existing Zustand store patterns",
            "description": "Inspect current store implementations to capture structure and conventions.",
            "dependencies": [],
            "details": "Read `studio/src/stores/project.ts`, `studio/src/stores/device.ts`, and `studio/src/stores/timeline.ts` to catalog `devtools`/`immer` composition, `temporal` wiring, the `markDirty`/`touch` autosave helper, and how selectors/exports like `serializeProject` and `undo` are surfaced for consumers.",
            "status": "pending",
            "testStrategy": "Capture findings in notes; no automated tests required.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Define graph state contract",
            "description": "Design types and selectors for the new graph store slice.",
            "dependencies": [
              1
            ],
            "details": "Draft the NodeKind union, GraphNode interfaces, graph metadata, and selectors mirroring the naming used in `project.ts`. Summarize trade-offs between `zundo`'s `temporal` middleware and a custom temporal helper (see `docs/research/PRISM_Studio_Architecture_Research.md`) and decide which undo/redo surface the store will expose alongside serialization helpers.",
            "status": "pending",
            "testStrategy": "Peer review design notes or shared type definitions before implementation, ensuring the undo/redo API and serialization plan are documented.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement graph store with undo support",
            "description": "Build the Zustand store using immer and zundo hooks.",
            "dependencies": [
              2
            ],
            "details": "Create `studio/src/stores/graph.ts` implementing the agreed contract, composing `devtools`, `immer`, and the chosen temporal middleware for undo/redo/history configuration. Implement actions (`addNode`, `updateNodeParams`, `connectPins`, `removeNode`, `setOutputGeometry`), wire selectors, and ensure each mutation invokes `useProjectStore.getState().touch()` so autosave reuse matches the `markDirty` pattern in `project.ts`. Export undo/redo helpers consistent with other stores.",
            "status": "pending",
            "testStrategy": "Run the existing unit suite locally and add temporary smoke calls ensuring the graph store exports compile and temporal history mutators behave as expected.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Extend project schema and defaults",
            "description": "Wire graph state into persistence and migrations.",
            "dependencies": [
              3
            ],
            "details": "Update `studio/src/lib/projectSchema.ts` to add the graph shape and migration defaults, seed `createEmptyProject` with a Solid → ToK1 starter graph, and ensure `serializeProject`/`deserializeProject` in `studio/src/stores/project.ts` handle the new field while tolerating payloads without `graph`. Keep migrations backward compatible.",
            "status": "pending",
            "testStrategy": "Run schema validation utilities (e.g., existing Vitest suites) to confirm legacy fixtures deserialize and new projects include the seeded graph.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Author graph store Vitest coverage",
            "description": "Add unit tests verifying store behaviors and serialization.",
            "dependencies": [
              3,
              4
            ],
            "details": "Create `studio/src/stores/graph.test.ts` covering default state seeding, CRUD flows, pin connection validation, undo/redo via the chosen temporal API, and serialization round-trips through `serializeProject`/`deserializeProject`. Mirror `project.test.ts` and `device.test.ts` patterns to reset store state and spy on the project store `touch` helper.",
            "status": "pending",
            "testStrategy": "Execute the Vitest suite and confirm the new tests cover the specified scenarios, including undo/redo and autosave touch assertions.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Smoke-test project autosave integration",
            "description": "Verify graph changes persist and autosave triggers correctly.",
            "dependencies": [
              4,
              5
            ],
            "details": "Use the graph store actions to mutate nodes and confirm `useProjectStore.getState().touch()` fires, driving the autosave throttle from `project.ts` while persisting graph data via `serializeProject`/`deserializeProject`. Validate persistence by saving/loading a project and confirming the graph state survives reloads.",
            "status": "pending",
            "testStrategy": "Run the app smoke script or a manual session to confirm autosave writes updated graph state and that reloaded projects restore the graph as expected.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Add NodeDefinitions and connect/param validation",
            "description": "Define NodeDefinitions per NodeKind and enforce validation in graph actions.",
            "dependencies": [
              3
            ],
            "details": "Create `studio/src/lib/graph/nodeDefinitions.ts` with per-`NodeKind` specs (input pins with arity and param keys/types/ranges). Update `connectPins` and `updateNodeParams` in `studio/src/stores/graph.ts` to enforce definitions and emit error codes via thrown `Error`: `NODE_NOT_FOUND`, `PIN_NOT_FOUND`, `TYPE_INVALID`, `RANGE_INVALID`, `CYCLE`. Ensure `removeNode` cleans inbound references. Update tests accordingly in `studio/src/stores/graph.test.ts`.",
            "status": "pending",
            "testStrategy": "Acceptance: Invalid connect/param paths are rejected; each error code is covered by a dedicated unit test asserting the thrown message equals the code; valid paths succeed. Include cycle-case tests for both `connectPins` precheck and `topoSort` backstop.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Add graph selectors and temporal equality policy",
            "description": "Provide standalone selectors and switch temporal equality to revision-based, with a history batching helper.",
            "dependencies": [
              3
            ],
            "details": "Add `studio/src/stores/graph.selectors.ts` exporting `topoSort`, `getEdges`, and `canConnect` (using NodeDefinitions). Update `studio/src/stores/graph.ts` to use revision-based temporal equality and export `withHistoryBatch` plus direct `pause/resume` from temporal for gesture grouping. Document policy in code comments and ensure UI-only actions remain excluded from history.",
            "status": "pending",
            "testStrategy": "Acceptance: Selectors are exported and unit-tested; temporal equality compares `graph.revision`; `withHistoryBatch` exists and a test asserts grouped changes yield a single history frame; gesture grouping policy is documented in `graph.ts` comments.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Implement `studio/src/stores/graph.ts` using `create` + `devtools` + `immer` + `temporal` mirroring `useProjectStore` and `useDeviceStore`. Define `NodeKind`, `ParamValue`, `GraphNode`, `Graph`, and a UI slice excluded from history. Configure zundo with `{ limit: 50, partialize: (s)=>({ graph: s.graph }), equality: (a,b)=>(a as any).graph === (b as any).graph }`. Add actions: `addNode(node, pos?)`, `removeNode(id)`, `updateNodeParams(id,key,value)`, `connectPins(toNodeId,toPin,fromNodeId)` (with self-loop and cycle DFS guard), `setOutputGeometry(geometry)`. Every mutating action increments `graph.revision` and calls `useProjectStore.getState().touch()`. Export `graphUndo`, `graphRedo`, `graphHistoryClear` from `useGraphStore.temporal.getState()`. Extend `studio/src/lib/projectSchema.ts` with `GraphSchema` and add `graph` default in `createEmptyProject` (seed Solid → ToK1). Add `studio/src/stores/graph.test.ts` (undo/redo, pin wiring, autosave touch spy, serialization round-trip) and `studio/src/stores/graph.bench.test.ts` (1k mixed ops, undo/redo timing).",
        "updatedAt": "2025-10-17T10:17:14.853Z"
      },
      {
        "id": 2,
        "title": "Build Visual Node Graph Editor",
        "description": "Implement a React authoring surface for creating and wiring the tiny node set.",
        "status": "done",
        "dependencies": [
          "1"
        ],
        "priority": "medium",
        "details": "Add `studio/src/features/graph/GraphCanvas.tsx` and supporting components that render draggable node cards inside an SVG/canvas layer, styled with existing design tokens. Bind to the graph store for node lists and connections, showing typed input/output ports per node definition. Support gestures: drag to move, click toolbar to add node, drag from port to port to connect (validating fan-in/out rules), delete via keyboard. Provide accessible labels and integrate with undo/redo by calling store actions. Update `App.tsx` to mount the graph editor above the DevicePanel so authoring precedes bake/upload. Additionally, implement a dedicated DPR-aware canvas grid/edges layer leveraging `setupDprCanvas` and `resizeIfNeeded` from `studio/src/lib/canvas.ts` and an rAF loop patterned after `studio/src/features/timeline/TimelineCanvas.tsx`, including scroll-blit and dirty-region redraw similar to `maybeRebuildStatic`. Draw edges from graph store selectors (once the graph slice exists per Task 1) and clamp zoom to sane bounds. Add world pan/zoom transform, rubber-band selection, and hit-testing computed in transformed screen space with keyboard selection parity.\nWireframe refs: Timeline Editor screen in 'User-Facing App Wireframes 3/src/components/prism/TimelineEditorScreen.tsx' and App.tsx:Timeline; docs in PRODUCTION_READY_SUMMARY.md and WIRED_FUNCTIONALITY.md (Timeline zoom/scrub).\n\nAcceptance Checklist (wireframe parity)\n- [ ] Timeline zoom matches wireframe states (in/out extremes)\n- [ ] Scrubbing behavior & playhead visuals match wireframe\n- [ ] Keyboard focus order/tab stops per wireframe; ports tabbable\n- [ ] Canvas edges redraw correctly after pan/zoom (100 nodes/200 edges)",
        "testStrategy": "Use @testing-library/react and Vitest to simulate adding nodes, wiring them, and verifying DOM reflects store state; add Cypress/Playwright smoke test ensuring nodes persist after reload via project autosave. Extend with a performance harness asserting average draw/frame time ≤16.7ms while panning at ~100 nodes/200 edges, and accessibility tests validating focus management, tabbable ports, and Enter/Space activation (reuse Playwright config at `studio/playwright.config.ts`).\nVisual parity: zoom states and scrubbing match wireframe; keyboard focus order mirrors wireframe interactions.",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold GraphCanvas and node card layout",
            "description": "Create the GraphCanvas surface and supporting node card components within the graph feature.",
            "dependencies": [],
            "details": "Add GraphCanvas.tsx and child components that render nodes inside an SVG/canvas layer using existing design tokens and pull node data from the graph store.",
            "status": "pending",
            "testStrategy": "Render GraphCanvas with mocked store data in @testing-library/react and assert nodes and ports appear with correct styling.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement node gestures and connection wiring",
            "description": "Enable core authoring gestures for moving nodes, adding new nodes, and wiring ports with validation.",
            "dependencies": [
              1
            ],
            "details": "Wire drag handlers for node repositioning, toolbar actions for adding nodes, and port-to-port drag interactions that enforce fan-in/out rules and update the graph store.",
            "status": "pending",
            "testStrategy": "Use @testing-library/react with pointer events to simulate drag and connect flows, verifying store actions fire and DOM updates accordingly.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate accessibility, undo/redo, and App mounting",
            "description": "Finalize editor integration with accessibility affordances and application shell embedding.",
            "dependencies": [
              1,
              2
            ],
            "details": "Provide ARIA labels, keyboard delete handling, undo/redo hookups via store actions, and mount the editor in App.tsx above the DevicePanel per layout requirements.",
            "status": "pending",
            "testStrategy": "Add React tests for keyboard delete and ARIA attributes, plus integration smoke test ensuring editor renders in App and undo/redo calls trigger store mocks.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Canvas grid/edges layer with DPR + dirty-region redraw",
            "description": "Add a DPR-aware canvas-backed grid/edges layer to GraphCanvas with scroll-blit and partial redraw.",
            "dependencies": [
              1
            ],
            "details": "Create a dedicated 2D canvas inside GraphCanvas using `setupDprCanvas` and `resizeIfNeeded` from `studio/src/lib/canvas.ts`. Drive rendering via an rAF loop following `studio/src/features/timeline/TimelineCanvas.tsx` (see `useRaf`, offscreen buffer, and `maybeRebuildStatic`-style scroll-blit). Render: (1) static grid lines to an offscreen buffer, (2) edges from graph selectors (e.g., `useGraphStore`-derived connections) onto the onscreen layer. On pan: blit the buffer and redraw only newly exposed strips; on zoom: rebuild the buffer. Clamp zoom to configured min/max to avoid numerical drift. Ensure edges reproject correctly under the world transform.",
            "status": "pending",
            "testStrategy": "- Vitest unit/perf harness: simulate 100 nodes/200 edges and programmatic pan; assert average rAF frame ≤16.7ms (60 FPS) over a 2s window using `performance.now()` sampling.\n- Visual correctness: after pan/zoom, edges connect the correct ports (no misalignment) by sampling projected endpoints from the store and comparing to canvas-drawn positions within ±1px.\n- Acceptance: Sustains ~60 FPS during continuous pan on dev hardware; edges remain correct after pan/zoom.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add pan/zoom + selection rectangle + hit-testing at scale",
            "description": "Implement world transform (pan/zoom), rubber-band selection, and accurate hit-testing under transforms.",
            "dependencies": [
              1,
              4
            ],
            "details": "Track `panX/panY/zoom` as a world transform applied to canvas draw and DOM overlay. Implement wheel zoom with clamped bounds and pointer-drag panning similar to TimelineCanvas interactions. Add a rubber-band selection rectangle overlay (DOM/SVG) that maps screen→world using the inverse transform. Compute hit-tests for nodes/ports using transformed bounds (Path2D or AABB in world space) and ensure keyboard selection (arrow keys, Shift+click/Space/Enter) mirrors pointer semantics.",
            "status": "pending",
            "testStrategy": "- @testing-library/react: simulate wheel zoom, pan drag, and Shift+drag rubber-band; verify selected node set matches expected world-space intersection at various zoom levels (min/max) with no drift beyond 1px tolerance.\n- Keyboard parity: simulate keyboard navigation/selection; assert selection result equals pointer-based selection for identical geometries.\n- Acceptance: Keyboard and pointer selection parity; rubber-band selects expected nodes; no hit-test drift at zoom extremes.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Performance and accessibility tests (60 FPS & WCAG)",
            "description": "Add automated performance and a11y coverage for the graph editor.",
            "dependencies": [
              2,
              4
            ],
            "details": "Introduce a perf harness that measures draw time while panning at scale (≈100 nodes/200 edges), validating average frame time ≤16.7ms. Add React Testing Library specs for focus order, roving tabindex (if used), and keyboard activation of ports/nodes (Enter/Space). Ensure ARIA roles/labels on the canvas/editor (patterned after `TimelineCanvas` role/label) and tabbable interactive ports.",
            "status": "pending",
            "testStrategy": "- Perf: rAF-based measurement test that drives pan over a synthetic graph and asserts average frame ≤16.7ms.\n- A11y: RTL tests confirm focus is trapped within the graph when active, ports/nodes are tabbable, and Enter/Space activate expected actions (selection/connection start/confirm). Optionally run Playwright to verify end-to-end tab order.\n- Acceptance: Perf harness passes; a11y tests pass with tabbable ports and Enter/Space activation.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Create `studio/src/features/graph/GraphCanvas.tsx` with SVG/canvas layers and node card components bound to `useGraphStore` for nodes/edges. Implement interactions: drag to reposition (UI slice only), toolbar to add nodes, port‑to‑port drag to connect with `canConnect`/validation, keyboard delete. Add ARIA labels and focus management, and wire undo/redo via graph store. Mount the editor in `studio/src/App.tsx` above `DevicePanel`. Add @testing‑library/react tests for adding/moving/connecting/deleting nodes and ensuring DOM ↔ store sync; include a simple mocked store state provider for tests.",
        "updatedAt": "2025-10-17T10:17:15.700Z"
      },
      {
        "id": 3,
        "title": "Implement Graph Evaluation Engine",
        "description": "Evaluate authored node graphs into frame buffers at 60–120 FPS on the host, with an operator registry and compile cache supporting deterministic evaluation.",
        "status": "done",
        "dependencies": [
          "1"
        ],
        "priority": "high",
        "details": "Implement `studio/src/lib/graph/evaluator.ts` to compile node graphs into pure evaluator functions and stream frames. Align with existing project structure under `studio/src`. Core requirements:\n- Operators: Deterministic Noise2D (seeded), Gradient, Solid generators; affine transforms (Rotate, Scale, Mirror); combiners (Add, Multiply with clamping); color operators (PaletteMap placeholder, HueShift, Brightness).\n- Topology: Build execution order via topological sort; guard cycles and missing inputs; enforce FPS 60–120.\n- Registry + Compile Cache: Introduce `NodeDef`/`OpDef` types and a typed op registry (e.g., `studio/src/lib/graph/ops/registry.ts`) with parameter specs and ranges. Implement `compile(node)` returning a resolver; add a compile cache keyed by node id + params hash; clamp param inputs to declared ranges.\n- Seeding + Time Base: Define a stable, reproducible seed (from graph/project or node param) and use it to seed Noise2D. Provide deterministic time base `t` in seconds per frame (e.g., `frameIndex / fps`) passed to evaluators to ensure reproducibility across runs.\n- API: `evaluateGraph({ graph, seconds, fps, geometry })` returns/streams `Float32Array` RGB frames sized to 2×160 LEDs (320 px × 3 channels) and exposes hooks for per-frame consumption.\n- Errors: Clear errors for cycles, missing inputs, bad params (out of range), and invalid fps.\nSuggested file organization (adapt if needed):\n- `studio/src/lib/graph/evaluator.ts` – orchestration + topological sort + evaluateGraph\n- `studio/src/lib/graph/ops/*` – op implementations (`noise2d.ts`, `gradient.ts`, `solid.ts`, `affine.ts`, `combine.ts`, `color.ts`) and `registry.ts`\n- `studio/src/lib/graph/types.ts` – `Graph`, `Node`, `Port`, `OpDef`, `NodeDef`, and param range types.\nPerformance: Ensure p95 per-frame evaluation for 320 LEDs at 120 FPS is <5ms on dev hardware by minimizing allocations and leveraging compile cache.",
        "testStrategy": "Add Vitest suites under `studio/src/lib/graph/__tests__`:\n- Topology & Validation: cycle detection, missing inputs, fps bounds (60–120), topological order correctness using sample graphs.\n- Registry & Clamping: param range clamping tests and compile cache hit/miss behavior using a node+params hash key.\n- Determinism: seeded Noise2D produces reproducible buffers given the same seed and `t = frameIndex/fps` time base; changing seed or time changes output.\n- Math correctness: HueShift/Brightness arithmetic, affine transforms (Rotate/Scale/Mirror), combiners with clamping.\n- Integration & Frames: `evaluateGraph` yields correct frame count (`seconds × fps`) and buffer size (`320 * 3` floats) for sample graphs.\n- Performance: benchmark harness verifying p95 per-frame eval for 320 LEDs at 120 FPS is <5ms (skip in CI if necessary).",
        "subtasks": [
          {
            "id": 1,
            "title": "Design evaluator topology and validation layer",
            "description": "Establish evaluator scaffolding with data structures for graph nodes, edges, and execution order validation.",
            "dependencies": [],
            "details": "Create `studio/src/lib/graph/evaluator.ts` scaffolding with TypeScript types for nodes/ports, implement guards for missing inputs, enforce fps bounds, and add pure helpers for topological sorting plus cycle detection.",
            "status": "done",
            "testStrategy": "Author Vitest unit tests covering cycle detection, missing input errors, and fps range validation.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:34:01.393Z"
          },
          {
            "id": 2,
            "title": "Implement deterministic node resolver functions",
            "description": "Add resolver implementations for generators, transforms, combiners, and color operators with deterministic behavior.",
            "dependencies": [
              1
            ],
            "details": "Implement pure resolver factories for Noise2D using seeded simplex-noise, Gradient, Solid generators, affine transforms (Rotate, Scale, Mirror), combiners (Add, Multiply with clamping), and color operations (PaletteMap placeholder, HueShift, Brightness) producing Float32Array outputs.",
            "status": "done",
            "testStrategy": "Add Vitest cases verifying deterministic noise given a seed, correct transform math, and clamped combiner outputs.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:25:00.116Z"
          },
          {
            "id": 3,
            "title": "Stream evaluated frames via evaluateGraph API",
            "description": "Compose the full evaluation pipeline that builds execution order, executes resolvers per frame, and streams RGB buffers.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement `evaluateGraph({ graph, seconds, fps, geometry })` to topologically order resolvers, evaluate frames for 2×160 LEDs, accumulate Float32Array RGB outputs, and handle frame streaming hooks while propagating errors from invalid graphs.",
            "status": "done",
            "testStrategy": "Write Vitest suites ensuring frame counts equal seconds×fps, RGB buffer sizing is correct, and integration across sample graphs succeeds.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:25:01.014Z"
          },
          {
            "id": 4,
            "title": "Define op registry + compile cache + parameter ranges",
            "description": "Add typed operator registry with parameter specs, compile() per node, and a compile cache with clamped params.",
            "dependencies": [
              1
            ],
            "details": "Create `NodeDef`/`OpDef` types and parameter range definitions (e.g., min/max/step, enums). Implement a registry module (e.g., `studio/src/lib/graph/ops/registry.ts`) mapping op keys to `OpDef` with typed params and defaults. Provide `compile(node, registry)` that returns a pure evaluator and clamps incoming params to declared ranges. Add a compile cache keyed by stable node id + params hash to avoid rebuilding evaluators across frames.",
            "status": "done",
            "testStrategy": "Acceptance: (1) registry is exported with expected ops, (2) clamping applies to out-of-range params, (3) compile cache yields hits for identical node+params hash and misses when params change.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:25:01.940Z"
          },
          {
            "id": 5,
            "title": "Noise2D seeding and deterministic time base",
            "description": "Integrate stable seeding and a deterministic time base for Noise2D and time-dependent ops.",
            "dependencies": [
              2
            ],
            "details": "Derive a stable seed (e.g., from project/graph seed or explicit node param) and pass it to seeded Noise2D. Define a deterministic time base `t = frameIndex / fps` provided to evaluators so repeated runs with the same graph, seed, and fps produce identical outputs.",
            "status": "done",
            "testStrategy": "Acceptance: Reproducible output given the same seed and time `t`; different seed or time produces different outputs.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:25:02.762Z"
          },
          {
            "id": 6,
            "title": "Test vectors and performance benchmark (<5 ms)",
            "description": "Provide golden test vectors and a perf harness ensuring p95 < 5ms per frame for 320 LEDs @120 FPS.",
            "dependencies": [
              2,
              4
            ],
            "details": "Author Vitest cases for Solid, Gradient, Brightness, Rotate, and Noise2D operators producing small golden outputs. Add a performance benchmark that evaluates a representative graph at 320 LEDs × 120 FPS and asserts p95 eval time < 5ms on dev hardware. Use compile cache to minimize per-frame overhead.",
            "status": "done",
            "testStrategy": "Acceptance: Unit tests pass for the listed operators. Benchmark harness asserts p95 < 5 ms on dev hardware (allow skip in CI if variance is high).",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:28:54.145Z"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Add `studio/src/lib/graph/evaluator.ts` implementing: (1) topology builder with cycle detection and validation (missing inputs, fps bounds 60–120); (2) resolver factories for `Noise2D` (deterministic seeded noise), `Gradient`, `Solid`, affine transforms (`Rotate`,`Scale`,`Mirror`), combiners (`Add`,`Multiply` with clamping), and color ops (`PaletteMap` placeholder, `HueShift`,`Brightness`) producing `Float32Array`; (3) `evaluateGraph({ graph, seconds, fps, geometry })` that compiles resolvers in topological order and yields per‑frame RGB buffers for 2×160 LEDs; (4) Vitest covering topo sort, deterministic noise, math correctness, and frame count = seconds×fps.",
        "updatedAt": "2025-10-17T10:28:54.145Z"
      },
      {
        "id": 4,
        "title": "Add OKLCH Palette LUT Generation",
        "description": "Bake 256×RGB OKLCH lookup tables on the host per PRD color requirements, adding gamut handling modes, gamma policy coordination, and a memoized LUT cache with perf benchmarks.",
        "status": "done",
        "dependencies": [
          "1",
          "3"
        ],
        "priority": "high",
        "details": "- Add culori@^4 to `studio/package.json` and implement `studio/src/lib/color/oklchLut.ts` (new) to: (1) convert project palettes (see `studio/src/lib/projectSchema.ts` Palette) to OKLCH, (2) interpolate to 256 entries, (3) apply sRGB encoding per policy, and (4) return LUT bytes (Uint8Array RGB ×256) plus metadata.\n- API shape (typescript): `generateOklchLut(palette: string[], options?: { steps?: number; gamma?: number; gammaPolicy?: 'baked_2_2'|'flat_1_0'; gamutMode?: 'clip'|'compress'|'preserve-hue'; onStats?: (s:{fromCache:boolean; genMs:number})=>void }): { bytes: Uint8Array; meta: { steps:number; gamutMode:string; gammaPolicy:string; paletteHash:string } }`.\n- Gamut strategies in helper: `clip` (truncate out-of-gamut), `compress` (reduce chroma to fit, preserve L/H), and `preserve-hue` (hue-preserving compression along constant-H lines). Validate using synthetic high-L/high-C palettes.\n- Gamma policy coordination: default bake sRGB ≈2.2 into LUT bytes with device gamma set to 1.0; provide alternative policy `flat_1_0` (no bake) so device gamma applies, to avoid double-encoding. Expose via `gammaPolicy` option and thread through node integration (PaletteMap/HueShift/Brightness) in subtask 3.\n- Add an in-module memoized cache keyed by `paletteHash` + relevant options (steps, gammaPolicy, gamutMode). Expose lightweight stats via `onStats` callback and/or simple getter; log with `studio/src/lib/logger.ts` where appropriate.\n- File placement and conventions align with current project structure: TypeScript modules under `studio/src/lib`, vitest tests beside modules (e.g., `oklchLut.test.ts`), leveraging setup in `studio/src/test/setup.ts`. Node integration leverages forthcoming color nodes and respects existing UI flows in `studio/src/features/devices/DevicePanel.tsx` (for gamma controls in later tasks).",
        "testStrategy": "- Utility tests in `studio/src/lib/color/oklchLut.test.ts` validate: (1) output length 256, (2) endpoints match input palette bounds (within rounding), (3) gamma mapping correctness for `baked_2_2` vs `flat_1_0`, and (4) metadata fields populated.\n- Node integration tests (once nodes consume the helper) extend existing suites to ensure PaletteMap uses LUT indices correctly and the final RGB buffer matches expectations for both gamma policies.\n- Gamut strategy tests with synthetic palettes assert: no NaNs, out-of-gamut handling per mode, and hue preservation within tolerance (e.g., Δh ≤ 1–2° for preserve-hue).\n- Cache/perf tests: measure first-call vs cached-call timings and assert a perf guard on dev HW (<2 ms for cached path; relaxed threshold under `process.env.CI`). Verify cache hit rates are observable via stats hook.\n- Documentation check: verify gamma policy section added to `docs/user-manual.md` or a new `docs/bench/oklch.md` notes CI thresholds and measurement method.",
        "subtasks": [
          {
            "id": 1,
            "title": "Install culori and scaffold OKLCH LUT module",
            "description": "Add the culori package and create the initial OKLCH LUT helper file.",
            "dependencies": [],
            "details": "Add `culori@^4` to `studio/package.json`, install deps, and create `studio/src/lib/color/oklchLut.ts` with exported placeholders for LUT generation, metadata typing, and options (`gammaPolicy`, `gamutMode`, `steps`, `onStats`).",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:59.751Z"
          },
          {
            "id": 2,
            "title": "Implement OKLCH LUT generation pipeline",
            "description": "Fill the helper with full conversion, interpolation, and gamma logic.",
            "dependencies": [
              1
            ],
            "details": "Implement in `studio/src/lib/color/oklchLut.ts`: parse hex palette → OKLCH via culori, interpolate to 256 entries, apply sRGB encoding per `gammaPolicy` (`baked_2_2` default), and emit `{ bytes, meta }` including `paletteHash`, `steps`, `gamutMode`, `gammaPolicy`.",
            "status": "done",
            "testStrategy": "Vitest cases ensure 256-length output, endpoint fidelity (within 8-bit rounding), and gamma mapping correctness for both `baked_2_2` and `flat_1_0` policies.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:34:00.571Z"
          },
          {
            "id": 3,
            "title": "Integrate LUT helper into color nodes and tests",
            "description": "Update color nodes to consume the new LUT helper and validate behavior.",
            "dependencies": [
              2
            ],
            "details": "Refactor PaletteMap, HueShift, and Brightness evaluators to call the helper and pass through options (`gammaPolicy`, `gamutMode`). Evaluator should emit indexed palette references and final RGB buffer for packaging without changing external APIs.",
            "status": "done",
            "testStrategy": "Expand vitest suites for updated nodes to confirm LUT indices are applied, final RGB buffers align with expectations, and node-level gamma policy is honored without double-encoding.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:25:03.579Z"
          },
          {
            "id": 4,
            "title": "Implement gamut handling strategies and tests",
            "description": "Add clip/compress/preserve-hue gamut modes to the LUT helper and validate behavior.",
            "dependencies": [
              2
            ],
            "details": "Extend `studio/src/lib/color/oklchLut.ts` options with `gamutMode: 'clip'|'compress'|'preserve-hue'`. Implement: clip (truncate to sRGB), compress (reduce chroma to fit while preserving L/H as much as possible), preserve-hue (hue-preserving compression along constant-H lines). Validate using synthetic stress palettes (high C, high L).",
            "status": "done",
            "testStrategy": "Acceptance: (1) Unit tests produce no NaNs or Infs, (2) hue preserved within tolerance (e.g., Δh ≤ 2°) for preserve-hue, (3) out-of-gamut entries are handled per selected mode. Include tests in `studio/src/lib/color/oklchLut.gamut.test.ts`.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:25:04.399Z"
          },
          {
            "id": 5,
            "title": "Define gamma policy and device coordination",
            "description": "Decide and document gamma policy; plumb configuration through nodes to avoid double-encoding.",
            "dependencies": [
              3
            ],
            "details": "Adopt default policy: bake sRGB ≈2.2 into LUT bytes (`gammaPolicy='baked_2_2'`) and set device gamma to 1.0. Document alternative `flat_1_0` (no bake, device gamma applies). Add a config flag in the LUT options and ensure node integrations from subtask 3 forward the chosen policy. Document policy and trade-offs in `docs/user-manual.md` (Color/Gamma) including examples and when to use each.",
            "status": "done",
            "testStrategy": "Acceptance: (1) Config toggles switch the gamma pipeline in tests, (2) node integration honors the policy (no double-encoding), (3) documentation updated and linked in code comments (file paths referenced). Add verification tests in `oklchLut.test.ts` and node tests.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:28:55.009Z"
          },
          {
            "id": 6,
            "title": "Add paletteHash cache and LUT performance benchmarks",
            "description": "Memoize LUT results and add perf guard; expose stats for observability.",
            "dependencies": [
              2
            ],
            "details": "Implement a memoized cache in `oklchLut.ts` keyed by `paletteHash` + critical options (`steps`,`gammaPolicy`,`gamutMode`). Provide `onStats` callback for cache hit/miss and generation timing; optionally a simple `getCacheStats()` for tests. Add vitest perf tests that assert cached path completes under 2 ms on dev hardware and document relaxed CI thresholds in `docs/bench/oklch.md`.",
            "status": "done",
            "testStrategy": "Acceptance: (1) Cache hit rates measurable via stats hook, (2) perf tests pass on dev HW (<2 ms cached path; relax under `process.env.CI`), (3) CI thresholds and methodology documented with links to test files.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:25:05.214Z"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Install `culori@^4` and create `studio/src/lib/color/oklchLut.ts` exposing functions to: convert input palettes to OKLCH, interpolate to 256 entries, gamma‑map to 8‑bit sRGB (2.2), and return LUT bytes + metadata. Update color evaluators (`PaletteMap`,`HueShift`,`Brightness`) to consume the LUT helper and output both indexed references and final RGB buffers as needed. Add Vitest ensuring LUT length 256, edge color fidelity, gamma correctness, and PaletteMap index usage.",
        "updatedAt": "2025-10-17T10:28:55.009Z"
      },
      {
        "id": 5,
        "title": "Port ADR-009 .prism Packaging to TypeScript",
        "description": "Package evaluated frames into ADR-009 compliant .prism binaries with CRC-32.",
        "status": "done",
        "dependencies": [
          "3",
          "4"
        ],
        "priority": "high",
        "details": "Align implementation with current Studio/Tools layout. Build new TypeScript packer at `studio/src/lib/bake/packPrism.ts` and model its CRC usage on existing precedent in `studio/scripts/upload-pattern.mjs` (imports `crc-32`). Implement ADR-009 header assembly, payload chunking, XOR delta + RLE, palette metadata embedding, 256 KB cap enforcement, and CRC-32 IEEE 0xEDB88320 via the `crc-32` npm module already used in the repo. Provide API: `packPrism({ frames, fps, ledCount, paletteLut }) => { bytes: Uint8Array, stats: { version, frameCount, fps, ledCount, payloadSize, totalSize, headerCrc, payloadCrc, errors?: string[] } }`. Integrate stats with the project save flow in `studio/src/stores/project.ts` so the latest bake diagnostics are persisted for UI diagnostics. For Python parity and CRC cross-checks, use `tools/validation/prism_sanity.py` as the authoritative CRC verifier and create mirrored fixtures in `tools/tests/prism/` to compare bytes and CRCs. Tests should live under `studio/src/lib/bake/__tests__/packPrism.test.ts` and use `vitest` per `studio/vitest.config.ts`. Document size/CRC thresholds and error taxonomy to surface actionable messages to the UI and CI logs.",
        "testStrategy": "- Unit: Create Vitest cases under `studio/src/lib/bake/__tests__/packPrism.test.ts` comparing `packPrism` output to Python-generated fixtures in `tools/tests/prism/`. Assert byte-for-byte equality, header fields (version, frame count, fps), and both header/payload CRCs match values recomputed in test using `crc-32`.\n- Limits/guardrails: Tests for payload and total size boundaries (≤256 KB), invalid frames/palette lengths, and error taxonomy mapping (e.g., PRISM_TOO_LARGE, MALFORMED_FRAMES, PALETTE_LENGTH_MISMATCH) to actionable messages.\n- Integration: Stub the consumer in `studio/src/stores/project.ts` to confirm stats persistence and serialization/deserialization roundtrips. Ensure CI logs capture pack stats (sizes, CRCs) via a packer step and that UI components can read/display stats.\n- Parity: Add a script to re-verify fixtures with `tools/validation/prism_sanity.py` in CI; tests should fail if recomputed CRC mismatches.",
        "subtasks": [
          {
            "id": 1,
            "title": "Design TypeScript packPrism module structure",
            "description": "Review ADR-009 and the Python packer to outline the new TypeScript API surface.",
            "dependencies": [],
            "details": "Audit current repo CRC usage in `studio/scripts/upload-pattern.mjs` and any ADR-009 rules, then define TypeScript typings for frames, stats, and packPrism parameters/return values. Document module responsibilities and expected locations: implementation in `studio/src/lib/bake/packPrism.ts`, tests in `studio/src/lib/bake/__tests__/packPrism.test.ts`.",
            "status": "done",
            "testStrategy": "Draft interface unit tests verifying TypeScript typings compile with example inputs and that `crc-32` import pattern matches `studio/scripts/upload-pattern.mjs`.",
            "updatedAt": "2025-10-17T08:33:49.041Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement ADR-009 binary assembly in TypeScript",
            "description": "Port the Python packaging logic into packPrism.ts covering headers, payload transforms, and CRC.",
            "dependencies": [
              1
            ],
            "details": "Translate header construction, frame chunking, XOR delta plus RLE compression, palette metadata embedding, and 256KB enforcement. Integrate `crc-32` to emit bytes and stats from `packPrism`. Place implementation in `studio/src/lib/bake/packPrism.ts` and export `packPrism` with the defined API.",
            "status": "done",
            "testStrategy": "Add Vitest cases comparing generated bytes/CRC against Python fixture outputs and asserting size guardrails. Use `crc-32` to recompute CRCs and confirm equality.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:49.867Z"
          },
          {
            "id": 3,
            "title": "Expose packPrism stats and persistence integration",
            "description": "Add UI-facing stats reporting and persist latest bake metrics in project save flow.",
            "dependencies": [
              1,
              2
            ],
            "details": "Extend `packPrism` return shape with error/size stats. Update `studio/src/stores/project.ts` save logic to store recent bake diagnostics (sizes, CRCs, counts). Ensure consumers (UI) handle the new data contract and display stats.",
            "status": "done",
            "testStrategy": "Write integration tests stubbing the packPrism consumer to confirm stats persistence in project state and regression tests for new metadata serialization.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:14:49.256Z"
          },
          {
            "id": 4,
            "title": "Add Python parity fixtures and CRC cross-checks",
            "description": "Parity fixtures & CRC verification.",
            "dependencies": [
              2
            ],
            "details": "Create Python-mirrored fixtures derived from an equivalent algorithm and verified by `tools/validation/prism_sanity.py`. Store under `tools/tests/prism/` (e.g., `.prism` binaries plus JSON of expected header/payload CRCs). In Vitest (`studio/src/lib/bake/__tests__/packPrism.test.ts`), assert byte-for-byte equality and both header/payload CRCs via `crc-32` recomputation.",
            "status": "done",
            "testStrategy": "- Fixture tests pass locally and in CI.\n- Recompute CRC in tests and compare to both packed output and stored expected values.\n- Fail tests if any mismatch is detected.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:50.677Z"
          },
          {
            "id": 5,
            "title": "Implement size/format guardrails and error mapping",
            "description": "Error taxonomy & guardrails.",
            "dependencies": [
              2
            ],
            "details": "Enforce ≤256KB cap and surface `PRISM_TOO_LARGE`. Validate frames and palette lengths; surface `MALFORMED_FRAMES`, `PALETTE_LENGTH_MISMATCH`, `UNSUPPORTED_FPS_BOUNDS` (if applicable). Map pack errors to user-facing guidance for Task 9 and include remediation tips in error strings. Ensure guardrails are applied before packaging to avoid wasted work.",
            "status": "done",
            "testStrategy": "- Add tests for oversize payloads, malformed inputs (empty frames, inconsistent frame sizes), invalid palette sizes.\n- Verify correct error codes/messages, and that `stats.errors` are populated.\n- Ensure process aborts early for fatal guardrail violations.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:14:50.097Z"
          },
          {
            "id": 6,
            "title": "CI packer step and stats reporting",
            "description": "CI integration & stats.",
            "dependencies": [
              3
            ],
            "details": "Add a CI step to run the packer against sample inputs and emit pack stats (sizes, CRCs) to logs. Expose a small API/read helper for UI to display pack stats and thresholds. Document thresholds (≤256KB total, CRC expectations) in `docs/` and ensure logs include the same metrics for quick diagnosis.",
            "status": "done",
            "testStrategy": "- CI logs contain pack stats for sample runs and fail on threshold violations.\n- UI reads and displays pack size/CRC from persisted stats.\n- Documentation updated with thresholds and how to interpret stats.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:25:06.029Z"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Create `studio/src/lib/bake/packPrism.ts` that assembles ADR‑009 headers, performs XOR‑delta + RLE compression, enforces ≤256 KB cap, embeds palette metadata, and computes CRC‑32 (use `crc-32`). Expose `packPrism({ frames, fps, ledCount, paletteLut }) => { bytes, stats }`. Add Vitest comparing bytes/CRC and header fields against known fixtures (add small golden fixtures under `tools/tests` or generate via Python reference if available). Extend save logic to persist recent bake stats for diagnostics.",
        "updatedAt": "2025-10-17T10:25:06.029Z"
      },
      {
        "id": 6,
        "title": "Implement Streaming Upload Backend",
        "description": "Add Tauri commands to stream .prism payloads over a single WebSocket with PUT_* frames, now including cancel/reconnect handling and 10Hz EMA throughput reporting.",
        "status": "done",
        "dependencies": [
          "5"
        ],
        "priority": "high",
        "details": "Extend or create `studio/src-tauri/src/lib.rs` with `#[tauri::command] async fn device_upload(host: String, meta: UploadMeta, pattern: Vec<u8>)`. Use TLV helpers (if not present, add a small module alongside `lib.rs`, e.g., `studio/src-tauri/src/tlv.rs`) to request STATUS for `maxChunk` before any socket work. Establish a persistent websocket session (e.g., via `tokio_tungstenite`) and send firmware-aligned TLV frames: `PUT_BEGIN` (pattern name, size, CRC-32), `PUT_DATA` in `maxChunk` slices, and `PUT_END` with CRC confirmation. Emit progress to the UI via `app.emit(\"upload:progress\", UploadProgress { bytesSent, total, throughputBps })`, throttled to 10Hz, where `throughputBps` is computed as an EMA over a short sliding window. Add cancel handling and single-attempt reconnection: on cancel, stop streaming, close WS, and emit `upload:cancelled`; on transient WS failure, retry once and re-run STATUS to refresh `maxChunk` prior to resuming, otherwise abort with a typed error. Enforce payload size ≤ 256 KB and return detailed errors mapped from firmware STATUS/ERROR TLVs. Use repo guidance in `docs/research/PRISM_Studio_Architecture_Research.md` for Tauri structure and security notes; place integration tests under `studio/src-tauri/tests/` and consider CRC alignment with existing CRC usage in Python utilities under `tools/validation/` (use Rust `crc32fast` for parity).\nWireframe refs: Device Sync progress/ack now reflected from wireframe docs (PRODUCTION_READY_SUMMARY.md WebSocket Device Sync; WIRED_FUNCTIONALITY.md Upload progress).\n\nAcceptance Checklist (wireframe parity)\n- [ ] STATUS.maxChunk probed before upload\n- [ ] PUT_BEGIN/PUT_DATA/PUT_END acknowledged (per firmware) or handled per policy\n- [ ] Progress events (percent/bytes/s/eta) emitted @<=10Hz\n- [ ] Cancel emits final 'upload:cancelled' and closes WS",
        "testStrategy": "- Unit tests (Rust):\n  - TLV framing helpers: verify correct TLV types and payload packing for PUT_BEGIN/PUT_DATA/PUT_END and STATUS.\n  - Size guard: reject payloads > 256 KB.\n  - Throughput EMA: deterministic sequence verifies EMA/window math and 10Hz throttle behavior.\n- Integration tests (Tokio + mocked tungstenite server) under `studio/src-tauri/tests/`:\n  - Happy path: PUT_BEGIN → PUT_DATA (exact and uneven chunking) → PUT_END; server acks and validates sequencing.\n  - CRC: server-induced CRC mismatch triggers mapped, descriptive error; success path confirms CRC.\n  - Progress: events delivered at ~10Hz, include non-negative `throughputBps`, and reach total bytes.\n  - Cancel: mid-stream cancel stops further frames and emits final `upload:cancelled` event.\n  - Reconnect: forced WS drop triggers one reconnect attempt with a re-STATUS; on second failure, upload aborts with a typed reconnect error.\n  - Timeout: server delay produces a specific timeout error code and message.\nBackend progress events render UI states as per wireframe progress examples.",
        "subtasks": [
          {
            "id": 1,
            "title": "Define device_upload command skeleton",
            "description": "Add the async Tauri command stub with input validation and TLV setup.",
            "dependencies": [],
            "details": "Create `#[tauri::command] async fn device_upload(host: String, meta: UploadMeta, pattern: Vec<u8>)` in `studio/src-tauri/src/lib.rs`. Validate payload size ≤ 256 KB. Derive/calc CRC-32 (e.g., `crc32fast`) and call TLV STATUS to fetch `maxChunk` prior to socket work. Prepare `UploadProgress` struct matching emission payload.",
            "status": "done",
            "testStrategy": "Add a Rust unit test enforcing the size guard (>256 KB rejected). Add a unit test ensuring STATUS request is prepared before any websocket initiation.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:51.467Z"
          },
          {
            "id": 2,
            "title": "Stream PUT_* frames over persistent websocket",
            "description": "Implement the websocket session to stream pattern bytes using TLV PUT frames.",
            "dependencies": [
              1
            ],
            "details": "Open a persistent websocket to the target `host`. Send `PUT_BEGIN` with metadata (pattern name, total size, CRC-32). Iterate the pattern buffer in `maxChunk`-sized slices and send `PUT_DATA` per slice. After the final chunk, send `PUT_END` with CRC confirmation. Await and validate server acks and finalization before returning success.",
            "status": "done",
            "testStrategy": "Mock a tungstenite server to validate sequencing: `PUT_BEGIN` → `PUT_DATA` (correct chunk boundaries) → `PUT_END`. Assert that off-by-one and uneven sizes are chunked correctly and acknowledged in order.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:52.304Z"
          },
          {
            "id": 3,
            "title": "Emit progress and translate firmware errors",
            "description": "Report upload progress and map TLV errors to readable failures with tests.",
            "dependencies": [
              1,
              2
            ],
            "details": "During streaming, emit app events via `app.emit(\"upload:progress\", UploadProgress { bytesSent, total, throughputBps })`. Capture firmware STATUS/ERROR TLVs and map them to typed, descriptive errors (e.g., codes like `err.status.max_chunk_unsupported`, `err.crc.mismatch`, `err.ws.timeout`). Return a structured Result with these error categories.",
            "status": "done",
            "testStrategy": "Integration test asserts progress events fire with increasing `bytesSent` and include `throughputBps`. Inject ERROR TLVs in the mock server and assert mapped, descriptive error codes/messages are returned.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T09:35:48.215Z"
          },
          {
            "id": 4,
            "title": "Implement upload cancel and reconnection handling",
            "description": "Support cancellation and a single reconnection attempt with re-STATUS before aborting.",
            "dependencies": [
              2
            ],
            "details": "Add a cancel path that immediately stops streaming, cleanly closes the websocket, and marks the upload as cancelled; consistently emit `upload:cancelled`. Implement reconnection logic: on WS disconnect/connect error, retry connection once; re-run STATUS to refresh `maxChunk`; if reconnect fails again or STATUS differs incompatibly, abort with a typed reconnect error. Ensure in-progress state is preserved/restored correctly if resuming after reconnect.",
            "status": "done",
            "testStrategy": "Integration tests: (1) Cancel mid-stream → stop sending frames immediately and emit `upload:cancelled` once. (2) Simulate WS drop → exactly one reconnect attempt; verify a second failure returns a distinct reconnect error; verify a successful reconnect re-runs STATUS before resuming.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T09:05:11.993Z"
          },
          {
            "id": 5,
            "title": "Add progress EMA and throughput reporting",
            "description": "Report 10Hz-throttled progress events including EMA throughput.",
            "dependencies": [
              3
            ],
            "details": "Compute an EMA throughput (bytes/s) over a short sliding window (e.g., 1–3 s) using monotonically increasing time (Tokio Instant). Include `throughputBps` in progress events. Throttle `upload:progress` emissions to ~10Hz for consistent UI updates and lower overhead. Keep event shape consistent with the existing `UploadProgress` struct in `studio/src-tauri/src/lib.rs` (or a new `events.rs` if modularized).",
            "status": "done",
            "testStrategy": "- Unit tests for EMA: feed fixed byte/time samples → assert EMA matches expected within tolerance. - Integration: assert progress events are spaced at ~100 ms intervals and include `throughputBps ≥ 0`, converging appropriately under steady transfer.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T09:05:12.816Z"
          },
          {
            "id": 6,
            "title": "Add mock WS device and integration tests",
            "description": "Introduce a mock tungstenite server to validate TLV ACK/CRC behavior and error paths.",
            "dependencies": [
              2,
              3
            ],
            "details": "Create a Tokio-based mock WS server helper under `studio/src-tauri/tests/` that: responds to STATUS with `maxChunk`, ACKs `PUT_BEGIN`/`PUT_DATA`/`PUT_END`, validates chunk sizes and total length, verifies CRC, and can inject errors/timeouts (e.g., mid-stream drops, invalid CRC, delayed ACK). Reuse any shared TLV type definitions to ensure parity with client framing.",
            "status": "done",
            "testStrategy": "Integration tests cover: (1) exact and uneven chunk boundaries, (2) CRC success and CRC mismatch mapping, (3) cancellation emits `upload:cancelled` and halts frames, (4) reconnect tries once and re-STATUS before resuming/aborting, (5) timeout surfaces a clear timeout error class.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:14:51.004Z"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 3,
        "expansionPrompt": "In `studio/src-tauri/src/lib.rs`, add `#[tauri::command] async fn device_upload(host: String, meta: UploadMeta, pattern: Vec<u8>)` that: validates ≤256 KB; queries STATUS for `maxChunk`; opens a persistent WebSocket; sends TLV `PUT_BEGIN` (name,size,crc), streams `PUT_DATA` in `maxChunk` slices, then `PUT_END`; emits `upload:progress` events with bytes/throughput; maps error TLVs to readable strings. Use existing `tlv_request` and tungstenite patterns as a reference and mirror framing constants from `scripts/upload-pattern.mjs`. Add Rust tests with a mocked tungstenite server for chunking and CRC validation.",
        "updatedAt": "2025-10-17T10:14:51.004Z"
      },
      {
        "id": 7,
        "title": "Integrate Bake & Upload Workflow in UI",
        "description": "Wire graph evaluation, packaging, and device upload into a cohesive \"Bake & Upload\" flow.",
        "details": "Add a primary button in `DevicePanel.tsx` (or new `BakePanel.tsx`) that triggers `async function bakeAndUpload()` calling evaluator (Task 3), LUT builder (Task 4), packPrism (Task 5), then invokes `device_upload` (Task 6). Show realtime progress via a new Zustand slice (`useUploadStore`) and render percent + throughput with cancel option. After successful upload, auto-call CONTROL PLAY (once Task 8 exists) and log timings to measure TTFL. Persist last bake stats in project metadata for debugging.\nWireframe refs: Progress panel states (active/cancelled/error), TTFL display, and retry per wireframes.\n\nAcceptance Checklist (wireframe parity)\n- [ ] ProgressPanel shows active/cancelled/error states\n- [ ] TTFL displayed after auto-PLAY\n- [ ] Retry available after error; resets store cleanly",
        "testStrategy": "Create React component tests stubbing Tauri to ensure progress UI updates and error states render; add Playwright E2E that bakes the seeded sample graph, uploads to a mocked backend, and verifies completion banner.\nUI progress/TTFL matches wireframe states across happy-path and error flows.",
        "priority": "high",
        "dependencies": [
          "2",
          "3",
          "4",
          "5",
          "6"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement upload progress Zustand slice",
            "description": "Create a dedicated `useUploadStore` slice to track bake/upload progress, errors, timing and cancellation state.",
            "dependencies": [],
            "details": "Define state fields for phase, percent complete, bytes per second, started/completed timestamps, and last error; expose actions to start/reset/cancel uploads, feed progress payloads, and register/unregister the Tauri `upload:*` listeners so UI stays in sync.",
            "status": "done",
            "testStrategy": "Add vitest store tests that fake progress and error events, assert throughput math, and confirm cancel/reset actions clear listeners.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:53.106Z"
          },
          {
            "id": 2,
            "title": "Build bakeAndUpload orchestration flow",
            "description": "Wire an `async bakeAndUpload` helper that sequences evaluator, LUT builder, packPrism, and device upload while updating the progress store.",
            "dependencies": [
              1
            ],
            "details": "Compose the graph evaluation, LUT generation, and packaging utilities, invoke `device_upload` with cancellation support, emit store updates at each stage, and record timing checkpoints for bake, pack, upload, and overall TTFL to feed metrics.",
            "status": "done",
            "testStrategy": "Write integration-like vitest covering happy path and failure branches by stubbing evaluator, packer, and upload functions to ensure store transitions and error propagation behave as expected.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:53.978Z"
          },
          {
            "id": 3,
            "title": "Integrate Bake & Upload UI controls",
            "description": "Add the primary Bake & Upload entry point in `DevicePanel` (or new `BakePanel`), render progress telemetry, and persist post-upload metadata.",
            "dependencies": [
              2
            ],
            "details": "Insert a primary button that invokes `bakeAndUpload`, render progress percent/throughput with cancel option bound to the store, trigger CONTROL PLAY on success when Task 8 is available, surface toast/logging, and save last run metrics into project metadata for debugging.",
            "status": "done",
            "testStrategy": "Create React Testing Library specs that mock the store to cover idle/loading/success states, verify cancel disables the flow, ensure CONTROL PLAY dispatch fires on completion, and confirm metadata persistence calls occur.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:54.837Z"
          },
          {
            "title": "Add ProgressPanel component and UI states",
            "description": "Create ProgressPanel.tsx rendering phase/percent/throughput/eta with cancel and retry; subscribe to upload:* events.",
            "dependencies": [
              2
            ],
            "details": "Mount in DevicePanel; show determinate/indeterminate; disable controls during upload; expose minimal props for reuse.",
            "status": "done",
            "testStrategy": "RTL tests for idle/active/cancelled/error states; snapshot basic rendering.",
            "id": 4,
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:55.652Z"
          },
          {
            "title": "Implement error mapping util for Bake/Upload",
            "description": "Add mapUploadError() to convert backend codes to user guidance and toasts.",
            "dependencies": [
              2
            ],
            "details": "Map NET_*, DEV_*, INT_*, SIZE_*; ensure UI surfaces remediation hints.",
            "status": "done",
            "testStrategy": "Unit tests for mapping table and fallbacks.",
            "id": 5,
            "parentId": "undefined",
            "updatedAt": "2025-10-17T09:35:45.902Z"
          },
          {
            "title": "Persist TTFL and last-bake stats",
            "description": "Save TTFL, sizes, crc to project metadata after success for diagnostics.",
            "dependencies": [
              2
            ],
            "details": "Extend project store save path to include last bake stats; render in UI.",
            "status": "done",
            "testStrategy": "Unit tests verifying persistence and read-back.",
            "id": 6,
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:14:51.829Z"
          },
          {
            "title": "Playwright E2E for Bake→Upload happy path",
            "description": "End-to-end test (fake backend) that runs Bake→Upload and verifies UI progression.",
            "dependencies": [
              2,
              3
            ],
            "details": "Use mocked Tauri events; assert final success and TTFL shown.",
            "status": "done",
            "testStrategy": "Playwright spec with deterministic timings.",
            "id": 7,
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:25:06.864Z"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Add `useUploadStore` (Zustand) to track phase, percent, throughput, timestamps, error, and cancellation. Implement `bakeAndUpload` orchestration that calls evaluator (Task 3), LUT (Task 4), and `packPrism` (Task 5), then invokes Tauri `device_upload` (Task 6), updating progress via store and handling cancel. Mount a primary “Bake & Upload” control in `DevicePanel.tsx` (or `BakePanel.tsx`) with progress UI and TTFL timings; after success, trigger CONTROL PLAY when Task 8 exists. Add component tests stubbing Tauri and asserting progress transitions.",
        "updatedAt": "2025-10-17T10:25:06.864Z"
      },
      {
        "id": 8,
        "title": "Implement Device Playback & Parameter Controls",
        "description": "Support PLAY/STOP and brightness/gamma adjustments per firmware CONTROL subcommands.",
        "details": "Extend Tauri with `device_control_play`, `device_control_stop`, and `device_control_params` that wrap TLV CONTROL messages (type 0x31) with subcommand bytes for play/stop/brightness/gamma as defined in firmware spec. Update `DevicePanel.tsx` to surface buttons/toggles and sliders (0–100% brightness, gamma 1.0–3.0) bound to these commands, reflecting status via websockets or follow-up STATUS calls. Log actions through `lib/logger.ts` and disable controls when no device selected or upload in-flight.\nWireframe refs: Transport controls and device controls per wireframe Devices and Timeline tabs.\n\nAcceptance Checklist (wireframe parity)\n- [ ] PLAY/STOP buttons and shortcuts (mod+P/S) work\n- [ ] Brightness/gamma sliders ramp with 100–150ms throttle\n- [ ] Values clamped and validated before CONTROL",
        "testStrategy": "Add Rust unit tests asserting CONTROL TLV payload layout. Write React tests confirming sliders call the correct Tauri invoke args and that UI disables appropriately when device not connected.\nControls/shortcuts verified against wireframe interactions (labels, focus, ramp semantics).",
        "priority": "medium",
        "dependencies": [
          "6",
          "7"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement TLV control commands in Tauri",
            "description": "Add TLV wrappers for playback and parameter control commands in the Tauri backend.",
            "dependencies": [],
            "details": "Create device_control_play, device_control_stop, and device_control_params that wrap CONTROL type 0x31 messages with firmware-defined subcommand bytes and encode brightness and gamma payloads correctly.",
            "status": "done",
            "testStrategy": "Write Rust unit tests covering TLV payload layouts for play, stop, brightness, and gamma variants.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:56.469Z"
          },
          {
            "id": 2,
            "title": "Add playback and parameter UI controls",
            "description": "Expose playback toggles and parameter sliders in DevicePanel tied to new backend commands.",
            "dependencies": [
              1
            ],
            "details": "Update DevicePanel.tsx to render play/stop buttons and sliders for brightness 0–100% and gamma 1.0–3.0, binding each control to the new Tauri invokes and managing local state for current values.",
            "status": "done",
            "testStrategy": "Add React component tests asserting the correct invoke arguments fire when interacting with buttons and sliders and that controls disable when no device is selected.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:14:52.642Z"
          },
          {
            "id": 3,
            "title": "Integrate status feedback and logging",
            "description": "Handle control state feedback, logging, and disable conditions across the panel.",
            "dependencies": [
              1,
              2
            ],
            "details": "Wire websocket or STATUS polling responses to update control indicators, route user actions through lib/logger.ts, and enforce disabled states during uploads or when no device is active.",
            "status": "done",
            "testStrategy": "Extend component tests or utilities to verify status updates refresh UI, logging is triggered via mocks, and disable rules hold during simulated upload states.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:25:07.695Z"
          },
          {
            "title": "Keyboard shortcuts & a11y tests",
            "description": "Add WCAG-friendly shortcuts (Play/Stop, brightness/gamma adjust) and RTL tests for focus/aria.",
            "dependencies": [
              2
            ],
            "details": "Implement mod+P (play), mod+S (stop), Arrow keys for sliders with proper aria attributes.",
            "status": "done",
            "testStrategy": "RTL tests verify keyboard activation and aria roles.",
            "id": 4,
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:14:53.470Z"
          },
          {
            "title": "Throttled ramp semantics & validation",
            "description": "Throttle brightness/gamma slider updates and validate ranges before CONTROL dispatch.",
            "dependencies": [
              2
            ],
            "details": "100–150ms throttle; clamp values; guard disabled state during uploads.",
            "status": "done",
            "testStrategy": "Unit tests for throttle and clamping; integration verifies fewer CONTROL sends.",
            "id": 5,
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:14:54.310Z"
          },
          {
            "title": "Error mapper + toasts for CONTROL",
            "description": "Map CONTROL errors to friendly messages and surface as toasts/logs.",
            "dependencies": [
              2
            ],
            "details": "Reuse error util; ensure non-fatal STOP errors are informational.",
            "status": "pending",
            "testStrategy": "Unit tests for mapping; RTL checks toasts render.",
            "id": 6,
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Add Tauri commands `device_control_play`, `device_control_stop`, and `device_control_params` that wrap TLV CONTROL (0x31) per firmware subcommands, encoding brightness (0–100%) and gamma (1.0–3.0). Update `DevicePanel.tsx` to render play/stop and sliders bound to invokes, reflect state via STATUS polling or WS responses, and log via `lib/logger.ts`. Add Rust unit tests for CONTROL TLV payloads and React tests asserting correct invoke args and disabled states without a selected device.",
        "updatedAt": "2025-10-17T10:35:11.302Z"
      },
      {
        "id": 9,
        "title": "Surface Upload Progress, Errors, and TTFL Metrics",
        "description": "Deliver actionable progress UI, error mapping, and instrumentation to meet <3 min TTFL.",
        "details": "Augment `DevicePanel` and logger to subscribe to `upload:progress` / `upload:error` events, mapping error codes (CRC mismatch, TLV_CRC_INVALID, DEVICE_ERROR strings) to friendly messages with resolution tips. Record timeline marks (`performance.now()`) for graph bake, packaging, upload, and play commands, displaying latest TTFL and throughput in the UI. Add retry hints for oversized graphs (>256 KB) and highlight when fps defaults down from 120 due to limits.\nWireframe refs: Progress + error display patterns per WIRED_FUNCTIONALITY.md and PRODUCTION_READY_SUMMARY.md.\n\nAcceptance Checklist (wireframe parity)\n- [ ] Telemetry schema covers phases/percent/bytes/s/TTFL\n- [ ] Errors mapped to friendly messages per taxonomy\n- [ ] Optional JSONL export present in logs/",
        "testStrategy": "Add vitest tests for error mapper utility to ensure firmware errors map correctly. Use Playwright to simulate slow uploads (mock progress) validating TTFL metrics render and update. Verify logger receives structured entries.\nTelemetry/alerts presentation aligns with wireframe UI patterns.",
        "priority": "high",
        "dependencies": [
          "7",
          "8"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Instrument upload progress and TTFL timing hooks",
            "description": "Subscribe to upload events and capture timing metrics for bake, package, upload, and play.",
            "dependencies": [],
            "details": "Extend DevicePanel state management to listen for upload:progress and upload:error events, capture performance.now() marks for each upload phase, compute TTFL and throughput, and persist the latest metrics for display/logging.",
            "status": "done",
            "testStrategy": "Write unit tests that mock event emissions to ensure timing metrics and throughput calculations update as expected.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:57.285Z"
          },
          {
            "id": 2,
            "title": "Map firmware error codes to user-facing guidance",
            "description": "Create friendly messages and recovery tips for known upload error codes.",
            "dependencies": [],
            "details": "Implement an error mapping utility covering CRC mismatch, TLV_CRC_INVALID, DEVICE_ERROR variants, and oversized graph cases, providing user copy with resolution tips and retry guidance for >256 KB payloads.",
            "status": "done",
            "testStrategy": "Add vitest coverage verifying each error code yields the correct message, resolution hint, and logger payload.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T09:35:47.390Z"
          },
          {
            "id": 3,
            "title": "Render progress UI with TTFL, throughput, and fallback alerts",
            "description": "Display actionable progress, error, and performance signals in DevicePanel.",
            "dependencies": [
              1,
              2
            ],
            "details": "Update DevicePanel UI to render progress bars, TTFL and throughput metrics, show retry hints for large graphs, and highlight when FPS drops from 120, ensuring structured logs reflect the surfaced state.",
            "status": "done",
            "testStrategy": "Use React component tests to confirm progress UI reacts to mocked state changes and Playwright to validate end-to-end display of TTFL, throughput, and error hints.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:58.124Z"
          },
          {
            "title": "Telemetry types & mappers module",
            "description": "Create telemetry.ts with types for phases, progress payloads, and error taxonomy.",
            "dependencies": [],
            "details": "Exports UploadPhase, UploadProgress, UploadErrorCode and mapping helpers.",
            "status": "pending",
            "testStrategy": "Unit tests for schema and mapping.",
            "id": 4,
            "parentId": "undefined"
          },
          {
            "title": "Wire DevicePanel to telemetry events",
            "description": "Subscribe to telemetry:* and upload:* events; render TTFL/throughput; throttle updates.",
            "dependencies": [
              1
            ],
            "details": "Ensure UI updates at <=10Hz; combine with upload slice.",
            "status": "done",
            "testStrategy": "RTL tests for throttling and correct field rendering.",
            "id": 5,
            "parentId": "undefined",
            "updatedAt": "2025-10-17T08:33:58.933Z"
          },
          {
            "title": "Dashboard hooks & JSONL export",
            "description": "Add optional JSONL log export for soak/CI and dashboard ingestion.",
            "dependencies": [],
            "details": "Append to logs/recent_uploads.jsonl with structured entries.",
            "status": "pending",
            "testStrategy": "Integration test writes JSONL and validates fields.",
            "id": 6,
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Subscribe UI to `upload:progress`/`upload:error` and compute TTFL by marking bake, pack, upload, and play timings using `performance.now()`. Implement an error mapping utility for firmware codes (CRC mismatch, TLV_CRC_INVALID, DEVICE_ERROR variants, oversized payload), reusing semantics from `scripts/upload-pattern.mjs`. Render progress bars, TTFL and throughput, and show retry hints for >256 KB payloads or FPS downshift. Add unit tests for error mapping and component tests simulating slow progress and verifying metrics/log output.",
        "updatedAt": "2025-10-17T10:35:12.142Z"
      },
      {
        "id": 10,
        "title": "Automate Reliability & Performance Validation",
        "description": "Create automated tests to prove 50 consecutive uploads succeed and 120 FPS holds.",
        "details": "Write a soak script in `tools/validation/soak_playlist.ts` (or extend existing `tools/validation/soak_playlist.py`) that drives the Bake & Upload flow via Tauri CLI hooks or Playwright, executing 50 uploads against a loopback device stub verifying CRC at PUT_END. Add vitest performance tests asserting evaluator maintains 120 FPS for 2×160 LEDs (<16.7ms/frame) and integrate metrics into CI. Document manual visual verification steps in `docs/validation/TTFL.md` for hardware-in-loop checks.",
        "testStrategy": "Run soak script in CI nightly with artifacts capturing throughput/TTFL, failing if any CRC mismatch or upload error occurs. Include vitest performance assertions and Playwright regression to confirm fps + TTFL thresholds.",
        "priority": "medium",
        "dependencies": [
          "6",
          "7",
          "8",
          "9"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Build soak upload script for 50-run reliability",
            "description": "Implement an automated soak runner that executes 50 consecutive Bake & Upload cycles against a loopback stub via Tauri CLI or Playwright.",
            "dependencies": [],
            "details": "Create or extend tooling in `tools/validation/soak_playlist.(ts|py)` to orchestrate Bake & Upload workflows, drive the loopback device stub, verify CRC at PUT_END, gather timing metrics, and expose CLI flags for run count and report output.",
            "status": "done",
            "testStrategy": "Execute the soak script locally against the stub ensuring 50 uploads succeed without CRC mismatches, then add it to nightly CI and confirm artifacts capture upload metrics.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:34:44.021Z"
          },
          {
            "id": 2,
            "title": "Implement 120 FPS performance regression tests",
            "description": "Add automated performance checks ensuring evaluator sustains 120 FPS for 2×160 LEDs with <16.7 ms frame times.",
            "dependencies": [],
            "details": "Author vitest performance suites that load representative playlists, benchmark the evaluator for 2×160 LED payloads, assert frame processing stays under the 16.7 ms ceiling, and publish metrics for CI consumption alongside soak results.",
            "status": "done",
            "testStrategy": "Run the new vitest performance suite locally and in CI, failing the build when frame timing exceeds thresholds or metrics are missing.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:34:44.839Z"
          },
          {
            "id": 3,
            "title": "Document manual TTFL hardware verification protocol",
            "description": "Capture human-in-the-loop validation steps for verifying throughput and TTFL on real hardware.",
            "dependencies": [
              1,
              2
            ],
            "details": "Update `docs/validation/TTFL.md` detailing required test rigs, visual inspection checklist, confirmation steps for 50-upload soak results, FPS telemetry expectations, recovery actions, and how to correlate with automated soak/perf logs.",
            "status": "done",
            "testStrategy": "Have a teammate follow the documented procedure on hardware to ensure clarity and complete coverage, incorporating feedback into the document.",
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:34:45.691Z"
          },
          {
            "title": "Mock WebSocket device tool",
            "description": "Implement tools/validation/mock_device_ws.mjs handling TLV and CRC checks.",
            "dependencies": [],
            "details": "Ack PUT_*, enforce offsets, verify CRC on PUT_END; inject errors.",
            "status": "done",
            "testStrategy": "Self-test validating TLV/CRC paths.",
            "id": 4,
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:34:46.528Z"
          },
          {
            "title": "CI artifacts & thresholds",
            "description": "Produce summary.json with TTFL/throughput; fail on thresholds; upload artifacts.",
            "dependencies": [
              1
            ],
            "details": "Integrate with CI; parametrize limits; attach logs and bundles.",
            "status": "pending",
            "testStrategy": "CI job dry run captures artifacts and enforces thresholds.",
            "id": 5,
            "parentId": "undefined"
          },
          {
            "title": "Repro bundle collection",
            "description": "On failure, collect inputs, transcript, env and write to artifacts.",
            "dependencies": [
              1
            ],
            "details": "Zip .prism, chunks, error logs; include device STATUS and env snapshot.",
            "status": "done",
            "testStrategy": "Unit/integration test creates a sample bundle on forced failure.",
            "id": 6,
            "parentId": "undefined",
            "updatedAt": "2025-10-17T10:34:47.405Z"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Create `tools/validation/soak_playlist.ts` (or extend the existing Python soak tooling) to drive 50 Bake & Upload cycles via Playwright or a Tauri CLI hook against a loopback device stub that verifies CRC at PUT_END. Add Vitest performance tests ensuring the evaluator sustains 120 FPS for 2×160 LEDs (<16.7 ms/frame) on representative graphs. Document hardware‑in‑loop TTFL checks in `docs/validation/TTFL.md` with steps, expected telemetry, and recovery actions; wire the soak/perf runs into CI with artifact capture.",
        "updatedAt": "2025-10-17T10:44:15.439Z"
      },
      {
        "id": 11,
        "title": "Integrate Wireframes with Task Plan",
        "description": "Map the new wireframe prototype to tasks, align acceptance criteria, and ensure component/interaction parity across Timeline, Device Manager, and Bake→Upload flows.",
        "details": "Source: User-Facing App Wireframes 3 (local code bundle) and Figma link in README. Produce a traceability matrix linking wireframe screens/components to tasks/subtasks, update acceptance criteria in tasks to reference wireframe states, and flag any gaps as follow-up tasks.",
        "priority": "medium",
        "status": "done",
        "dependencies": [],
        "testStrategy": "Traceability matrix present; reviewers can click from each task to the corresponding wireframe section. Acceptance criteria updated to reference specific screen states. All gaps are captured as subtasks or new tasks.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create traceability matrix",
            "description": "List wireframe screens/components and map to tasks/subtasks (2,3,6,7,8,9,10).",
            "dependencies": [],
            "details": "Include paths: User-Facing App Wireframes 3/src/App.tsx, components/prism/*. Reference Figma URL in README.",
            "status": "pending",
            "testStrategy": "Matrix reviewed and approved; links open relevant files/IDs.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update acceptance criteria with wireframe references",
            "description": "For tasks 2,6,7,8,9, update acceptance to cite wireframe screen states (Timeline, Devices, Progress).",
            "dependencies": [
              1
            ],
            "details": "Add references like “matches TimelineEditorScreen state A/B/C” and specific UI interactions.",
            "status": "pending",
            "testStrategy": "Spot-check tasks show explicit references to screens; QA can verify visually.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Component inventory and design tokens alignment",
            "description": "Inventory wireframe components (Radix UI set) and align with Studio components/tokens.",
            "dependencies": [
              1
            ],
            "details": "List Accordion/Dialog/Slider/Select/Progress; confirm usage and theming match existing tokens.",
            "status": "pending",
            "testStrategy": "Checklist done; any missing components are added as follow-up tasks.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Interaction parity checklist",
            "description": "Document keyboard shortcuts, drag behaviors, and progress states from wireframes and ensure they appear in tasks 2/7/8/9.",
            "dependencies": [
              1
            ],
            "details": "Capture Timeline scrubbing, zoom, device add/remove, progress cancel/retry, auto-play.",
            "status": "pending",
            "testStrategy": "Checklist linked in tasks; QA can validate against wireframe behavior.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-10-17T10:34:48.256Z"
      },
      {
        "id": 12,
        "title": "Define Protocol Source of Truth and Pin SHAs",
        "description": "Create a single-page index documenting the authoritative protocol artifacts and pin immutable links (commit SHAs) to firmware protocol files and app ADR-009 packer. Update firmware and app entry points with back-links.",
        "details": "Scope and deliverables:\n- Author a single-page index at `docs/protocol/source-of-truth.md` enumerating authoritative protocol artifacts with permalinks pinned to specific commit SHAs:\n  - Firmware protocol parser public API and implementation: `firmware/components/network/include/protocol_parser.h`, `firmware/components/network/protocol_parser.c`\n  - Firmware configuration constants: `firmware/components/core/include/prism_config.h`\n  - App-side ADR-009 packer: `studio/src/lib/bake/packPrism.ts`\n  - Upload script reference for TLV types and CRC usage: `studio/scripts/upload-pattern.mjs`\n  - Optional: Mention `tools/validation/mock_ws_device.ts` and `tools/validation/soak_playlist.ts` as test oracles for frame layout and CRC.\n- Include a brief rationale on why each file is canonical (e.g., `prism_config.h` is generated from CANON and sets `LED_FPS_TARGET`, `PATTERN_MAX_SIZE`; `protocol_parser.[ch]` defines TLV framing and handlers; `packPrism.ts` implements ADR-009 header and CRC parity).\n- Document the minimal TLV and file format contract:\n  - TLV frame: `[TYPE:1][LENGTH:2 big-endian][PAYLOAD:N][CRC32:4 big-endian]` as implemented in `protocol_parser.c` (see `parse_tlv_frame` and `send_tlv_response`).\n  - Message types used by app tooling: PUT_BEGIN `0x10`, PUT_DATA `0x11`, PUT_END `0x12`, CONTROL `0x20`, STATUS `0x30`, ERROR `0x40`/`0xFF` (see `studio/scripts/upload-pattern.mjs` and `protocol_parser.h`).\n  - ADR-009 header parity and size cap (64-byte header, 256KB max) in `packPrism.ts` (`PATTERN_MAX_SIZE` should match firmware `prism_config.h`/`protocol_parser.h`).\n- Add a “Pinning policy” section describing:\n  - Use immutable permalinks in the index: `https://github.com/<org>/<repo>/blob/<SHA>/<path>` (or monorepo internal permalink pattern).\n  - When underlying files change, bump SHAs and update the changelog section within the index.\n  - Define owners and review gates (CODEOWNERS-style note) for protocol-affecting changes.\n- Add a “Cross-repo references” section with copy-pastable links for both audiences (firmware engineers, app/studio engineers) and anchors to sections (e.g., `#tlv-wire-format`, `#adr-009-header`).\n- Update entry points with back-links to the index:\n  - Insert a short “Protocol SoT” link in `firmware/README.md` (WebSocket Protocol section) pointing to `docs/protocol/source-of-truth.md#tlv-wire-format` and `#control-and-status`.\n  - Add header comment link in `studio/scripts/upload-pattern.mjs` and `studio/src/lib/bake/packPrism.ts` to the same index sections (wire format, ADR-009 header, size limits), so developers land on the SoT from code.\n- Add a small helper script `tools/docs/pin_protocol_links.ts` (or `.py`) that:\n  - Reads current HEAD SHA via `git rev-parse HEAD`.\n  - Generates/update a Markdown block in `docs/protocol/source-of-truth.md` with pinned permalinks for the four artifacts above.\n  - Optionally supports `--sha <commit>` to pin a release tag’s commit.\n- Add CI check to prevent drift:\n  - A job that runs `git cat-file -e <sha>:<path>` for each pinned link to ensure the referenced files exist at the pinned SHA.\n  - Fails if any path/sha combo is invalid or if `PATTERN_MAX_SIZE` differs between firmware header and app packer (simple grep and compare: `262144`).\n\nImplementation notes aligned to this repo:\n- Firmware references:\n  - Protocol API: `firmware/components/network/include/protocol_parser.h` (message types, limits, public API).\n  - Implementation: `firmware/components/network/protocol_parser.c` (`parse_tlv_frame`, CRC checks via `esp_rom_crc32_le`, handlers for PUT_* / CONTROL / STATUS, size cap, timeout enforcement).\n  - Config: `firmware/components/core/include/prism_config.h` (generated from CANON; includes `LED_FPS_TARGET`, `PATTERN_MAX_SIZE`, WS settings).\n- App references:\n  - ADR-009 packer: `studio/src/lib/bake/packPrism.ts` (ADR-009 header comment, size guard, CRC32 table implementation, palette block layout).\n  - Upload script: `studio/scripts/upload-pattern.mjs` (TLV constants, CRC-32, PUT_* / CONTROL flow, STATUS/ERROR handling) as a readable contract exemplar.\n- Best practices to capture in the doc:\n  - Always big-endian LENGTH and CRC in TLV frames; CRC covers TYPE+LENGTH+PAYLOAD (matches `protocol_parser.c`).\n  - Use IEEE CRC-32 poly 0xEDB88320 and ensure app and firmware parity (packer uses same polynomial; firmware uses `esp_rom_crc32_le`).\n  - Enforce single active upload session; PUT_END must validate CRC over the full buffer before persisting (as implemented).\n  - Keep `PATTERN_MAX_SIZE`/header parity consistent across firmware and app. Add a doc snippet on how to grep-verify values across both sides.\n  - Prefer immutable links for specs and code references; avoid linking to `main` to prevent drift in external docs and client implementations.\n",
        "testStrategy": "Verification checklist and commands:\n- Documentation presence and content\n  - `docs/protocol/source-of-truth.md` exists and includes sections: TLV wire format, ADR-009 header, size limits, pinning policy, cross-repo references, owners.\n  - Contains pinned permalinks for:\n    - `firmware/components/network/include/protocol_parser.h`\n    - `firmware/components/network/protocol_parser.c`\n    - `firmware/components/core/include/prism_config.h`\n    - `studio/src/lib/bake/packPrism.ts`\n  - Links use immutable SHAs (not branches). If offline, review the generated URLs for correct shape.\n- Entry-point back-links\n  - `firmware/README.md` WebSocket Protocol section includes a link to `docs/protocol/source-of-truth.md#tlv-wire-format` (open the file and confirm anchor text).\n  - `studio/src/lib/bake/packPrism.ts` top comment includes a link to `#adr-009-header` in the index.\n  - `studio/scripts/upload-pattern.mjs` header includes a link to `#tlv-wire-format` and `#control-and-status` in the index.\n- Consistency checks (local, no network required)\n  - Run a small script or manual commands to verify definitions:\n    - Confirm `PATTERN_MAX_SIZE` is `262144` in both `protocol_parser.h` and `packPrism.ts`:\n      - `rg -n \"PATTERN_MAX_SIZE\" firmware/components/network/include/protocol_parser.h`\n      - `rg -n \"262144|PATTERN_MAX_SIZE\" studio/src/lib/bake/packPrism.ts`\n    - Confirm TLV constants alignment between `upload-pattern.mjs` and `protocol_parser.h` (0x10, 0x11, 0x12, 0x20, 0x30, error type):\n      - `rg -n \"TLV_TYPE_|MSG_TYPE_\" studio/scripts/upload-pattern.mjs firmware/components/network/include/protocol_parser.h`\n  - If CI is available, add a job step to validate pinned SHAs refer to existing files using `git cat-file -e <sha>:<path>` per link block extracted from the index.\n- Reviewer acceptance\n  - Open the index and verify the rationale accurately reflects current code semantics:\n    - CRC coverage and endianness match `parse_tlv_frame` in `protocol_parser.c`.\n    - Size caps and ADR-009 header parity match `packPrism.ts` and `prism_config.h`.\n  - Confirm both firmware and app teams can navigate from their entry files to the index via the new links.",
        "status": "done",
        "dependencies": [
          "5"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Author Protocol SoT page with TLV/ADR-009/limits sections and anchors",
            "description": "Create docs/protocol/source-of-truth.md containing required sections, rationales per artifact, and named anchors.",
            "dependencies": [],
            "details": "Draft the single-page index with sections: TLV wire format, ADR-009 header, size limits, rationale per artifact, and placeholders for a pinned permalinks block. Include anchors #tlv-wire-format, #adr-009-header, and #control-and-status. Mention canonical files and CRC/payload rules.",
            "status": "pending",
            "testStrategy": "Open the Markdown file and verify required sections and anchors exist; run a markdown preview to ensure anchors navigate correctly.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement pin_protocol_links tool to generate pinned permalinks block",
            "description": "Create tools/docs/pin_protocol_links.(ts|py) to insert immutable links pinned to a commit SHA.",
            "dependencies": [
              1
            ],
            "details": "Script reads git rev-parse HEAD (or --sha override) and regenerates a delimited Markdown block listing permalinks for protocol_parser.h, protocol_parser.c, prism_config.h, and packPrism.ts. Idempotent updates between markers and supports custom permalink base if needed.",
            "status": "pending",
            "testStrategy": "Run the tool locally without args (uses HEAD) and with --sha <commit>; confirm the Markdown block updates deterministically and contains four expected links.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Populate pinned permalinks in SoT using current HEAD",
            "description": "Run the pin tool to add the pinned links block to the SoT document.",
            "dependencies": [
              2
            ],
            "details": "Execute the pinning script to write the permalinks block into docs/protocol/source-of-truth.md using current HEAD. Ensure each entry includes blob/<SHA>/<path> and a short label. Add a small updated-at note beneath the block.",
            "status": "pending",
            "testStrategy": "Use git cat-file -e <sha>:<path> for each pinned link to verify existence; visually inspect the block for correct paths and SHA.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add back-links in firmware README and Studio entry points",
            "description": "Insert SoT links in firmware/README.md and header comments in Studio files pointing to SoT anchors.",
            "dependencies": [
              1
            ],
            "details": "In firmware/README.md WebSocket Protocol section, add a short 'Protocol SoT' link to #tlv-wire-format and #control-and-status. In studio/scripts/upload-pattern.mjs and studio/src/lib/bake/packPrism.ts, add header comments linking to the SoT (wire format, ADR-009 header, and size limits).",
            "status": "pending",
            "testStrategy": "Open each file and verify links are present and correctly formatted; click anchors in preview to ensure they resolve to the expected sections.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Document pinning policy, cross-repo references, and owners",
            "description": "Expand SoT with pinning policy, cross-repo links, and CODEOWNERS-style review guidance.",
            "dependencies": [
              1
            ],
            "details": "Add a 'Pinning policy' section describing immutable permalinks, SHA bump workflow, and changelog updates. Add 'Cross-repo references' with copy-paste links for firmware and Studio audiences. Define owners and review gates for protocol-affecting changes.",
            "status": "pending",
            "testStrategy": "Review the section text for completeness; verify example links are valid paths in the repo; ensure anchors and headings render as expected.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Add CI validation for pinned links and PATTERN_MAX_SIZE parity",
            "description": "Create a CI job that checks pinned links resolve and enforces size cap consistency.",
            "dependencies": [
              2,
              4
            ],
            "details": "Implement a small script to parse the pinned links block, run git cat-file -e <sha>:<path> for each, and compare PATTERN_MAX_SIZE (expect 262144) between firmware header and packPrism.ts via rg/grep. Wire into CI to run on pushes and PRs, failing on drift.",
            "status": "pending",
            "testStrategy": "Run the script locally with a deliberately bad SHA and with a mismatched constant to confirm failures; push a branch to observe CI job failure, then fix and re-run to pass.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Finalize verification and add developer guidance for maintenance",
            "description": "Provide usage notes and perform an end-to-end check of links, anchors, and CI behavior.",
            "dependencies": [
              3,
              4,
              5,
              6
            ],
            "details": "Add brief instructions in the SoT and/or README on running the pin tool, bumping SHAs, and interpreting CI failures. Perform a final pass to confirm anchors work, links are immutable, back-links exist, and the CI check passes with current HEAD.",
            "status": "pending",
            "testStrategy": "Follow the documented steps to rotate to a test SHA, re-pin, run validation locally, and ensure CI passes after reverting to the intended SHA.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Create docs/protocol/source-of-truth.md with sections TLV wire format, ADR-009 header, size limits, pinning policy, cross-repo references, owners; add pinned permalinks for firmware/components/network/include/protocol_parser.h, firmware/components/network/protocol_parser.c, firmware/components/core/include/prism_config.h, studio/src/lib/bake/packPrism.ts using current HEAD SHA; add backlink in firmware/README.md WebSocket Protocol and header comments in studio/scripts/upload-pattern.mjs and studio/src/lib/bake/packPrism.ts; implement tools/docs/pin_protocol_links.(ts|py) to read git rev-parse HEAD (or --sha) and regenerate a Markdown block of pinned links; add a CI script that parses pinned links and runs git cat-file -e <sha>:<path> and verifies PATTERN_MAX_SIZE (262144) parity via rg across firmware header and packPrism.ts; document rationale per artifact and anchors (#tlv-wire-format, #adr-009-header, #control-and-status).",
        "updatedAt": "2025-10-17T11:44:44.316Z"
      },
      {
        "id": 13,
        "title": "Confirm CONTROL TLV spec and align Studio + firmware",
        "description": "Define the authoritative CONTROL TLV message type and subcommands with exact payload bytes and value ranges, then align firmware parser, Tauri commands, UI clamps, and error taxonomy across Studio and firmware.",
        "details": "Authoritative spec (based on current code):\n- TLV frame: [TYPE:1][LENGTH:2 BE][PAYLOAD:N][CRC32:4 BE]. Build helpers: studio/src-tauri/src/lib.rs:tlv_request and firmware/components/network/protocol_parser.c:send_tlv_response.\n- CONTROL TYPE: 0x20 (not 0x31). Declared in firmware/components/network/include/protocol_parser.h:MSG_TYPE_CONTROL and used in studio/src-tauri/src/lib.rs:device_control_*.\n- Subcommands and payloads (exact bytes):\n  - PLAY 0x01: [0x01][name_len:1][name:name_len]. Implemented in firmware/components/network/protocol_parser.c#L664-L707 and studio/src-tauri/src/lib.rs:564.\n  - STOP 0x02: [0x02]. Implemented in firmware/components/network/protocol_parser.c#L718-L726 and studio/src-tauri/src/lib.rs:575.\n  - BRIGHTNESS 0x10: [0x10][target:U8 0..255][duration_ms:U16 BE]. Implemented in firmware/components/network/protocol_parser.c#L727-L746 and studio/src-tauri/src/lib.rs:582. UI currently clamps to 0..255 and sends durationMs.\n  - GAMMA 0x11: [0x11][gamma_x100:U16 BE][duration_ms:U16 BE]. Implemented in firmware/components/network/protocol_parser.c#L785-L804 (case 0x11) and studio/src-tauri/src/lib.rs:591. Define CONTROL_CMD_GAMMA = 0x11 in header for clarity.\n- Ranges to standardize:\n  - Brightness: 0..255 (firmware expects U8). Update any 0–100% UI displays to scale internally but transmit 0..255.\n  - Gamma: gamma_x100: 50..500 recommended (UI already clamps in studio/src/features/devices/DevicePanel.tsx:328). Document UI display (0.50–5.00) while transmitting x100 integer.\n\nChanges to implement:\n1) Firmware constants and comments\n- Add CONTROL_CMD_GAMMA macro next to other CONTROL_CMD_* (protocol_parser.c) and replace literal 0x11 switch label for consistency.\n- In firmware/components/network/include/protocol_parser.h, add control subcommand section with byte-accurate payload docs for PLAY/STOP/BRIGHTNESS/GAMMA; keep TYPE 0x20.\n- In protocol_parser.c handle_control():\n  - Validate BRIGHTNESS: enforce target in [0,255]; return ERR_INVALID_FRAME if out-of-range.\n  - Validate GAMMA: enforce gamma_x100 in [50,500]; return ERR_INVALID_FRAME if out-of-range.\n  - Ensure both AT MOST 4/5 byte payload lengths as currently coded; keep BE parsing.\n\n2) Studio (Tauri + UI)\n- Confirm Tauri uses TYPE 0x20 (already correct in studio/src-tauri/src/lib.rs) and BE encoding for u16 fields (already correct).\n- Normalize DevicePanel slider semantics:\n  - Brightness slider to show 0–100% but convert to 0..255 when invoking; current code already clamps to 0..255 (line 325). Ensure UI label reflects 0–100% mapping.\n  - Gamma slider to show 0.50–5.00 (or 1.00–3.00 if product insists); transmit 50..500 with clamp [50,500]. Current code clamps 50..500 (line 328). Update any mismatched labels/tooltips.\n\n3) Error taxonomy alignment\n- Firmware error codes (protocol_parser.h):\n  - 0x01 ERR_INVALID_FRAME, 0x02 ERR_CRC_MISMATCH, 0x03 ERR_SIZE_EXCEEDED, 0x04 ERR_STORAGE_FULL, 0x05 ERR_NOT_FOUND.\n- Firmware ERROR frame payload: [code:U8][utf8_message?]. Studio currently treats MSG_TYPE_ERROR as DEVICE_ERROR string. Update mapper to parse leading code byte when present and map to friendly messages, while retaining text fallback.\n  - Update studio/src/lib/uploadErrors.ts to handle:\n    - TLV_TOO_SHORT/TLV_LENGTH_MISMATCH/TLV_CRC_INVALID (already present).\n    - DEVICE_ERROR with code 0x05 → “Pattern not found”, 0x04 → “Device storage full”, 0x03 → “Pattern exceeds 256 KB limit”, 0x02 → “CRC mismatch”, 0x01 → “Invalid command or payload”. If only string is present, show it.\n- Ensure tauri tlv_request returns DEVICE_ERROR: <text> on MSG_TYPE_ERROR; consider returning DEVICE_ERROR:<code>:<text> for structured mapping, or decode in Rust and surface canonical error IDs.\n\n4) Documentation\n- Add/extend docs at docs/protocol/source-of-truth.md (Task 12 artifact) with CONTROL type and subcommands table, including byte-exact payloads, ranges, and examples. If Task 12 is pending, still prepare the section and link file paths:\n  - Firmware: firmware/components/network/include/protocol_parser.h, firmware/components/network/protocol_parser.c:handle_control.\n  - App: studio/src-tauri/src/lib.rs device_control_*, studio/src/features/devices/DevicePanel.tsx.\n- Include error taxonomy table (code → meaning → Studio message).\n\n5) Optional cleanup\n- Rename literal case 0x11 in firmware to CONTROL_CMD_GAMMA for parity with BRIGHTNESS.\n- Add unit-level bounds checks where missing; keep error messages concise to fit TLV payload limits.\n\nExamples (wire format):\n- PLAY “baked”: 0x20 00 07  01 05 62 61 6b 65 64  [crc]\n- STOP: 0x20 00 01  02  [crc]\n- BRIGHTNESS 128 over 150ms: 0x20 00 04  10 80 00 96  [crc]\n- GAMMA 2.20 over 150ms: 0x20 00 05  11 00 DC 00 96  [crc]\n\nFiles to touch:\n- firmware/components/network/include/protocol_parser.h (doc comments for CONTROL + error code table)\n- firmware/components/network/protocol_parser.c (CONTROL_CMD_GAMMA macro; bounds validation; comment corrections)\n- studio/src/lib/uploadErrors.ts (parse DEVICE_ERROR codes; map to friendly text)\n- docs/protocol/source-of-truth.md (add CONTROL section and error taxonomy; pin line references to current files)\n",
        "testStrategy": "Firmware\n- Add Unity tests in firmware/components/network/test/test_protocol_parser.c:\n  - CONTROL PLAY encodes name_len-matched payload; returns STATUS 0x30 success with echoed name; NOT_FOUND maps to ERR_NOT_FOUND (0x05).\n  - CONTROL STOP returns STATUS 0x30 0x00.\n  - CONTROL BRIGHTNESS rejects payload len != 4 and out-of-range target (<0 or >255) and returns ERROR with ERR_INVALID_FRAME (0x01); accepts 0 and 255; verifies duration parsing (BE) by asserting formatted response message.\n  - CONTROL GAMMA rejects payload len != 5 and out-of-range gamma_x100 (<50 or >500); accepts 220; verifies duration parsing.\n  - Verify MSG_TYPE_CONTROL remains 0x20 via frame.type assertions.\n\nStudio (Rust)\n- Add unit tests in studio/src-tauri/src/lib.rs (tokio tests with local WS echo server) to assert built payloads for device_control_play/stop/brightness/gamma contain:\n  - TYPE 0x20, LENGTH matching payload, u16 BE ordering, and expected command byte.\n  - For brightness 128/150ms and gamma_x100=220/150ms, inspect sent binary frame prior to CRC and assert payload contents.\n\nUI (React)\n- In studio/src/features/devices/DevicePanel.test.tsx:\n  - Brightness slider: simulate drag 0%, 50%, 100% and assert invokes 0, 128, 255 respectively with durationMs=150.\n  - Gamma slider: simulate 1.00, 2.20, 5.00 (or chosen max) and assert invokes 100, 220, 500 respectively with durationMs=150.\n  - Ensure controls disabled when no device selected.\n\nError mapping\n- Add vitest tests for studio/src/lib/uploadErrors.ts to map:\n  - DEVICE_ERROR payloads with code bytes 0x01..0x05 to canonical messages.\n  - Fallback string-only DEVICE_ERROR messages.\n  - Existing TLV_* errors remain mapped as before.\n\nDocs\n- Lint docs/protocol/source-of-truth.md includes: CONTROL type=0x20; PLAY/STOP/BRIGHTNESS(0x10)/GAMMA(0x11) tables; ranges; examples; error code table. Reviewer can cross-check against file references provided.",
        "status": "in-progress",
        "dependencies": [
          "8",
          "9",
          "12"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Document CONTROL (0x20) and subcommands in firmware header",
            "description": "Add authoritative byte-accurate docs for CONTROL TLV and error codes in protocol_parser.h.",
            "dependencies": [],
            "details": "In firmware/components/network/include/protocol_parser.h, add a CONTROL (0x20) section documenting PLAY (0x01), STOP (0x02), BRIGHTNESS (0x10: [cmd,u8,duration U16 BE]) and GAMMA (0x11: [cmd,u16 BE,duration U16 BE]) payloads, value ranges, and examples. Include an error code table (0x01..0x05) with brief meanings.",
            "status": "pending",
            "testStrategy": "Peer review plus consistency check: verify comments match protocol_parser.c switch cases and Studio builders via grep and example bytes.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Introduce CONTROL_CMD_GAMMA macro and replace literal 0x11",
            "description": "Create macro for GAMMA command and use it consistently in protocol_parser.c.",
            "dependencies": [
              1
            ],
            "details": "Define CONTROL_CMD_GAMMA 0x11 alongside other CONTROL_CMD_* in protocol_parser.c (or shared header if applicable) and replace the hardcoded case 0x11 in handle_control() to improve clarity and parity with other subcommands.",
            "status": "pending",
            "testStrategy": "Build/compile and grep to confirm no remaining literal 0x11 cases in control switch; logic should remain unchanged.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add BRIGHTNESS and GAMMA bounds validation in handle_control()",
            "description": "Enforce payload ranges and length checks; return ERR_INVALID_FRAME on violations.",
            "dependencies": [
              2
            ],
            "details": "In firmware/components/network/protocol_parser.c handle_control(), validate BRIGHTNESS target is [0..255] and GAMMA gamma_x100 is [50..500]. Keep big-endian parsing and ensure payload lengths are exactly as expected (4 or 5 bytes). On violation, return ERR_INVALID_FRAME and avoid side effects.",
            "status": "pending",
            "testStrategy": "Add/extend Unity tests to assert out-of-range payloads are rejected with ERR_INVALID_FRAME; verify valid edge cases pass.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Standardize Tauri error propagation for MSG_TYPE_ERROR",
            "description": "Ensure tlv_request decodes or forwards error code and text consistently for Studio mapping.",
            "dependencies": [
              1
            ],
            "details": "In studio/src-tauri/src/lib.rs, confirm MSG_TYPE_ERROR (0xFF) handling: either decode [code:U8][text?] and return a canonical error ID+message, or return a structured string (e.g., DEVICE_ERROR:<code>:<text>). Preserve backward-compatible text fallback.",
            "status": "pending",
            "testStrategy": "Rust unit test: simulate an ERROR frame payload with code and text, assert tlv_request returns structured output or decoded error ID as intended.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Extend Studio error mapper to parse DEVICE_ERROR codes",
            "description": "Update uploadErrors.ts to map firmware error codes to friendly messages with string fallback.",
            "dependencies": [
              4,
              1
            ],
            "details": "In studio/src/lib/uploadErrors.ts, parse the leading code byte when present for MSG_TYPE_ERROR and map: 0x05→\"Pattern not found\", 0x04→\"Device storage full\", 0x03→\"Pattern exceeds 256 KB limit\", 0x02→\"CRC mismatch\", 0x01→\"Invalid command or payload\". Fall back to provided text if no code is present.",
            "status": "pending",
            "testStrategy": "TS unit tests: feed representative payloads/strings into the mapper; assert friendly messages match mapping and fallback behavior works.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Verify CONTROL builders in Tauri and add unit tests",
            "description": "Confirm TYPE 0x20 and BE packing for u16 fields; add tests for payload bytes.",
            "dependencies": [
              1
            ],
            "details": "Review studio/src-tauri/src/lib.rs device_control_* to ensure CONTROL type is 0x20 and u16 fields are big-endian. Add Rust tests covering PLAY, STOP, BRIGHTNESS, and GAMMA payload construction with exact byte assertions.",
            "status": "pending",
            "testStrategy": "Rust tests (tokio or standard): build frames and assert type, length, and payload bytes match the documented spec.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Align DevicePanel sliders and labels with wire ranges",
            "description": "Reflect 0–100%→0..255 for brightness and 0.50–5.00→50..500 for gamma in UI text.",
            "dependencies": [
              6
            ],
            "details": "In studio/src/features/devices/DevicePanel.tsx, ensure brightness label/tooltips explain 0–100% UI maps to 0..255 on wire, and gamma label/tooltips show 0.50–5.00 mapped to x100 integers. Confirm clamps remain [0..255] and [50..500] before invoking Tauri.",
            "status": "pending",
            "testStrategy": "React tests: render slider UI, verify labels/tooltips, and check conversion helpers produce 255 from 100% and 220 from 2.20 gamma.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Add firmware Unity tests for CONTROL payloads and validation",
            "description": "Create or extend tests covering PLAY/STOP/BRIGHTNESS/GAMMA including range enforcement.",
            "dependencies": [
              3
            ],
            "details": "In firmware/components/network/test/test_protocol_parser.c, add tests: PLAY validates name_len, STOP baseline success, BRIGHTNESS accepts 0 and 255 and rejects out-of-range, GAMMA accepts 50 and 500 and rejects out-of-range. Ensure CRC and payload lengths are respected.",
            "status": "pending",
            "testStrategy": "Unity-based unit tests invoking handle_control() via framed inputs; assert return codes and state changes for valid cases and error codes for invalid ones.",
            "parentId": "undefined"
          },
          {
            "id": 9,
            "title": "Update protocol source-of-truth with CONTROL and errors",
            "description": "Expand docs/protocol/source-of-truth.md with CONTROL details, examples, and error taxonomy.",
            "dependencies": [
              1,
              3,
              4,
              5,
              6,
              8
            ],
            "details": "Add a CONTROL section: type 0x20, subcommand table with byte-accurate payloads, ranges, and worked wire examples. Include an error taxonomy table mapping code→meaning→Studio message, and reference file locations (firmware header/C implementation and Studio files).",
            "status": "pending",
            "testStrategy": "Documentation review checklist: verify examples compile to exact hex sequences shown and cross-reference file paths exist.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 9,
        "expansionPrompt": "Update firmware header firmware/components/network/include/protocol_parser.h to document CONTROL type 0x20 and subcommands with byte-accurate payloads (PLAY 0x01, STOP 0x02, BRIGHTNESS 0x10: [cmd,u8,durBE], GAMMA 0x11: [cmd,u16BE,durBE]) and error code table; in firmware/components/network/protocol_parser.c add CONTROL_CMD_GAMMA macro and replace literal case 0x11, add bounds checks (brightness 0..255, gamma_x100 50..500) returning ERR_INVALID_FRAME on violation; keep big-endian parsing; confirm Studio Tauri builders in studio/src-tauri/src/lib.rs use type 0x20 and BE fields (they do), adjust labels/tooltips in studio/src/features/devices/DevicePanel.tsx to reflect 0–100% → 0..255 and 0.50–5.00 → 50..500; extend studio/src/lib/uploadErrors.ts to parse MSG_TYPE_ERROR (0xFF) payload code byte and map {0x05:\"Pattern not found\",0x04:\"Device storage full\",0x03:\"Pattern exceeds 256 KB\",0x02:\"CRC mismatch\",0x01:\"Invalid command/payload\"} with string fallback; add tests: firmware Unity for PLAY/STOP/BRIGHTNESS/GAMMA payload/validation, Rust tokio tests for CONTROL payload packing, React tests for slider clamps; document CONTROL and error taxonomy tables in docs/protocol/source-of-truth.md with examples and file references.",
        "updatedAt": "2025-10-17T11:44:46.634Z"
      },
      {
        "id": 14,
        "title": "Confirm PUT_END CRC semantics and align app/firmware + tests",
        "description": "Establish the authoritative semantics for PUT_END payload (empty vs includes CRC), update both Studio uploader and firmware to match, and add end-to-end acceptance tests to prove behavior including CRC-mismatch handling.",
        "details": "Current implementation analysis (codebase):\n- TLV framing (Studio): studio/src-tauri/src/lib.rs:599 builds frames as [TYPE:1][LEN:2 BE][PAYLOAD:N][CRC32:4 BE] via crc32fast (IEEE). PUT_END is sent with an empty payload: studio/src-tauri/src/lib.rs:537-541.\n- TLV parsing + CRC (Firmware): firmware/components/network/protocol_parser.c:124-208 validates frame CRC using esp_rom_crc32_le over TYPE+LEN+PAYLOAD.\n- Upload state machine (Firmware):\n  - PUT_BEGIN stores expected_size and expected_crc (from payload) and allocates buffer: firmware/components/network/protocol_parser.c:374-418.\n  - PUT_DATA writes chunks and accumulates CRC for streaming; PUT_END recalculates CRC over the entire buffer and compares to expected_crc: firmware/components/network/protocol_parser.c:537-760. Tests cover “PUT_END validates CRC” and “rejects incomplete upload”: firmware/components/network/test/test_protocol_parser.c:360-420.\n- Message type constants: firmware/components/network/include/protocol_parser.h:47-49 (comments currently say PUT_END: {success}).\n- Studio uploader flow uses empty payload for PUT_END and relies on firmware CRC validation at end: studio/src-tauri/src/lib.rs:420-541.\n\nDecision and required alignment (authoritative spec):\n- PUT_END payload is EMPTY. No CRC bytes are included in PUT_END. The single source of truth is: CRC is provided once in PUT_BEGIN payload; firmware must validate on PUT_END by recomputing CRC over the received buffer and comparing to the PUT_BEGIN CRC.\n\nImplementation steps:\n1) Protocol spec clarifications in code\n- Update protocol header comments to explicitly define payloads:\n  - firmware/components/network/include/protocol_parser.h:\n    - MSG_TYPE_PUT_BEGIN 0x10: {name_len:1, name:name_len, size:U32 BE, crc32:U32 BE}\n    - MSG_TYPE_PUT_DATA 0x11: {offset:U32 BE, data:N}\n    - MSG_TYPE_PUT_END  0x12: {} (empty). CRC validation occurs here against PUT_BEGIN.crc32.\n- Add a note in firmware/components/network/protocol_parser.c above handle_put_end documenting the validation algorithm and that out-of-order chunks are supported by full-buffer CRC on end.\n- In Studio, add a brief docstring near upload_with_emitter confirming PUT_END is empty and CRC is only supplied in PUT_BEGIN: studio/src-tauri/src/lib.rs:420.\n\n2) Studio uploader hardening\n- Keep PUT_END payload as empty (already correct); add a unit test that constructs a fake upload and asserts the frame for 0x12 has LEN=0 and no payload before CRC (reuse build_tlv_frame): studio/src-tauri/src/lib.rs:703 ff test scaffolding shows a local WS server harness; extend it to assert the received PUT_END frame header has 0 length.\n- Add an error mapping for firmware’s CRC failure if not already covered: studio/src/lib/uploadErrors.ts — map strings containing \"CRC\" or specific status such as TLV_CRC_INVALID/ERR_INVALID_CRC to “Upload failed: CRC mismatch. Your baked bytes were altered in transit.”\n\n3) Firmware behavior tightening (only if needed)\n- Ensure handle_put_end rejects any non-empty payload (defensive check) with ERR_INVALID_FRAME and a STATUS error response. If payload length is not zero, return ESP_ERR_INVALID_ARG and send error TLV via send_error_response. This locks in the empty-payload contract.\n- Confirm existing tests cover CRC mismatch and incomplete upload; add a focused unit test where PUT_BEGIN declares a CRC different from the sent bytes and PUT_END returns ESP_ERR_INVALID_CRC (mirrors existing Integration/validation but asserts the specific code): add to firmware/components/network/test/test_protocol_parser.c next to PUT_END tests.\n\n4) Acceptance tests (end-to-end)\n- Studio-side integration test (Rust async test using tungstenite mock server) is already scaffolded: studio/src-tauri/src/lib.rs:703-755. Add two new tests:\n  - Test: Full flow with PUT_END empty payload. The mock server inspects the third frame and asserts TLV length field is 0 for TYPE 0x12, then responds with STATUS ack. Expect upload:progress phases include \"finalizing\" and \"done\".\n  - Test: CRC mismatch path. Mock server accepts PUT_BEGIN and PUT_DATA, but when client sends PUT_END, respond with a TLV error frame indicating CRC mismatch (or close). Verify that uploadWithEmitter surfaces an error string that triggers the mapped CRC error message.\n- Firmware Unity tests:\n  - Add test \"Upload - CRC mismatch on PUT_END\" that: PUT_BEGIN(size=N, crc=bad), PUT_DATA with N bytes, PUT_END; expect ESP_ERR_INVALID_CRC and session reset. Reuse esp_rom_crc32_le to generate mismatched CRC.\n\n5) Documentation touchpoint\n- In docs/protocol/source-of-truth.md (created by Task 12), add/adjust the Upload section to explicitly state PUT_END has empty payload and references to the exact files/lines above. If Task 12 is not yet merged, include an inline TODO tag here and open a follow-up to update the doc once Task 12 lands.\n\nBest practices incorporated:\n- Single point for CRC materiality (PUT_BEGIN declaration, validated on PUT_END), avoiding duplicated CRC fields.\n- BE fields for size/offset consistent across Studio and Firmware.\n- Tests assert contracts at frame level, not just behavioral outcomes.\n- Defensive parsing rejecting unexpected payloads to prevent ambiguity.\n",
        "testStrategy": "Studio (Rust/Tauri):\n- Unit: Add a test that calls build_tlv_frame(0x12, &[]) and decodes it locally to assert LEN==0 and no payload before CRC. Place under the existing test module in studio/src-tauri/src/lib.rs (around current WS tests). Pass criteria: assertion holds.\n- Integration (mock WS):\n  - Server asserts received 0x12 frame has LEN=0; replies with STATUS ack; client emits phases \"finalizing\" then \"done\"; no errors thrown.\n  - Server simulates CRC mismatch by replying with an error TLV upon PUT_END; client surfaces an error whose string matches uploadErrors mapping. Add a vitest/Playwright UI test to show the friendly message is rendered when invoking upload.\n\nFirmware (Unity):\n- Unit: New test \"PUT_END rejects non-empty payload\" builds MSG_TYPE_PUT_END with a 1-byte payload; expect ESP_ERR_INVALID_ARG.\n- Unit: New test \"PUT_END CRC mismatch\" performs PUT_BEGIN with expected_crc = known value, sends PUT_DATA with different bytes, then PUT_END; expect ESP_ERR_INVALID_CRC and session cleared.\n- Regression: Existing tests continue to pass (PUT_END validates CRC, rejects incomplete uploads).\n\nManual sanity (optional):\n- Upload a known .prism via Studio to a dev board. Flip one byte in transit using a proxy (or temporary code to alter one PUT_DATA chunk); confirm Studio displays CRC mismatch and firmware logs \"PUT_END: CRC32 mismatch\".\n",
        "status": "in-progress",
        "dependencies": [
          "12"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Clarify PUT_END spec in headers and code comments",
            "description": "Document that PUT_END (0x12) has an empty payload and that CRC is only provided in PUT_BEGIN.",
            "dependencies": [],
            "details": "Update firmware/components/network/include/protocol_parser.h to explicitly define payloads for PUT_BEGIN/PUT_DATA/PUT_END with PUT_END:{} and note CRC validation occurs on PUT_END against PUT_BEGIN.crc32. Add a concise comment above handle_put_end in firmware/components/network/protocol_parser.c outlining the full-buffer CRC algorithm and support for out-of-order chunks. In Studio, add a brief docstring near upload_with_emitter in studio/src-tauri/src/lib.rs confirming PUT_END is empty and CRC is only supplied in PUT_BEGIN.",
            "status": "pending",
            "testStrategy": "Doc-only change: rely on code review; confirm comments render in IDE and paths match.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Enforce empty PUT_END payload in firmware parser",
            "description": "Add defensive parsing to reject any non-zero-length payload for PUT_END with an error.",
            "dependencies": [
              1
            ],
            "details": "In handle_put_end (firmware/components/network/protocol_parser.c), before CRC validation, check frame.length == 0. If non-zero, return ESP_ERR_INVALID_ARG (or mapped internal ERR_INVALID_FRAME) and send an error TLV via send_error_response. Keep existing logic for recomputing CRC over the full received buffer and comparing with PUT_BEGIN.crc32.",
            "status": "pending",
            "testStrategy": "Unit test via protocol parser tests to send a PUT_END with payload bytes and assert error response and status code.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Firmware unit test: CRC mismatch on PUT_END returns invalid CRC",
            "description": "Add Unity test asserting CRC mismatch is detected on PUT_END and proper error code is returned.",
            "dependencies": [
              2
            ],
            "details": "In firmware/components/network/test/test_protocol_parser.c, add a test that performs PUT_BEGIN with size N and an intentionally wrong crc32, sends PUT_DATA with N bytes, then sends PUT_END. Expect ESP_ERR_INVALID_CRC (or internal mapped error) and session reset/cleanup. Use esp_rom_crc32_le to create the mismatched CRC.",
            "status": "pending",
            "testStrategy": "New Unity test case with synthetic frames; assert return codes, error TLV contents, and that internal state resets.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Firmware unit test: Reject non-empty PUT_END payload",
            "description": "Add Unity test verifying parser rejects any PUT_END frame with non-zero payload length.",
            "dependencies": [
              2
            ],
            "details": "In firmware/components/network/test/test_protocol_parser.c, add a test that crafts a PUT_END with a 1+ byte payload. Feed it to the parser and assert an error is returned (ESP_ERR_INVALID_ARG/ERR_INVALID_FRAME) and an error TLV is emitted; verify no CRC validation is attempted when payload is non-empty.",
            "status": "pending",
            "testStrategy": "Unity test that inspects parser return value and captured TX frames for error TLV with correct code.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Studio unit test: PUT_END TLV has LEN==0",
            "description": "Add a Rust unit test that builds a PUT_END frame and asserts length field is zero with no payload.",
            "dependencies": [
              1
            ],
            "details": "In studio/src-tauri/src/lib.rs test module, call build_tlv_frame(0x12, &[]) (or equivalent helper) and locally decode to verify the TLV [LEN:2 BE] is 0 and there are no payload bytes before the CRC32. Keep existing framing using crc32fast over TYPE+LEN+PAYLOAD.",
            "status": "pending",
            "testStrategy": "Rust unit test asserting encoded bytes for TYPE=0x12 include length=0x0000 and payload slice is empty before CRC.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Studio error mapping for CRC failures",
            "description": "Map firmware CRC errors to a user-friendly message in Studio uploader.",
            "dependencies": [
              1
            ],
            "details": "In studio/src/lib/uploadErrors.ts (or equivalent), add mapping for error strings containing \"CRC\" or specific codes (e.g., TLV_CRC_INVALID/ERR_INVALID_CRC) to: \"Upload failed: CRC mismatch. Your baked bytes were altered in transit.\" Ensure uploader paths surface these errors consistently.",
            "status": "pending",
            "testStrategy": "Unit test for error mapper: feed representative error strings/codes and assert normalized message. Optional integration test verifies propagation.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Studio integration tests: PUT_END empty and CRC-mismatch path",
            "description": "Extend Rust async WS mock tests to cover empty PUT_END and CRC-mismatch behavior end-to-end.",
            "dependencies": [
              5,
              6
            ],
            "details": "Using the existing tungstenite mock server scaffold in studio/src-tauri/src/lib.rs tests, add: (a) Happy path: mock inspects the third frame (TYPE 0x12) and asserts TLV length field is 0, then responds with STATUS ack; verify progress includes \"finalizing\" and \"done\". (b) CRC-mismatch path: mock accepts PUT_BEGIN/DATA and on PUT_END returns an error TLV indicating CRC mismatch; assert uploadWithEmitter propagates the mapped CRC error message.",
            "status": "pending",
            "testStrategy": "Rust integration tests with mock server asserting on-wire TLV fields and resulting client events/messages.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Update protocol documentation and verify cross-side consistency",
            "description": "Revise Upload section in protocol docs to state single-source CRC in PUT_BEGIN validated on PUT_END; verify BE fields and constants across code.",
            "dependencies": [
              1,
              2,
              7,
              3
            ],
            "details": "Edit docs/protocol/source-of-truth.md to explicitly state that PUT_END has an empty payload and that firmware recomputes CRC over the received buffer on PUT_END, comparing against PUT_BEGIN.crc32. Include references to firmware/components/network/include/protocol_parser.h and studio/src-tauri/src/lib.rs. Run repository-wide checks (rg) to confirm BE endianness for LEN/size/offset and message type constants align between Studio and firmware.",
            "status": "pending",
            "testStrategy": "Doc review plus a lightweight checklist referencing file paths; optionally include a scripted grep in CI to guard constants/endianness.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Clarify spec in firmware/components/network/include/protocol_parser.h that PUT_END (0x12) payload is empty; add comment above handle_put_end in firmware/components/network/protocol_parser.c documenting full-buffer CRC validation against PUT_BEGIN.crc32; add defensive rejection if frame.length != 0 returning ERR_INVALID_FRAME; confirm Studio uploader in studio/src-tauri/src/lib.rs continues to send empty PUT_END and add a brief docstring; extend Rust unit/integration tests to assert PUT_END LEN==0, and simulate CRC-mismatch to verify error mapping; add firmware Unity tests for CRC mismatch on PUT_END and \"reject non-empty PUT_END\"; update docs/protocol/source-of-truth.md Upload section describing single-source CRC in PUT_BEGIN validated on PUT_END with file references; verify endianness and constants across sides via rg checks.",
        "updatedAt": "2025-10-17T11:44:45.816Z"
      },
      {
        "id": 15,
        "title": "Studio Graph: Add Angle/Radius fields, SinOsc, PhaseAccumulator, distance/ring bands, Decay/Fade, CenterOutMirror, and ColorFromPalette‑parity PaletteMap with unit tests",
        "description": "Extend the Studio node graph to support spatial fields and temporal ops used by FastLED patterns, align PaletteMap semantics with ColorFromPalette, and add unit tests that reproduce Wave, Sinelon, and Ripple building blocks on a 1D LED strip.",
        "details": "Codebase analysis and targets (Studio):\n- Node graph lives under `studio/src/lib/graph/` with core entry points `types.ts`, `registry.ts`, `nodeDefinitions.ts`, `runtime.ts`, `evaluator.ts`. Current nodes include `Solid`, `Gradient`, `Brightness`, `HueShift`, `Add`, `Multiply`, `PaletteMap`, `ToK1` (see `studio/src/lib/graph/types.ts:1` and `studio/src/lib/graph/registry.ts:5`).\n- Baking and palette LUT are handled in `studio/src/lib/bake/bake.ts` (calls `evaluateGraphOnce` and passes `ctx.lut`) and `studio/src/lib/color/oklchLut.ts`.\n- Tests and harnesses exist in `studio/src/lib/graph/*.test.ts` (`perf.test.ts`, `registry.test.ts`, `runtime.test.ts`) and example UI-facing tests in `studio/src/features/devices/DevicePanel.test.tsx`.\n\nDeliverables\n1) New NodeKinds and definitions\n- Update `studio/src/lib/graph/types.ts` to append:\n  - `AngleField`, `RadiusField` (spatial scalar fields)\n  - `SinOsc` (phase/freq/offset; outputs scalar→RGB gray by default)\n  - `PhaseAccumulator` (maintains `phase = (phase + speed*dt) mod 1`)\n  - `DistCenter` and `Ring` (band ops; scalar masks 0–255)\n  - `Decay`/`Fade` (temporal decay with per‑pixel state)\n  - `CenterOutMirror` (mirror effect around center)\n\n- Extend `studio/src/lib/graph/nodeDefinitions.ts` with pins/params:\n  - `AngleField`: inputs `{}`; params `{ turns: number (min 0–10), offset: number (deg -360–360) }`\n  - `RadiusField`: inputs `{}`; params `{ scale: number (0.1–4.0) }`\n  - `SinOsc`: inputs `{ phase?: optional }`; params `{ freq: number (0–10 Hz), amp: number (0–255), offset: number (-255–255) }`\n  - `PhaseAccumulator`: inputs `{}`; params `{ speed: number (-10–10) }`\n  - `DistCenter`: inputs `{}`; params `{ scale: number (0.1–4.0) }`\n  - `Ring`: inputs `{}`; params `{ bands: number (1–20), width: number (0–1), speed: number (-10–10) }`\n  - `Decay`: inputs `{ src: required }`; params `{ amount: number (0–1), perSecond: boolean }`\n  - `CenterOutMirror`: inputs `{ src: required }`; params `{}`\n\n2) Registry implementations (`studio/src/lib/graph/registry.ts`)\n- Utilities already present: `iNorm`, `clamp`. Add small helpers:\n  - `const N = (total=320)=>total; const mid=(total=320)=> (total-1)/2;`\n  - State closures per node are acceptable because samplers persist across frames (see use in PaletteMap and evaluator loop in `runtime.ts:60`).\n\n- AngleField:\n  - For a 1D strip, approximate angular phase by mapping index around a virtual circle: `theta = (i / N) * 2π + offsetRad`; output scalar 0–255 as `[v,v,v]`. Param `turns` multiplies cycles along strip; `offset` in degrees.\n\n- RadiusField:\n  - Compute normalized distance from center: `r = |i - mid| / mid`; scale by `scale`; output `[v,v,v]` with `v = clamp(round(255*(1 - min(1, r*scale))))` to make center bright.\n\n- PhaseAccumulator:\n  - Maintain `lastT` and `phase` closure per sampler. On call: `dt = Math.max(0, t - (lastT ?? t)); phase = (phase + speed*dt) % 1; lastT = t;` Return scalar phase mapped to `[v,v,v]` with `v = round(phase*255)`; also expose phase to downstream ops via an optional pin pattern (see SinOsc below).\n\n- SinOsc:\n  - Inputs: optional `phase` sampler providing scalar in `[0,1]` via gray channel. If missing, use time‑based phase: `phi = (t*freq) % 1`. If provided, `phi = gray(inputs.phase(i,t))/255`. Compute `y = sin(2π*phi)`. Output `val = clamp(round(offset + amp*(0.5*(y+1))))` and return `[val,val,val]`.\n\n- DistCenter:\n  - Return `[v,v,v]` where `v = clamp(round(255 * (1 - min(1, (|i - mid|/mid) * scale))))` for masking forms.\n\n- Ring:\n  - Animated concentric bands on 1D mapped to phase around center. Compute normalized position `u = (i / N)` and time phase `p = (u*bands + speed*t) % 1`; band mask `m = step(1 - width, fract(p))` shape; convert to `[0,0,0]` or `[255,255,255]` then optionally apply soft edges with a small smoothstep for niceness.\n\n- Decay/Fade:\n  - Per‑pixel temporal decay: keep `map = new Uint8Array(N)` state and `lastT`. For each `i`:\n    - `dt = t - lastT` (0 on first)\n    - If `perSecond`: `k = exp(-amount*dt)` else `k = 1 - amount` (frame‑rate dependent mode)\n    - `prev = map[i]`; `src = src(i,t)` luminance; `out = round(prev*k + srcLum*(1-k))`; write `map[i]=out`; return `[out,out,out]`.\n\n- CenterOutMirror:\n  - Mirror `src` around the center index: map `j = i <= mid ? i : (N-1-i)` then sample `src(j,t)` to create outward symmetry.\n\n3) PaletteMap parity with FastLED ColorFromPalette semantics\n- Adjust `PaletteMap` in `registry.ts:42` to match FastLED’s `ColorFromPalette`:\n  - Support params `{ blend: 'nearest'|'linear', brightness: number (0–255), wrap: boolean }` via `nodeDefinitions.ts`.\n  - Use `ctx.lut` as palette with 256 slots: if provided stops < 256 in bake, we already expand to LUT in `oklchLut.ts`.\n  - Indexing: use scalar `idx = luminance(src)/1` (current) but allow mapping from any scalar node if wired later; apply `if (wrap) idx = idx & 0xFF else clamp 0..255`.\n  - Nearest: same as current; Linear: `c = lerp(lut[floor]*, lut[ceil]*, fract(index))` across RGB with brightness scaling `* (brightness/255)`.\n\n4) Unit tests\n- Add tests under `studio/src/lib/graph/`:\n  - `fields.test.ts`: verify `AngleField`, `RadiusField`, `DistCenter`, `CenterOutMirror` produce expected symmetry (center brightness peaks, mirror equality `frame[i]==frame[N-1-i]`).\n  - `oscillators.test.ts`: `PhaseAccumulator` advances correctly with varying `dt`; `SinOsc` with injected `phase` node yields same output as time‑based when phase matches `t*freq`.\n  - `paletteMap.test.ts`: confirm nearest vs linear blend and brightness produce expected RGB from a synthetic LUT (e.g., two‑color palette), and parity with a small reference `ColorFromPalette` JS reimplementation.\n  - `fl_building_blocks.test.ts`: implement minimal Wave, Sinelon, and Ripple:\n    - Wave: `AngleField -> SinOsc(freq=k) -> PaletteMap` produces smooth gradient consistent with sine values; assert monotonic segments and peak locations.\n    - Sinelon: moving bright dot with `PhaseAccumulator(speed) -> SinOsc(amp=255, freq=1)` and `Decay(amount=...)` trail; assert peak index advances frame‑to‑frame and decays behind.\n    - Ripple: center impulse via time‑phased `Ring(bands=..., speed)` modulating brightness with decay; assert expanding ring positions and amplitude decay over time.\n\n5) Performance guardrails\n- Reuse `studio/src/lib/graph/perf.test.ts` patterns to assert a 320‑LED frame renders <16.7ms with new nodes. Avoid per‑sample object allocations and prefer primitive math, reusing closure arrays if any.\n\nBest practices applied\n- Stateless RGB return with closure state only where required (phase/decay); avoid dynamic allocations in hot loops.\n- Clamp and min/max bounds applied via `clampParams` hook in `runtime.ts:19` and additional fast clamps within samplers.\n- Deterministic behavior from time `t` input; dt computed via internal `lastT` state.\n- Palette blending done in linear space of the LUT values (already 8‑bit), with brightness multiplier applied post‑blend.\n\nIntegration notes\n- No UI changes required; these are compute nodes. `bake.ts` already passes `ctx.lut` when a palette is provided; tests can pass `ctx: { lut }` directly.\n- Extend `Graph` type order or rely on `topoSort` in `runtime.ts:5`. Add nodes to `NodeDefinitions` so editor/inspector has pins and param ranges.\n",
        "testStrategy": "Studio unit tests (Vitest):\n1) Fields and symmetry\n- Build a 33‑LED graph for deterministic mid index. Assert:\n  - RadiusField center index is max and decreases symmetrically.\n  - CenterOutMirror mirrors `Solid`+`Gradient` inputs so `frame[i]==frame[N-1-i]`.\n2) Oscillator/phase correctness\n- PhaseAccumulator: simulate frames at `t = [0, 1/120, 2/120, 10/120]` with `speed=0.25` and assert phase increments by `0.25*(1/120)` modulo 1.\n- SinOsc: with explicit phase source from PhaseAccumulator and with implicit time phase; assert both produce identical frames at same `t`.\n3) PaletteMap parity\n- Construct a two‑color LUT (e.g., red→blue). For indices 0, 0.5, 1.0:\n  - Nearest mode returns exact palette endpoints.\n  - Linear mode returns mid‐blend within ±1 LSB. Verify brightness scaling 50% halves channel values (±1 tolerance).\n4) FastLED building blocks mapping\n- Wave: Graph: `AngleField(turns=1) -> SinOsc(freq=1, amp=255, offset=0) -> PaletteMap(linear, brightness=255) -> ToK1`. For a fixed `t`, assert sinusoidal peak spacing and smoothness (no negative differences beyond rounding).\n- Sinelon: Graph: `PhaseAccumulator(speed=0.5)` → `SinOsc(amp=255)` → `Decay(amount=0.2, perSecond=true)`.\n  - Across 5 frames at 120 FPS, assert the max index advances and prior max decays by expected factor within tolerance.\n- Ripple: Graph combining `Ring(bands=3, width=0.1, speed=0.3)` with `Decay(amount=0.5, perSecond=true)`. Assert ring radius increases over frames and amplitude decays.\n5) Performance\n- Modify/extend `studio/src/lib/graph/perf.test.ts` to include graphs with the new nodes; assert rendering 10 frames of 320 LEDs averages <16.7ms/frame on CI runner.\n",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Studio: Integrate FL.ledstrip Motion Node Kit (Angle/Radius fields, SinOsc, PhaseAccum, DistCenter, Ring, Fade, CenterOutMirror, PaletteMap-angle) with tests and example graphs",
        "description": "Add spatial/temporal motion primitives to the Studio graph runtime and evaluator, align PaletteMap to support angle-based indexing, and provide unit tests plus example graphs that reproduce Wave, Sinelon, and Ripple on a 1D LED strip.",
        "details": "Codebase analysis (Studio targets)\n- Graph stack lives under `studio/src/lib/graph/` with `types.ts`, `nodeDefinitions.ts`, `registry.ts`, `runtime.ts`, and `evaluator.ts`. Existing nodes include `Solid`, `Gradient`, `Brightness`, `HueShift`, `Add`, `Multiply`, `PaletteMap`, `Noise2D`, and `ToK1` (see `studio/src/lib/graph/types.ts`, `studio/src/lib/graph/nodeDefinitions.ts`, `studio/src/lib/graph/registry.ts`). Baking uses `evaluateGraphOnce` in `studio/src/lib/bake/bake.ts` and already passes a palette LUT via `ctx.lut`.\n- Tests exist in `studio/src/lib/graph/registry.test.ts`, `runtime.test.ts`, and `perf.test.ts` and use Vitest. `PaletteMap` currently indexes by luminance; we will add an alternative angle-index mode while preserving current behavior as default.\n- Docs outline the exact node kit and patterns in `docs/motion/fl-node-kit.md` (Wave, Sinelon, Ripple).\n\nImplementation plan\n1) Types and node definitions\n- Update `studio/src/stores/graph.ts` NodeKind union and `studio/src/lib/graph/types.ts:NodeKind` to include:\n  - `AngleField`, `RadiusField`, `SinOsc`, `PhaseAccum`, `DistCenter`, `Ring`, `Fade`, `CenterOutMirror`.\n- Extend `studio/src/lib/graph/nodeDefinitions.ts` to declare inputs/params for each new node:\n  - `AngleField`: params `{ wrap?: '0-1'|'0-255' }` no inputs.\n  - `RadiusField`: params `{ normalize?: boolean }` no inputs.\n  - `SinOsc`: inputs `{ phase? , freq? , amp? , bias? }` with params defaults `{ freq: 1, amp: 255, bias: 0 }` (accept scalar field on `phase`).\n  - `PhaseAccum`: inputs `{ rate? }`, params `{ speed: number }` (accumulate `speed * dt`), expose phase in 0..1.\n  - `DistCenter`: no inputs; params `{ }` (derive from `ledCount`).\n  - `Ring`: inputs `{ center, width }` where `center` is scalar field (e.g., beatsin) and `width` numeric; outputs a mask 0..255.\n  - `Fade`: inputs `{ src }`, params `{ amount: number }` meaning fade-by per frame (like FastLED `fadeToBlackBy`).\n  - `CenterOutMirror`: inputs `{ src }`, params `{ }`.\n  - `PaletteMap`: keep existing def; add optional param `{ indexStrategy?: 'luma'|'angle' }` for angle indexing.\n\n2) Registry implementations (`studio/src/lib/graph/registry.ts`)\n- Reuse `Sampler = (i,t)=>[r,g,b]` convention; for scalar fields, emit gray `[v,v,v]` to compose with existing math and `PaletteMap`.\n- Utility helpers:\n  - Access `ledCount` inside samplers by adding `CompileContext` extension: add `ledCount?: number` (plumb from `evaluateFrame` via `compileGraph`). This allows center index and normalization.\n  - Add `getScalar(s:Sampler,i,t):number` returning clamped 0..255 from `[r,g,b]` luma or first channel.\n- Implement nodes:\n  - `AngleField`: center-origin angle mapped to 0..255 (0 at +X, increasing CCW). For 1D strip, map position to angle across [0,2π) or use symmetric mapping from center outward: `theta = atan2(0, i-center)` degenerates; instead, define angle as normalized position around a virtual circle: `idxNorm∈[0,1] -> angleIdx=round(idxNorm*255)`. For 2-edge future, keep simple 1D policy now. Output `[v,v,v]`.\n  - `RadiusField`: distance from center; if `normalize`, map 0 at center to 255 at endpoints, else output pixel units scaled to 255 range. Output scalar as gray.\n  - `DistCenter`: same as `RadiusField` without normalization option but in pixel units (gray scaled 0..255 using `ledCount`).\n  - `PhaseAccum`: maintain internal closure state; increment by `speed / fps` each call. Since our evaluator passes `t` not `dt`, compute phase = `(phase0 + speed * t) mod 1` by deriving from `t` to keep determinism. Provide input pin `rate` to modulate speed per-pixel/over time.\n  - `SinOsc`: `value = bias + amp * 0.5*(1+sin(2π*(phase + freq*t)))`; `phase` input (0..1) optionally offsets each pixel; `freq` can be param or scalar input; clamp 0..255; gray output.\n  - `Ring`: band mask around `center` index with half-width `width` (either param or scalar). Compute `d = abs(i - centerIdx)`; mask = 255 if `d<=width`, else falloff 0 with optional smoothstep edge. Output gray.\n  - `Fade`: apply temporal decay: `src(i,t) * (1 - amount/255)` per call. Since runtime is stateless per frame, approximate by scaling each frame; for truly accumulative trails, a future stateful framebuffer node may be added. For now, ensure consistent visual decay when composed with Add.\n  - `CenterOutMirror`: mirror samples about center: for output index i, sample from `min(i, N-1-i)` of `src`. Implement by sampling `src(symIdx,t)`.\n  - `PaletteMap` angle indexing: if `params.indexStrategy==='angle'`, use `AngleField`-compatible scalar at the same pixel as index. If an explicit `src` is provided, compute index from its scalar value (0..255). When `luma` (default), preserve current behavior.\n- Ensure param clamping via existing `clampParams` in `runtime.ts`.\n\n3) Runtime plumbing (`studio/src/lib/graph/runtime.ts`/`evaluator.ts`)\n- Pass `ledCount` in `CompileContext` from `evaluateFrame(g,t,ctx)` to `compileGraph` and into node compilers. Extend `CompileContext` in `types.ts` accordingly.\n- Keep compile caching valid by including params in cache key (already done). Avoid caching samplers that capture time-dependent or stateful closures incorrectly; `PhaseAccum` should derive from `t` instead of mutable state to remain pure.\n\n4) Example graphs (Wave, Sinelon, Ripple)\n- Add small factory functions under `studio/src/lib/graph/examples/`:\n  - `wave.ts`: AngleField → Add(phase) → SinOsc → PaletteMap(indexStrategy='angle') → ToK1.\n  - `sinelon.ts`: PhaseAccum(speed) → SinOsc(freq≈0.5,amp=255) → CenterOutMirror → Fade → PaletteMap.\n  - `ripple.ts`: PhaseAccum or RandomImpulse placeholder → Ring(center,width) → Multiply(decay from Fade/RadiusField) → PaletteMap → Add → Fade.\n- Each returns a `Graph` configured for 33 LEDs to simplify midpoint assertions in tests, and optionally accepts overrides.\n\n5) Performance considerations\n- Keep all samplers branch-light and numeric; avoid allocation in inner loops. Prefer precomputing center index `c = Math.floor((N-1)/2)` and reusing.\n- Angle/radius computations use simple integer math and pre-normalized constants where possible. Use `Math.imul`-based hashing only if needed (we already have `Noise2D`).\n\n6) Documentation\n- Update `docs/motion/fl-node-kit.md` with the exact parameter names, ranges, defaults, and example node graphs consistent with the implementation.\n\nReferences to current code\n- `studio/src/lib/graph/registry.ts` for node compiler patterns (e.g., `PaletteMap`, `Brightness`, `Add`, `Multiply`).\n- `studio/src/lib/graph/nodeDefinitions.ts` for input/param shape and editor metadata.\n- `studio/src/lib/graph/evaluator.ts` and `runtime.ts` for evaluation flow and context passing.\n- `studio/src/lib/bake/bake.ts` for existing LUT build and palette handling.\n",
        "testStrategy": "Vitest unit tests in `studio/src/lib/graph/` and example verification\n1) Fields and symmetry (33 LEDs for deterministic center)\n- AngleField basics: Construct a graph with `AngleField -> ToK1` and assert indices increase monotonically from 0 to 255 scaled across the strip; midpoint is approximately 128. Verify wrap policy if added.\n- RadiusField symmetry: `RadiusField -> ToK1` yields symmetric values: `frame[i] === frame[N-1-i]` and center is minimum.\n- CenterOutMirror: `Solid('#ff0000')` on left half and `Gradient` on right, then `CenterOutMirror -> ToK1`; assert `frame[i]==frame[N-1-i]` for all i.\n\n2) Oscillator/phase\n- SinOsc with phase: Build `AngleField -> SinOsc(freq=0, amp=255, bias=0) -> ToK1` and assert phase shifts along strip (neighbor pixels differ), and `t` progression changes output at fixed index. With `freq>0`, check periodicity over 1 second.\n- PhaseAccum determinism: With `speed=0.25`, assert that between `t=0` and `t=2`, accumulated phase wraps exactly mod 1 and drives `SinOsc` to the expected cycle counts.\n\n3) Distance and ring\n- DistCenter: At `t=0`, assert `frame[c] == 0` and values increase toward ends.\n- Ring: With `center=c` and `width=2`, assert pixels `[c-2..c+2]` are 255 and outside are 0; with smooth edges (if implemented), verify near-edge falloff.\n\n4) Fade semantics\n- Compose `Add(Solid(255), Solid(0)) -> Fade(amount=64) -> ToK1` at `t=0` vs `t=1/fps`; assert scaled output equals expected decay factor consistently frame-to-frame.\n\n5) PaletteMap indexing\n- Luma (default): Reuse current test style; ensure behavior remains unchanged by default.\n- Angle strategy: `AngleField -> PaletteMap(indexStrategy='angle') -> ToK1` with LUT gradient `i -> [i,0,255-i]`; assert left end is blue-heavy, right end red-heavy.\n\n6) Pattern reproduction (example graphs)\n- Wave: Use `examples/wave` factory; evaluate 1s @ 60fps; assert color pattern shifts consistently and palette indices cover a wide range (>50% of bins touched).\n- Sinelon: Use `examples/sinelon`; evaluate several frames; assert bright lobe at center mirrored outward with decay over time.\n- Ripple: Use `examples/ripple`; generate impulse at `t≈0`; assert expanding ring and trailing fade over frames.\n\n7) Performance sanity\n- For a 320-LED graph, ensure `evaluateGraphOnce` for Wave/Sinelon/Ripple runs <2ms/frame on CI runner using `perf.test.ts` pattern, similar to existing `perf.test.ts` thresholds.\n",
        "status": "in-progress",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-10-17T11:44:47.476Z"
      },
      {
        "id": 17,
        "title": "Implement K1 GeometryProfile schema and device application with dual-edge output",
        "description": "Define a GeometryProfile (u,v mapping, per-edge weights, per-channel gain, white balance, gamma) in Studio’s .prism format, implement parsing and application on firmware, and ensure frames render in parallel to both edges using two RMT TX channels.",
        "details": "Codebase alignment and targets\n- Studio (Tauri/React + packer):\n  - Add GeometryProfile to .prism container in `studio/src/lib/bake/packPrism.ts` by introducing an optional metadata block placed after the 64-byte header and optional palette block. Include: `version: u8`, `flags: u8` (bit0: has_uv, bit1: has_edge_weights, bit2: has_wb, bit3: has_gain, bit4: has_gamma), `led_count: u16`, `stride: u8` (struct size), followed by per-LED structs: `{u:i16, v:i16, w_edge1:u8, w_edge2:u8}`, and global `{gain:u8, wb_r:u8, wb_g:u8, wb_b:u8, gamma_x100:u16}`. Compute CRC32 for the block and set offset/length fields in header (use next available reserved header bytes similar to palette fields at `studio/src/lib/bake/packPrism.ts:68-90`).\n  - Expose authoring inputs: update `studio/src/lib/graph/nodeDefinitions.ts` and `studio/src/lib/graph/types.ts` so `ToK1` accepts a GeometryProfile reference or computed UV/weights (for now, allow simple generated UV for 1D strips). Update `studio/src/lib/bake/bake.ts:22-49` to optionally attach a GeometryProfile block when baking (e.g., for 2×160 edge layout: u in [0,1], v=0, w_edge1/w_edge2 set by mirror or custom split).\n  - Keep gamma handling: continue to populate gamma defaults in LUT build at `studio/src/lib/bake/bake.ts:31` and also reflect into GeometryProfile’s `gamma_x100` for device startup.\n- Tauri (Rust):\n  - No protocol change needed for transport: the existing uploader in `studio/src-tauri/src/lib.rs:427-807` already streams arbitrary bytes via PUT_* frames. Ensure `device_upload` carries the augmented `.prism` bytes unchanged.\n- Firmware (ESP-IDF):\n  - GeometryProfile storage and parsing:\n    - Extend pattern loader in `firmware/components/playback/led_playback.c` to locate and parse the optional GeometryProfile block after reading the header and optional palette payload. Add a small parser struct and validation (version==1, `led_count` matches, bounds checks on block length, CRC32 match).\n    - Store parsed profile in a static context accessible to playback (e.g., `static geometry_profile_t s_geom` in `led_playback.c` or a new `geometry_profile.c` under `playback`). Struct: per-LED `uv` (Q8.8 fixed for i16), `w_edge1`, `w_edge2`, globals `{gain, wb_r/g/b, gamma_x100}`.\n  - Device-side application:\n    - Apply white balance, per-channel gain, and gamma in `firmware/components/playback/effect_engine.c` inside `effect_chain_apply`: 1) gamma LUT (already present) should initialize from `gamma_x100` if present; 2) multiply RGB by `wb_r/g/b` (u8 0–255) then apply `gain` (u8 0–255) with saturating arithmetic; 3) keep brightness and gamma ramp semantics via existing transitions.\n    - Dual-edge routing: ensure `led_driver_submit_frames` in `firmware/components/playback/led_driver.c:292-329` is used by playback to submit independent frames for edge 1 and edge 2. In the playback loop, map the single synthesized frame buffer into two edge-specific GRB buffers using `w_edge1`/`w_edge2` per LED index, or produce two buffers directly in the temporal runtime. For mirror strips, `w_edge1` or `w_edge2` becomes 255 and the other 0; for blended configurations, proportionally split.\n    - Initialization path: on pattern load, call `effect_add_gamma(profile.gamma_x100)` to seed LUT and set `wb/gain` globals. Provide setters guarded by profile presence.\n  - RMT parallel output: The dual RMT channels are already implemented and started in `firmware/components/playback/led_driver.c:342-419` and used in `led_refresh_task` to transmit both channels back-to-back. Verify both channels receive distinct `front_buffer`s from `led_driver_submit_frames`.\n- Protocol/format resilience and best practices:\n  - Version and CRC: include a `geom_crc32` (IEEE) for the GeometryProfile block and reject on mismatch. Treat absence of block as defaults: `u=v=0`, `w_edge1=255`, `w_edge2=0`, `wb=(255,255,255)`, `gain=255`, `gamma_x100=220`.\n  - Fixed-point math: use Q8.8 for `u,v`, and u8 weights/gain/WB to keep inner loops branch-free; prefer saturating multiply-add with 16-bit intermediates.\n  - Memory and timing: precompute channelized, WB/gain-adjusted, gamma-LUT’ed buffers before calling `led_driver_submit_frames` to keep ISR path light; avoid malloc in frame loop; keep per-frame work under the existing frame period (see `LED_FRAME_TIME_MS`).\n\nImplementation sketch\n- Studio packer (TypeScript):\n  - Add header fields (choose two reserved bytes for `geom_count`/`geom_offset` akin to palette’s `count`/`offset` at `studio/src/lib/bake/packPrism.ts:78-85`).\n  - Implement `packGeometryProfile(profile, ledCount): Uint8Array` and splice into final file after palette block, updating offsets and CRC.\n- Firmware parser (C):\n  - In `playback_play_prism_blob`, after validating header/palette, compute `geom_offset`/`geom_len`, validate bounds, validate CRC, then parse into `s_geom`. Provide `geometry_profile_apply(rgb_in, out_ch1, out_ch2)` to map/split and apply WB/gain before gamma/brightness.\n  - Update the playback loop to build `frame_ch1` and `frame_ch2`, then call `led_driver_submit_frames(LED_CHANNEL_1, frame_ch1, LED_CHANNEL_2, frame_ch2)`.\n\nNotes on alignment with current code\n- Dual-edge RMT is implemented: `firmware/components/playback/led_driver.c` provides two TX channels and a `submit_frames` API.\n- Gamma and brightness pipelines exist in `firmware/components/playback/effect_engine.c`; extend to include WB and gain, and initialize gamma from the profile.\n- Transport is complete in `studio/src-tauri/src/lib.rs` with PUT_BEGIN/PUT_DATA/PUT_END and CRC validation; no command additions required.\n",
        "testStrategy": "Studio\n- Unit (Vitest): `studio/src/lib/bake/packPrism.ts`\n  - Asserts: packing with a 2×160 profile sets `geom_offset>0`, correct `geom_len`, and CRC field equals `crc32(block)`.\n  - Round-trip: `unpackPrism` detects GeometryProfile block and reproduces original fields.\n- Graph integration: build a simple 1D strip project and bake with mirror edge weights; ensure `packPrism` includes the profile when requested.\n\nFirmware\n- Unit (Unity/C):\n  - Parser: valid/invalid GeometryProfile blocks (bad CRC, wrong `led_count`, truncated block) return the correct error and do not alter active profile.\n  - WB/gain/gamma: feed a small 4-LED buffer through `geometry_profile_apply` + `effect_chain_apply`; assert per-channel RGB values match expected saturating math with LUT gamma.\n  - Dual-edge routing: with `w_edge1=255,w_edge2=0` for first half and inverse for second half, assert bytes written to `frame_ch1` and `frame_ch2` map as expected.\n- Integration:\n  - Load a `.prism` blob containing both palette and GeometryProfile via the existing upload path; start playback and poll a test seam that exposes `led_driver_get_stats` ensuring both channels are transmitting; in a test build, expose a hook to capture the last submitted frames and validate WB/gain/gamma effects.\n  - Performance: verify frame loop completes under `LED_FRAME_TIME_MS` with geometry/WB/gain applied (log underruns as in `led_driver.c`).\n\nManual/acceptance\n- Bake a pattern with mirror edges on 2×160; upload; observe symmetrical rendering on both edges; adjust `gamma` via CONTROL and confirm runtime LUT changes while respecting profile’s initial gamma.\n",
        "status": "in-progress",
        "dependencies": [
          "6",
          "8"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-10-17T11:54:24.575Z"
      },
      {
        "id": 18,
        "title": "Palette Pipeline Parity: Decide Blend Location, Add UI Controls, Implement Host-vs-Device Mapping",
        "description": "Introduce a Palette Manager that supports host-side OKLCH LUT blending and device-side palette blending, add Studio UI to choose the blend location and parameters, and wire the graph/evaluator and packer to honor the selection.",
        "details": "Codebase analysis and current architecture\n- Host LUT generation exists: studio/src/lib/color/oklchLut.ts provides buildOklchLut() and paletteHexToRgbBytes().\n- Graph runtime/evaluator consumes a LUT when provided: studio/src/lib/graph/registry.ts PaletteMap indexes ctx.lut by luminance; studio/src/lib/bake/bake.ts passes { lut } into evaluateGraphOnce when a palette is present.\n- Packer supports a palette block in .prism: studio/src/lib/bake/packPrism.ts writes an optional palette block (≤16 colors, RGB triplets + reserved byte) and header.\n- Uploader pipeline exists: Task 6 delivers a streaming Tauri command for .prism uploads.\n\nGoal\n- Decide and enable where palette blending happens: (A) host (pre-blend LUT in Studio) or (B) device (firmware blends between two palettes over time).\n- Add a Palette Manager in Studio that exposes blend location and parameters (factor, rate/curve).\n- Implement host LUT blend path now (no firmware change required), and define container metadata + CONTROL stubs for device path so firmware alignment can later flip it on without format churn.\n\nDesign decisions (best practices)\n- Prefer host-LUT blending for minimal device compute and determinism: compute a blended 256×RGB LUT using OKLCH with gamut policy; keep graph evaluation pure and predictable. This keeps bandwidth identical (indices → LUT lookup) and keeps palette transitions artifact-free in perceptual space.\n- Offer device blending for dynamic transitions without rebake: package both palettes + initial factor and emit CONTROL hooks to drive on-device interpolation. This reduces host churn but requires firmware/state agreement (to be aligned with Task 13 CONTROL spec).\n- Use a single source of truth for palette inputs: two palettes: base and target, with gamma/gamut options (reuse existing LutOptions). Serialize enough metadata in .prism for either mode while maintaining backward compatibility: add a small metadata block before frames, guarded by a feature flag bit.\n\nImplementation plan\n1) Studio: Palette Manager types and helpers\n- Add studio/src/lib/color/paletteManager.ts with:\n  - type BlendLocation = 'host_lut' | 'device_runtime'\n  - function blendOklchLut(aStops: string[], bStops: string[], factor: number, opts: LutOptions): Uint8Array that:\n    - Generates two LUTs via buildOklchLut(aStops), buildOklchLut(bStops) and linear-interpolates RGB8 per index (factor∈[0,1]).\n    - Optionally performs pre-blend in OKLCH: interpolate a and b stops into larger common stop list, then build a single LUT; expose mode: 'rgb_lut' | 'oklch_stops'. Default to 'rgb_lut' for performance and determinism given existing culori usage.\n  - function clamp01, memoization key: {aStops,bStops,gamma,gamut,factor} to avoid churn.\n\n2) Studio: Settings/UI controls\n- Add a lightweight settings panel component (if none exists) under studio/src/features/settings/PaletteSettings.tsx (or reuse existing settings scaffold under UI root):\n  - Controls: Blend Location (radio: Host (recommended), Device), Blend Factor slider (0–100%), Blend Rate (ms per 1.0 step), Curve (linear|easeIn|easeOut, used for device hints only), Gamut Policy (clip|compress|preserve-hue), Gamma Policy numeric (default 2.2).\n  - Persist under a small settings store: studio/src/stores/settings.ts { palette: { location, factor, rateMs, curve, gamma, gamut } } with localStorage persistence similar to recent files usage seen in the app shell.\n\n3) Graph/Evaluator integration\n- Update bake path to honor host_lut selection:\n  - studio/src/lib/bake/bake.ts: when paletteStops are provided and settings.palette.location==='host_lut':\n    - If one palette: use buildOklchLut(stops, opts) as today.\n    - If two palettes (base+target): use blendOklchLut(base, target, factor, opts) to obtain a blended LUT.\n    - Pass ctx={ lut } into evaluateGraphOnce unchanged; PaletteMap in studio/src/lib/graph/registry.ts already maps luminance→RGB via lut.\n- Add a small options conduit so PaletteMap can optionally index by a provided scalar field later (angle/radius from Tasks 15/16); for this task, keep luminance-based mapping and document extension point.\n\n4) Container metadata and device-runtime mapping\n- Extend packPrism to optionally include a PaletteBlend metadata block when settings.palette.location==='device_runtime':\n  - Update studio/src/lib/bake/packPrism.ts to build an additional block after existing palette block:\n    - layout v1: [TAG:1 'P'][VERSION:1=1][FLAGS:1 bit0=device_palette_blend][COUNT_A:1][COUNT_B:1][GAMMA_Q8:1][GAMUT:1 enum][FACTOR_Q8:1][RESV:1] followed by A palette RGB triplets then B palette RGB triplets.\n    - Preserve backward compatibility: gate block presence with header feature bit and adjust offsets/lengths. If header doesn’t expose a flag byte yet, place block as optional after palette block and set header.ext_count+=1 with ext tag 'P'. Keep CRC as-is over the whole payload (existing code already finalizes CRC).\n  - Emit a host hint (not enforced): desired blend rate/curve encoded in a tiny TLV list inside the block, e.g., [len][key=value...] where key codes 0x01=rateMs, 0x02=curve.\n- Stub Studio CONTROL hooks for device path (no firmware change yet):\n  - Add a Tauri-side no-op function device_set_palette_blend(host, factor) that, for now, logs an intent. Once Task 13 finalizes CONTROL messages, wire it to send CONTROL 0x20 SUBCMD PALETTE_BLEND [factor_q8].\n\n5) Studio UX affordances in authoring\n- In the graph authoring surface (studio/src), surface current blend mode in a compact toolbar chip near playback controls; link to settings. When location==='device_runtime', warn that a device aligned to Task 13 is required.\n\n6) Documentation\n- Add a doc note to docs/motion/fl-node-kit.md Palette Strategy section clarifying the parity, default to host-lut, and how device-runtime will engage once CONTROL is aligned (Task 13). Mention luminance index for PaletteMap (studio/src/lib/graph/registry.ts:96) and upcoming index strategies from Tasks 15/16.\n\nKey file edits/new files\n- New: studio/src/lib/color/paletteManager.ts (host blending helpers & types)\n- Update: studio/src/lib/bake/bake.ts (select blended LUT when host mode)\n- Update: studio/src/lib/bake/packPrism.ts (optional PaletteBlend block for device mode)\n- New: studio/src/stores/settings.ts (palette settings) and studio/src/features/settings/PaletteSettings.tsx (UI)\n- Optional small UI badge in main shell to expose mode quickly.\n\nNon-goals\n- Do not change on-device decode yet; CONTROL and runtime application will be finalized in Task 13.\n- Do not change PaletteMap index semantics in this task (angle/radius will land in Tasks 15/16).\n\n",
        "testStrategy": "Unit tests (Vitest)\n- studio/src/lib/color/paletteManager.test.ts\n  - blendOklchLut: Given two simple 2-stop palettes, factor=0.0 returns LUT A; factor=1.0 returns LUT B; 0.5 yields midpoint RGB8 per entry (±1 rounding).\n  - Memoization key produces cache hit for repeated calls with same inputs.\n- studio/src/lib/bake/bake.test.ts\n  - With settings.palette.location='host_lut' and two palettes, ensure evaluateGraphOnce receives ctx.lut and frames change when factor changes.\n  - With single palette, LUT length==256*3 and endpoints match stops within rounding.\n- studio/src/lib/bake/packPrism.test.ts\n  - When device_runtime selected and two palettes provided, asserts PaletteBlend block exists with expected tag/version/flags, counts match, and CRC over payload remains valid (reuse existing CRC utility if present; otherwise local recompute and compare with packer’s field).\n\nGraph/runtime tests\n- studio/src/lib/graph/registry.test.ts\n  - PaletteMap maps via provided blended lut: craft src sampler with known luminances (0, 127, 255) and assert output RGB triplets match lut slices for indices 0, 127, 255.\n\nUI tests\n- @testing-library/react for PaletteSettings: toggling Blend Location updates settings store and the chip in UI reflects the mode; slider commits factor and triggers re-bake path (assert via a mocked bake call observing ctx.lut changes).\n\nManual and integration checks\n- Bake two variants (factor 0.25 and 0.75) and visually compare a short graph (Solid→PaletteMap→ToK1) to confirm hue progression changes as expected.\n- Upload .prism via existing Tauri command (Task 6) to ensure payload structure still accepted; when device_runtime mode is selected, verify legacy firmware ignores the extra block (no crash) by inspecting device logs if available; otherwise validate on the packer side that header/offset math is consistent.\n\n",
        "status": "in-progress",
        "dependencies": [
          "4",
          "3",
          "6"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-10-17T11:54:25.383Z"
      },
      {
        "id": 19,
        "title": "Add K1 Program publish mode (IR v0.1): Studio exporter, firmware decoder/VM, ToK1 toggle",
        "description": "Introduce a new .prism publish mode that exports a compact IR program instead of raw frames and add a branchless per‑pixel VM on firmware to render it. Surface a ToK1 toggle in Studio to choose between current “Clip” (frames) and new “Program” (IR) modes.",
        "details": "Codebase alignment and targets\n- Studio (exporter + graph integration)\n  - IR container: extend `studio/src/lib/bake/packPrism.ts` to support a second payload form, “Program”, alongside the current raw-frames “Clip”. Keep ADR‑009 header parity; add IR markers via flags and offsets without breaking existing devices.\n    - Header additions (use remaining header bytes):\n      - `flags` bit: set `bit2: is_program` (retaining existing LOOP flag).\n      - `prog_offset:u16 LE` at header[46..47] (unused today) for program block start after the 64‑byte header and optional palette block.\n      - `prog_len:u32 LE` at header[52..55] (repurpose existing palette CRC field only when is_program=1; when palette present and is_program=1, store palette CRC in the program block header, see below).\n    - Program block layout (IR v0.1):\n      - `[magic:u16=0x4B31][ver:u8=1]` → “K1” v1.\n      - `[const_count:u8][consts:const_count*3 bytes RGB8]` constant pool for colors.\n      - `[lut_count:u8][luts:lut_count*256*3 bytes]` optional palette LUTs (0 or 1 for now). Build from `buildOklchLut()` when graph uses `PaletteMap`.\n      - `[op_count:u16][ops:op_count bytes][op_params:varlen]` where each op is an opcode byte, followed by compact params (fixed‑point, big‑endian). No control flow; linear op stream executes per pixel.\n      - CRC32 (IEEE) over program block bytes (excluding this CRC) at the tail.\n    - Opcodes (IR v0.1 minimal parity with current graph in `studio/src/lib/graph/registry.ts`):\n      - `0x01 LOAD_CONST idx:u8` → r,g,b = const[idx].\n      - `0x02 GRADIENT c0:u8 c1:u8 speed_q8:u8` → linear x ∈ [0,1) with time shift; colors by const indices (c0,c1); `speed_q8` is cycles/sec in Q0.8.\n      - `0x10 BRIGHTNESS scale:u8` → r,g,b = (r,g,b)*scale/255.\n      - `0x11 HUE_SHIFT deg_i16_be rate_q8_i16_be` → branchless hue rotate using matrix; deg in degrees; rate in deg/sec (Q8.8 signed).\n      - `0x20 ADD` (no params) → r = min(255, rA+rB) (stack‑2 → 1); VM is register + tiny stack of one RGB to support `Add`/`Multiply`.\n      - `0x21 MUL` → r = (rA*rB)/255, etc.\n      - `0x30 PALETTE_MAP lut_idx:u8` → luminance index to LUT.\n      - `0x3F END` terminator.\n    - Graph → IR compiler: add `studio/src/lib/bake/compileToProgram.ts` that compiles the graph (`Graph` from `studio/src/lib/graph/types.ts`) into the op stream + const pool + optional LUTs. Respect topological order via `topoSort` in `studio/src/lib/graph/runtime.ts`. Use deterministic hashing for const re‑use.\n    - Export mode: update `studio/src/lib/bake/bake.ts` to:\n      - Accept `{ publishMode: 'clip'|'program' }` and, when `program`, build LUT if `PaletteMap` is used and call `compileToProgram()`, then `packPrism({ ..., program: {consts, luts, ops} })` which writes the program block and sets header flags/offsets. Keep current frames path intact for ‘clip’.\n    - ToK1 toggle: in graph runtime, update `Registry.ToK1` (`studio/src/lib/graph/registry.ts`) and node typing (`studio/src/lib/graph/types.ts`) to accept a param `mode: 'clip'|'program'` default `'clip'`. Baking path should read this param to choose export mode automatically when the output node is ToK1 with `mode='program'`.\n  - UI: surface a simple toggle for ToK1 in the node inspector (existing graph editor is under `studio/src/features/graph/`). If no inspector exists, minimally support setting the param in the serialized node object through existing form/panel infrastructure.\n\n- Firmware (decoder/VM + playback integration)\n  - Decoder: add `firmware/components/playback/k1_program_vm.c` and header in `firmware/components/playback/include/k1_program_vm.h` implementing a branchless per‑pixel VM:\n    - Parse program block once on load: validate magic/version, read consts, LUT pointers, and op stream; store in a `k1_prog_t` with predecoded parameters (e.g., precompute hue matrices per op if rate=0, normalize Q formats, and align op stream to 4 bytes for tight fetch).\n    - VM execute loop per pixel: fixed register file `{r,g,b}` and a single RGB stack slot for binary ops; iterate `ops` with a jump table (computed goto if allowed by toolchain, else a dense `switch` compiled with `-O3` ensures branch prediction/locality). No control flow ops; linear pass avoids divergence.\n    - Implement luminance via integer math: `lum = (54*r + 183*g + 19*b) >> 8` to match sRGB luma weights efficiently.\n    - Time and x inputs: pass `t` (float or Q16.16) and `x` (Q0.16 ∈ [0,1)) to ops requiring them (e.g., GRADIENT). Favor fixed‑point to keep FPU off hot path.\n    - Clamping: saturate writes with `__builtin_add_overflow` patterns or lookup clamps to keep branchless.\n  - Integration:\n    - Extend pattern loader (search `firmware/components/storage/include/prism_parser.h` and users) to detect header `flags.is_program` and expose a `pattern_kind` enum: CLIP vs PROGRAM. For PROGRAM, parse program block into `k1_prog_t` during load with full CRC check and store in playback state.\n    - Extend playback core (files under `firmware/components/playback/`) to, on each refresh tick, choose render path: for CLIP read RGB triplets; for PROGRAM run VM over `led_count` with current `t`. Reuse dual‑edge handling introduced elsewhere (Task 17 will layer on geometry later; this task only supports linear strip mapping).\n    - Memory: store program in IR form; avoid per‑frame buffers. Guard total program size ≤ 16 KB to keep RAM footprint bounded.\n\n- Best practices applied\n  - IR stability: keep versioned header and explicit counts/offsets; add CRC per block.\n  - Branchless hot loop: linear ops, no control flow; all clamps via arithmetic; avoid dynamic memory during render.\n  - Determinism: seedless ops are deterministic; any time‑varying ops derive only from provided `t`.\n  - Backward compatibility: non‑program devices ignore `is_program` and still accept clips. Studio keeps both paths and current uploader (`studio/src-tauri/src/lib.rs`) unchanged since it streams opaque bytes.\n",
        "testStrategy": "Studio\n- Unit (Vitest)\n  - `studio/src/lib/bake/compileToProgram.test.ts`:\n    - Solid path: `Solid(#112233) -> ToK1(mode=program)` compiles to [LOAD_CONST,END] with const pool `[0x11,0x22,0x33]`; no LUT; op_count and CRC valid.\n    - Gradient parity: `Gradient(c0=#000000,c1=#ffffff,speed=0)` produces monotonic ramp when interpreted by a small JS reference VM over 33 LEDs; midpoint ≈ 127.\n    - PaletteMap: graph with `PaletteMap` passes a LUT into program; compiled ops contain `PALETTE_MAP(0)` and block carries exactly 256*3 bytes; CRC matches `crc32`.\n  - `studio/src/lib/bake/packPrism.program.test.ts`:\n    - Header flags: `is_program` bit set; `prog_offset > 0`; `prog_len` equals program block size; header CRC matches.\n    - Backward safety: when `publishMode='clip'`, flags remain unchanged and bytes equal previous implementation for same frames.\n  - Baking switch: `bakeProjectToPrism` chooses program path when terminal `ToK1.mode='program'`.\n\nFirmware\n- Unit (Unity/CMocka existing infra)\n  - `firmware/components/playback/test/test_k1_program_vm.c`:\n    - Decoder validation: rejects bad magic/version; validates CRC; enforces program size ≤ 16 KB.\n    - Op correctness: feed a minimal program [LOAD_CONST(0), BRIGHTNESS(128), END]; VM result equals half of const.\n    - Gradient correctness: with t=0 and x swept, output r=g=b monotonic from 0..255.\n    - PaletteMap: with a LUT that is identity gray ramp, VM output equals input luminance mapped to same value per channel.\n  - Performance: measure render time for 320 LEDs with op stream [LOAD_CONST, END] and with [GRADIENT, HUE_SHIFT, BRIGHTNESS, PALETTE_MAP, END]; assert both remain under 1.6 ms on target (simulate with cycle budget or compile‑time checks if HW not in CI).\n\nIntegration\n- End‑to‑end (firmware + Studio uploader unchanged):\n  - Build a graph that previously baked to frames; set `ToK1.mode='program'`; bake and upload. Device reports successful PUT_* sequence (existing tests) and renders comparable visuals to host reference for at least two patterns (Solid, Gradient+Palette).\n- Regression: ensure legacy ‘clip’ publish still renders as before by re‑uploading a known clip and snapshotting 10 frames for byte equality to pre‑change output.\n",
        "status": "pending",
        "dependencies": [
          "3",
          "6"
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "Graph Editor: Pan/Zoom, Drag/Move, Edge Drawing, Selection, Multi-Select, and A11y with Batched History",
        "description": "Enhance the Studio graph editor with robust interactions: node drag/move, canvas pan/zoom, port-to-port edge drawing, single and multi-selection, and keyboard/focus accessibility. Integrate all mutating interactions with the graph store’s temporal history using batching for smooth undo/redo.",
        "details": "Tech stack and current hooks\n- React + Zustand + zundo temporal history in `studio` app. Graph store exposes selection/layout and history helpers in `studio/src/stores/graph.ts:1` with `withHistoryBatch()`, `graphUndo`, and `connectPins()`.\n- Minimal canvas placeholder exists at `studio/src/features/graph/GraphCanvas.tsx:1` showing nodes and add/remove controls. Node definitions live in `studio/src/lib/graph/nodeDefinitions.ts:1`.\n\nScope\n- Implement interactive graph editing surface supporting:\n  - Node drag/move (pointer-based) with history batching across the drag gesture.\n  - Canvas pan/zoom (wheel+panning) via CSS transforms on inner layer; keep viewport state local (not persisted in undo/redo).\n  - Edge drawing: drag from a node “output” to another node’s input pin; drop to connect using `useGraphStore.getState().connectPins()` which prevents cycles.\n  - Selection: click to select, shift-click to toggle, marquee selection via drag on blank space, and keyboard multi-select (Shift+Arrow to extend; Cmd/Ctrl+A select all).\n  - A11y/keyboard: roving tab focus among nodes/ports, Enter/Space to toggle selection, Arrow keys to nudge selected nodes by 1px (with Alt for 10px), Delete/Backspace to delete selected.\n  - History batching: wrap drag and multi-update interactions with `withHistoryBatch()` so undo collapses continuous gestures into single steps.\n\nFiles to update/add\n- Update `studio/src/features/graph/GraphCanvas.tsx:1`:\n  - Introduce viewport state: `{ panX, panY, scale }` in component state/refs. Apply to inner layer: `style={{ transform: translate(panX, panY) scale(scale) }}`.\n  - Render node cards from store `graph.nodes` at positions from `layout` and wrap each in a draggable header area (use `pointerdown` + `setPointerCapture`). During drag, update positions for all selected nodes; on drag end, commit via `withHistoryBatch`.\n  - Ports UI: for each node, render a single output port (right edge) and input ports based on `NodeDefinitions[kind].inputs` (left edge). Ports are focusable with `tabIndex=0`, `aria-label=\"<node>:<port>\"`.\n  - Edge drawing: on pointerdown on output port, start a temp connection and draw a following SVG path; on pointerup over an input port, call `connectPins(toNodeId, toPin, fromNodeId)`; cancel on `Escape`.\n  - Selection model: click blank space clears selection; click node selects; shift-click toggles; drag-blank starts marquee rectangle (absolute overlay) and updates selection live by hit-testing node bounds.\n  - Keyboard handlers on canvas container: Tab cycles focus among nodes/ports; Enter/Space toggles selection; Arrow keys nudge selected nodes (1px or 10px with Alt); Delete removes `selection` via existing `removeNode` (wrapped in `withHistoryBatch`).\n  - Wheel zoom: if `ctrlKey` (or trackpad pinch), adjust `scale` around cursor position (convert cursor to world coords to keep point under cursor stable); otherwise if middle-button or space+drag, pan.\n  - Performance: throttle drag move updates via `requestAnimationFrame`; use `React.memo` for Node components; avoid layout churn by setting `will-change: transform`.\n- Update `studio/src/stores/graph.ts:1`:\n  - Add actions to support editor features (using immer and devtools names):\n    - `setSelection(ids: string[])`, `toggleSelection(id: string)`, `clearSelection()`.\n    - `moveNodes(ids: string[], dx: number, dy: number)` that updates `layout` for the provided IDs and increments `graph.revision`. Use this in drags and keyboard nudges. Wrap higher-level gestures in `withHistoryBatch` at the component level.\n  - Ensure `selection` is included in store state and not part of the temporal partialize (keep current partialize limiting to `graph` so viewport/selection aren’t undone unless desired). Keep as-is unless tests require undo for selection changes.\n- Add `studio/src/features/graph/edges/EdgesLayer.tsx` (optional helper) to render SVG connections based on `graph.nodes[*].inputs`. Recomputes paths when `graph.revision` or `layout` changes. Uses straight or cubic paths with small hit slop.\n\nInteraction specifics\n- Node dragging: pointerdown on node header sets dragging = true. If node is not selected, set selection to [id] unless Shift is pressed. Track pointermove; for selected node IDs, apply `moveNodes(selection, dx, dy)` batched per RAF. On pointerup, finalize; surround the drag lifecycle with `withHistoryBatch(() => {/* all moves */})` by pausing/resuming in effect cleanup.\n- Marquee selection: pointerdown on blank; draw overlay rect; on move, compute nodes whose bounding boxes are fully or partially within rect; update `selection` live (no history). On up, finalize selection.\n- Edge drawing: dragging from right-side output port sets `edgeDraft = { from: nodeId }`; hovering an input port highlights; dropping calls `connectPins(targetNodeId, pinName, fromNodeId)`; wrap the connect action in `withHistoryBatch`.\n- A11y focus: use roving tabindex. The canvas container has `tabIndex=0` and manages focus ring. Each node is a `role=\"group\"` with a focusable header `role=\"button\"`. Ports have `role=\"button\"`. Provide labels including node kind and port name. Provide `aria-keyshortcuts` hints where applicable.\n\nEdge cases and safeguards\n- Prevent self-connections and cycles (store `connectPins` already checks; rely on it).\n- On delete, remove nodes in selection and clear selection of removed IDs. Ensure inputs pointing to deleted nodes are nulled (already handled by `removeNode`).\n- Do not push pan/zoom/selection to undo history (temporal partialize already excludes them via equality/partialize in `graph.ts`).\n- Keep zoom bounds, e.g., `0.25 ≤ scale ≤ 2.0`; clamp pan in large ranges.\n\nDeveloper experience\n- Name devtools actions: `graph/selection/set`, `graph/selection/toggle`, `graph/moveNodes`, `graph/edge/connect`, `graph/drag/batch`.\n- Co-locate small utilities for world<->screen transforms within `GraphCanvas.tsx` or a `canvasUtils.ts` if preferred.\n",
        "testStrategy": "Unit tests (Vitest + @testing-library/react)\n- File: `studio/src/features/graph/GraphCanvas.test.tsx`\n  - Drag move with history: render two nodes at known positions; select both; simulate pointer drag by 10px; assert `useGraphStore.getState().layout[id]` shifted; call `graphUndo()` and verify both revert in one step; call `graphRedo()` and verify re-applied.\n  - Edge connect: create nodes A, B with input `src`; simulate drag from A’s output to B’s `src` input; assert `useGraphStore.getState().graph.nodes[B.id].inputs.src === A.id`; undo/redo validate single-step batch.\n  - Selection toggles: click node A selects only A; Shift+click node B results in `[A,B]`; click blank clears selection.\n  - Keyboard nudge: select A; press ArrowRight; assert `layout[A].x += 1`; with Alt+ArrowDown assert `+10` Y. Undo nudge groups per keydown into single steps if implemented with `withHistoryBatch`.\n  - A11y focus: Tab focuses first node header; `Space` toggles selection; Enter on an output port enters “connect” mode and Enter on a compatible input completes connection.\n- Store tests (Vitest)\n  - File: `studio/src/stores/graph.test.ts`\n    - `moveNodes` updates multiple layouts and increments `graph.revision` once per call. `setSelection`, `toggleSelection`, `clearSelection` update `selection` predictably.\n- Visual layer tests\n  - Edges layer recomputes on `graph.revision` change: update a connection, assert one path is present; delete upstream node, assert edge removed.\n\nE2E (Playwright)\n- File: `studio/e2e/graph.spec.ts`\n  - Add two nodes via toolbar; drag to reposition; draw a connection from A to B; reload app (if autosave is present) or re-open view to ensure layout/connection round-trips visually (best-effort).\n  - Pan/zoom smoke: Ctrl+wheel zooms in; assert node appears larger via bounding box; drag canvas to pan, assert node screen position changes while layout stays constant.\n\nAccessibility checks\n- Assert nodes/ports have `tabIndex`, `role`, and readable `aria-label`s. Verify tab order cycles across nodes and ports. Confirm Delete removes selected nodes via keyboard.\n",
        "status": "pending",
        "dependencies": [
          2
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 21,
        "title": "Node Params UI: Typed Property Inspector with Validation, Live Preview, and Batched History",
        "description": "Add a property inspector panel that renders typed controls from nodeDefinitions for the currently selected node, clamps/validates inputs, updates params with batched undo/redo, and triggers a live preview on change.",
        "details": "Architecture and integration\n- Location and structure\n  - Add `studio/src/features/graph/NodeInspector.tsx` to render a property panel beside `GraphCanvas.tsx`.\n  - Wire into the existing Zustand graph store in `studio/src/stores/graph.ts:1` using `useGraphStore` selectors: `graph`, `selection`, and `updateNodeParams`.\n  - Consume param specs from `studio/src/lib/graph/nodeDefinitions.ts:1` (`NodeDefinitions`) to generate typed controls. Supported types today: `number`, `string`, `color`, and optional `enum`.\n  - Use `withHistoryBatch()` from `studio/src/stores/graph.ts:95` to batch related param edits for smooth undo/redo.\n\n- Selection and display\n  - Use the selected node ID from the graph store (first entry in `selection`) as the active node. If none selected, show a lightweight empty state.\n  - Read the active node’s `kind` to fetch `NodeDefinitions[kind].params` and generate a labeled control per parameter.\n\n- Typed controls and validation/clamping\n  - For `number`: render `<input type=\"number\">` with `min`, `max`, and sensible `step` from the spec; clamp to `[min,max]` on change/blur and skip commit if the value is NaN.\n  - For `string`: render `<input type=\"text\">` with basic trimming, allow empty unless otherwise specified by future spec.\n  - For `color`: render `<input type=\"color\">` and accept hex `#rrggbb`; on invalid, keep last valid value and show a subtle inline warning.\n  - For `enum`: render `<select>` with options, validate against allowed set.\n  - Mirror the runtime’s defensive clamp (see `studio/src/lib/graph/runtime.ts:15 clampParams`) by applying the same clamping rules in the UI before dispatch. This keeps UI and evaluator behavior aligned.\n\n- Param updates and undo/redo batching\n  - On control change, debounce keystrokes for text/number inputs (e.g., 150 ms). On commit (debounce fire or blur), call `withHistoryBatch(() => updateNodeParams(activeId, key, value))` so that sequences of small changes form one history entry.\n  - Ensure each individual parameter edit increments graph revision once (the store already increments in `updateNodeParams`).\n\n- Live preview\n  - When params change, compute a small in-memory preview using graph runtime:\n    - Import `evaluateGraphOnce` from `studio/src/lib/graph/evaluator.ts:17`.\n    - Build a minimal “current graph” object from store state for preview; reuse the project’s current `ledCount` if available (`graph.outputGeometry` in store uses `setOutputGeometry`, otherwise fallback e.g., 320).\n    - Debounce preview evaluation to 120–200 ms and guard for cycles via `compileGraph` exception handling.\n    - Render the preview as a simple horizontal LED strip canvas in `NodeInspector` (e.g., 320×20) mapping bytes to pixel colors.\n\n- A11y and UX\n  - Ensure all controls are labeled and keyboard accessible.\n  - Show inline validation hints for out-of-range values (before clamp) and reflect clamped value on blur.\n  - Persist last-opened section per node kind in `localStorage` for convenience (optional, small helper).\n\n- Files to add/update\n  - Add: `studio/src/features/graph/NodeInspector.tsx` (main component, controls, preview canvas).\n  - Update: `studio/src/App.tsx:168` to render `<NodeInspector />` next to `<GraphCanvas />` in a flexible layout.\n  - Optional small style tweaks in `studio/src/index.css` for panel layout.\n\n- Example control mappings\n  - `HueShift`: params `{ deg: number [-180,180], rate: number [-360,360] }` in `studio/src/lib/graph/nodeDefinitions.ts:13` → two number inputs with clamping.\n  - `Gradient`: `{ c0: color, c1: color, speed: number [-5,5] }` → two color pickers and one number input.\n  - `Brightness`: `{ amount: number [0,255] }` → number input with clamp to [0,255].\n\n- Error handling\n  - If selection references a missing node, show an error state with an option to clear selection.\n  - Wrap preview evaluation in try/catch (e.g., for cycle errors from `compileGraph`) and show a small warning banner.\n",
        "testStrategy": "Unit and component tests (Vitest + @testing-library/react)\n- File: `studio/src/features/graph/NodeInspector.test.tsx`\n  - Renders controls from definitions: Mount with a store state containing a selected `HueShift` node; assert inputs for `deg` and `rate` exist with correct min/max attributes.\n  - Color controls: For `Gradient`, change `c0` and `c1` using `<input type=\"color\">`; assert `updateNodeParams` dispatched with valid `#rrggbb` values.\n  - Number clamping: For `Brightness.amount`, type `-10` then blur; expect the input value to be corrected to `0` and store updated to `0`.\n  - Enum handling: Provide a dummy test node with `{ mode: { type: 'string', enum: ['a','b'] } }`; select `b` and assert store update to `b` only.\n  - Batched history: Simulate typing `15`, `150`, `180` into `HueShift.deg` quickly; ensure only one temporal history entry is created (spy `useGraphStore.temporal.getState().undo()` reduces to prior value in one step).\n  - Live preview smoke: With a simple `{ Solid(color:'#112233') -> ToK1 }` graph selected, change color and wait for debounce; assert the preview canvas first pixel reflects `#112233` bytes. Mock `evaluateGraphOnce` if needed for deterministic bytes.\n  - Error guards: Force a cycle and ensure the preview shows a warning without throwing.\n\nIntegration tests\n- File: `studio/src/features/graph/GraphCanvas.test.tsx` (extend existing)\n  - Select a node in the canvas (from Task 20 interactions), verify `NodeInspector` shows the correct param controls for that node kind.\n  - Change a param and call graph undo via `graphUndo()`; assert node params revert.\n",
        "status": "pending",
        "dependencies": [
          20
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 22,
        "title": "Publish Metadata: Thread geometryId and palettePolicy through ToK1 publish and surface in telemetry/lastBake",
        "description": "Persist and propagate geometryId and palettePolicy through the Studio ToK1 publish flow, and include them in telemetry events and project.lastBake so they are visible post‑publish.",
        "details": "Codebase alignment and current state\n- ToK1 publish path exists in `studio/src/features/devices/DevicePanel.tsx:1` with bake + upload, including local UI state for `geometryId` and `devicePaletteBlend` (palette policy), and it already sets `lastBake` with these fields on upload completion at `studio/src/features/devices/DevicePanel.tsx:56`.\n- Telemetry append helper is in `studio/src/lib/telemetry.ts:1` (JSONL writer). Current `TelemetryEvent` lacks geometry/palette fields.\n- Upload state machine emits telemetry for phases in `studio/src/stores/upload.ts:1`, but does not include geometryId/palettePolicy because it doesn’t have that context.\n- Project schema already supports `lastBake.geometryId` and `lastBake.palettePolicy` in `studio/src/lib/projectSchema.ts:108`, and `setLastBake` persists them in `studio/src/stores/project.ts:213`.\n\nScope\n- Persist and thread: Ensure `geometryId` and `palettePolicy` flow from the publish UI into both `lastBake` and telemetry entries emitted during/after publish.\n- Surface in telemetry and lastBake: Include these fields in the telemetry JSON lines, at least on the summary \"publish\" (and optionally \"finalizing\"/\"done\") events, and confirm `lastBake` is populated.\n\nImplementation plan\n1) Extend telemetry event shape\n- Update `studio/src/lib/telemetry.ts:1` to add optional fields to `TelemetryEvent`:\n  - `geometryId?: string`\n  - `palettePolicy?: 'host_lut' | 'device_blend'`\n  No changes to write logic; it serializes whatever is provided.\n\n2) Include metadata in publish telemetry snapshot\n- Update `appendTelemetry` call on publish completion in `studio/src/features/devices/DevicePanel.tsx:56` to pass `geometryId` and `palettePolicy`:\n  - palette policy derives from `devicePaletteBlend` toggle and `CAP_PALETTE` capability check (already used at `DevicePanel.tsx:508`) – use the same logic applied for `lastBake`:\n    - `palettePolicy = devicePaletteBlend ? 'device_blend' : 'host_lut'`.\n  - `geometryId` sourced from component state (`DevicePanel.tsx:323`).\n- Optionally, also include these fields on the `finalizing` and `done` events by wiring DevicePanel to emit a final summary event (preferred) or by enriching `useUploadStore.subscribe` only when DevicePanel has context. Simpler and explicit: keep enriched telemetry in DevicePanel’s existing publish snapshot, which already runs when `upload.phase === 'done'`.\n\n3) Thread through bake stats (non‑breaking, future‑proof)\n- Augment return type of `bakeProjectToPrism()` and `packPrism()` to optionally include `geometryId` and `palettePolicy` in `stats` so future callers don’t depend on UI state:\n  - `studio/src/lib/bake/bake.ts:22` – include to `return { bytes, stats: { …, geometryId?, palettePolicy? } }` when provided as optional params to the function (add new optional parameters `geometryId?: string` and `palettePolicy?: 'host_lut'|'device_blend'`).\n  - `studio/src/lib/bake/packPrism.ts:10` and `:131` – extend `PackResult.stats` to allow these fields; do not write them into the ADR‑009 header yet (metadata only).\n- Update `DevicePanel` bake call sites to pass the two fields when available, but continue setting `lastBake` directly (backwards compatible). This keeps the path consistent if other parts start relying on bake stats.\n\n4) No change to graph evaluator\n- The ToK1 graph node (`studio/src/lib/graph/registry.ts:192`) is a sink; no runtime changes required for metadata threading.\n\nNotes\n- Do not change ADR‑009 on‑device file format in this task. Future tasks (e.g., Task 17) will define GeometryProfile packing; this task only ensures Studio metadata is persisted and surfaced.\n- Respect current capability guard for device palette blending (`CAP_PALETTE` in `DevicePanel`).\n",
        "testStrategy": "Unit and integration tests (Vitest + React Testing Library)\n- Telemetry typing: `studio/src/lib/telemetry.ts`\n  - Compile‑time: Ensure `TelemetryEvent` accepts `geometryId` and `palettePolicy`.\n  - Runtime: Mock `@tauri-apps/plugin-fs` and call `appendTelemetry({ ts: 1, phase: 'publish', geometryId: 'K1_LGP_v1', palettePolicy: 'device_blend' })`; assert written JSONL contains those fields.\n\n- DevicePanel publish snapshot: `studio/src/features/devices/DevicePanel.test.tsx` (new)\n  - Render `DevicePanel` with fake window Tauri and an `upload` store transitioning to `done` with known `startedAt/finishedAt` and `bytesPerSec/totalBytes`.\n  - Set local state: `geometryId='K1_LGP_v1'`, `devicePaletteBlend=true`.\n  - Spy on `appendTelemetry` and `useProjectStore.getState().setLastBake`.\n  - Trigger `upload.phase` → 'done' and assert:\n    - `setLastBake` called with `{ geometryId: 'K1_LGP_v1', palettePolicy: 'device_blend', ... }`.\n    - `appendTelemetry` called with `{ phase: 'publish', geometryId: 'K1_LGP_v1', palettePolicy: 'device_blend', ... }`.\n\n- Bake stats threading (optional if implemented): `studio/src/lib/bake/bake.test.ts`\n  - Call `bakeProjectToPrism(graph, 1, 120, 320, [\"#000000\"], true, 'K1_LGP_v1', 'host_lut')` and assert `res.stats.geometryId === 'K1_LGP_v1'` and `res.stats.palettePolicy==='host_lut'`.\n\nManual QA\n- In Studio, run a bake+upload with Geometry set to `K1_LGP_v1` and device palette blend toggled on.\n- Verify `project.lastBake` in memory contains both fields and the telemetry JSONL includes them in the publish entry.\n",
        "status": "pending",
        "dependencies": [
          17,
          18
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 23,
        "title": "Uploader robustness: retries, jittered backoff, ack validation, timeout taxonomy, unified error mapping",
        "description": "Harden the Studio uploader by adding exponential backoff with jitter and bounded retries, strict acknowledgment validation, clear timeout categories, and a consistent error mapping from device and client errors, all the way to user-facing logs/telemetry.",
        "details": "Codebase alignment and targets\n- Primary uploader path: `studio/scripts/upload-pattern.mjs:1`. Current design uses a simple pending-ack queue with a single `ACK_TIMEOUT_MS=5000` and no retries, and does not validate that the acknowledgment matches the request semantics.\n- Protocol reference: `docs/protocol/source-of-truth.md:9` and related sections define TLV types (`PUT_BEGIN=0x10`, `PUT_DATA=0x11`, `PUT_END=0x12`, `CONTROL=0x20`, `STATUS=0x30`, `ERROR=0x40`) and outline maxChunk negotiation and CRC/ack behavior.\n- Mock server: `tools/validation/mock_ws_device.ts:1` echoes the same TLV as ack and can serve as a target for integration tests.\n\nScope\n1) Retry policy + jittered backoff\n- Add a configurable retry policy for send/ack cycles in `upload-pattern.mjs`:\n  - Config: `MAX_RETRIES` (default 4), `BACKOFF_BASE_MS` (default 200), `BACKOFF_FACTOR` (default 2), `BACKOFF_MAX_MS` (default 5000), `JITTER` (full jitter: random in [0, delay]).\n  - Transient errors eligible for retry: WebSocket send errors, ack timeouts, unexpected close during an in-flight op, and recoverable `ERROR` codes (see mapping below; e.g., `max-clients`, `overflow`).\n  - Implement a `withRetry(label, fn)` helper that wraps an operation returning a promise, applying exponential backoff with full jitter between attempts, bailing on non-retryable errors.\n  - When retrying after a dropped connection, perform a reconnect and resume from last confirmed offset for `PUT_DATA` (requires tracking the last successfully acked offset; see ack validation below). If `PUT_BEGIN` has no durable server-side session, restart from `PUT_BEGIN`.\n\n2) Acknowledgment validation\n- Replace the loosely-coupled pending queue resolution with operation-aware ack validation:\n  - Define `validateAck(expected)` that checks:\n    - Frame type: must be either echo of the sent TLV (as in `mock_ws_device.ts`) or a `STATUS` frame when protocol dictates (e.g., future status acks). Default policy: echo is accepted for PUT_* and CONTROL; STATUS is accepted for `STATUS` queries.\n    - For `PUT_DATA`, when echoing, verify the echoed payload’s first 4 bytes `offset_be` matches the requested offset.\n    - For `PUT_BEGIN`, if STATUS acks are ever used, ensure fields are syntactically valid; otherwise, accept echo.\n    - Reject any `ERROR` frame and pass through mapped code (see mapping).\n  - Add sequence context so that only the next expected ack can resolve the current promise; ignore spurious frames unless they are STATUS/info frames and log them as informational.\n\n3) Timeout taxonomy\n- Replace the single `ACK_TIMEOUT_MS` constant with distinct, labeled timeouts:\n  - `CONNECT_TIMEOUT_MS` (open handshake; default 5s)\n  - `ACK_TIMEOUT_MS` (per-frame acknowledgment; default 5s)\n  - `IDLE_TIMEOUT_MS` (no traffic during multi-chunk upload; default 10s)\n- When a timeout triggers, surface a specific error code/category (`timeout/connect`, `timeout/ack`, `timeout/idle`) so downstream code and tests can assert the correct failure mode.\n\n4) Unified error mapping\n- Add a `mapUploaderError(err)` helper that normalizes errors to a stable shape: `{ code: string, cause?: Error, detail?: any }`.\n  - Device `ERROR` payload (type `0x40`) first byte → human code mapping, aligned with current `describeError()` in `upload-pattern.mjs:203` but returned as normalized codes:\n    - `0x00: ok`, `0x01: max-clients`, `0x02: overflow`, `0x03: invalid`, `0x04: storage-full`, `0x05: not-found`, `else: device-error`.\n  - Client-side: `ws/connect-failed`, `ws/send-failed`, `ws/closed`, `timeout/connect`, `timeout/ack`, `timeout/idle`, `protocol/invalid-ack`, `protocol/crc-mismatch`.\n  - Ensure every thrown error in uploader paths wraps via `mapUploaderError` before logging or rethrowing.\n- Update console output to show normalized codes alongside short human text. Keep raw Error stack attached as `cause` when running with `NODE_ENV=development`.\n\n5) Preflight STATUS + maxChunk negotiation (optional but recommended)\n- Before `PUT_BEGIN`, send a `STATUS` request, parse `maxChunk` (see `docs/protocol/source-of-truth.md:52`) and clamp `chunkSize` to `≤maxChunk`. Fall back to default when absent.\n\n6) Implementation outline (file: `studio/scripts/upload-pattern.mjs`)\n- Introduce new config constants at top of file and a small `sleep(ms)` util.\n- Add `connectWithTimeout(url, timeout)` that returns an open socket or throws `timeout/connect`.\n- Refactor `sendFrame()` into `sendWithAck(type, payload, ctx)` that:\n  - pushes a single pending waiter, starts an `ACK_TIMEOUT_MS` timer, sends, and validates incoming frame using `validateAck`.\n  - wraps send/ack in `withRetry(label, op)` and reconnects on retry if socket closed.\n- Track `uploadCtx = { ws, pending, lastAckedOffset }`. Update `uploadPattern` to set `lastAckedOffset` after each `PUT_DATA` ack.\n- On reconnect retry, if `lastAckedOffset >= 0`, resume `PUT_DATA` from `lastAckedOffset + chunkLen` with a fresh `PUT_BEGIN` only when device-side sessions don’t persist beyond disconnect (default: restart BEGIN for safety unless a future STATUS indicates resumable sessions).\n\n7) Telemetry/log hooks (non-breaking)\n- Leave breadcrumbs in logs with normalized error codes and attempt counts, so `tools/validation/soak_*` scripts can parse outcomes. Do not change log format in ways that break existing CI, only enrich lines.\n\nReferences in repo\n- Uploader implementation to modify: `studio/scripts/upload-pattern.mjs`.\n- Protocol reference: `docs/protocol/source-of-truth.md` (types, maxChunk, CRC, behavior notes).\n- Mock device for tests: `tools/validation/mock_ws_device.ts`.\n- Soak tools that will benefit: `tools/validation/soak_playlist.ts` and `.py` (they already verify CRC at `PUT_END`).\n",
        "testStrategy": "Unit and integration tests (Node + Vitest)\n- Unit: `studio/scripts/upload-pattern.test.mjs`\n  - backoff: Given `MAX_RETRIES=3`, verify attempt intervals follow ~200ms, ~400ms, ~800ms with full jitter bounds and cap at `BACKOFF_MAX_MS`.\n  - ack validator: For a `PUT_DATA` with offset 4096, feed an echoed ack frame with matching offset → pass; feed a mismatched offset → throw `protocol/invalid-ack`.\n  - timeout taxonomy: Stub timers to force `CONNECT_TIMEOUT_MS`, `ACK_TIMEOUT_MS`, `IDLE_TIMEOUT_MS` expirations and assert mapped codes (`timeout/connect`, `timeout/ack`, `timeout/idle`).\n  - error mapping: Map device `ERROR 0x04` to `{ code: 'storage-full' }`; map send error to `{ code: 'ws/send-failed' }`.\n\n- Integration: `tools/validation/mock_ws_device.ts`\n  - Happy path: Run the CLI against the mock server to upload a small `.prism` file, asserting logs include `PUT_BEGIN acknowledged`, `PUT_DATA complete`, `PUT_END acknowledged`.\n  - Chaos acks: Extend mock to support env flags (e.g., `MOCK_DROP_RATE=0.2`, `MOCK_DELAY_MS=150`) to randomly drop or delay responses. Verify uploader retries and eventually completes within retry budget.\n  - Reconnect resume: Add a mode where the mock closes the connection once during `PUT_DATA` (e.g., after first 3 chunks). Assert the uploader reconnects and restarts (BEGIN+DATA) or resumes per policy, then completes.\n\n- Soak/CI signal\n  - Run a 50-upload soak (Task 10 tooling) against the mock with `MOCK_DROP_RATE` set to a small value (e.g., 0.05) and ensure zero failures. Capture attempt counts and confirm no individual upload exceeds a set max duration.\n",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 24,
        "title": "Resumable Uploads with STATUS‑Gated Caps and Studio/Firmware Support",
        "description": "Add offset‑resumable pattern uploads gated by STATUS capabilities. Negotiate resume support, implement device state machine changes, add a PUT_RESUME path in Studio with fallback to full upload when caps are absent.",
        "details": "Codebase alignment and current behavior\n- Studio backend currently streams PUT_BEGIN → PUT_DATA(offset,u8[]) → PUT_END in `studio/src-tauri/src/lib.rs:420` via `upload_with_emitter()`. It does a single reconnect on send failure by re‑STATUSing, reopening WS, and re‑issuing PUT_BEGIN, then continues sending chunks from the current client offset without server negotiation (no explicit resume support on device).\n- STATUS payload decoding already threads optional capabilities to the UI as `caps` (see `studio/src-tauri/src/lib.rs:640` decode_status_payload) and Studio has capability bits defined in `studio/src/lib/protocol.ts:14` including `CAP_RESUME`.\n\nWhat to implement\n1) Protocol additions (Studio side)\n- Add a new TLV constant for resume: `export const TLV_PUT_RESUME = 0x13 as const;` in `studio/src/lib/protocol.ts:1` alongside PUT_*.\n- Define client resume frame payload layout to keep messages compact and self‑consistent with existing `PUT_BEGIN`:\n  - `PUT_RESUME` payload: `[name_len:u8][name:bytes][offset:u32 BE]`.\n  - Server acks by echoing a valid TLV with matched type/len/crc (same validator used today). If the device supports a stronger validator, it may respond with `ERROR` (0xFF) on mismatch.\n\n2) Device state machine (firmware)\n- Extend the upload handler state to include `RxBegin{ name,size,crc,received }`, `RxData`, `Completed`, and add a `ResumeAllowed` flag that is set when STATUS caps includes `CAP_RESUME`.\n- On `PUT_BEGIN`: initialize a fresh session and truncate/rewind partial file if any; set `received=0`.\n- On `PUT_RESUME`: if `ResumeAllowed` is true and `session.name` matches, seek to `offset` if `offset ≤ size` and underlying storage contains exactly `offset` bytes; set `received=offset` and return ack. Otherwise return `ERROR(\"SESSION/RESUME\")`.\n- On `PUT_DATA`: continue to require `[offset:u32 BE][bytes...]`; validate `offset==received` using safe bounds checks (see patterns in `firmware/components/core/prism_secure.c:182` and related tests). Append and increment `received`.\n- On `PUT_END`: reject non‑empty payload (existing Studio tests assert 0‑length). Finalize only if `received == size`.\n- STATUS caps: set `CAP_RESUME` bit to advertise support; already decoded by Studio when present.\n\n3) Studio uploader negotiation and resume path\n- Parse `caps` early in `upload_with_emitter()` by decoding the STATUS payload (already fetched). Gate resume behavior with a boolean `can_resume = caps & CAP_RESUME`.\n- First session follows existing flow: send `PUT_BEGIN` and stream `PUT_DATA` frames with `[offset:u32 BE]` (already implemented at `studio/src-tauri/src/lib.rs:480`).\n- On send/read failure mid‑stream or WS drop:\n  - If `can_resume`:\n    - Reconnect WS.\n    - Send `PUT_RESUME` with `[name_len][name][offset=sent:u32 BE]`.\n    - Await ack; on success, continue sending PUT_DATA from `sent` offset without re‑sending old bytes.\n    - On `PUT_RESUME` NACK/ERROR, fall back to fresh upload (below).\n  - If not `can_resume` (or resume failed): re‑STATUS, re‑open WS, re‑send `PUT_BEGIN`, and restart from offset 0 as today.\n- Preserve existing behaviors: maxChunk negotiation via STATUS, cancel semantics, EMA throughput, 10 Hz progress emits, and empty `PUT_END`.\n- Add resume telemetry breadcrumbs in `studio/src/lib/telemetry.ts` emit path (optional but recommended): `appendTelemetry({ phase: 'upload', action: 'resume', offset, ts })` when a resume handshake succeeds or when falling back.\n\n4) UI/UX affordances (minimal)\n- No new UI required. Optionally annotate `ProgressPanel` with a transient toast like “Resumed at 16384 bytes” on successful resume; leverage existing toast mechanism in `DevicePanel.tsx` where feasible.\n\n5) Error mapping additions\n- In `studio/src/lib/uploadErrors.ts`, map resume‑specific server errors to actionable text, e.g., codes containing `RESUME` → “Device could not resume upload (session mismatch or storage unavailable). Restarting from the beginning.” Ensure mapping maintains current fallbacks.\n\n6) Wire‑ups and constants\n- Add TLV constant to Rust side for readability (optional): `const TLV_PUT_RESUME: u8 = 0x13;` and use it to build frames for the resume handshake.\n- Keep CRC framing identical by reusing `build_tlv_frame()` in `studio/src-tauri/src/lib.rs:336`.\n\nImplementation sketch (Studio, Rust)\n- In `upload_with_emitter()` around the reconnect branch at `studio/src-tauri/src/lib.rs:500`:\n  - Decode STATUS caps to set `can_resume` (parse `caps` u32 if present after `max_chunk` and `templateCount`).\n  - If `can_resume`, before `PUT_BEGIN` on reconnect, send `PUT_RESUME`:\n    `let mut resume = Vec::with_capacity(1+name.len()+4); resume.push(name.len() as u8); resume.extend_from_slice(name.as_bytes()); resume.extend_from_slice(&(sent as u32).to_be_bytes()); let frame_r = build_tlv_frame(0x13, &resume); ws.send(Message::Binary(frame_r)).await?; if let Some(Ok(Message::Binary(_))) = ws.next().await { /* ok */ } else { /* fallback to begin */ }`\n  - Else fall back to the existing `PUT_BEGIN` re‑start branch.\n\nNotes and constraints\n- Backward compatibility: All resume logic is gated by STATUS caps; devices without `CAP_RESUME` see no change.\n- Security/robustness: Maintain 256KB device file limit and offset bounds checks. Keep TLV CRC checks unchanged.\n- Keep `PUT_END` payload empty; tests already enforce this (`studio/src-tauri/src/lib.rs:788`).\n",
        "testStrategy": "Unit and integration tests (Rust + Vitest where applicable)\n\nRust (Tauri backend)\n1) Resume handshake success\n- In `studio/src-tauri/src/lib.rs` tests module, add a mock WS server that:\n  - First connection: ack `PUT_BEGIN`, drop after first `PUT_DATA`.\n  - Second connection: expect `PUT_RESUME` with correct `[name_len][name][offset=chunk_size]`, ack, then accept remaining `PUT_DATA`, then expect `PUT_END` with 0‑length payload.\n- Assert uploader returns Ok and that the number of bytes sent after resume equals the remaining payload.\n\n2) Resume fallback when caps absent\n- Mock STATUS without caps field or with `caps & CAP_RESUME == 0`.\n- Server drops after first `PUT_DATA`.\n- Assert client re‑sends `PUT_BEGIN` and restarts from offset 0; verify by capturing offsets in received `PUT_DATA` frames.\n\n3) Resume rejected by server\n- Caps signal resume, but server responds with `ERROR` frame on `PUT_RESUME`.\n- Assert client falls back to `PUT_BEGIN` restart and completes upload.\n\n4) Invariants preserved\n- Reuse existing `put_end_has_empty_payload` test to ensure unchanged behavior for PUT_END.\n- Add a test asserting that `max_chunk` re‑negotiation still happens on reconnect prior to resuming.\n\nTypeScript (Studio)\n- Protocol constants\n  - Add a unit test in `studio/src/lib/protocol.test.ts` asserting TLV constants include `TLV_PUT_RESUME=0x13` and bit math for `CAP_RESUME` remains stable.\n\nOptional UI test\n- If a toast is added for resume, add a small React test in `studio/tests` or colocated test ensuring the resume toast appears when a mock progress event with `{ action: 'resume' }` is appended.\n",
        "status": "pending",
        "dependencies": [
          23
        ],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-10-17T11:54:25.384Z",
      "taskCount": 19,
      "completedCount": 12,
      "tags": [
        "master"
      ],
      "created": "2025-10-17T13:31:13.120Z",
      "description": "Tasks for master context",
      "updated": "2025-10-17T13:43:08.768Z"
    }
  }
}