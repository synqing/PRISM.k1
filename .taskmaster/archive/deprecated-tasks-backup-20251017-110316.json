{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Establish component scaffolding and runtime orchestration",
        "description": "Create ESP-IDF component structure for network, storage, playback, and templates, then wire them into the main firmware entry point with task scheduling and error propagation.",
        "details": "Implementation:\n- Create `firmware/components/{network,storage,playback,templates}` with `CMakeLists.txt`, public headers (e.g., `network_manager.h`, `pattern_storage.h`), and stub source files exposing `*_init()` and FreeRTOS task entry points.\n- Update `firmware/CMakeLists.txt` `EXTRA_COMPONENT_DIRS` to include the new components and ensure include paths export shared headers (`components/include`).\n- Extend `firmware/main/main.c` to include the new headers, call `network_init()`, `storage_init()`, `playback_init()`, `templates_init()` after `system_init()`, and create FreeRTOS tasks using the defined stack sizes and priorities.\n- Add centralized failure handling so any init error routes through `error_handler` once implemented.\nPseudo-code:\n```\nvoid app_main(void) {\n    print_system_info();\n    ESP_ERROR_CHECK(system_init());\n    ESP_ERROR_CHECK(network_init());\n    ESP_ERROR_CHECK(storage_init());\n    ESP_ERROR_CHECK(playback_init());\n    ESP_ERROR_CHECK(templates_init());\n    xTaskCreate(network_task, \"network\", STACK_NETWORK, NULL, PRIORITY_NETWORK, NULL);\n    ...\n}\n```",
        "testStrategy": "Run `idf.py build` to verify new components integrate; add Unity smoke tests that call each `*_init()` stub; flash to hardware and confirm boot log shows all init stages without watchdog resets.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold ESP-IDF component directories",
            "description": "Create initial network, storage, playback, and templates components with headers and stub sources.",
            "dependencies": [],
            "details": "Under `firmware/components`, add folders for network, storage, playback, and templates, each with `CMakeLists.txt`, a public header exposing `*_init()` and FreeRTOS task prototypes, and stub `.c` files returning `ESP_OK`.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Wire new components into build system",
            "description": "Register the new components with the firmware build configuration and shared include paths.",
            "dependencies": [
              1
            ],
            "details": "Update `firmware/CMakeLists.txt` to append the four component directories to `EXTRA_COMPONENT_DIRS`, ensure `components/include` is exported for shared headers, and confirm each component lists its public headers in `idf_component_register`.",
            "status": "done",
            "testStrategy": "Run `idf.py reconfigure` to ensure CMake picks up the new directories without errors.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Extend app_main for initialization and task orchestration",
            "description": "Modify the firmware entry point to initialize components and launch tasks with centralized error handling.",
            "dependencies": [
              1,
              2
            ],
            "details": "Include the new component headers in `firmware/main/main.c`, call each `*_init()` after `system_init()` wrapped in `ESP_ERROR_CHECK`, create FreeRTOS tasks with agreed stack sizes/priorities, and route any init failure through the shared `error_handler`.",
            "status": "done",
            "testStrategy": "Build the project and inspect the `app_main` flow in `idf.py monitor` once tasks are running to verify staged init logs.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add scaffolding smoke tests and build verification",
            "description": "Introduce basic tests and build checks covering the new component scaffolding and orchestrated startup.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Create Unity smoke tests that call each `*_init()` stub to confirm linkage, add a CI or local script target running `idf.py build`, and document the expected boot log checkpoints for manual verification.",
            "status": "done",
            "testStrategy": "Execute Unity smoke tests via `idf.py test` (or equivalent) and run `idf.py build` to ensure the scaffolding integrates cleanly.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Break this work into subtasks covering (1) creating ESP-IDF component skeletons for network/storage/playback/templates with headers and stubs, (2) updating build files and exports, (3) extending app_main to orchestrate init and FreeRTOS tasks with centralized error routing, and (4) adding smoke tests/build verification.",
        "updatedAt": "2025-10-15T17:23:29.510Z"
      },
      {
        "id": 2,
        "title": "Implement WiFi lifecycle, captive portal, and mDNS broadcasting",
        "description": "Develop the network manager component providing AP setup, STA onboarding, credential persistence, captive portal, and mDNS service advertisement per PRD requirements.",
        "details": "Implementation:\n- In `components/network/network_manager.c`, configure dual-mode WiFi: start AP (`PRISM-SETUP`) using `esp_netif_create_default_wifi_ap()`, host captive portal via `esp_http_server`, and transition to STA mode once credentials are submitted, storing them with NVS APIs.\n- Implement exponential backoff reconnect loop (`WIFI_RETRY_MAX`) with event handlers for `WIFI_EVENT` and `IP_EVENT` to maintain uptime.\n- Register mDNS using `mdns_init()` with host `\"prism-k1\"` and service `_prism._tcp`.\n- Expose `network_init()` to set up netifs and `network_task(void*)` to manage portal lifecycle and status broadcasts.\nPseudo-code:\n```\nesp_err_t network_init(void) {\n    wifi_init_config_t wifi_cfg = WIFI_INIT_CONFIG_DEFAULT();\n    ESP_ERROR_CHECK(esp_wifi_init(&wifi_cfg));\n    start_ap_portal();\n    register_event_handlers();\n    mdns_init();\n    return ESP_OK;\n}\n```\n- Ensure memory allocations use `prism_pool_alloc` where possible to avoid fragmentation.",
        "testStrategy": "Add Unity tests with `esp_event_loop_run()` mocked to validate backoff timing; on hardware, run captive portal flow and verify `mdns_query_ptr()` returns `prism-k1.local`; measure reconnect handling by cycling router power.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Establish WiFi dual-mode initialization",
            "description": "Set up foundational WiFi interfaces and event loop enabling AP and STA operation.",
            "dependencies": [],
            "details": "Initialize ESP netifs, configure PRISM-SETUP SSID via esp_netif_create_default_wifi_ap, call esp_wifi_init with default config, and expose network_init while using prism_pool_alloc for dynamic buffers.\n<info added on 2025-10-15T17:58:33.766Z>\nImplemented network_private.h with the WiFi lifecycle state machine scaffolding and declarations, updated components/network/CMakeLists.txt to pull in esp_http_server, mdns, core, and lwip, and added init_wifi_dual_mode() to initialize esp_netif, create the default event loop, bring up AP and STA netifs, set WiFi storage to RAM, and delegate AP startup to start_ap_mode() configured for the PRISM-SETUP open AP. Expanded network_init() to initialize NVS, call init_wifi_dual_mode(), register WIFI_EVENT/IP_EVENT handlers (logging only for now), launch the AP, and chain into start_captive_portal() and load_credentials_from_nvs() placeholders; introduced additional stubs (e.g., mDNS helpers) earmarked for subtasks 2.2–2.5 with build readiness confirmed under the ESP-IDF environment.\n</info added on 2025-10-15T17:58:33.766Z>",
            "status": "done",
            "testStrategy": "Create a Unity test harness that stubs esp_wifi_init and verifies network_init registers both AP and STA netifs.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Build captive portal HTTP workflow",
            "description": "Implement the captive portal server handling credential submission and AP lifecycle.",
            "dependencies": [
              1
            ],
            "details": "Spin up esp_http_server with handlers for credential form, serve minimal assets from flash, and ensure portal teardown triggers STA transition when credentials are posted.\n<info added on 2025-10-15T18:00:05.532Z>\nCaptive portal HTTP server implemented with embedded credential and success HTML forms, GET “/” serving the form, POST “/connect” parsing URL-encoded payloads via parse_form_data, persisting credentials through save_credentials_to_nvs, updating g_net_state, and signaling STA transition while a wildcard GET handler satisfies captive portal probes. start_captive_portal launches esp_http_server on port 80 with four sockets, LRU purge, and 4KB stack; stop_captive_portal performs graceful teardown. Form buffers now come from prism_pool_alloc and are released after use, HTML assets live in firmware, and 400/408/500 responses cover error paths. Success flow leaves the portal with credentials_available set for network_task to continue with Subtask 2.3.\n</info added on 2025-10-15T18:00:05.532Z>",
            "status": "done",
            "testStrategy": "Use Unity plus HTTP client mocks to submit credentials and confirm portal handlers return expected responses and cleanup callbacks run.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement credential persistence with NVS",
            "description": "Store and retrieve WiFi credentials securely using NVS once provided by the portal.",
            "dependencies": [
              2
            ],
            "details": "Leverage nvs_open and nvs_set_str to persist SSID/password, ensure prism_pool_alloc buffers are zeroed after use, and validate credentials before initiating STA connect.\n<info added on 2025-10-15T18:01:26.128Z>\nImplemented load_credentials_from_nvs() to open the prism_wifi namespace in read-only mode, check the u8 configured flag, and hydrate g_net_state SSID/password buffers (33/64 byte limits) with NULL-safe handling for open networks while setting credentials_available when successful. Added save_credentials_to_nvs() that opens prism_wifi in read-write mode, writes ssid/password keys with nvs_set_str (erasing password for open networks), updates configured=1, commits, and always closes the handle with proper error propagation. Documented the prism_wifi schema (configured u8, ssid string, password string), wired load into network_init() and save into portal_post_handler() so network_task can act on credentials_available, and emphasized NVS handle cleanup plus the recommendation to enable flash encryption to protect stored passwords.\n</info added on 2025-10-15T18:01:26.128Z>",
            "status": "done",
            "testStrategy": "Write NVS mock-based tests verifying credentials persist across network_task restarts and that invalid data paths trigger cleanup.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add reconnect backoff and event handlers",
            "description": "Maintain WiFi uptime through exponential backoff reconnect logic tied to system events.",
            "dependencies": [
              1,
              3
            ],
            "details": "Register WIFI_EVENT and IP_EVENT handlers, implement WIFI_RETRY_MAX governed exponential backoff, and ensure timers use prism_pool_alloc allocations while updating status broadcasts.\n<info added on 2025-10-15T18:02:57.812Z>\nImplemented start_sta_connection() to configure the STA with persisted credentials, enforce WPA2-PSK with optional PMF, and enter WIFI_MODE_STA_CONNECTING via esp_wifi_connect(); transition_to_sta_mode() now halts the captive portal while retaining AP fallback, resets retry counters (retry_count=0, retry_delay_ms=1000), and launches the first STA attempt; update_retry_delay() applies capped exponential backoff (1s, 2s, 4s, 8s, 16s, then 30s) with continuous retries after the fifth attempt; wifi_event_handler() covers AP join/leave along with the full STA lifecycle, triggering timed reconnects on disconnect, clearing counters on success, and updating mode state when the STA stops; ip_event_handler() starts or stops mDNS as IP leases are gained or lost and synchronizes mode state accordingly; network_task() now boots into STA when credentials exist, reacts to new portal credentials, and polls every five seconds for mode monitoring, leaving the subtask ready for 2.5 mDNS advertisement work.\n</info added on 2025-10-15T18:02:57.812Z>",
            "status": "done",
            "testStrategy": "Simulate event sequences in Unity to assert backoff timing increases exponentially and resets on successful connection.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Configure mDNS advertisement service",
            "description": "Expose device discovery via mDNS once STA connectivity is established.",
            "dependencies": [
              1,
              4
            ],
            "details": "Call mdns_init after WiFi stack ready, register host prism-k1 and _ws._tcp service with correct port, and ensure lifecycle hooks restart mDNS on reconnect events.\n<info added on 2025-10-15T18:03:59.113Z>\nImplemented start_mdns_service() to call mdns_init(), set hostname prism-k1 (prism-k1.local), assign instance name PRISM K1 LED Controller, and register _http._tcp and _prism._tcp services on port 80 with TXT records version=1.0, device=prism-k1, leds=320. Added stop_mdns_service() that guards with g_net_state.mdns_initialized, invokes mdns_free(), and clears the flag for idempotent teardown. start_mdns_service() now runs from ip_event_handler() on IP_EVENT_STA_GOT_IP, while stop_mdns_service() executes on IP_EVENT_STA_LOST_IP and during network_deinit(), ensuring the service restarts cleanly across reconnects. Error paths propagate mdns_* failures and ensure mdns_free() executes so partial registrations do not leak resources.\n</info added on 2025-10-15T18:03:59.113Z>",
            "status": "done",
            "testStrategy": "Mock mdns APIs to verify service registration parameters and confirm restart occurs after reconnect event sequence.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Define unit and integration validation coverage",
            "description": "Plan and script tests covering WiFi lifecycle, portal flow, persistence, and mDNS discovery.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "Document Unity test cases, hardware-in-loop procedures for captive portal, reconnection cycling, and mdns_query_ptr discovery; integrate into CI runbook.\n<info added on 2025-10-15T18:05:58.853Z>\nCaptured comprehensive Unity suite under components/network/test with test_network_manager.c (23 cases spanning network init, NVS persistence, captive portal HTTP parsing, reconnection backoff, mDNS registration, integration flows, and memory safety) plus test/CMakeLists.txt and test/README.md documenting run steps and >80% coverage goals. Documented required mocks for esp_wifi, esp_netif, nvs, mdns, esp_http_server, and esp_event loop; outlined manual hardware checklists (6-step portal flow, 7-step reconnection timing, 5-step persistence power-cycle, mDNS discovery via avahi-browse/dns-sd) so validation can start immediately while mock implementation and hardware execution remain outstanding.\n</info added on 2025-10-15T18:05:58.853Z>",
            "status": "done",
            "testStrategy": "Consolidate test matrix ensuring continuous integration runs Unity suites and schedules periodic on-device verification.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Decompose into subtasks for WiFi dual-mode setup, captive portal HTTP server, credential persistence via NVS, reconnect/backoff logic with event handlers, mDNS advertisement, and unit/integration test coverage."
      },
      {
        "id": 3,
        "title": "Build WebSocket server with TLV-aware session management",
        "description": "Create a WebSocket handler supporting binary TLV messages, 4KB receive buffer, two concurrent clients, reconnection backoff, and error codes per ADR-002.",
        "details": "Implementation:\n- Under `components/network/websocket_handler.c`, use `httpd_ws_conn` from ESP-IDF to upgrade HTTP connections to WebSocket; allocate a fixed 4KB RX buffer per connection using memory pools.\n- Track active clients in a bounded array, rejecting additional connections with error 0x01.\n- Implement state machine (IDLE→RECEIVING→VALIDATING→STORING) with timers enforcing `WS_TIMEOUT_MS` and resume logic after errors.\n- Encode status frames (type 0x30) reporting heap and cache metrics from `prism_heap_monitor` and storage stats.\nPseudo-code:\n```\nstatic esp_err_t websocket_recv_task(void* arg) {\n    while (1) {\n        size_t len = WS_BUFFER_SIZE;\n        httpd_ws_recv_frame(client->hd, &frame, WS_TIMEOUT_MS);\n        switch (frame.type) {\n            case 0x10: handle_put_begin(frame.payload); break;\n            ...\n        }\n    }\n}\n```\n- Integrate exponential backoff reconnect attempts for clients and propagate errors via `error_handler`.",
        "testStrategy": "Create unit tests using `unity` with mocked `httpd_ws_recv_frame` to validate buffer boundaries and error code responses; run throughput benchmark using `idf.py monitor` with host script pushing 500KB/s payloads verifying sustained rate and no heap growth.",
        "priority": "medium",
        "dependencies": [
          "1",
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement WebSocket upgrade and session registry",
            "description": "Integrate ESP-IDF WebSocket upgrade flow and track connected sessions in the handler entry point.",
            "dependencies": [],
            "details": "Create the initial handler in components/network/websocket_handler.c that upgrades HTTP requests via httpd_ws_conn, persists client metadata, and initializes session bookkeeping structures.",
            "status": "pending",
            "testStrategy": "Add a Unity test with mocked httpd request objects verifying upgrade success and client slot initialization.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Enforce two-client limit with fixed 4KB buffers",
            "description": "Allocate per-client receive buffers and reject excess connection attempts with ADR-002 error codes.",
            "dependencies": [
              1
            ],
            "details": "Attach a 4KB RX buffer from the memory pool to each active client and block additional upgrades by responding with error code 0x01 while freeing any provisional resources.",
            "status": "pending",
            "testStrategy": "Use Unity to simulate three connection attempts and assert only two succeed while the third receives the expected error response.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build TLV-driven session state machine",
            "description": "Implement IDLE→RECEIVING→VALIDATING→STORING states handling TLV frames and timeout enforcement.",
            "dependencies": [
              1,
              2
            ],
            "details": "Design a state machine that reads binary frames, validates TLV payloads, transitions across protocol states, and resets on timeout or validation failure while preserving resume logic.",
            "status": "pending",
            "testStrategy": "Mock httpd_ws_recv_frame delivering ordered and malformed TLVs to ensure state transitions and timeout handling follow ADR-002.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate reconnect backoff and error propagation",
            "description": "Add exponential backoff retry logic per client and route failures through error_handler.",
            "dependencies": [
              3
            ],
            "details": "Implement reconnect scheduling that escalates delays on repeated failures, invokes error_handler with ADR-002 codes, and restores sessions without leaking buffers or dangling timers.",
            "status": "pending",
            "testStrategy": "Simulate repeated disconnects to confirm increasing backoff intervals and verify error_handler captures each failure path.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Execute validation and throughput testing",
            "description": "Run automated checks covering buffer bounds, state transitions, and sustained data rates.",
            "dependencies": [
              3,
              4
            ],
            "details": "Develop Unity suites for buffer overflow prevention and state coverage, then run integration throughput checks driving 500KB/s payloads via idf.py monitor to observe heap and cache stability.",
            "status": "pending",
            "testStrategy": "Leverage existing Unity harness plus manual throughput script to confirm metrics and absence of heap growth during sustained transfers.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Outline subtasks for WebSocket upgrade handling with two-client limit, fixed-buffer management, TLV state machine implementation, reconnect/error propagation, and validation/testing including throughput checks.",
        "updatedAt": "2025-10-16T08:13:17.108Z"
      },
      {
        "id": 4,
        "title": "Implement TLV protocol parser and command dispatcher",
        "description": "Develop a protocol parser that validates TLV payloads, performs CRC checks, and dispatches commands to storage and playback subsystems.",
        "details": "Implementation:\n- Add `components/network/protocol_parser.c` with `protocol_parse_frame(const ws_frame_t*, protocol_context_t*)` that decodes `[TYPE][LEN][PAYLOAD][CRC]` per PRD, using `ws_validate_*` helpers from `prism_secure`.\n- Maintain upload context for PUT_BEGIN/DATA/END with CRC32 accumulation via `esp_rom_crc32`, ensuring 256KB size cap.\n- Map CONTROL commands to playback actions (play, pause, crossfade) and STATUS queries to telemetry assembly.\n- Provide callback hooks (`protocol_handlers_t`) so storage and playback modules register their handlers during init.\nPseudo-code:\n```\nswitch (type) {\n    case MSG_PUT_BEGIN: storage_begin_upload(payload);\n    case MSG_PUT_DATA: storage_write_chunk(offset, data, len);\n    case MSG_PUT_END: storage_finalize_upload(success_flag);\n    case MSG_CONTROL: playback_apply_command(command_id, params);\n}\n```\n- Ensure invalid sequences trigger error frames with codes 0x02/0x03.",
        "testStrategy": "Add parser unit tests feeding crafted frames to verify CRC rejection and size enforcement; run integration test with `idf.py unity` ensuring uploads stream into a mocked storage backend without fragmentation.",
        "priority": "medium",
        "dependencies": [
          "3"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement TLV frame validation and CRC checks",
            "description": "Add TLV parsing routine that validates headers, lengths, and CRC for inbound frames.",
            "dependencies": [],
            "details": "Create protocol_parse_frame to read TYPE/LEN/PAYLOAD/CRC, use ws_validate helpers, and accumulate CRC32 with esp_rom_crc32 while enforcing payload length limits.",
            "status": "pending",
            "testStrategy": "Write unit tests feeding malformed frames to confirm length and CRC failures return expected error codes 0x02 and 0x03.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Manage upload session state with size enforcement",
            "description": "Track PUT upload lifecycle and cap aggregated payload size at 256KB.",
            "dependencies": [
              1
            ],
            "details": "Maintain protocol_context_t fields for PUT_BEGIN/DATA/END, accumulate CRC across chunks, reject out-of-order frames, and abort sessions exceeding 256KB.",
            "status": "pending",
            "testStrategy": "Simulate segmented uploads in tests to verify CRC accumulation, overflow rejection, and invalid sequencing handling.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Wire storage command dispatch handlers",
            "description": "Forward storage-related protocol messages to registered storage callbacks.",
            "dependencies": [
              2
            ],
            "details": "Implement protocol_handlers_t registration and route MSG_PUT_* cases to storage_begin_upload, storage_write_chunk, and storage_finalize_upload with success flag resolution.",
            "status": "pending",
            "testStrategy": "Mock storage handlers in unit tests to assert correct invocation sequence and error handling when callbacks report failures.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate playback control and status dispatch",
            "description": "Handle CONTROL and STATUS frames by invoking playback callbacks and assembling telemetry responses.",
            "dependencies": [
              1
            ],
            "details": "Map MSG_CONTROL frames to playback_apply_command operations, translate payload params, and compose STATUS replies using telemetry helpers exposed via protocol_handlers_t.",
            "status": "pending",
            "testStrategy": "Add tests verifying playback command decoding, telemetry assembly, and error frame emission when handlers decline commands.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Build comprehensive parser test suite",
            "description": "Create unit and integration tests covering parser, storage, and playback interactions.",
            "dependencies": [
              3,
              4
            ],
            "details": "Extend Unity test harness with crafted TLV vectors, end-to-end upload simulations, and playback command scenarios to validate protocol_parser behavior across success and failure cases.",
            "status": "pending",
            "testStrategy": "Run Unity suite and integration flows ensuring PUT uploads reach mock storage, playback commands execute, and status queries return expected telemetry.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Create subtasks for frame validation/CRC logic, upload session management with size enforcement, command-to-storage mapping, playback control hookups, and comprehensive unit/integration tests.",
        "updatedAt": "2025-10-16T08:13:17.843Z"
      },
      {
        "id": 5,
        "title": "Integrate LittleFS storage and pattern persistence APIs",
        "description": "Mount the LittleFS partition, expose pattern CRUD operations, and enforce storage quotas and CRC verification per ADR-001/005.",
        "details": "Implementation:\n- In `components/storage/pattern_storage.c`, call `esp_vfs_littlefs_register` for partition `\"littlefs\"` at mount path `/littlefs`, fail fast if formatting needed.\n- Implement APIs: `storage_init()`, `pattern_storage_open`, `pattern_storage_write_chunk`, `pattern_storage_finalize` (with CRC32), `pattern_storage_list`, and quota checks to maintain 1.5MB limit minus safety margin.\n- Use shared palette files under `/littlefs/templates` and manage atomic writes via temp files and `rename`.\nPseudo-code:\n```\nesp_err_t storage_init(void) {\n    const esp_vfs_littlefs_conf_t conf = { .base_path = STORAGE_PATH, .partition_label = STORAGE_LABEL, ... };\n    ESP_ERROR_CHECK(esp_vfs_littlefs_register(&conf));\n    return storage_verify_templates();\n}\n```\n- Wire into protocol callbacks for PUT_* handling.",
        "testStrategy": "Add Unity tests using `esp_littlefs` host stub to simulate writes and CRC mismatches; run on device with power cycle to ensure remount succeeds and files persist; monitor heap via `prism_heap_monitor_dump_stats` after repeated uploads.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Mount LittleFS partition for pattern storage",
            "description": "Configure and verify the LittleFS partition mount used by pattern storage.",
            "dependencies": [],
            "details": "Define mount constants, call esp_vfs_littlefs_register for label \"littlefs\", ensure format-on-fail is disabled, and return an error if registration fails.\n<info added on 2025-10-15T18:06:58.881Z>\nPre-implementation analysis underway: inventorying all usages of the LittleFS partition offset so the shift from 0x320000 to 0x311000 per ADR-001 updates `firmware/partitions.csv`, build artifacts under `firmware/build/log/`, and any hardcoded mount descriptors without breaking alignment or overlapping OTA slots. Also auditing every reference to `PATTERN_MIN_COUNT` (currently defined in `firmware/components/core/include/prism_config.h`) to confirm dropping the baseline to 15 per ADR-006 stays compatible with quota math, CRC validations, and existing unit/integration tests before touching code.\n</info added on 2025-10-15T18:06:58.881Z>\n<info added on 2025-10-15T18:20:55.422Z>\nIntroduce a static FreeRTOS mutex to guard mount/unmount sequencing; fetch the LittleFS partition via esp_partition_find_first and validate its offset/size against ADR-001 before mounting; call esp_vfs_littlefs_register for label littlefs at /littlefs with format_if_mount_failed kept false; emit detailed ESP_LOGE entries for each failure path (partition lookup, validation, registration, directory creation) capturing esp_err_to_name codes; on success create /littlefs/templates with mkdir and treat any errno other than EEXIST as fatal; ensure every exit path releases the mutex and propagates the precise esp_err_t to callers.\n</info added on 2025-10-15T18:20:55.422Z>\n<info added on 2025-10-15T18:23:45.091Z>\nImplementation finalized: storage_init creates a static FreeRTOS mutex, validates the ADR-007 LittleFS partition (offset 0x320000, size 0x180000) via esp_partition_find_first, mounts at /littlefs with format_if_mount_failed=false, logs detailed ESP_LOGE errors for every failure path, emits partition statistics (total/used/free) each mount, triggers an 80 percent utilization warning, and ensures /littlefs/templates exists; storage_deinit now unmounts and frees resources cleanly. Updated pattern_storage.c to encapsulate this logic and CMakeLists.txt to link esp_partition and esp_littlefs. Pending action: run idf.py build in the ESP-IDF shell to verify the build.\n</info added on 2025-10-15T18:23:45.091Z>\n<info added on 2025-10-15T18:55:56.328Z>\nRecovery plan after losing uncommitted work: re-implement the LittleFS mount flow in storage_init/storage_deinit, rerun idf.py build plus mount verification, then stage and commit the restored files before touching task status; from now on never mark a subtask complete until its git commit exists.\n</info added on 2025-10-15T18:55:56.328Z>\n<info added on 2025-10-15T19:02:44.051Z>\nRecovered implementation finalized and committed in a9e860f: storage_init/storage_deinit mount littlefs at /littlefs per ADR-005, validate the ADR-007 partition offset 0x320000 with a 1.5MB span, auto-format on first boot, log filesystem metrics, and expand pattern_storage.c (122 lines) plus pattern_storage.h (71 lines) while updating idf_component.yml to joltwallet/littlefs ^1.14.8 and adjusting CMakeLists.txt dependencies. Build verification outstanding—Captain to run idf.py build in the ESP-IDF shell. Subtask ready to hand off to 5.2 for CRUD work.\n</info added on 2025-10-15T19:02:44.051Z>",
            "status": "done",
            "testStrategy": "Add a boot-time Unity test that mocks esp_vfs_littlefs_register outcomes to confirm failures propagate.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement pattern storage CRUD APIs with quotas and CRC",
            "description": "Create the core pattern storage APIs handling file lifecycle, quotas, and data integrity checks.",
            "dependencies": [
              1
            ],
            "details": "Implement storage_init, pattern_storage_open, pattern_storage_write_chunk, pattern_storage_finalize, and pattern_storage_list using LittleFS handles, enforce 1.5MB minus safety margin, and compute CRC32 before finalizing writes.\n<info added on 2025-10-15T18:34:26.575Z>\nCompleted LittleFS CRUD module in `components/storage/pattern_storage_crud.c`, providing open/write/finalize/close/read/list/delete/stat APIs with temp-file atomicity, per-write quota checks (1.5MB minus 100KB per ADR-004), hardware-accelerated CRC32 validation, and mutex-guarded operations; added helper routines for ID/path validation and directory bootstrap, plus corresponding declarations/build entries in `pattern_storage.h` and `CMakeLists.txt`, ready for build verification.\n</info added on 2025-10-15T18:34:26.575Z>\n<info added on 2025-10-15T19:05:16.566Z>\nRecovered implementation reinstates pattern_storage_crud.c with storage_pattern_create enforcing 100 KB per pattern and a 25-pattern ceiling, storage_pattern_read validating buffers, storage_pattern_delete removing orphaned files, storage_pattern_list skipping dot entries, and storage_pattern_count reporting totals; pattern_storage.h now provides documented declarations and CMakeLists.txt builds the module. Error handling returns ESP_ERR_INVALID_ARG for null inputs, ESP_ERR_INVALID_SIZE when payloads or buffers exceed limits, ESP_ERR_NO_MEM once the 25 pattern quota is exhausted, and ESP_ERR_NOT_FOUND for missing files. Patterns persist under /littlefs/patterns/ as <pattern_id>.bin with automatic directory creation and ADR-006 bounds enforced. Changes are captured in commit 8f7e2fb and require idf.py build verification before handing off to subtask 5.3.\n</info added on 2025-10-15T19:05:16.566Z>",
            "status": "done",
            "testStrategy": "Use host-based Unity tests to simulate uploads, verify quota enforcement, and exercise CRC mismatch paths.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Handle template assets and atomic write flow",
            "description": "Manage shared template files and ensure atomic persistence semantics for pattern updates.",
            "dependencies": [
              2
            ],
            "details": "Load palette and template data from /littlefs/templates, stage writes into temporary files, perform fsync, and atomically replace targets via rename while cleaning up remnants on error.\n<info added on 2025-10-15T18:38:41.115Z>\nAdd declarations for template read/write/list utilities in pattern_storage.h and implement template_storage_write, template_storage_read, and template_storage_list so palette/template assets under /littlefs/templates use the existing temp-file + fsync + rename flow, guaranteeing temporary artifacts are removed on error paths.\n</info added on 2025-10-15T18:38:41.115Z>\n<info added on 2025-10-15T19:11:38.657Z>\nImplementation underway: add template_storage_write/template_storage_read/template_storage_list declarations to pattern_storage.h and define them in pattern_storage_crud.c so /littlefs/templates assets use the <name>.tmp staging file, call fsync before rename, and unlink any temporary artifacts on failure to keep palette/template data consistent.\n</info added on 2025-10-15T19:11:38.657Z>\n<info added on 2025-10-15T19:13:44.205Z>\nImplemented template_storage_write/read/list/delete in pattern_storage_crud.c with declarations in pattern_storage.h; template_storage_write stages writes through <name>.tmp, flushes, fsyncs via fileno, and atomically renames while every failure path unlinks temps; list skips .tmp files, delete removes residual temps and targets while auto-creating /littlefs/templates; all error exits return ESP_ERR_INVALID_ARG, ESP_ERR_NO_MEM, ESP_ERR_NOT_FOUND, ESP_ERR_INVALID_SIZE, or ESP_FAIL with cleanup; work committed in 0d9998c and the API is ready for 5.4 integration once the Task 3 WebSocket dependency lands.\n</info added on 2025-10-15T19:13:44.205Z>",
            "status": "done",
            "testStrategy": "Extend unit tests to confirm template reads succeed and that interrupted writes leave no partial files.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate storage APIs with protocol callbacks",
            "description": "Wire the new storage functions into protocol upload and control handlers.",
            "dependencies": [
              2,
              3
            ],
            "details": "Update protocol PUT_* handling to call the storage APIs, maintain upload session state, surface storage errors, and ensure quota or CRC failures translate into protocol error responses.\n<info added on 2025-10-15T19:26:00.332Z>\nIntegration plan: create a storage protocol integration layer under components/storage/ with dispatch helpers; add WebSocket command handler stubs and wire storage create/read/delete calls into the protocol callbacks; implement upload session state tracking and map quota/CRC/storage failures to protocol error responses; expose a public API callable from the WebSocket layer; update network_manager.c:1238 to replace the TLV dispatcher TODO with storage_protocol_dispatch(). Starting implementation.\n</info added on 2025-10-15T19:26:00.332Z>\n<info added on 2025-10-15T19:30:25.068Z>\nImplemented storage_protocol.c integration layer with storage_protocol_dispatch handling TLV commands 0x10 PUT_BEGIN, 0x11 PUT_CHUNK, 0x12 PUT_END, 0x20 DELETE, and 0x21 LIST, including TLV frame validation, upload session tracking keyed by pattern_id, and mapping ESP_ERR_* values to protocol error codes 0x01-0x05 with STATUS 0x30 and ERROR 0x40 responses. Added storage_protocol_is_upload_active and storage_protocol_abort_upload helpers, replaced the TLV dispatcher TODO at network_manager.c:1238 with storage_protocol_dispatch, and confirmed the protocol layer is ready for WebSocket integration. Changes committed in b7e6dc8.\n</info added on 2025-10-15T19:30:25.068Z>",
            "status": "done",
            "testStrategy": "Add integration-level tests using mocked protocol frames to verify successful uploads and error propagation.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Execute persistence validation and endurance tests",
            "description": "Plan and run verification covering filesystem persistence, power cycling, and memory usage.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Run Unity tests with esp_littlefs host stub, perform on-device upload cycles with power resets to confirm remount and data persistence, and capture heap metrics after repeated transfers.",
            "status": "pending",
            "testStrategy": "Document and execute the endurance runbook, capturing results and logs for regression tracking.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Split into subtasks covering LittleFS mount/config, CRUD API implementations with quotas/CRC, template file handling and atomic updates, protocol integration points, and test strategy execution.",
        "updatedAt": "2025-10-16T08:13:18.621Z"
      },
      {
        "id": 6,
        "title": "Create .prism pattern format parser and metadata validation",
        "description": "Implement parsing and validation for the 1KB header, shared palettes, and delta-encoded payloads to guarantee instant access and structural efficiency.",
        "details": "Implementation:\n- Introduce `components/storage/pattern_format.c` with `pattern_format_parse(const uint8_t* header, size_t header_len, pattern_descriptor_t* out)` enforcing limits: version 0x01, <=256KB payload, valid palette references.\n- Decode metadata fields (name, category, parameters) using `safe_memcpy` and guard lengths; implement delta decode routines that can stream into cache without extra heap allocations.\n- Provide functions to serialize metadata for STATUS responses and to validate template headers during boot.\nPseudo-code:\n```\nesp_err_t pattern_format_parse(...) {\n    if (header_len != 1024) return ESP_ERR_INVALID_SIZE;\n    parse_fixed_header();\n    parse_palette_table();\n    parse_parameter_blocks();\n}\n```\n- Document struct definitions in `pattern_format.h` for re-use by playback engine.",
        "testStrategy": "Create offline tests feeding golden `.prism` headers to verify parsing correctness; fuzz header parser via Unity with random data ensuring graceful failures; benchmark parsing time to confirm <5ms per pattern using `esp_timer_get_time`.",
        "priority": "medium",
        "dependencies": [
          "5"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement 1KB header parser with strict validation",
            "description": "Create parsing logic that verifies the 1024-byte header, version tag, and payload size caps before populating pattern descriptors.",
            "dependencies": [],
            "details": "Add pattern_format_parse skeleton in components/storage/pattern_format.c that checks header_len, version byte equals 0x01, payload length <= 256KB, and records offsets for later decoding using safe_memcpy.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Decode palette table and metadata fields safely",
            "description": "Parse shared palette references and metadata strings while preventing buffer overruns and invalid indices.",
            "dependencies": [
              1
            ],
            "details": "Extend parser to walk palette table entries, confirm indices within shared palette limits, and decode name/category/parameter blocks with safe_memcpy plus length guards defined in pattern_format.h.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement streaming delta payload decoder routines",
            "description": "Build delta decoding helpers that can stream pattern payloads directly into cache without heap allocations.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create functions that process delta-encoded sections sequentially, reuse small stack buffers, validate segment boundaries, and expose streaming callbacks for the playback engine integration.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add parser regression tests and fuzz harness",
            "description": "Develop automated coverage to validate nominal parsing, edge cases, and failure behavior for malformed headers.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Set up Unity-based golden header tests, random input fuzz seeds, and timing checks ensuring parsing completes under 5ms while asserting deliberate error codes on corrupt data.",
            "status": "pending",
            "testStrategy": "Unity golden-header suite plus fuzz harness injecting random headers to confirm graceful failures and timing assertions.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Define subtasks for header parsing/validation, palette and metadata decoding with bounds checks, delta payload streaming routines, and test/fuzz coverage for parser robustness."
      },
      {
        "id": 7,
        "title": "Implement RAM hot cache with LRU eviction and preloading",
        "description": "Manage in-memory pattern cache (3-5 entries) to guarantee <100ms switching while respecting the 150KB heap budget.",
        "details": "Implementation:\n- Add `components/storage/cache_manager.c` exposing `cache_init(max_entries)`, `cache_preload(category_defaults)`, `cache_get(pattern_id)`, using memory pools for buffer allocations.\n- Track entries with LRU metadata and preload popular templates at boot; integrate with pattern storage to load headers/payloads once and share palette blocks across cached items.\n- Hook cache lookups into playback control path so template switches reference cached buffers.\nPseudo-code:\n```\ncache_entry_t* cache_get(const char* pattern_id) {\n    entry = lru_find(pattern_id);\n    if (!entry) {\n        entry = cache_load_from_storage(pattern_id);\n    }\n    return entry;\n}\n```\n- Provide metrics to WebSocket STATUS frames (cached count, misses).\n",
        "testStrategy": "Add unit tests that simulate repeated pattern requests to assert LRU eviction order; run long-duration soak test (simulate 24h pattern cycling) while monitoring heap fragmentation via `heap_caps_check_integrity_all` and ensure cache hit rate meets targets.",
        "priority": "medium",
        "dependencies": [
          "5",
          "6"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define cache manager structures and memory pools",
            "description": "Create the cache manager module skeleton with structs for entries, memory pools, and public API in cache_manager.c/.h.",
            "dependencies": [],
            "details": "Set up cache metadata structs, memory pool initialization for 3-5 entries within 150KB, and stub the cache_init/cache_get/cache_preload functions with TODO markers.",
            "status": "pending",
            "testStrategy": "Add initial unit tests that instantiate the cache and confirm pool allocation within budget.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement preload workflow tied to pattern storage",
            "description": "Wire cache_preload to load category defaults from storage templates into shared buffers at boot.",
            "dependencies": [
              1
            ],
            "details": "Use pattern storage APIs to fetch headers/payloads, reuse palette blocks, and ensure preload respects pool limits while flagging loaded entries.",
            "status": "pending",
            "testStrategy": "Write unit tests mocking storage calls to ensure preload populates expected entries and handles storage failures.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Finalize LRU eviction and playback integration",
            "description": "Complete cache_get logic with LRU tracking and connect playback control path to cached buffers.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement LRU queue updates, eviction when pools are full, and hook playback code paths to request entries via cache_get and handle cache misses.",
            "status": "pending",
            "testStrategy": "Create simulated playback sequence tests verifying eviction order, miss handling, and <100ms access via timing mocks.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Expose cache metrics to WebSocket status frames",
            "description": "Add instrumentation reporting cache counts, hits, and misses through existing telemetry channels.",
            "dependencies": [
              3
            ],
            "details": "Track counters inside cache manager, extend status frame assembly to include cache metrics, and ensure thread-safe reads.",
            "status": "pending",
            "testStrategy": "Extend telemetry unit tests to validate metrics payload fields and values after cache operations.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Execute stress and soak testing scenarios",
            "description": "Design and run stress scenarios that validate cache stability, memory integrity, and performance targets.",
            "dependencies": [
              3,
              4
            ],
            "details": "Script 24-hour pattern cycling with varied patterns, check heap integrity via heap_caps_check_integrity_all, and log cache hit/miss ratios.",
            "status": "pending",
            "testStrategy": "Automate soak test harness that verifies integrity checks pass and hit rate maintains required threshold.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Plan subtasks for cache data structures and memory pool wiring, preload routines tied to storage/templates, LRU eviction/path integration with playback, metrics instrumentation, and stress testing."
      },
      {
        "id": 8,
        "title": "Develop RMT-based LED driver with double buffering",
        "description": "Implement a playback driver that streams frames to 320 WS2812B LEDs at 60 FPS using double-buffered DMA-friendly memory.",
        "details": "Implementation:\n- In `components/playback/led_driver.c`, configure RMT TX channel (`rmt_new_tx_channel`) with 3.2MHz clock and install WS2812 encoder (ESP-IDF LED strip driver) or custom translator to meet timing.\n- Allocate two frame buffers via `heap_caps_malloc(MALLOC_CAP_DMA)` and expose APIs `led_driver_submit_frame(const uint8_t* frame)` and `led_driver_swap_buffers()`.\n- Use hardware timer or animation scheduler to trigger frame swaps while ensuring ISR-safe operations.\nPseudo-code:\n```\nstatic void led_refresh_task(void* arg) {\n    while (1) {\n        rmt_transmit(channel, encoder, front_buffer, frame_len, &tx_config);\n        xSemaphoreTake(frame_ready_sem, pdMS_TO_TICKS(frame_period));\n        swap_buffers();\n    }\n}\n```\n- Implement diagnostics for underruns and log if frame time exceeds 16.6ms.",
        "testStrategy": "Create hardware-in-the-loop test sending gradient frames and verifying with logic analyzer that timing meets WS2812 spec; add simulated unit tests using IDF RMT mock to ensure buffer swaps occur within deadline; monitor CPU utilization via `esp_pm_lock_type` metrics.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure RMT channel and WS2812 encoder",
            "description": "Set up the RMT TX peripheral to meet WS2812 timing requirements.",
            "dependencies": [],
            "details": "Configure `rmt_new_tx_channel` at 3.2MHz, install WS2812 encoder or custom translator, and tune timing constants for 320 LEDs.",
            "status": "done",
            "testStrategy": "Unit-test encoder configuration with IDF RMT mock to verify timing parameters.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement DMA-capable double-frame buffers",
            "description": "Create double-buffered LED frame storage using DMA-capable memory.",
            "dependencies": [
              1
            ],
            "details": "Allocate two frame buffers with `heap_caps_malloc(MALLOC_CAP_DMA)`, manage ownership, and ensure alignment for RMT transfers.",
            "status": "done",
            "testStrategy": "Add allocation tests ensuring buffers meet DMA capabilities and verify swap readiness logic in isolation.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Design frame submission and swap APIs",
            "description": "Expose APIs for frame submission and buffer swapping.",
            "dependencies": [
              2
            ],
            "details": "Implement `led_driver_submit_frame` to copy new frames into the back buffer and `led_driver_swap_buffers` to rotate buffers safely.",
            "status": "done",
            "testStrategy": "Mock submit/swap calls to confirm data integrity and buffer state transitions without RMT involvement.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate timing control and ISR-safe workflow",
            "description": "Coordinate frame transmission timing and ISR-safe synchronization.",
            "dependencies": [
              3
            ],
            "details": "Use hardware timer or scheduler to trigger `rmt_transmit`, manage semaphores for frame readiness, and ensure swaps occur within ISR constraints.",
            "status": "done",
            "testStrategy": "Create FreeRTOS timer tests simulating 60 FPS cadence to verify semaphore timing and ISR-safe operations.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add underrun diagnostics and validation tests",
            "description": "Implement runtime diagnostics and verification for frame timing.",
            "dependencies": [
              4
            ],
            "details": "Log underruns when frame time exceeds 16.6ms, expose metrics, and validate behavior via hardware-in-the-loop and simulated tests.",
            "status": "done",
            "testStrategy": "Run HIL gradient playback with logic analyzer plus simulated tests checking logged diagnostics and timing thresholds.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Break down into subtasks for RMT channel/config setup, DMA-capable double-buffer management, frame submission/swap API design, timing/ISR coordination, and validation via hardware and simulated tests."
      },
      {
        "id": 9,
        "title": "Build effect engine with parameter interpolation and crossfade scheduler",
        "description": "Translate parsed pattern instructions into frame buffers with smooth parameter transitions and <100ms switch latency.",
        "details": "Implementation:\n- Implement `components/playback/effect_engine.c` to interpret pattern descriptors, generate frame deltas, and manage crossfades between patterns using eased interpolation (e.g., cubic). Maintain per-pattern state machines.\n- Add `animation_timer.c` to configure a 60 FPS hardware timer (`esp_timer_create_periodic`) that triggers rendering pipelines and interacts with the LED driver.\n- Provide APIs `effect_engine_play(pattern_descriptor_t*, playback_params_t*)`, `effect_engine_set_parameters(...)`, `effect_engine_update()` invoked by the timer callback.\nPseudo-code:\n```\nstatic void animation_tick(void* arg) {\n    blend_progress = compute_easing(step++);\n    generate_frame(active_pattern, blend_progress, scratch_buffer);\n    led_driver_submit_frame(scratch_buffer);\n}\n```\n- Ensure CPU usage stays <50% by profiling loops and using fixed-point math where feasible.",
        "testStrategy": "Create bench tests that render synthetic patterns and measure frame time with `esp_timer_get_time`; validate crossfades by sampling LED buffer outputs; run integration test by issuing CONTROL messages triggering parameter ramps and confirming transitions remain smooth.",
        "priority": "medium",
        "dependencies": [
          "6",
          "7",
          "8"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define effect engine architecture and state flow",
            "description": "Design the effect engine module structure, state machines, and data contracts for pattern playback.",
            "dependencies": [],
            "details": "Outline structs for pattern descriptors, per-pattern state, and frame buffers; document state transitions and public API contracts matching playback requirements.",
            "status": "pending",
            "testStrategy": "Review design doc with team and validate state diagrams against PRD scenarios",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement pattern interpretation and crossfade core",
            "description": "Code the effect engine logic to interpret descriptors, run state machines, and compute eased crossfades.",
            "dependencies": [
              1
            ],
            "details": "Implement frame delta generation, easing curve calculation, and state transitions in `components/playback/effect_engine.c`, ensuring parameter interpolation hooks are present.",
            "status": "pending",
            "testStrategy": "Add unit tests for easing curves and state transitions using synthetic descriptors",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build 60 FPS animation timer and update loop",
            "description": "Create the animation timer module to drive effect updates and call the engine each frame.",
            "dependencies": [
              1,
              2
            ],
            "details": "Develop `animation_timer.c` using `esp_timer_create_periodic` at 60 FPS, wiring callbacks to `effect_engine_update()` and handling timer lifecycle APIs.",
            "status": "pending",
            "testStrategy": "Write timer mock tests verifying 60 FPS cadence and correct invocation of engine hooks",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate LED driver and cache handoff",
            "description": "Connect the effect engine output with LED driver submission and RAM cache fetch paths.",
            "dependencies": [
              2,
              3
            ],
            "details": "Implement buffer handoff to `led_driver_submit_frame`, ensure cache lookups provide pattern data, and manage scratch buffer reuse with minimal allocations.",
            "status": "pending",
            "testStrategy": "Create integration test stubs that simulate cache hits/misses and assert driver submissions receive expected buffers",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Optimize and profile effect engine performance",
            "description": "Profile the engine loop and apply optimizations to meet CPU budget and latency constraints.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Instrument timing with `esp_timer_get_time`, convert hot paths to fixed-point math, and verify CPU usage remains under 50 percent with representative patterns.",
            "status": "pending",
            "testStrategy": "Add profiling harness measuring frame computation time and CPU load under mixed pattern workloads",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Develop bench and integration testing suite",
            "description": "Assemble bench tests and end-to-end integration validations for the effect engine.",
            "dependencies": [
              2,
              3,
              4,
              5
            ],
            "details": "Implement synthetic pattern benches, parameter ramp tests, and crossfade validation scripts ensuring smooth transitions and <100ms switch latency.",
            "status": "pending",
            "testStrategy": "Run automated bench tests plus hardware-in-loop scenarios sampling LED outputs and verifying timing metrics",
            "parentId": "undefined"
          }
        ],
        "complexity": 9,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Segment into subtasks for pattern interpretation pipeline, crossfade/interpolation algorithms, render scheduling via timers, integration with LED driver/cache, performance profiling, and bench/integration testing."
      },
      {
        "id": 10,
        "title": "Deliver template system with 15 categorized patterns and deployment flow",
        "description": "Ship built-in templates (Ambient, Energy, Special), preload them on first boot, and expose metadata for one-click deployment via WebSocket.",
        "details": "Implementation:\n- Populate `components/templates/template_patterns.c` with 15 template descriptors referencing shared palette data and precomputed parameter curves; ensure total storage fits 1.5MB partition.\n- Implement `template_loader.c` to copy templates into LittleFS on first boot (if absent), register metadata (name, preview hash, category) with cache manager, and provide APIs `templates_init()`, `templates_list(category)`, `templates_deploy(id)`.\n- Integrate with protocol dispatcher so CONTROL commands trigger deployments and with cache to guarantee templates are cached at boot.\nPseudo-code:\n```\nesp_err_t templates_init(void) {\n    for each template_def in builtin_templates {\n        if (!storage_exists(template_def.id)) {\n            storage_write_template(template_def);\n        }\n        cache_preload(template_def.id);\n    }\n    return ESP_OK;\n}\n```\n- Update STATUS payloads to include template metadata snapshots for clients.",
        "testStrategy": "Add unit tests verifying template install idempotency and category counts (5 each); flash firmware and confirm first boot copies occur within 60s; use WebSocket CONTROL `deploy` to measure <2s deployment and <100ms playback switch via logs.",
        "priority": "medium",
        "dependencies": [
          "5",
          "6",
          "7",
          "9"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define built-in template descriptors",
            "description": "Create the 15 categorized template descriptors with shared palette and curve references in template_patterns.c.",
            "dependencies": [],
            "details": "Author Ambient, Energy, and Special template structs referencing shared palette data and precomputed parameter curves while verifying the combined binary payload fits within the 1.5MB partition budget.",
            "status": "pending",
            "testStrategy": "Add static asserts or unit tests verifying descriptor counts per category and aggregate storage footprint under 1.5MB.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement first-boot template provisioning",
            "description": "Build template_loader.c routines to seed LittleFS with built-in templates when missing.",
            "dependencies": [
              1
            ],
            "details": "Write logic to detect absent templates on initial boot, copy compiled descriptors into LittleFS, and ensure idempotent storage writes using existing pattern storage APIs for reliability.",
            "status": "pending",
            "testStrategy": "Create integration-style tests stubbing LittleFS to confirm first boot populates files once and subsequent boots skip rewrites.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Register template metadata and cache preload",
            "description": "Integrate metadata cataloging and cache warming after templates are provisioned.",
            "dependencies": [
              2
            ],
            "details": "Expose templates_init/list/deploy APIs that register name, preview hash, and category with the cache manager and trigger cache_preload calls for all templates during initialization.",
            "status": "pending",
            "testStrategy": "Extend unit tests to assert metadata registry contents and that cache_preload executes for every template id after initialization.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Wire deployment flow through protocol dispatcher",
            "description": "Connect CONTROL/WebSocket commands to template deployment routines and update STATUS payloads.",
            "dependencies": [
              3
            ],
            "details": "Update protocol dispatcher handlers to call templates_deploy on CONTROL commands, stream deployment notifications over WebSocket, and embed template metadata snapshots in STATUS payloads for client discovery.",
            "status": "pending",
            "testStrategy": "Use protocol dispatcher tests that simulate CONTROL deploy commands and verify WebSocket/status messages reflect the selected template id and metadata.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Validate storage size and deployment performance",
            "description": "Measure template storage usage and runtime deployment behavior against targets.",
            "dependencies": [
              4
            ],
            "details": "Instrument measurements ensuring total template data stays under 1.5MB, first-boot provisioning completes within 60 seconds, and WebSocket deployments achieve <2s launch with <100ms playback switch via logs.",
            "status": "pending",
            "testStrategy": "Run on-device tests capturing provisioning timestamps and deployment latency while asserting log-derived metrics meet storage and performance thresholds.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Create subtasks for authoring template data structures, first-boot install and storage sync, cache preload and metadata registration, protocol/WebSocket deployments, and verification of size/performance targets."
      },
      {
        "id": 11,
        "title": "Create Motion & Sync Enumerations and Temporal Interfaces",
        "description": "Establish the core enums, data structures, and public APIs for motion and sync modes required by the temporal sequencing system.",
        "details": "Files: firmware/components/playback/include/prism_motion.h.\nSteps:\n1. Define `typedef enum` values for `motion_direction_t` {LEFT, RIGHT, CENTER, EDGE, STATIC} and `sync_mode_t` {SYNC, OFFSET, PROGRESSIVE, WAVE, CUSTOM} per ADR-010.\n2. Introduce structs:\n   - `sync_params_t { uint16_t delay_ms; uint16_t progressive_start_ms; uint16_t progressive_end_ms; uint16_t wave_amplitude_ms; uint16_t wave_frequency_hz; uint16_t wave_phase_deg; }`.\n   - `prism_temporal_ctx_t { uint16_t frame_index; const prism_pattern_t *pattern; const sync_params_t *params; }`.\n3. Declare `void prism_motion_init(prism_temporal_ctx_t *ctx);` and `void calculate_ch2_frame(prism_temporal_ctx_t *ctx, uint16_t *ch1_frame, uint16_t *ch2_frame, size_t led_count, TickType_t tick_now);`.\nPseudo-code:\n```\ntypedef struct {\n    motion_direction_t motion;\n    sync_mode_t sync_mode;\n    sync_params_t sync_params;\n} prism_temporal_header_t;\n```\n4. Document API expectations (static allocations, 160 LEDs, 320-byte buffers).\n5. Export constants for timing budgets (e.g., `#define PRISM_LGP_LED_COUNT 160`).",
        "testStrategy": "Author unit test skeleton in test_prism_temporal.c verifying enums map to expected integer values and header structs align with protocol requirements via `sizeof` static assertions.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add prism_motion_t enum and validation macro",
            "description": "Define the motion direction enum alongside its validation helper in the shared playback header.",
            "dependencies": [],
            "details": "Update firmware/components/playback/include/led_playback.h to declare typedef enum prism_motion_t with STATIC=0, LEFT, RIGHT, CENTER, EDGE and add IS_VALID_MOTION macro consistent with ADR-010 direction table.",
            "status": "pending",
            "testStrategy": "Confirm firmware headers compile cleanly by running the existing playback target build or lint step.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Create prism_sync_mode_t enum with validation macro",
            "description": "Introduce sync mode enumeration definitions and validation macro in the playback include file.",
            "dependencies": [
              1
            ],
            "details": "Extend firmware/components/playback/include/led_playback.h with typedef enum prism_sync_mode_t starting at SYNC=0 followed by OFFSET, PROGRESSIVE, WAVE, CUSTOM and implement IS_VALID_SYNC macro mirroring ADR-010 sync specifications.",
            "status": "pending",
            "testStrategy": "Rebuild the playback component to ensure new enum and macro integrate without compiler diagnostics.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add temporal enum validation unit tests",
            "description": "Author unit tests covering enum ordinal values and macro validation behavior.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create firmware/components/tests/test_temporal_enums.c Unity cases asserting motion/sync enum integer values, static_assert bounds, and that IS_VALID_MOTION/IS_VALID_SYNC accept valid constants while rejecting out-of-range inputs.",
            "status": "pending",
            "testStrategy": "Run the Unity test target (e.g., idf.py test playback) to verify the new temporal enum tests execute and pass.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Define motion and sync enums with validation",
            "description": "Create the new prism_motion.h header declaring motion and sync enumerations required per ADR-010.",
            "dependencies": [],
            "details": "Author typedef enums for motion_direction_t and sync_mode_t with five modes plus *_COUNT sentinels, add PRISM_MOTION_IS_VALID-style validation macros, and include static_assert checks for enum widths.",
            "status": "pending",
            "testStrategy": "Add compile-time static_assert checks and a Unity enum-value test skeleton in test_prism_temporal.c verifying ordinal mapping.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add temporal context structs and ownership docs",
            "description": "Implement the shared temporal context and sync parameter structs that consume the new enums.",
            "dependencies": [
              4
            ],
            "details": "Define sync_params_t and prism_temporal_ctx_t with uint16_t fields, include delay_table pointer wiring, and document ownership/lifetime expectations for pattern and params references in the public header.",
            "status": "pending",
            "testStrategy": "Extend test_prism_temporal.c to assert sizeof/layout expectations and validate null/const assumptions in doc comments.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Introduce pattern metadata header aligned with new enums",
            "description": "Create auxiliary pattern_metadata.h to hold packed metadata that leverages the motion/sync enums and parameters.",
            "dependencies": [
              4,
              5
            ],
            "details": "Define prism_pattern_meta_v11_t as a packed struct containing version, motion_direction_t, sync_mode_t, sync_params_t, and CRC fields, integrating with pattern_storage.h contract and documenting serialization expectations.",
            "status": "pending",
            "testStrategy": "Plan alignment and CRC integration checks via sizeof/static_assert coverage and future pattern_storage parsing tests.",
            "parentId": "undefined"
          }
        ],
        "complexity": 3,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down the work into defining enums, declaring shared structs/context headers, and documenting/testing the new public API expectations for motion and sync interfaces.",
        "updatedAt": "2025-10-16T08:45:10.524Z"
      },
      {
        "id": 12,
        "title": "Implement SYNC and OFFSET Temporal Sequencing",
        "description": "Develop the initial calculate_ch2_frame() logic supporting SYNC and OFFSET modes with timing guarantees.",
        "details": "Files: firmware/components/playback/prism_temporal.c.\nSteps:\n1. Implement `prism_motion_init` to zero context and validate pointers.\n2. Implement `calculate_ch2_frame` with early exit for SYNC copying `memcpy(ch2_frame, ch1_frame, led_count * sizeof(*ch1_frame));`.\n3. For OFFSET mode, compute delay buckets:\n```\nstatic inline uint16_t apply_offset(uint16_t base_value, uint16_t delay_ms, uint32_t frame_time_ms){\n    if(frame_time_ms < delay_ms) return 0;\n    return base_value; // simple first-pass all-or-nothing\n}\n```\n4. Use FreeRTOS `xTaskGetTickCount()` passed in to maintain 120 FPS budget; convert delays using `esp_timer_get_time()` if tick resolution insufficient.\n5. Cache previous frame timestamp in static context to maintain 3.38 ms CPU budget (avoid expensive math).\n6. Instrument microsecond timings with `esp_timer_get_time()` under `CONFIG_PRISM_PROFILE_TEMPORAL`.\n7. Guard all operations with static allocations and no heap usage.",
        "testStrategy": "Add unit tests mocking frames: verify SYNC outputs identical arrays; OFFSET with 150ms shift results in expected zero-filled leading frames; confirm processing time <3.38ms via `unity` performance assertions.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement prism_motion_init context validation",
            "description": "Create the motion initialization routine that validates input pointers and zeros the temporal context structure.",
            "dependencies": [],
            "details": "Use PRISM_CHECK_ARG macros to guard null pointers, memset the provided context to zero, initialize cached timestamps, and return esp_err_t codes across firmware/components/playback/prism_temporal.c.",
            "status": "pending",
            "testStrategy": "Add Unity tests that pass null pointers and valid inputs to confirm ESP_ERR_INVALID_ARG handling and full context reset.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add prism_frame_time_ms and apply_offset helpers",
            "description": "Introduce shared inline helpers that compute frame durations and gate delayed output values for temporal sequencing.",
            "dependencies": [
              1
            ],
            "details": "Create static inline functions in prism_temporal.c that convert FreeRTOS tick counts to milliseconds, fall back to esp_timer_get_time when finer resolution is required, and implement apply_offset returning zero until delay_ms elapses.",
            "status": "pending",
            "testStrategy": "Unit-test helper behavior with mocked tick counts and microsecond timers to confirm correct millisecond calculation and delay gating.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement calculate_ch2_frame SYNC branch",
            "description": "Wire up the SYNC path in calculate_ch2_frame to perform an optimized copy from channel 1 to channel 2.",
            "dependencies": [
              1,
              2
            ],
            "details": "Add early exit for SYNC mode using memcpy on restrict-qualified buffers, respect 4-byte alignment optimizations, and integrate optional profiling guards controlled by CONFIG_PRISM_PROFILE_TEMPORAL.",
            "status": "pending",
            "testStrategy": "Create unit coverage ensuring SYNC mode copies all LED values correctly and triggers profiling hooks when enabled.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement calculate_ch2_frame OFFSET branch",
            "description": "Complete the OFFSET mode logic that applies per-LED delay buckets and handles zero-filling before activation.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Iterate LEDs, compute frame_time_ms via helpers, apply delay table values, zero-fill elements when frame_time is below delay, and cache previous frame timestamps in static context to stay within the 3.38 ms budget.",
            "status": "pending",
            "testStrategy": "Verify OFFSET mode with mocked delay tables yields expected zero-fill windows and updates cached timing without exceeding processing budget in unit tests.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create Unity tests for SYNC and OFFSET modes",
            "description": "Author test_prism_temporal.c to validate SYNC copying, OFFSET delay handling, and performance instrumentation requirements.",
            "dependencies": [
              3,
              4
            ],
            "details": "Add Unity cases that mock esp_timer_get_time, assert channel equality for SYNC, confirm OFFSET zero windows at configured delays, and use timing hooks to enforce the <3.38 ms processing target.",
            "status": "pending",
            "testStrategy": "Run new Unity suite focused on prism_temporal.c verifying both functional outputs and instrumentation-driven performance guards.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Separate tasks for context init, SYNC fast path, OFFSET delay handling, performance/timing safeguards, and unit/integration test coverage for both modes.",
        "updatedAt": "2025-10-16T08:45:11.282Z"
      },
      {
        "id": 13,
        "title": "Extend .prism v1.1 Header and Parser",
        "description": "Update storage and protocol parsing to support new motion and sync metadata in .prism v1.1 files.",
        "details": "Files: pattern_storage.h, protocol_parser.c, firmware/components/playback/prism_temporal.c (for struct integration).\nSteps:\n1. Update `prism_header_t` adding fields: `motion_direction_t motion; sync_mode_t sync_mode; sync_params_t sync_params;` ensuring total header size 70 bytes.\n2. Adjust CRC32 computation to include new fields and maintain backward compatibility by zero-filling when absent.\n3. Update `protocol_parser.c` TLV handling to accept `PRISM_VERSION_1_1`, parse motion/sync TLVs, validate range (motion enum bounds, sync modes known, delay <=500ms).\n4. Support fallback for v1.0 patterns by defaulting to `motion=STATIC`, `sync_mode=SYNC`, zeroed params.\n5. Expose helper `bool prism_pattern_is_legacy(const prism_header_t *header);` for migration tooling.\nPseudo-code snippet:\n```\nif (version == 0x0101) {\n    header->motion = read_u8();\n    header->sync_mode = read_u8();\n    header->sync_params.delay_ms = read_u16();\n    // ...\n} else {\n    header->motion = MOTION_STATIC;\n    header->sync_mode = SYNC_MODE_SYNC;\n}\n```\n6. Regenerate binary layout docs in ADR-009 appendix to note offsets.",
        "testStrategy": "Create parser unit tests using golden binaries for v1.0 and v1.1 ensuring CRC acceptance, correct field population, and rejection for out-of-range enums.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Extend prism_header_t for v1.1 motion and sync metadata",
            "description": "Modify the prism_header_t definition so the v1.1 binary header expands to 70 bytes and accommodates motion and sync metadata.",
            "dependencies": [],
            "details": "Insert motion_direction_t, sync_mode_t, and sync_params_t fields at byte offsets 56-63, apply packed alignment pragmas or attributes, and add static_assert checks to guarantee sizeof(prism_header_t)==70.",
            "status": "pending",
            "testStrategy": "Compile-time sizeof assertions and a layout inspection unit test that serializes the header and verifies offsets.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Introduce motion and sync TLVs in protocol_parser.c",
            "description": "Update the TLV parser to recognize the new motion and sync TLVs and populate the extended header fields when version >= 0x0101.",
            "dependencies": [
              1
            ],
            "details": "Define PRISM_TLV_MOTION=0x20 and PRISM_TLV_SYNC=0x21, enforce expected payload lengths, gate parsing to PRISM_VERSION_1_1+, and reject values outside enum bounds or >500 ms delay.",
            "status": "pending",
            "testStrategy": "Parser unit tests feeding crafted TLVs to confirm acceptance of valid frames and rejection of malformed or out-of-range inputs.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement v1.0 fallback and zero-fill compatibility path",
            "description": "Ensure legacy patterns without motion or sync TLVs default to safe values and zeroed fields while staying CRC-compatible.",
            "dependencies": [
              1,
              2
            ],
            "details": "Detect headers/version <0x0101, set motion=MOTION_STATIC, sync_mode=SYNC_MODE_SYNC, zero sync_params, and guarantee padding bytes are cleared before CRC operations or serialization.",
            "status": "pending",
            "testStrategy": "Regression tests loading v1.0 headers to verify default population and that emitted headers remain byte-identical to legacy expectations.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Extend CRC32 computation for new header fields",
            "description": "Adjust CRC accumulation logic so the new motion and sync bytes factor into the checksum without breaking older assets.",
            "dependencies": [
              1,
              3
            ],
            "details": "Update CRC32 routines to include bytes 56-69 for v1.1 headers, zero-initialize missing fields for legacy payloads prior to hashing, and validate endianness when reading multi-byte sync parameters.",
            "status": "pending",
            "testStrategy": "CRC unit tests comparing computed checksums against golden values for both 64-byte v1.0 and 70-byte v1.1 headers, plus tampered-field detection cases.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add regression tests and ADR-009 documentation updates",
            "description": "Create comprehensive tests and documentation artifacts covering the expanded header layout and parser behavior.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Author unit tests using golden binaries for both header versions, cover corrupted CRC and enum range rejections, and regenerate ADR-009 appendix diagrams with updated byte offsets.",
            "status": "pending",
            "testStrategy": "Golden-binary based tests in the playback suite and documentation checks ensuring ADR-009 reflects the new 70-byte layout and TLV handling.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Create subtasks for struct size updates, CRC/backward-compat adjustments, TLV parsing with validation, legacy defaults, and regression tests plus documentation updates.",
        "updatedAt": "2025-10-16T08:42:20.971Z"
      },
      {
        "id": 14,
        "title": "Integrate Temporal Calculation with Playback Task",
        "description": "Wire the new calculation logic into led_playback.c and generate baseline sample patterns.",
        "details": "Files: firmware/components/playback/led_playback.c, firmware/components/playback/prism_temporal.c, pattern files in assets/.\nSteps:\n1. Update `playback_task()` to construct `prism_temporal_ctx_t` from loaded pattern header and call `calculate_ch2_frame()` each frame.\n2. Ensure double-buffer safety: `uint16_t ch2_frame[PRISM_LGP_LED_COUNT]` allocated static per task.\n3. Add switch over motion enum to handle direction-specific indexing (LEFT/RIGHT etc.) for future modes (stub now but return input unchanged).\n4. Create 3 demo patterns (.prism) for SYNC, OFFSET rising (delay 0→150ms), OFFSET falling (150→0ms) stored under `.taskmaster/docs/patterns/phase1/`.\n5. Include event logging `ESP_LOGD(TAG, \"temporal mode=%d motion=%d frame=%u\", ...)` guarded by debug flag.",
        "testStrategy": "Run integration unit test with simulated playback loop verifying ch2 buffer updates and that log instrumentation toggles with config flag; confirm patterns load successfully via existing playback regression test harness.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add static ch2 buffer lifecycle hooks",
            "description": "Introduce a persistent channel 2 frame buffer in led_playback.c and manage its initialization.",
            "dependencies": [],
            "details": "Declare static uint16_t ch2_frame[PRISM_LGP_LED_COUNT] within led_playback.c, ensure it zeroes when playback_task swaps patterns, and only write to it inside frame calculation routines to maintain double-buffer safety.",
            "status": "pending",
            "testStrategy": "Add unit coverage ensuring buffer zeros on pattern changes and is untouched by unrelated code paths.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Build prism_temporal context from pattern headers",
            "description": "Populate prism_temporal_ctx_t fields using parsed pattern metadata and verify motion init behavior.",
            "dependencies": [
              1
            ],
            "details": "Extract temporal mode, timing parameters, and motion metadata from the loaded .prism pattern header, cache the resulting prism_temporal_ctx_t on the playback descriptor, and validate the structure through prism_motion_init to catch invalid fields early.",
            "status": "pending",
            "testStrategy": "Create a mocked pattern header test confirming context fields match expected values and motion init rejects malformed data.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate calculate_ch2_frame with RMT flow",
            "description": "Invoke calculate_ch2_frame ahead of RMT transmission while respecting FreeRTOS synchronization needs.",
            "dependencies": [
              1,
              2
            ],
            "details": "Trigger calculate_ch2_frame() just before rmt_write_items(), gate the send path so the buffer is ready, and coordinate completion via rmt_wait_tx_done plus the existing ISR semaphore to avoid frame overlap.",
            "status": "pending",
            "testStrategy": "Use the playback regression harness to simulate successive frames and assert RMT writes observe updated ch2 buffer contents without timing violations.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement esp_timer driven frame timing",
            "description": "Track playback timestamps with esp_timer to compute accurate per-frame timing and handle reference updates.",
            "dependencies": [
              2,
              3
            ],
            "details": "Store pattern start ticks via esp_timer_get_time(), derive frame_time_ms each loop, and honor TLV set_reference commands by resetting the baseline so temporal calculations stay synchronized.",
            "status": "pending",
            "testStrategy": "Add an integration test that fakes esp_timer readings to confirm frame timing reacts to reference resets and produces expected deltas for the temporal calculator.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Plan subtasks for wiring context construction, channel buffering, motion switch scaffolding, demo pattern generation, and integration test/logging validation.",
        "updatedAt": "2025-10-16T08:45:12.012Z"
      },
      {
        "id": 15,
        "title": "Implement PROGRESSIVE Mode with Shape Presets",
        "description": "Add linear interpolation temporal delays enabling progressive shapes and provide preset pattern definitions.",
        "details": "Files: prism_temporal.c, new preset files under assets/presets/progressive/.\nSteps:\n1. Extend `calculate_ch2_frame()` to handle `SYNC_MODE_PROGRESSIVE` using formula `delay[i] = start_ms + ((end_ms - start_ms) * i) / 159` (precomputed into static array on pattern load).\n2. Support motion direction by swapping LED index iteration for LEFT vs RIGHT and mirroring for EDGE vs CENTER.\n3. Define shape preset generator helper:\n```\nstatic void prism_build_shape(shape_t type, uint16_t *start, uint16_t *end){\n    switch(type){\n        case SHAPE_RIGHT_TRIANGLE: *start=0; *end=200; break;\n        // etc.\n    }\n}\n```\n4. Produce 5 presets (right triangle, left triangle, diamond, chevron, gradient) with metadata stored in pattern repository.\n5. Ensure per-LED counters stored in `uint16_t progressive_delay_table[160]` within context (static allocation).",
        "testStrategy": "Unit tests validating interpolation endpoints, monotonicity for triangles, and symmetry for diamond; snapshot tests comparing generated preset delay tables against golden arrays.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement progressive ramp generator",
            "description": "Add a build_progressive_ramp helper that fills delay tables with linear interpolation math.",
            "dependencies": [],
            "details": "Use fixed-point int32_t math to compute delay[i] = start_ms + span * i / 159, writing into the static uint16_t progressive_delay_table[160] allocated in prism_temporal.c and enforce monotonic increase with guard checks.",
            "status": "pending",
            "testStrategy": "Add focused unit coverage that feeds known start/end pairs to validate endpoints, monotonicity, and overflow handling for build_progressive_ramp.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add motion direction handling to progressive frames",
            "description": "Update calculate_ch2_frame to respect LEFT/RIGHT direction and EDGE/CENTER mirroring when populating progressive delays.",
            "dependencies": [
              1
            ],
            "details": "Integrate direction flags so LEFT iterates LEDs 0→159, RIGHT iterates 159→0, and EDGE/CENTER patterns mirror indices around midpoint while reusing the populated progressive_delay_table values when emitting ch2 frames.",
            "status": "pending",
            "testStrategy": "Extend existing temporal tests to confirm direction swaps and mirroring yield expected index ordering for representative presets.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Create prism_build_shape dispatcher",
            "description": "Introduce prism_build_shape that routes shape_t enums to specific preset builders and annotates pattern metadata.",
            "dependencies": [
              1
            ],
            "details": "Implement a switch-based dispatcher in prism_temporal.c that selects triangle, wedge, diamond, chevron, and gradient builders, populates start/end ranges via prism_build_shape helpers, and records direction flags for downstream rendering.",
            "status": "pending",
            "testStrategy": "Add lightweight dispatcher tests that mock shape_t inputs to confirm correct function pointers and metadata fields are selected.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement triangle preset builder",
            "description": "Author the triangle preset builder producing symmetric progressive ramps with seamless midpoint transition.",
            "dependencies": [
              1,
              3
            ],
            "details": "Use build_progressive_ramp to generate a two-phase ramp: indices 0-79 ascend toward peak_ms and 80-159 descend while ensuring continuity at index 79/80, storing metadata for LEFT/RIGHT variants in assets/presets/progressive/triangle files.",
            "status": "pending",
            "testStrategy": "Create golden delay arrays verifying peak alignment and symmetry checks for triangle presets within the new unit test suite.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement wedge preset builder",
            "description": "Develop wedge preset preset generating edge-biased plateau shapes using the progressive delay table infrastructure.",
            "dependencies": [
              1,
              3
            ],
            "details": "Produce an ascending ramp up to a configurable plateau_index then fill remaining LEDs with end_ms values, supporting edge-biased peaks and exporting metadata for chevron, diamond, and gradient variants in preset assets.",
            "status": "pending",
            "testStrategy": "Capture golden outputs for representative wedge configurations and assert plateau sections remain constant while ramps stay monotonic.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Add progressive temporal unit tests",
            "description": "Create test_prism_temporal_progressive.c covering ramp math, direction handling, and preset outputs using golden tables.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "Author Unity tests that validate delay[0]==start_ms, delay[159]==end_ms, monotonic properties for ramps, symmetry for triangle/diamond presets, and compare generated tables against stored golden snapshots.",
            "status": "pending",
            "testStrategy": "Integrate the new test module into firmware tests and run it in CI to guard against regressions in interpolation, direction logic, and preset builders.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Define subtasks covering delay table generation, motion-direction handling, preset builders, static allocation management, firmware logic updates, and verification tests with goldens.",
        "updatedAt": "2025-10-16T08:42:21.657Z"
      },
      {
        "id": 16,
        "title": "Execute Progressive Mode Hardware Validation & Performance Profiling",
        "description": "Validate visual correctness of progressive shapes on hardware and capture performance data at 120 FPS.",
        "details": "Steps:\n1. Deploy firmware to three ESP32-S3 units attached to dual-edge LGP rig.\n2. Capture high-speed (240 FPS) video for each preset; extract frame-by-frame delay measurements using Python script + OpenCV to compute LED activation timing.\n3. Record observer feedback confirming phi phenomenon (triangles perceived smoothly).\n4. Use ESP-IDF `esp_timer` tracing to measure per-frame temporal compute time (<0.1% CPU budget) and generate profiling report.\n5. Store hardware photos and performance graphs in `docs/phase2/` and update ADR-010 appendix.\n6. File bug reports if any flicker or over-budget frames detected.",
        "testStrategy": "Review captured media vs expected shape outlines, compare timer logs against threshold, and run automated script ensuring frame variance <±5ms across LED indices.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure Chronos 2.1 high-speed capture rig",
            "description": "Prepare Chronos 2.1 camera for 240 FPS progressive LED capture on the dual-edge rig.",
            "dependencies": [],
            "details": "Mount the camera on the rig, place calibration grid, set 240 FPS with 1/1000s shutter, balance lighting, and document lens and exposure parameters.",
            "status": "pending",
            "testStrategy": "Record a calibration clip and verify frame metadata plus grid alignment in review software.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Develop analyze_progressive.py timing extractor",
            "description": "Implement OpenCV timing analyzer for progressive LED activation footage.",
            "dependencies": [
              1
            ],
            "details": "Build analyze_progressive.py to load Chronos videos, segment LED regions, track luminance per frame, calculate activation latency, and output CSV summaries with plots.",
            "status": "pending",
            "testStrategy": "Run the script on the calibration capture and confirm CSV latency traces match expected sequencing.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Conduct phi phenomenon observer trials",
            "description": "Run observer validation sessions to confirm smooth progressive motion perception.",
            "dependencies": [
              1,
              2
            ],
            "details": "Recruit 3-5 testers, brief them on rating scales, play processed sequences at 120 FPS, capture 60-150 ms smoothness ratings, and log qualitative comments.",
            "status": "pending",
            "testStrategy": "Collect signed observation forms and check all ratings meet the acceptance threshold without missing entries.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Instrument firmware with esp_timer profiling",
            "description": "Add esp_timer-based profiling hooks to measure progressive mode CPU usage.",
            "dependencies": [
              1
            ],
            "details": "Wrap progressive rendering routines with esp_timer_get_time, aggregate microsecond timings, guard with config flag, and ensure compute budget stays under 0.1 percent CPU.",
            "status": "pending",
            "testStrategy": "Flash instrumented firmware and review serial logs confirming per-frame averages remain within the CPU budget.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Execute visual shape verification analytics",
            "description": "Quantify shape fidelity using jitter and CAD overlay comparisons.",
            "dependencies": [
              2,
              4
            ],
            "details": "Post-process LED timing data to compute RMS deviations versus CAD overlays, measure peak-to-peak jitter, and generate visual reports comparing expected and observed shapes.",
            "status": "pending",
            "testStrategy": "Automate the analytics routine to flag deviations beyond ±5 ms or geometry limits and validate on a sample dataset.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Archive validation artifacts and update Task Master records",
            "description": "Consolidate validation outputs and document results in project systems.",
            "dependencies": [
              2,
              3,
              4,
              5
            ],
            "details": "Store CSVs, videos, observer notes, profiling logs, and graphs under docs/phase2/, update ADR-010 appendix, and link artifacts within Task Master entries.",
            "status": "pending",
            "testStrategy": "Confirm repository updates include new docs paths and Task Master references to each archived artifact.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Outline subtasks for firmware deployment, high-speed capture workflow, quantitative analysis scripts, performance logging, documentation updates, and bug triage/reporting.",
        "updatedAt": "2025-10-16T08:42:22.333Z"
      },
      {
        "id": 17,
        "title": "Add WAVE Mode with Lookup Tables",
        "description": "Introduce WAVE sync mode using precomputed delay lookup tables and generate sine, triangle, and sawtooth presets.",
        "details": "Files: prism_temporal.c, new module `firmware/components/playback/wave_lut.c`.\nSteps:\n1. Create lookup generator `void prism_wave_build_table(waveform_t type, uint16_t amplitude_ms, uint16_t frequency_fp8, uint16_t phase_deg, uint16_t *out_table)` producing 160 entries.\n2. Precompute tables on pattern load (effect start) storing in static `uint16_t wave_delay_table[160]`.\n3. Implement WAVE branch in `calculate_ch2_frame()` fetching `delay = wave_delay_table[index];` and applying motion direction transforms.\n4. Inline hot-path helpers with `static inline` or `ESP_FORCE_INLINE` to cut call overhead.\n5. Create presets for sine, sawtooth, triangle waves with amplitude/frequency param sets aligned to spec.\nPseudo-code:\n```\nfor i in 0..159:\n    float theta = (i / 160.0f) * 2π * frequency + phase;\n    switch(type){\n        case SINE: delay[i] = base + amplitude * (sin_table[theta_fp] + 1)/2;\n        ...\n    }\n```\n6. Ensure tables use ADR-009 sin8() for fixed-point math (no floating point in render loop).",
        "testStrategy": "Unit tests ensuring LUT generation matches expected waveform math, verifying execution time <0.5µs using cycle counter, and checking presets produce correct amplitude extrema.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Build wave LUT generator module",
            "description": "Implement the prism_wave_build_table function to emit 160-entry fixed-point lookup tables.",
            "dependencies": [],
            "details": "Create firmware/components/playback/wave_lut.c and header defining waveform_t enum usage, implement prism_wave_build_table using ADR-009 sin8() helpers, fixed-point arithmetic, and ESP_FORCE_INLINE utility helpers.",
            "status": "pending",
            "testStrategy": "Add unit coverage in test_wave_lut.c comparing generated sine and triangle tables against precalculated fixtures for multiple amplitudes and phases.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Precompute wave delay table on pattern load",
            "description": "Integrate table allocation and generation during pattern initialization to populate the static cache.",
            "dependencies": [
              1
            ],
            "details": "Extend prism_temporal.c pattern load path to declare static uint16_t wave_delay_table[160], invoke prism_wave_build_table with current sync parameters, and ensure memory lifetime spans effect duration while guarding against re-entry.",
            "status": "pending",
            "testStrategy": "Add integration test in test_prism_temporal.c verifying wave_delay_table populates with non-zero values after mock pattern load and that repeated loads refresh contents.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add WAVE branch to calculate_ch2_frame",
            "description": "Update the temporal rendering loop to consume the precomputed wave table for delay selection.",
            "dependencies": [
              2
            ],
            "details": "Modify calculate_ch2_frame() to recognize sync mode WAVE, compute table index from frame counter, fetch delay from wave_delay_table, and maintain existing behavior for other modes.",
            "status": "pending",
            "testStrategy": "Extend temporal loop unit tests to assert WAVE mode reads expected indices and preserves baseline behavior for SYNC/PROGRESSIVE paths.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement motion direction transforms for WAVE mode",
            "description": "Apply motion-direction-specific adjustments to wave-based delays using inlined helpers.",
            "dependencies": [
              3
            ],
            "details": "Introduce static inline helpers in prism_temporal.c mapping wave_delay_table outputs through LEFT/RIGHT/CENTER/EDGE/STANDARD transforms, leveraging ESP_FORCE_INLINE where needed to avoid call overhead.",
            "status": "pending",
            "testStrategy": "Add focused tests verifying each motion direction produces expected mirrored or shifted indices, plus review assembly output to confirm helpers inline.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create sine, triangle, sawtooth presets",
            "description": "Define preset parameter sets and hook them into the effect pipeline.",
            "dependencies": [
              4
            ],
            "details": "Implement preset factory routines selecting waveform type, amplitude, frequency, and phase per spec, wire into pattern loader so WAVE mode selects presets by name, and document options in playback headers.",
            "status": "pending",
            "testStrategy": "Add preset unit tests ensuring each preset yields expected min/max delay extremes and correct waveform type routing.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Add LUT regression and performance tests",
            "description": "Validate waveform accuracy and execution timing for the completed WAVE implementation.",
            "dependencies": [
              5
            ],
            "details": "Author regression tests comparing generated tables against golden vectors, integrate cycle-counter measurement to assert calculate_ch2_frame WAVE path stays under 0.5µs, and include basic fuzz inputs for amplitude/frequency bounds.",
            "status": "pending",
            "testStrategy": "Extend Unity harness with timing assertions using esp_clk_cpu_freq(), run tests under CI profile, and capture perf metrics for documentation.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Split into subtasks for LUT generator module, table allocation/loading, calculate_ch2_frame wave branch, motion transforms, preset creation, and unit/perf testing.",
        "updatedAt": "2025-10-16T08:37:04.824Z"
      },
      {
        "id": 18,
        "title": "Profile and Optimize WAVE Mode Execution",
        "description": "Benchmark LUT vs realtime sinusoid calculations and ensure CPU utilization remains within budget.",
        "details": "Steps:\n1. Implement profiling hooks toggled via `CONFIG_PRISM_PROFILE_TEMPORAL` measuring cycle counts for LUT lookup vs `sinf` baseline.\n2. Compare average runtime across 10k frames, target reduction from ~80µs to <1µs.\n3. Document cache effects: ensure tables placed in DRAM with `DRAM_ATTR` to avoid flash latency.\n4. Validate no heap fragmentation by inspecting `heap_caps_get_free_size(MALLOC_CAP_8BIT)` before/after wave mode run.\n5. Publish report `docs/phase3/wave_performance.md` with table of results and optimization notes.",
        "testStrategy": "Automated profiling test harness asserting LUT path <1µs median runtime, verifying no heap usage via custom allocator hooks, and ensuring wave visuals remain artifact-free under 120 FPS playback in simulation.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Enable CONFIG_PRISM_PROFILE_TEMPORAL profiling framework",
            "description": "Add the configurable profiling framework for wave mode so temporal hooks can be toggled at build time.",
            "dependencies": [],
            "details": "Define CONFIG_PRISM_PROFILE_TEMPORAL in Kconfig, add wave_profiler_begin/end inline helpers, and schedule a ring-buffer drain task that writes CSV rows to /spiffs/profile_wave.csv.",
            "status": "done",
            "testStrategy": "Toggle the config in idf.py menuconfig and confirm the CSV writer task emits entries during a simulated wave run.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T08:38:12.667Z"
          },
          {
            "id": 2,
            "title": "Instrument wave execution with esp_cpu_get_cycle_count",
            "description": "Capture precise cycle counts for LUT and sinf paths to compare execution cost.",
            "dependencies": [
              1
            ],
            "details": "Wrap wave sections with portENTER_CRITICAL/portEXIT_CRITICAL, invoke esp_cpu_get_cycle_count with rollover handling, convert cycles to nanoseconds, and pin the profiler task to core 0.",
            "status": "done",
            "testStrategy": "Run the profiler under load and verify cycle deltas remain stable across iterations and that rollover logic preserves monotonic timings.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T08:38:14.078Z"
          },
          {
            "id": 3,
            "title": "Integrate Xtensa PMU cache profiling and DRAM audits",
            "description": "Measure cache behavior and ensure lookup tables stay in DRAM to avoid flash latency.",
            "dependencies": [
              1,
              2
            ],
            "details": "Configure perfmon_config_t for PM_CYCLES and PM_DCACHE_MISS, log miss ratios alongside timings, and validate DRAM_ATTR placement and 64-byte alignment via build/prism.map inspection.",
            "status": "done",
            "testStrategy": "Enable PMU counters during the profiling run and confirm logged miss counts drop when DRAM_ATTR placement is correct.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T08:38:49.734Z"
          },
          {
            "id": 4,
            "title": "Optimize LUT access path for wave mode",
            "description": "Refine the LUT code path to minimize instruction count and memory stalls.",
            "dependencies": [
              2,
              3
            ],
            "details": "Introduce branchless phase-to-index masking, apply ESP_FORCE_INLINE to phase helpers, locate hot kernels in IRAM_ATTR, and store a 1024-entry sin8 table in DRAM.",
            "status": "done",
            "testStrategy": "Benchmark the optimized LUT path against the baseline and confirm the median runtime approaches the <1µs target.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T08:38:50.506Z"
          },
          {
            "id": 5,
            "title": "Build wave profiling harness and generate validation artifacts",
            "description": "Create the automated harness to validate performance, heap health, and reporting outputs.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Implement tests/profile_wave_mode.c to run 10k frames, emit JSON results to .taskmaster/reports/, assert median runtime <1µs, and check heap_caps_get_minimum_free_size for fragmentation.",
            "status": "done",
            "testStrategy": "Execute the harness on hardware, review JSON output for pass criteria, and ensure heap metrics remain unchanged pre/post run.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T08:38:51.292Z"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Create subtasks for profiling hook implementation, benchmark harness, memory placement audits, heap diagnostics, and report generation with recommendations.",
        "updatedAt": "2025-10-16T08:38:51.292Z"
      },
      {
        "id": 19,
        "title": "Implement CUSTOM Mode and Web-Based Delay Map Editor",
        "description": "Deliver CUSTOM sync mode with arbitrary delay maps and a web editor for authoring .prism v1.1 patterns.",
        "details": "Steps:\n1. Extend `calculate_ch2_frame()` for CUSTOM mode loading 320-byte delay map into static array `custom_delay_map[160]` and reading per LED.\n2. Add validation during pattern upload ensuring delay range 0-500ms and map size correct; reject invalid TLVs.\n3. Build web editor (React or Svelte per existing stack) in `tools/custom-delay-editor/` with:\n   - Canvas preview of 160 LEDs (top/bottom channels).\n   - Drag control points generating cubic spline curve mapped to delay values.\n   - Import/export `.prism` via WebUSB or file download.\n4. Implement export pipeline: serialize header + delay map using WebAssembly helper reusing existing C structs compiled via Emscripten.\n5. Seed preset library with triangle/diamond/wave templates.\nPseudo-code (CUSTOM evaluation):\n```\nfor i in 0..159:\n    uint16_t delay = custom_delay_map[i];\n    if (frame_elapsed_ms < delay) ch2[i] = 0;\n    else ch2[i] = ch1[i];\n```\n6. Provide documentation `docs/phase4/custom_mode.md` describing workflow.",
        "testStrategy": "Unit tests for delay map parsing, web editor Jest tests validating curve-to-delay conversion, end-to-end test exporting pattern and verifying firmware playback matches authored delay map using hardware loopback harness.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up WebAssembly serializer build",
            "description": "Establish the emscripten build pipeline for the shared .prism serializer module.",
            "dependencies": [],
            "details": "Create emcc configuration, integrate existing C structs, and produce reusable WASM/JS glue exposing serialization APIs for the web tool.",
            "status": "pending",
            "testStrategy": "Add CI step invoking emcc build and verify exported functions via wasm-smoke tests.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement spline-based curve editor UI",
            "description": "Build interactive curve editor interface supporting control point manipulation.",
            "dependencies": [
              1
            ],
            "details": "Use existing frontend stack to create canvas UI with draggable Bezier/spline handles, dual-channel LED layout, and state management for 160-point curve authoring.",
            "status": "pending",
            "testStrategy": "Jest + React Testing Library checks for control point interactions and state persistence.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Create curve-to-delay sampling engine",
            "description": "Convert authored curves into 160 delay samples between 0 and 500 ms.",
            "dependencies": [
              2
            ],
            "details": "Implement sampling routine that evaluates spline geometry, clamps values within allowed bounds, and outputs 320-byte delay map ready for firmware consumption.",
            "status": "pending",
            "testStrategy": "Unit tests comparing sampled arrays against analytic references and boundary conditions.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add firmware delay map validation",
            "description": "Extend firmware upload validation for CUSTOM delay maps and constraints.",
            "dependencies": [
              3
            ],
            "details": "Update pattern ingestion to enforce TLV size of 320 bytes, validate each delay within 0-500 ms, and reject malformed payloads before storage.",
            "status": "pending",
            "testStrategy": "Unity tests feeding valid/invalid TLVs verifying acceptance, rejection codes, and error logging.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement real-time LED preview renderer",
            "description": "Render dual-channel LED preview reflecting sampled delays in the browser.",
            "dependencies": [
              3
            ],
            "details": "Build WebGL or Canvas2D renderer that simulates top/bottom LED playback using incoming ch1 data and computed ch2 delays for live visualization.",
            "status": "pending",
            "testStrategy": "Visual regression via Jest canvas snapshots and manual QA checklist for playback timing.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": ".prism export and TLV integration",
            "description": "Wire WebAssembly serializer into export flow for .prism files.",
            "dependencies": [
              1,
              3,
              5
            ],
            "details": "Connect sampling output to WASM serializer, package header and delay map into TLV-compliant .prism payload, and support WebUSB download/upload flows.",
            "status": "pending",
            "testStrategy": "End-to-end browser tests verifying generated files load in firmware harness and pass TLV checks.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Seed preset library with CUSTOM patterns",
            "description": "Author preset delay maps (triangle, diamond, wave) leveraging prior tasks.",
            "dependencies": [
              3,
              6
            ],
            "details": "Use curve editor and serialization path to create preset JSON/.prism assets, cross-reference Task 15 shapes, and register them in preset catalog.",
            "status": "pending",
            "testStrategy": "Snapshot tests ensuring preset delay arrays match expected shapes and metadata integrity checks.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Build comprehensive CUSTOM mode test suite",
            "description": "Develop automated tests covering web tool, serialization, and firmware integration.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6,
              7
            ],
            "details": "Expand Jest suites for UI/sampling, add integration tests for export/import, and create Unity firmware tests validating runtime playback with seeded presets.",
            "status": "pending",
            "testStrategy": "Run combined Jest suite and Unity hardware-in-the-loop regression verifying outputs align with reference delay maps.",
            "parentId": "undefined"
          }
        ],
        "complexity": 9,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Plan subtasks spanning firmware support for custom maps, validation logic, web editor UI/UX, curve-to-delay algorithms, import/export tooling, WASM glue, preset seeding, and documentation/tests.",
        "updatedAt": "2025-10-16T09:01:10.918Z"
      },
      {
        "id": 20,
        "title": "Finalize Documentation, Migration, and Release Validation",
        "description": "Finalize firmware v1.1 deliverables by leveraging the finished migration CLI and user manual to complete media assets, long-run validation, preset packaging, and the public release handoff.",
        "status": "in-progress",
        "dependencies": [
          "23",
          "26",
          "27",
          "28"
        ],
        "priority": "medium",
        "details": "Steps:\n1. Completed: Ship the `tools/prism-migrate` CLI converting v1.0 patterns to v1.1 with default motion/sync metadata and idempotent re-runs.\n2. Completed: Publish the user manual and tutorials set in `docs/user-manual/`, covering temporal sequencing, motion directions, sync modes, and advanced techniques.\n3. Produce five narrated 10–15 minute tutorial videos capturing screen and hardware demos, then upload to YouTube and link from the README.\n4. Conduct the 24-hour soak test cycling 20+ presets on at least three hardware units with telemetry for heap fragmentation (<5%), frame timings, and thermals.\n5. Assemble and package a ≥20 pattern preset library that exercises all motion and sync combinations alongside metadata defaults.\n6. Extend the updated `CHANGELOG.md` and local `firmware-v1.1` tag into polished release notes that summarize validation evidence, link multimedia assets, and outline migration steps.\n7. Publish the v1.1 release by distributing artifacts, confirming OTA upgrades on three units, verifying rollback procedure, and archiving the complete asset bundle.",
        "testStrategy": "Confirm migration CLI regression logs remain green, re-review the published manual against the PRD checklist, validate tutorial videos for audio/visual quality and working README links, analyze soak test telemetry for zero frame drops and acceptable temperature margins, spot-check the preset library on hardware, and verify final release artifacts (including CHANGELOG updates and tag) pass the QA checklist before publication.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement v1.0→v1.1 migration CLI",
            "description": "Create the `tools/prism-migrate` CLI to upgrade legacy pattern packs to firmware v1.1 format.",
            "dependencies": [],
            "details": "Build parser for v1.0 headers, enforce CRC validation, inject default motion and sync metadata, and ensure repeated runs remain idempotent.",
            "status": "done",
            "testStrategy": "Add regression suite comparing source and migrated pattern CRCs and verifying metadata defaults.','parentId':'undefined'",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Write comprehensive user manual",
            "description": "Author Markdown documentation covering firmware v1.1 concepts and workflows.",
            "dependencies": [],
            "details": "Organize docs in `docs/user-manual/`, explain temporal sequencing, motion directions, sync modes, advanced techniques, and include phi phenomenon discussion.",
            "status": "done",
            "testStrategy": "Peer review against PRD checklist and lint Markdown for broken links.','parentId':'undefined'",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Produce five narrated tutorial videos",
            "description": "Develop and publish 10-15 minute instructional videos for firmware v1.1.",
            "dependencies": [
              2
            ],
            "details": "Draft scripts, capture screen plus hardware demos, record narration, edit, upload to YouTube, and add links to README.",
            "status": "pending",
            "testStrategy": "Review audio/video quality checklist and confirm published links play end-to-end.','parentId':'undefined'",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Set up 24-hour soak test infrastructure",
            "description": "Prepare automation and hardware to run extended stability testing.",
            "dependencies": [
              1
            ],
            "details": "Provision three test units, script pattern cycling over 20+ presets, enable telemetry capture for heap usage, frame timing, and thermal logging.",
            "status": "pending",
            "testStrategy": "Dry-run automation for one hour verifying telemetry files generate correctly.','parentId':'undefined'",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Execute soak test and analyze telemetry",
            "description": "Run long-duration test and compile stability findings.",
            "dependencies": [
              4
            ],
            "details": "Execute 24-hour run, collect logs, analyze heap fragmentation, frame drops, and thermal trends, then summarize results in report.",
            "status": "pending",
            "testStrategy": "Validate analysis scripts with spot checks and confirm report includes required metrics.','parentId':'undefined'",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Assemble pattern preset library",
            "description": "Curate and package patterns showcasing all mode combinations.",
            "dependencies": [
              1
            ],
            "details": "Design 20+ presets as `.prism` files with metadata covering motion and sync permutations, bundle artifacts with release package.",
            "status": "pending",
            "testStrategy": "Load presets on hardware to verify metadata recognition and playback quality.','parentId':'undefined'",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Draft production release notes",
            "description": "Document firmware v1.1 changes and migration guidance.",
            "dependencies": [
              1,
              5,
              6
            ],
            "details": "Roll forward the updated `CHANGELOG.md`, incorporate soak-test findings, highlight breaking changes, and reference validation evidence plus multimedia links.",
            "status": "pending",
            "testStrategy": "Cross-check notes against completed work and run Markdown link checker.','parentId':'undefined'",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Deploy v1.1 firmware and validate release",
            "description": "Publish artifacts and confirm rollout on target hardware.",
            "dependencies": [
              5,
              6,
              7
            ],
            "details": "Convert the local `firmware-v1.1` tag into the public release, distribute firmware, perform OTA updates on three units, verify rollback procedure, and archive all release assets.",
            "status": "pending",
            "testStrategy": "Execute upgrade/rollback smoke tests on each unit and verify checksums of published artifacts.','parentId':'undefined'",
            "parentId": "undefined"
          }
        ],
        "complexity": 9,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Break into subtasks for migration CLI, user manual authoring, tutorial production, soak testing plus telemetry analysis, pattern library packaging, release notes, QA checklist, and artifact publication."
      },
      {
        "id": 21,
        "title": "Establish CLI tooling core",
        "description": "Create shared CLI scaffolding and deterministic JSON/CSV writers for PRISM authoring tools.",
        "details": "Implementation:\n- Add `tools/tooling_core.py` housing argparse helpers, stdout/stderr logging, and deterministic JSON/CSV writers (ensure UTF-8, sorted keys, newline termination).\n- Provide reusable `write_json(output_path, payload, metadata)` and `write_csv(output_path, rows, headers)` utilities that include metadata blocks as required by PRD.\n- Expose base `build_parser(description)` that injects common arguments (`--output`, optional `--csv`, `--meta` seed info) and validates writable paths.\n- Ensure CLI entrypoints in `tools/__main__.py` or module-level guards call these helpers.\nPseudo-code:\n```python\n# tools/tooling_core.py\ndef build_parser(description: str) -> argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(description=description)\n    parser.add_argument(\"--output\", required=True)\n    parser.add_argument(\"--csv\")\n    parser.add_argument(\"--meta\", help=\"Path to optional metadata JSON\")\n    return parser\n\ndef write_json(path, rgb_frames, metadata):\n    payload = {\"data\": rgb_frames, \"meta\": metadata, \"version\": \"1.0\"}\n    with open(path, \"w\", encoding=\"utf-8\") as fh:\n        json.dump(payload, fh, indent=2, sort_keys=True)\n        fh.write(\"\\n\")\n```\n",
        "testStrategy": "Unit:\n- Writer tests verifying stable key ordering, newline termination, and metadata merge.\n- Parser smoke tests covering help output and required arguments.\nIntegration:\n- CLI stub that invokes writers and asserts file creation in tmpdir.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design shared CLI parser scaffolding",
            "description": "Create argparse utilities that enforce common CLI options and path validation.",
            "dependencies": [],
            "details": "Implement tools/tooling_core.py with build_parser(description) returning an ArgumentParser that registers --output, optional --csv, and --meta arguments, validates writable paths, and hooks shared stdout/stderr logging helpers for downstream CLIs.",
            "status": "pending",
            "testStrategy": "Unit smoke tests asserting parser enforces required --output, optional flags, and help text formatting."
          },
          {
            "id": 2,
            "title": "Implement deterministic JSON and CSV writers",
            "description": "Provide reusable writer helpers ensuring stable output for PRISM tools.",
            "dependencies": [
              1
            ],
            "details": "Add write_json(output_path, payload, metadata) and write_csv(output_path, rows, headers) in tools/tooling_core.py to merge metadata blocks, emit UTF-8 files with sorted keys, newline termination, and deterministic column ordering, sharing logging from the parser scaffolding.",
            "status": "pending",
            "testStrategy": "Unit tests that write to tmp paths, verify newline termination, key ordering, encoded metadata blocks, and deterministic CSV header ordering."
          },
          {
            "id": 3,
            "title": "Add tests and CLI integration harness",
            "description": "Create automated validation covering parser and writer behaviors via CLI entrypoints.",
            "dependencies": [
              1,
              2
            ],
            "details": "Introduce tools/__main__.py or module guard that wires build_parser and writer helpers into a stub CLI command, plus dedicated pytest modules exercising integration flows in temp directories to ensure files create correctly and errors surface via logging.",
            "status": "pending",
            "testStrategy": "Integration tests invoking python -m tools with sample arguments plus unit coverage for log output and failure modes."
          }
        ]
      },
      {
        "id": 22,
        "title": "Configure color library dependencies",
        "description": "Add and validate third-party color dependencies required for HSLuv and RGBW conversions.",
        "details": "Implementation:\n- Update `tools/requirements.txt` to include pinned versions of `hsluv>=0.1.2`, `rgbw-colorspace-converter` (latest stable), `colr`, `ansi2html`, and `aha`.\n- Add dependency availability checks in a lightweight `tools/check_deps.py` to import each library and raise actionable errors.\n- Document installation instructions and virtualenv guidance in `tools/README.md`.\nPseudo-code:\n```python\n# tools/check_deps.py\nREQUIRED = [\"hsluv\", \"rgbw_colorspace_converter\", \"colr\", \"ansi2html\", \"aha\"]\nfor name in REQUIRED:\n    try:\n        importlib.import_module(name)\n    except ImportError as exc:\n        raise SystemExit(f\"Missing dependency {name}: {exc}\")\n```\n",
        "testStrategy": "Unit:\n- Run `python -m tools.check_deps` in CI to confirm imports succeed.\n- Verify requirements hash lock (if using pip-tools) regenerates cleanly.\nDocumentation:\n- Manual validation by following README steps in a fresh venv.",
        "priority": "high",
        "dependencies": [
          21
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Pin required color libraries in tooling manifests",
            "description": "Add the new color dependencies to the tooling requirements files with appropriate version pins and refresh any generated lock artifacts.",
            "dependencies": [],
            "details": "Update `tools/requirements.txt` with pinned entries for hsluv>=0.1.2, rgbw-colorspace-converter (latest stable), colr, ansi2html, and aha, then regenerate and stage any lockfile or hashes workflow expects so downstream installs pull the exact versions.",
            "status": "pending",
            "testStrategy": "Re-run the project’s dependency lock workflow (e.g., `pip-compile` or hash regeneration) to confirm the manifest resolves cleanly and `pip install -r tools/requirements.txt` succeeds in a clean virtualenv."
          },
          {
            "id": 2,
            "title": "Add dependency verification script and contributor setup docs",
            "description": "Implement the lightweight dependency import checker and document installation guidance for developers.",
            "dependencies": [
              1
            ],
            "details": "Create `tools/check_deps.py` that imports each required library and raises friendly SystemExit errors when missing, then expand `tools/README.md` with virtualenv setup and instructions for running the checker after installing requirements.",
            "status": "pending",
            "testStrategy": "Run `python -m tools.check_deps` in a clean environment to ensure success with installed deps and verify it exits with actionable messaging when a library is removed temporarily."
          }
        ]
      },
      {
        "id": 23,
        "title": "Implement HSLuv and baseline palette interpolation",
        "description": "Build palette generation core supporting HSLuv, HSV, and HSL interpolation with perceptual hue wrapping.",
        "details": "Implementation:\n- Extend `tools/palette_to_prism.py` with interpolation utilities converting HEX stops to RGB tuples via hsluv for `--space hsluv`, and Python colorsys for HSV/HSL.\n- Implement hue wrapping logic to always choose shortest angular distance across 0/360.\n- Support arbitrary LED counts by distributing segments with remainder handling.\n- Expose reusable `interpolate_palette(stops, led_count, space, easing=\"linear\")` returning list of RGB floats normalized to [0,1].\nPseudo-code:\n```python\ndef interpolate_palette(hex_stops: list[str], led_count: int, space: str) -> list[tuple[float,float,float]]:\n    stops = [hex_to_space(stop, space) for stop in hex_stops]\n    ramp = []\n    for idx in range(led_count):\n        t = idx / (led_count - 1)\n        seg_idx = locate_segment(t, len(stops))\n        local_t = compute_local_t(t, seg_idx, len(stops))\n        blended = blend(stops[seg_idx], stops[seg_idx + 1], local_t, wrap_hue=True)\n        ramp.append(space_to_rgb(blended, space))\n    return ramp\n```\n",
        "testStrategy": "Unit:\n- Golden tests comparing generated RGB arrays against fixtures for known palettes (2-stop and 3-stop).\n- Edge-case tests for hue wrapping across 0° and LED counts smaller than stop count.\n- Property tests ensuring RGB outputs stay within [0,255] after scaling.\nIntegration:\n- Smoke CLI run generating JSON for sample palette.",
        "priority": "high",
        "dependencies": [
          21,
          22,
          "33"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Build color space conversion helpers",
            "description": "Implement reusable conversions between HEX, HSLuv, HSV, HSL, and RGB tuples.",
            "dependencies": [],
            "details": "Add helper functions in tools/palette_to_prism.py to decode hex stops, call hsluv library, and normalize RGB floats for each supported color space.",
            "status": "pending",
            "testStrategy": "Unit tests covering round-trip HEX ↔ RGB for HSLuv, HSV, and HSL using known fixtures."
          },
          {
            "id": 2,
            "title": "Implement hue-aware interpolation core",
            "description": "Create interpolation pipeline that blends stops with perceptual hue wrapping.",
            "dependencies": [
              1
            ],
            "details": "Develop interpolate_palette logic that maps to color space values, locates segment indices, computes local t, and blends hues using shortest angular distance across 0/360 with optional easing hooks.",
            "status": "pending",
            "testStrategy": "Unit tests verifying hue wrapping across 359°→1° cases and linear blending accuracy for 2- and 3-stop palettes."
          },
          {
            "id": 3,
            "title": "Handle LED distribution and API exposure",
            "description": "Support arbitrary LED counts and expose the reusable interpolation API.",
            "dependencies": [
              2
            ],
            "details": "Implement LED segment distribution with remainder handling, ensure RGB outputs stay normalized, and surface interpolate_palette(stops, led_count, space, easing) from tools/palette_to_prism.py.",
            "status": "pending",
            "testStrategy": "Unit tests confirming segment allocation for uneven LED counts and correct output length/value ranges."
          },
          {
            "id": 4,
            "title": "Author comprehensive regression tests",
            "description": "Add golden fixtures and property checks for the palette interpolation workflow.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Create golden RGB arrays for reference palettes, add regression tests for edge cases, and include property tests ensuring outputs remain in range and consistent across spaces.",
            "status": "pending",
            "testStrategy": "Integration tests generating palettes against fixtures plus property tests validating RGB bounds and consistency."
          }
        ]
      },
      {
        "id": 24,
        "title": "Finalize palette_to_prism CLI and metadata output",
        "description": "Wire CLI arguments for palette generation and write deterministic JSON/CSV payloads with metadata.",
        "details": "Implementation:\n- Use tooling core parser to accept `--palette`, `--led-count`, `--space`, `--include-rgbw`, optional `--seed`, and output paths.\n- Parse comma-separated HEX list, validate format, and call interpolation logic from Task 23.\n- Attach metadata capturing inputs (palette stops, space, timestamp, software version, random seed).\n- Ensure CSV writing supports optional RGBW columns but is gated by `--include-rgbw`.\nPseudo-code:\n```python\ndef main():\n    parser = build_parser(\"Generate PRISM palette payload\")\n    parser.add_argument(\"--palette\", required=True)\n    parser.add_argument(\"--led-count\", type=int, required=True)\n    parser.add_argument(\"--space\", choices=[\"hsv\",\"hsl\",\"hsluv\"], default=\"hsluv\")\n    parser.add_argument(\"--include-rgbw\", action=\"store_true\")\n    args = parser.parse_args()\n    rgb = interpolate_palette(args.palette.split(','), args.led_count, args.space)\n    rgbw = compute_rgbw(rgb) if args.include_rgbw else None\n    write_outputs(args, rgb, rgbw)\n```\n",
        "testStrategy": "Unit:\n- Argument parsing tests covering default values, error cases, and help text.\n- Verify metadata contains all expected keys and matches inputs.\nIntegration:\n- CLI end-to-end test writing JSON and CSV fixtures compared against goldens.\nRegression:\n- Ensure unicode/hex parsing works on CI (UTF-8).",
        "priority": "medium",
        "dependencies": [
          21,
          22,
          23
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement palette_to_prism CLI argument handling",
            "description": "Wire up CLI parser options and validations for palette generation.",
            "dependencies": [],
            "details": "Add required arguments including palette list, led count, color space, include-rgbw toggle, optional seed, and output paths with robust validation.",
            "status": "pending",
            "testStrategy": "Unit test parser to cover required/optional flags, defaults, and failure cases."
          },
          {
            "id": 2,
            "title": "Integrate palette parsing and interpolation logic",
            "description": "Parse palette input and connect interpolation functions.",
            "dependencies": [
              1
            ],
            "details": "Split comma-separated hex inputs, validate formatting, convert to RGB tuples, and invoke Task 23 interpolation respecting selected color space.",
            "status": "pending",
            "testStrategy": "Unit test parsing acceptance of valid palettes, rejection of malformed entries, and correctness of interpolation calls."
          },
          {
            "id": 3,
            "title": "Generate deterministic JSON and CSV payloads with metadata",
            "description": "Produce serialized outputs with deterministic ordering and metadata capture.",
            "dependencies": [
              1,
              2
            ],
            "details": "Emit JSON and CSV files with stable key ordering, include metadata for inputs, timestamps, versions, seeds, and guard RGBW columns behind include-rgbw flag.",
            "status": "pending",
            "testStrategy": "Unit tests verifying metadata completeness, deterministic ordering, and CSV schema with/without RGBW."
          },
          {
            "id": 4,
            "title": "Run end-to-end palette_to_prism CLI validation",
            "description": "Execute CLI flow to confirm full pipeline behavior.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Craft integration fixture invoking CLI to produce JSON/CSV outputs, verify against goldens, and ensure exit codes and logging align with expectations.",
            "status": "pending",
            "testStrategy": "Integration test invoking CLI, diff outputs with fixtures, assert deterministic behavior across repeated runs."
          }
        ]
      },
      {
        "id": 25,
        "title": "Implement RGBW offline emission pipeline",
        "description": "Add RGBW tuple generation leveraging rgbw_colorspace_converter for authoring-only payloads.",
        "details": "Implementation:\n- Integrate `rgbw_colorspace_converter` to map RGB values to RGBW using HSI-based algorithm tuned for authoring.\n- Provide configurable white channel scaling (0–1) and clamp outputs to 8-bit integers.\n- Extend metadata to flag RGBW inclusion and transformation parameters.\n- Ensure RGBW arrays align index-wise with RGB arrays for downstream shows.\nPseudo-code:\n```python\ndef compute_rgbw(rgb_values: list[tuple[int,int,int]], white_shift=0.0) -> list[tuple[int,int,int,int]]:\n    converter = RGBWConverter(white_point=\"D65\", white_shift=white_shift)\n    rgbw = []\n    for rgb in rgb_values:\n        r, g, b, w = converter.rgb_to_rgbw(*rgb)\n        rgbw.append(tuple(int(round(channel)) for channel in (r, g, b, w)))\n    return rgbw\n```\n",
        "testStrategy": "Unit:\n- Property tests verifying each component remains within 0–255 and sums do not exceed expected ranges.\n- Compare converter output against known fixtures from rgbw_colorspace_converter repo.\nIntegration:\n- CLI run with `--include-rgbw` producing JSON/CSV validated for correct schema.\nPerformance:\n- Benchmark on 1000 LEDs to ensure runtime within acceptable bounds (<100ms).",
        "priority": "high",
        "dependencies": [
          21,
          22,
          23,
          24
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate rgbw_colorspace_converter core",
            "description": "Wire the rgbw_colorspace_converter into the offline emission pipeline to translate RGB tuples into RGBW outputs.",
            "dependencies": [],
            "details": "Add converter initialization, call rgb_to_rgbw for each frame payload, and ensure the converter uses the authoring-tuned HSI algorithm.",
            "status": "pending",
            "testStrategy": "Create unit tests comparing converter outputs against fixtures supplied by rgbw_colorspace_converter to validate baseline accuracy."
          },
          {
            "id": 2,
            "title": "Implement white channel scaling and clamping",
            "description": "Expose configurable white channel scaling and clamp resulting RGBW channels to 8-bit integer bounds.",
            "dependencies": [
              1
            ],
            "details": "Introduce parameters for white channel scaling (0-1), apply scaling before finalizing tuples, and clamp all channels to 0-255 integers before serialization.",
            "status": "pending",
            "testStrategy": "Add parameterized unit tests covering edge scaling values (0, 0.5, 1) and verifying clamped outputs never exceed 0-255."
          },
          {
            "id": 3,
            "title": "Extend metadata and array alignment",
            "description": "Update payload metadata to include RGBW transformation flags and guarantee RGBW arrays stay index-aligned with RGB data.",
            "dependencies": [
              1,
              2
            ],
            "details": "Augment metadata schemas with RGBW enablement and converter settings, propagate through serializers, and validate array ordering remains consistent for downstream show processors.",
            "status": "pending",
            "testStrategy": "Write integration tests that serialize sample payloads and assert metadata fields plus per-index RGB↔RGBW alignment are correct."
          },
          {
            "id": 4,
            "title": "Add performance and regression coverage",
            "description": "Profile the RGBW pipeline and implement regression tests guarding against performance or numerical drift.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Benchmark converter execution on representative payload sizes, set performance thresholds, and add regression tests comparing outputs to stored baselines to detect drift.",
            "status": "pending",
            "testStrategy": "Introduce performance benchmarks with assertions on max runtime and add regression comparisons against golden RGBW snapshots to detect deviations."
          }
        ]
      },
      {
        "id": 26,
        "title": "Build terminal preview renderer",
        "description": "Create `previews/terminal_preview.py` to render palettes and shows in ANSI using colr.",
        "details": "Implementation:\n- Add `render_terminal(rgb_frames, fps)` that down-samples frames if necessary and prints ANSI blocks using `colr` with configurable width.\n- Support both palette (single frame) and show sequences (timed playback with sleep respecting fps +/- tolerance).\n- Provide CLI hook (e.g., `python -m tools.previews.terminal_preview --input palette.json`).\n- Include options for static preview (no animation) for docs.\nPseudo-code:\n```python\ndef render_terminal(rgb_frames, fps=30, loop=False):\n    interval = 1.0 / fps\n    for frame in rgb_frames:\n        line = ''.join(colr.rgb(*pixel)('█') for pixel in frame)\n        print(line)\n        time.sleep(interval)\n    if loop:\n        render_terminal(rgb_frames, fps, loop=True)\n```\n",
        "testStrategy": "Unit:\n- Use monkeypatch to assert `time.sleep` call frequency and ANSI escape sequences for sample frame.\n- Snapshot test comparing generated line strings against expected ANSI codes.\nIntegration:\n- Manual smoke run verifying playback smoothness and fallback in non-TTY environments.",
        "priority": "medium",
        "dependencies": [
          23,
          24,
          "37"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement ANSI frame rendering utilities",
            "description": "Build the core terminal renderer that converts RGB pixel grids into ANSI strings using colr.",
            "dependencies": [],
            "details": "Create previews/terminal_preview.py with render_terminal accepting rgb_frames, optional width, and downsampling logic that maps RGB tuples to colr-colored block characters while handling palette-only inputs and non-TTY fallbacks.",
            "status": "pending",
            "testStrategy": "Add isolated tests for render_terminal that assert generated ANSI strings for small sample frames and verify downsampling behavior without performing sleeps."
          },
          {
            "id": 2,
            "title": "Add playback control and CLI interface",
            "description": "Layer timing, looping, and command-line entry point on top of the renderer.",
            "dependencies": [
              1
            ],
            "details": "Introduce timed playback that respects fps tolerance via time.sleep, implement looping/static preview flags, and expose python -m tools.previews.terminal_preview CLI accepting palette or show JSON inputs with safe error reporting.",
            "status": "pending",
            "testStrategy": "Use monkeypatched time.sleep to confirm interval calculations, and run CLI invocation in dry-run mode to ensure argument parsing and non-TTY fallbacks behave."
          },
          {
            "id": 3,
            "title": "Author snapshot tests and documentation hooks",
            "description": "Create automated checks and doc-friendly outputs for the terminal preview.",
            "dependencies": [
              1,
              2
            ],
            "details": "Capture deterministic snapshots of ANSI frames for regression tests, cover non-TTY behavior via buffered outputs, and document static preview usage for docs workflows.",
            "status": "pending",
            "testStrategy": "Implement snapshot comparisons of rendered lines, add unit coverage for non-TTY branches, and document manual verification steps for documentation builds."
          }
        ]
      },
      {
        "id": 27,
        "title": "Implement HTML preview exporter",
        "description": "Generate HTML previews by piping ANSI output through ansi2html/aha for embeddable docs.",
        "details": "Implementation:\n- Create `previews/html_preview.py` that accepts RGB frames, calls `render_terminal` to produce ANSI stream (without sleeps), captures it, and converts via `ansi2html.Ansi2HTMLConverter` or `aha` CLI fallback.\n- Output standalone HTML file with embedded CSS and optional autoplay using `<meta http-equiv=\"refresh\">` or JavaScript for sequence playback.\n- Provide CLI interface for specifying output path and frame rate metadata.\nPseudo-code:\n```python\ndef render_html(rgb_frames, fps, out_html):\n    ansi_stream = capture_ansi(rgb_frames)\n    converter = ansi2html.Ansi2HTMLConverter(inline=True)\n    html_body = converter.convert(ansi_stream, full=True)\n    with open(out_html, \"w\", encoding=\"utf-8\") as fh:\n        fh.write(html_body)\n```\n",
        "testStrategy": "Unit:\n- Mock converter to assert HTML contains expected inline styles and frame markers.\n- Validate generated HTML passes basic parsing via `html5lib`.\nIntegration:\n- End-to-end test producing HTML from sample palette and verifying file size/contents.\nRegression:\n- Ensure fallback path using `aha` binary is covered when ansi2html unavailable.",
        "priority": "medium",
        "dependencies": [
          26,
          "37"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate ANSI stream capture pipeline",
            "description": "Wire the HTML exporter to capture ANSI output from RGB frames via the terminal renderer.",
            "dependencies": [],
            "details": "Implement `capture_ansi` helper that invokes `render_terminal` without delays, captures output using pseudo-terminal or io stream, and normalizes line endings for downstream converters.",
            "status": "pending",
            "testStrategy": "Unit test the capture helper with mocked `render_terminal` to ensure the ANSI buffer matches expected escape sequences and no sleeps are triggered."
          },
          {
            "id": 2,
            "title": "Convert ANSI stream to standalone HTML preview",
            "description": "Transform captured ANSI into embeddable HTML with inline assets and CLI fallbacks.",
            "dependencies": [
              1
            ],
            "details": "Create `previews/html_preview.py` logic that prefers `ansi2html.Ansi2HTMLConverter(inline=True)` while falling back to the `aha` CLI, embeds CSS, supports optional autoplay tags, and exposes CLI parameters for output path and frame metadata.",
            "status": "pending",
            "testStrategy": "Integration test that feeds a sample ANSI stream, verifies HTML contains inline styles or fallback markup, and confirms CLI arguments map to output metadata."
          },
          {
            "id": 3,
            "title": "Automate HTML preview validation",
            "description": "Ensure generated HTML documents are portable and regressions are caught automatically.",
            "dependencies": [
              2
            ],
            "details": "Add tests or scripts that parse produced HTML via `html5lib`, assert presence of expected frames and metadata, and exercise both converter paths for coverage.",
            "status": "pending",
            "testStrategy": "Automated regression test verifying generated HTML passes parsing, includes required tags, and that fallback path produces structurally valid output."
          }
        ]
      },
      {
        "id": 28,
        "title": "Develop minimal show engine for sine and morph presets",
        "description": "Implement CPU-side frame generator producing reference sine-wave and morphing gradient shows.",
        "details": "Implementation:\n- Add `tools/show_to_prism.py` with classes for `SineWaveShow` and `MorphGradientShow` that accept palette, led count, fps, duration, and optional seed.\n- For sine show, modulate brightness per LED using temporal sine with phase offset; map palette index via normalized value.\n- For morph show, interpolate between multiple palette frames using easing controlling speed.\n- Reuse palette interpolation to map palette stops to frames per tick.\nPseudo-code:\n```python\nclass SineWaveShow:\n    def __init__(self, palette, led_count, speed, amplitude, fps):\n        self.palette = palette\n        ...\n    def frame_at(self, t):\n        frame = []\n        for idx in range(self.led_count):\n            phase = (idx / self.led_count) * 2 * math.pi\n            value = 0.5 + self.amplitude * math.sin(phase + self.speed * t)\n            frame.append(sample_palette(self.palette, value))\n        return frame\n\ndef generate_frames(show, duration, fps):\n    return [show.frame_at(i / fps) for i in range(int(duration * fps))]\n```\n",
        "testStrategy": "Unit:\n- Deterministic tests verifying frame counts and RGB shapes for fixed seeds and parameters.\n- Numerical assertions comparing sample frames to expected sine values within tolerance.\nIntegration:\n- CLI smoke test generating JSON/CSV frames and checking metadata for show parameters.",
        "priority": "high",
        "dependencies": [
          23,
          24,
          25,
          "35"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement palette sampling and frame generator scaffold",
            "description": "Create shared utilities for palette sampling and time-stepped frame generation used by both show types.",
            "dependencies": [],
            "details": "Add helper functions for normalized palette lookup, easing selection, and a deterministic generate_frames(show, duration, fps) routine with seeded RNG wiring.",
            "status": "pending",
            "testStrategy": "Write unit tests ensuring palette sampling returns expected RGB tuples for edge values and frame counts match duration*fps."
          },
          {
            "id": 2,
            "title": "Build SineWaveShow with temporal brightness modulation",
            "description": "Define SineWaveShow producing sine-modulated frames using palette mapping and deterministic seeding.",
            "dependencies": [
              1
            ],
            "details": "Implement constructor capturing palette, led_count, fps, amplitude, speed, duration, optional seed, and frame_at() computing per-LED sine phase with normalized brightness mapped via palette helpers.",
            "status": "pending",
            "testStrategy": "Validate frame_at() against known sine samples, asserting max/min brightness and palette index continuity for small led_counts."
          },
          {
            "id": 3,
            "title": "Develop MorphGradientShow with palette frame interpolation",
            "description": "Implement MorphGradientShow interpolating palette frames over time using easing and seeded reproducibility.",
            "dependencies": [
              1
            ],
            "details": "Create frame_at() blending palette keyframes using easing curves, managing wrapped transitions, and honoring seeded RNG when selecting palette frame sequences.",
            "status": "pending",
            "testStrategy": "Check that successive frames smoothly interpolate between palette anchors and easing parameters alter transition timing as expected."
          },
          {
            "id": 4,
            "title": "Author deterministic regression tests and CLI smoke path",
            "description": "Add tests covering shared utilities, both shows, and CLI entry that exports reference frames for validation.",
            "dependencies": [
              2,
              3
            ],
            "details": "Introduce pytest suite exercising determinism with fixed seeds, numeric tolerances for sine amplitude, morph interpolation snapshots, plus minimal CLI script verifying metadata structure.",
            "status": "pending",
            "testStrategy": "Run pytest to compare generated frames to stored fixtures within tolerance and execute CLI smoke command to confirm output schema."
          }
        ]
      },
      {
        "id": 29,
        "title": "Expose parameterized show CLI with validation",
        "description": "Add robust CLI parameter handling, validation, and metadata recording for show generation.",
        "details": "Implementation:\n- Extend show CLI to accept `--show`, `--duration`, `--fps`, `--palette`, `--speed`, `--amplitude`, `--seed`, ensuring sensible defaults and bounds.\n- Validate parameter ranges (e.g., fps 1–120, duration >0, amplitude 0–1) with helpful error messages.\n- Record metadata capturing parameter values, generator version, and random seed.\n- Support reproducibility by seeding RNG for morph transitions.\nPseudo-code:\n```python\ndef main():\n    parser = build_parser(\"Generate PRISM show frames\")\n    parser.add_argument(\"--show\", choices=[\"sine\",\"morph\"], required=True)\n    parser.add_argument(\"--duration\", type=float, default=10.0)\n    parser.add_argument(\"--fps\", type=int, default=30)\n    parser.add_argument(\"--speed\", type=float, default=1.0)\n    parser.add_argument(\"--amplitude\", type=float, default=0.5)\n    args = parser.parse_args()\n    validate(args)\n    show = SHOW_FACTORY[args.show](args)\n    frames = generate_frames(show, args.duration, args.fps)\n    write_json(args.output, frames, metadata=args.__dict__)\n```\n",
        "testStrategy": "Unit:\n- Argument parsing tests covering defaults, invalid ranges, and enum validation.\n- Metadata snapshot tests ensuring reproducible output given fixed seed.\nIntegration:\n- End-to-end CLI run verifying generated frames respect fps/duration (frame count = fps*duration).\nRegression:\n- Fuzzer-style test feeding random parameter combinations within bounds to ensure no crashes.",
        "priority": "medium",
        "dependencies": [
          21,
          22,
          23,
          24,
          25,
          28,
          "35"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement CLI argument parsing and validation",
            "description": "Extend the show CLI to accept new parameters and enforce required constraints.",
            "dependencies": [],
            "details": "Add parser options for show selection, timing, palette, speed, amplitude, and seed, then guard each with range checks and descriptive error messages.",
            "status": "pending",
            "testStrategy": "Add unit coverage for defaults, enum enforcement, and invalid boundary cases."
          },
          {
            "id": 2,
            "title": "Persist metadata and seed controlled RNG",
            "description": "Ensure the CLI records execution metadata and uses deterministic random seeding for reproducible shows.",
            "dependencies": [
              1
            ],
            "details": "Capture parsed argument values plus generator version into the metadata payload and initialize RNG from the provided seed before morph generation executes.",
            "status": "pending",
            "testStrategy": "Create metadata serialization tests confirming seed and version fields are stored and RNG seeding produces stable sequences."
          },
          {
            "id": 3,
            "title": "Author integration tests for frame generation reproducibility",
            "description": "Verify end-to-end CLI behavior for frame counts and deterministic output with seeding.",
            "dependencies": [
              1,
              2
            ],
            "details": "Run the CLI in test mode to confirm output frame count equals fps times duration and that identical seeds produce matching frame data runs.",
            "status": "pending",
            "testStrategy": "Add integration scenario invoking the CLI twice with the same seed, asserting identical outputs and correct frame totals."
          }
        ]
      },
      {
        "id": 30,
        "title": "Prototype .prism v1.1 packaging pipeline",
        "description": "Convert generated frame sequences into .prism v1.1 files with headers and CRC checks.",
        "details": "Implementation:\n- Implement `tools/prism_packaging.py` to read JSON frame payloads and serialize into .prism format per firmware spec (header, payload length, CRC32).\n- Enforce size caps and align frames to expected byte ordering (RGB or RGBW depending on metadata).\n- Add CLI (`--input`, `--output`, `--format prism11`) and update README for workflow.\n- Provide pluggable checksum strategy to stay firmware-agnostic.\nPseudo-code:\n```python\ndef write_prism(input_json, out_path):\n    data = load_json(input_json)\n    header = struct.pack(\"<4sIHH\", b\"PRSM\", VERSION, frame_count, led_count)\n    payload = encode_frames(data[\"data\"])\n    crc = zlib.crc32(header + payload) & 0xFFFFFFFF\n    with open(out_path, \"wb\") as fh:\n        fh.write(header)\n        fh.write(payload)\n        fh.write(struct.pack(\"<I\", crc))\n```\n",
        "testStrategy": "Unit:\n- Header parsing tests ensuring correct magic, version, and CRC calculation using fixture frames.\n- Negative tests for oversized payloads and unsupported channel counts.\nIntegration:\n- Round-trip test reading produced .prism file with firmware parser stub to confirm compatibility.\nRegression:\n- Binary diff tests verifying determinism across repeated runs with same inputs.",
        "priority": "medium",
        "dependencies": [
          21,
          22,
          23,
          24,
          25,
          28,
          29,
          "36",
          "39"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement frame payload encoder",
            "description": "Build payload encoder converting JSON frame arrays into binary buffers that follow .prism v1.1 channel layout rules.",
            "dependencies": [],
            "details": "Parse metadata to detect RGB versus RGBW frames, enforce per-frame size limits, pack color tuples into contiguous little-endian byte streams, and expose helpers for alignment padding.",
            "status": "pending",
            "testStrategy": "Create unit fixtures for RGB/RGBW frames and assert packed bytes match expected ordering and size caps."
          },
          {
            "id": 2,
            "title": "Implement header and CRC writer",
            "description": "Create header serialization and CRC32 routines for .prism v1.1 output files.",
            "dependencies": [
              1
            ],
            "details": "Assemble magic, version, frame count, and LED count into the prescribed little-endian struct, append payload length metadata, then compute and append CRC32 using pluggable checksum implementations.",
            "status": "pending",
            "testStrategy": "Write unit tests confirming header fields, payload length, and CRC outputs align with known-good vectors and that alternate checksum strategies plug in cleanly."
          },
          {
            "id": 3,
            "title": "Add CLI wrapper and documentation updates",
            "description": "Expose packaging functionality through CLI flags and document the workflow updates.",
            "dependencies": [
              1,
              2
            ],
            "details": "Add argparse entry point in tools CLI supporting --input, --output, --format prism11, integrate encoder and serializer modules, and refresh README with usage steps and checksum strategy notes.",
            "status": "pending",
            "testStrategy": "Run CLI integration tests invoking the command with sample JSON inputs to verify output file creation and argument validation."
          },
          {
            "id": 4,
            "title": "Validate round-trip against parser fixtures",
            "description": "Confirm generated .prism files deserialize correctly using existing parser fixtures.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Generate sample packages via CLI, feed them through firmware parser stubs or fixture scripts, and compare recovered headers and frames against originals to ensure deterministic results.",
            "status": "pending",
            "testStrategy": "Add regression test that builds a sample file, parses it with the fixture reader, and asserts header values, frame payloads, and CRC checks all match expected data."
          }
        ]
      },
      {
        "id": 31,
        "title": "Set Up Research Memo Framework",
        "description": "Create reusable structure and tooling for PRISM K1 research memos and source logging.",
        "details": "Deliverable: docs/research/_template.md plus README guidance.\nImplementation outline:\n- Review existing docs/research/ layout and confirm file naming conventions from PRD.\n- Author Markdown template capturing sections: Problem, Options, Evaluation (quant + qual), Decision, Migration Plan, Action Items, Source Log (with provider/date fields).\n- Add checklist for scope/timeboxing and risk notes.\nPseudo-code:\n```\npseudo:\nif not exists(\"docs/research/_template.md\"):\n    write_template()\nupdate_readme(sections=[\"How to instantiate memo\", \"Source logging policy\"])\n```\n- Document workflow in docs/research/README.md including command snippet for copying template before starting each memo.\n- Record catalog of preferred 2024+ references (OKLab updates, LED calibration papers, ESP32-S3 benchmarks).",
        "testStrategy": "Run doc linting (markdownlint) on new template and README, verify sections match PRD validation checklist, and dry-run template instantiation via copy command.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Author research memo template markdown",
            "description": "Draft the reusable docs/research memo template with required sections and checklists.",
            "dependencies": [],
            "details": "Create docs/research/_template.md capturing Problem, Options, Evaluation (quant+qual), Decision, Migration Plan, Action Items, and Source Log fields plus scope/timeboxing and risk checklists.",
            "status": "pending",
            "testStrategy": "Run markdownlint on docs/research/_template.md to confirm formatting and section headings meet PRD checklist."
          },
          {
            "id": 2,
            "title": "Document memo workflow and references in README",
            "description": "Update docs/research/README.md with template usage instructions and reference catalog.",
            "dependencies": [
              1
            ],
            "details": "Describe how to instantiate new memos via copy command, outline source logging policy, include workflow notes, and add catalog of preferred 2024+ references for OKLab, LED calibration, and ESP32-S3 benchmarks.",
            "status": "pending",
            "testStrategy": "Lint updated README with markdownlint and verify copy command and reference list render correctly in preview."
          }
        ]
      },
      {
        "id": 32,
        "title": "Research Firmware Decode Budget Envelope (R1.1)",
        "description": "Measure safe per-frame decode CPU and memory budgets on target S3 hardware.",
        "details": "Deliverable: docs/research/R1.1_firmware_decode_budget.md with benchmarks.\nImplementation outline:\n- Assemble minimal decode harness on ESP32-S3 with FreeRTOS timers emulating 120 FPS loop and 160 LED buffer.\n- Profile CPU cycles, heap usage, and flash bandwidth for representative decode kernels (palette lookup, delta+rle decode) using ESP-IDF 5.x perf counters.\nPseudo-code:\n```\nsetup_decoder_harness()\nfor payload in test_payloads:\n    start_timer(120fps)\n    cycles = measure_cycles(run_decode(payload))\n    record(payload.name, cycles, heap_free())\n```\n- Compare results against 8.33 ms/frame budget and annotate headroom for future features.\n- Summarize calibration methodology, toolchain versions, and measurement limitations.",
        "testStrategy": "Repeat measurements across at least three runs, export CSV of cycles/heap, validate variance <5%, attach profiler screenshots/logs to memo, and peer review numbers with firmware engineer.",
        "priority": "medium",
        "dependencies": [
          31
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement ESP32-S3 decode benchmarking harness",
            "description": "Create firmware harness that emulates 120 FPS loop and captures perf counters.",
            "dependencies": [],
            "details": "Set up FreeRTOS timer, allocate 160 LED buffer, integrate ESP-IDF 5.x perf counters, and stub payload loader.",
            "status": "pending",
            "testStrategy": "Run `idf.py build flash monitor` confirming loop timing and perf counter outputs match expected cadence."
          },
          {
            "id": 2,
            "title": "Profile representative payload decodes",
            "description": "Execute benchmarking harness across palette and delta RLE payload sets.",
            "dependencies": [
              1
            ],
            "details": "Load curated payload set, capture CPU cycles, heap usage, and flash bandwidth over three runs, export raw readings to CSV.",
            "status": "pending",
            "testStrategy": "Automate three-run sampling script verifying variance under 5% and spot-check profiler logs for each payload class."
          },
          {
            "id": 3,
            "title": "Compile firmware decode budget memo",
            "description": "Synthesize collected data into research memo with methodology and findings.",
            "dependencies": [
              1,
              2
            ],
            "details": "Summarize harness setup, toolchain versions, calibration method, analyze headroom versus 8.33 ms budget, attach CSV and logs.",
            "status": "pending",
            "testStrategy": "Peer review memo against template, verify referenced data artifacts exist, and lint Markdown before submission."
          }
        ]
      },
      {
        "id": 33,
        "title": "Decide PRISM v1 Color Space & Palette Authoring Strategy (R3.1)",
        "description": "Evaluate candidate perceptual color spaces and recommend migration plan for palette tooling.",
        "details": "Deliverable: docs/research/R3.1_color_space_decision.md.\nImplementation outline:\n- Compare OKLab/OKLCH, HSLuv, HSV/HSL using sample 2–3 stop ramps at 160 LEDs, measuring ΔE, hue constancy, and UX implications.\n- Benchmark performance in TypeScript (tooling) and microcontroller conversions; document licensing constraints.\nPseudo-code:\n```\nfor space in [OKLCH, HSLuv, HSV]:\n    palette = generate_ramp(space, stops)\n    metrics = compute_delta_e(palette)\n    render_preview(space, palette)\n    log(space, metrics)\n```\n- Provide migration plan outlining palette storage, conversion helpers, and fallback strategy.\n- Include recommended libraries (latest OKLab refs, 2024 updates) and testing hooks for presets.",
        "testStrategy": "Validate ΔE calculations with unit tests, review renders in tooling preview, solicit sign-off from palette tooling owner, and ensure memo includes Pros/Cons matrix plus migration steps.",
        "priority": "medium",
        "dependencies": [
          31
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Evaluate color ramps across candidate spaces",
            "description": "Generate sample ramps and capture perceptual metrics for OKLCH, HSLuv, and HSV.",
            "dependencies": [],
            "details": "Produce 2-3 stop ramps at 160 LEDs per space, record ΔE, hue drift, UX notes, and archive visual previews.",
            "status": "pending",
            "testStrategy": "Validate ΔE computations against trusted colorimetry library and have tooling lead review preview captures."
          },
          {
            "id": 2,
            "title": "Benchmark tooling and firmware conversions",
            "description": "Measure palette conversion performance and review licensing constraints.",
            "dependencies": [
              1
            ],
            "details": "Profile TypeScript and microcontroller conversions using gathered ramps, note memory/CPU budgets, and document library licensing or patent risks.",
            "status": "pending",
            "testStrategy": "Compare measured timings with prior firmware budgets and confirm licensing conclusions with legal checklist."
          },
          {
            "id": 3,
            "title": "Draft migration strategy and recommendation memo",
            "description": "Synthesize findings into the color space decision document with migration plan.",
            "dependencies": [
              1,
              2
            ],
            "details": "Author docs/research/R3.1_color_space_decision.md covering metrics summary, pros/cons matrix, storage plan, helper APIs, fallbacks, and testing hooks.",
            "status": "pending",
            "testStrategy": "Peer review memo outline with palette tooling owner and verify checklist covers migration steps before sign-off."
          }
        ]
      },
      {
        "id": 34,
        "title": "Define RGB→RGBW Mapping Strategy (R3.2)",
        "description": "Select baseline RGBW conversion and calibration roadmap aligned with color decision.",
        "details": "Deliverable: docs/research/R3.2_rgbw_strategy.md.\nImplementation outline:\n- Evaluate HSI-based mapping vs whiteness extraction + SK6812 calibration for pastel and saturated samples using outputs from task 33.\n- Model luminous efficiency and CCT options (e.g., 4500K, 6000K) considering firmware cost.\nPseudo-code:\n```\nfor method in [HSI_map, whiteness_extract]:\n    for color in sample_palette:\n        rgbw = method(color)\n        error = compare_to_target(rgbw)\n        record(method, color, error)\n```\n- Propose staged calibration plan (lab jig, factory QC) with tooling hooks.\n- Document integration points for dev tools and firmware runtime, referencing latest SK6812 datasheets.",
        "testStrategy": "Run comparative plots of luminance error, validate mapping with lab measurements or calibrated photodiode data, and peer review roadmap with hardware team.",
        "priority": "medium",
        "dependencies": [
          31,
          33
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Assemble RGB→RGBW evaluation harness",
            "description": "Consolidate task 33 palette outputs and build scripts to compare HSI versus whiteness extraction mappings.",
            "dependencies": [],
            "details": "Gather pastel and saturated samples, implement looping harness matching provided pseudocode, and log per-method color error metrics.",
            "status": "pending",
            "testStrategy": "Run harness on a small palette subset and confirm error logging matches manual calculations for at least two colors."
          },
          {
            "id": 2,
            "title": "Model luminous efficiency and CCT options",
            "description": "Quantify luminous flux and firmware cost impacts for candidate CCTs using the evaluation results.",
            "dependencies": [
              1
            ],
            "details": "Use recorded RGBW errors to evaluate 4500K and 6000K configurations, estimate power budgets, and note firmware compute/storage overheads for each mapping.",
            "status": "pending",
            "testStrategy": "Cross-check modeled efficiency numbers against existing SK6812 datasheet curves and flag discrepancies beyond 5%."
          },
          {
            "id": 3,
            "title": "Document RGBW mapping strategy and calibration plan",
            "description": "Produce the deliverable detailing the chosen mapping approach, calibration stages, and integration hooks.",
            "dependencies": [
              1,
              2
            ],
            "details": "Summarize findings in docs/research/R3.2_rgbw_strategy.md, outline lab jig and factory QC steps, and list firmware/tooling integration touchpoints with references.",
            "status": "pending",
            "testStrategy": "Peer review document with hardware team to ensure calibration roadmap and integration notes cover lab and production needs."
          }
        ]
      },
      {
        "id": 35,
        "title": "Select Launch Show Generator Families (R3.3)",
        "description": "Identify 2–3 show algorithm families optimized for 160 LEDs and compression.",
        "details": "Deliverable: docs/research/R3.3_show_families.md.\nImplementation outline:\n- Survey literature/repos (2024 best-of) for phase waves, noise morphs, flow fields with strong compression traits.\n- Prototype small generators in Python/TypeScript, evaluating parameter richness, memory footprint, and visual fidelity.\nPseudo-code:\n```\nfor family in candidate_families:\n    params = sample_parameters(family)\n    frames = simulate_show(family, params, led_count=160)\n    score = evaluate_visual_and_size(frames)\n    log_result(family, score)\n```\n- Define parameter schema JSON for each selected family and outline preset starter pack.\n- Include compression test results using planned packaging options.",
        "testStrategy": "Collect subjective review clips, compute compression ratio vs SSIM, and run design critique with tooling + content teams before finalizing memo.",
        "priority": "medium",
        "dependencies": [
          31
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Survey compression-friendly show generators",
            "description": "Compile candidate show algorithm families optimized for 160-LED compression use.",
            "dependencies": [],
            "details": "Review 2024 literature, repos, and demo showcases for phase waves, noise morphs, and flow fields noting compression traits and parameter richness.",
            "status": "pending",
            "testStrategy": "Log all sources and selection criteria; peer review list for coverage gaps."
          },
          {
            "id": 2,
            "title": "Prototype and score candidate families",
            "description": "Implement lightweight prototypes to evaluate visual quality, parameter range, and compression metrics.",
            "dependencies": [
              1
            ],
            "details": "Build Python/TypeScript harness that samples parameters, simulates 160-LED frames, runs compression tests, and records size, SSIM, and subjective notes per family.",
            "status": "pending",
            "testStrategy": "Automate harness to output metric tables; verify repeatability on at least two machines."
          },
          {
            "id": 3,
            "title": "Document selected families and schemas",
            "description": "Summarize chosen generator families, parameter schemas, and starter presets in deliverable file.",
            "dependencies": [
              1,
              2
            ],
            "details": "Draft docs/research/R3.3_show_families.md capturing top families, JSON schema definitions, recommended presets, and compression findings with rationale.",
            "status": "pending",
            "testStrategy": "Run documentation lint/format check and request cross-team review for clarity and completeness."
          }
        ]
      },
      {
        "id": 36,
        "title": "Analyze Packaging Trade-offs for .prism Sequences (R3.4)",
        "description": "Compare encoding approaches for palette+indices, delta encoding, and RLE under firmware constraints.",
        "details": "Deliverable: docs/research/R3.4_packaging_tradeoffs.md.\nImplementation outline:\n- Use outcomes from tasks 32 and 35 to model data rates for 16s @120 FPS, 160 LEDs.\n- Prototype encoders in Python to measure size vs decode cycles.\nPseudo-code:\n```\nfor codec in [palette_indices, delta, rle, hybrid]:\n    compressed = codec.encode(sample_frames)\n    cycles = measure_decode_cycles(codec, sample_frames)\n    report(codec, len(compressed), cycles)\n```\n- Evaluate streaming feasibility on ESP32-S3 with buffer constraints and document guardrails (max frame size, burst limits).\n- Recommend encoding(s) and enforcement rules for tooling export.",
        "testStrategy": "Unit test encoder prototypes, run timing harness on hardware or simulator, verify results align with budget from task 32, and capture benchmark tables/plots in memo.",
        "priority": "medium",
        "dependencies": [
          32,
          35
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Prototype candidate sequence encoders in Python",
            "description": "Build working palette+indices, delta, RLE, and hybrid encoder/decoder stubs using shared sample frames.",
            "dependencies": [],
            "details": "Implement codec classes covering encode/decode paths, reuse data gathered in tasks 32 and 35, and prepare hooks for instrumentation and cycle measurement.",
            "status": "pending",
            "testStrategy": "Create unit tests ensuring round-trip fidelity for each codec on representative sample frame sets."
          },
          {
            "id": 2,
            "title": "Benchmark compression ratios and decode cycle budgets",
            "description": "Measure output sizes and decode performance of each codec against ESP32-S3 budget targets.",
            "dependencies": [
              1
            ],
            "details": "Integrate timing and size logging into prototypes, collect decode cycle counts, memory usage, and buffer behavior to compare with task 32 firmware envelopes.",
            "status": "pending",
            "testStrategy": "Run automated benchmark harness across multiple frame captures, export CSV summaries, and verify values stay within task 32 limits."
          },
          {
            "id": 3,
            "title": "Draft packaging trade-off memo with enforcement rules",
            "description": "Document comparative analysis, streaming guardrails, and recommended tooling policies in the required memo.",
            "dependencies": [
              1,
              2
            ],
            "details": "Summarize benchmark findings, highlight feasible codecs, specify frame size/burst guardrails, and capture enforcement rules in docs/research/R3.4_packaging_tradeoffs.md.",
            "status": "pending",
            "testStrategy": "Conduct peer review of the memo and double-check calculations against benchmark data before finalization."
          }
        ]
      },
      {
        "id": 37,
        "title": "Develop Preview Mapping Guidelines (R3.5)",
        "description": "Define gamma and saturation adjustments so terminal/HTML previews match LED output.",
        "details": "Deliverable: docs/research/R3.5_preview_guidelines.md.\nImplementation outline:\n- Analyze LED gamma curves (from calibration data) and compare to sRGB/linear previews.\n- Evaluate tone-mapping and saturation strategies for different browsers/terminal color spaces.\nPseudo-code:\n```\nfor mapping in candidate_mappings:\n    preview = apply_mapping(mapping, sample_frames)\n    delta = compare_led_capture(preview, led_capture)\n    record(mapping, delta)\n```\n- Recommend preview pipeline parameters and fallback path when hardware measurements unavailable.\n- Provide doc snippet for tooling integration tasks 26/27.",
        "testStrategy": "Cross-check preview frames against HDR photos/video of actual LEDs, collect feedback from tooling/QA, and ensure memo includes parameter tables plus validation methodology.",
        "priority": "medium",
        "dependencies": [
          33
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Aggregate LED calibration datasets",
            "description": "Collect and summarize LED calibration curves alongside preview reference baselines for comparison.",
            "dependencies": [],
            "details": "Pull recent photometric captures, normalize gamma curves against sRGB and linear preview references, and archive comparison plots for later analysis.",
            "status": "pending",
            "testStrategy": "Verify extracted curves match source calibration logs by spot-checking sample timestamps and luminance values."
          },
          {
            "id": 2,
            "title": "Prototype preview gamma and saturation mappings",
            "description": "Experiment with candidate tone-mapping and saturation pipelines using sample frames and measure error to LED captures.",
            "dependencies": [
              1
            ],
            "details": "Implement evaluation loop that applies candidate mappings to representative frames, computes LED delta metrics per browser/terminal color space, and ranks results.",
            "status": "pending",
            "testStrategy": "Plot delta metrics and confirm the selected mapping improves error versus the baseline preview configuration."
          },
          {
            "id": 3,
            "title": "Document recommended preview parameters and fallback flow",
            "description": "Write guidelines summarizing recommended parameters, fallback assumptions, and cross-team integration notes.",
            "dependencies": [
              1,
              2
            ],
            "details": "Draft docs/research/R3.5_preview_guidelines.md with gamma and saturation tables, fallback procedure when measurements are unavailable, and integration snippet for tooling tasks 26 and 27.",
            "status": "pending",
            "testStrategy": "Request tooling team review to confirm parameter tables, fallback instructions, and integration notes address their requirements."
          }
        ]
      },
      {
        "id": 38,
        "title": "Specify Parser Metadata Extensions v1.1 (R2.1)",
        "description": "Propose new metadata tags to capture palette/ramp details and show parameters.",
        "details": "Deliverable: docs/research/R2.1_metadata_extensions.md.\nImplementation outline:\n- Use outputs from tasks 33 and 35 to define `palette_id`, `ramp_space`, and show parameter encoding structures.\n- Draft JSON schema fragments and backward compatibility notes.\nPseudo-code:\n```\nspec = Schema()\nspec.add_field(\"palette_id\", type=\"string\", required=True)\nspec.add_field(\"ramp_space\", enum=[\"oklch\",\"hsluv\"], default=\"oklch\")\nspec.extend(\"show_params\", schema=family_param_schemas)\n```\n- Evaluate tooling impact (serialization/deserialization) and migration plan for existing assets.\n- Document any interaction with research provider metadata logging.",
        "testStrategy": "Validate schema with sample files using JSON Schema validator, run round-trip parse tests in parser prototype, and review memo with Agent 2 (parser/format owner).",
        "priority": "medium",
        "dependencies": [
          33,
          35
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Draft palette and show metadata schema fragments",
            "description": "Consolidate outputs from tasks 33 and 35 to define palette and show parameter metadata additions for v1.1.",
            "dependencies": [],
            "details": "Author JSON schema fragments for palette_id, ramp_space, and show_params fields, including required flags, enums, defaults, and inline compatibility annotations with v1.0.",
            "status": "pending",
            "testStrategy": "Validate the draft fragments with the project JSON Schema validator and ensure they load alongside existing v1.0 definitions."
          },
          {
            "id": 2,
            "title": "Validate backward compatibility with sample assets",
            "description": "Exercise draft schema against representative legacy and new sample assets to confirm compatibility.",
            "dependencies": [
              1
            ],
            "details": "Apply the updated schema to a curated set of legacy show files and newly generated palettes to confirm required fields and defaults align with migration expectations.",
            "status": "pending",
            "testStrategy": "Run round-trip parse and serialize tests on sample assets and capture any mismatches or validation errors."
          },
          {
            "id": 3,
            "title": "Document tooling and firmware impact in memo",
            "description": "Summarize schema changes, parser implications, and migration steps in the R2.1 memo.",
            "dependencies": [
              1,
              2
            ],
            "details": "Update docs/research/R2.1_metadata_extensions.md with schema rationale, serialization/deserialization updates, firmware parser adjustments, and migration guidance referencing validation outcomes.",
            "status": "pending",
            "testStrategy": "Peer-review the memo with firmware and tooling stakeholders to confirm accuracy and completeness."
          }
        ]
      },
      {
        "id": 39,
        "title": "Assess Header and CRC Implications for v1.1 Format (R2.2)",
        "description": "Confirm header layout supports new metadata fields and ensure CRC coverage and streaming remain valid.",
        "details": "Deliverable: docs/research/R2.2_header_crc_implications.md.\nImplementation outline:\n- Extend existing v1.0 header diagram with new offsets for metadata from task 38.\n- Simulate streaming scenarios with partial frames to ensure CRC coverage protects new fields without regressions.\nPseudo-code:\n```\nheader = build_header(v1_1_fields)\ncrc = compute_crc(header + payload)\nassert validate_streaming(header, crc) == True\n```\n- Evaluate impact on tooling exporters and firmware parsers; recommend guardrails or version bump strategy.\n- Document compatibility with existing CRC polynomial and suggest tests for future implementations.",
        "testStrategy": "Run parser unit tests with mutated headers, confirm CRC failure cases trigger expected errors, and obtain sign-off from firmware + parser stakeholders.",
        "priority": "medium",
        "dependencies": [
          38
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Model v1.1 header layout offsets",
            "description": "Review the v1.0 header map and new metadata definitions to draft an updated v1.1 header layout.",
            "dependencies": [],
            "details": "Pull field requirements from task 38 outputs and extend the existing diagram with byte offsets, reserved gaps, and alignment notes, ensuring the total size constraint still holds.",
            "status": "pending",
            "testStrategy": "Cross-check computed offsets against struct layouts in pattern_storage.h and protocol_parser.c to confirm consistent packing."
          },
          {
            "id": 2,
            "title": "Simulate streaming CRC coverage paths",
            "description": "Design streaming scenarios to verify CRC coverage over new metadata during partial frame transfers.",
            "dependencies": [
              1
            ],
            "details": "Generate sample headers using the v1.1 layout, mutate payload segments, and run compute_crc plus validate_streaming routines to observe protection of new fields under staggered delivery.",
            "status": "pending",
            "testStrategy": "Automate simulations that compare expected CRC failures and successes, and log any regression versus v1.0 baselines."
          },
          {
            "id": 3,
            "title": "Document compatibility and testing guidance",
            "description": "Summarize tooling and firmware impacts and outline guardrails plus regression tests for v1.1 adoption.",
            "dependencies": [
              1,
              2
            ],
            "details": "Capture exporter/parser adjustments, recommend versioning or feature flags, and describe future validation suites in docs/research/R2.2_header_crc_implications.md.",
            "status": "pending",
            "testStrategy": "Request review from firmware and tooling stakeholders and ensure recommended tests cover parser regression, CRC failure handling, and new metadata acceptance."
          }
        ]
      },
      {
        "id": 40,
        "title": "Synthesize Cross-Track Decisions and Gating Actions",
        "description": "Consolidate research outputs into release-ready checklist and update downstream task gating.",
        "details": "Deliverable: docs/research/PRISM_K1_decision_rollup.md plus task gating updates.\nImplementation outline:\n- Aggregate recommendations from tasks 32–39 into summary matrix highlighting decisions, owners, and action items for tasks 23, 26–30.\n- Update Task Master/issue tracker notes to gate implementation on completed memos.\nPseudo-code:\n```\nrollup = collect_decisions(tasks=[32,33,34,35,36,37,38,39])\nfor gate in downstream_tasks:\n    gate.dependencies.add(rollup.decision_ids)\nwrite_rollup_doc(rollup)\n```\n- Include risk mitigation follow-ups and reference links to source memos.\n- Share with stakeholders via async review (Slack/email) and capture approvals.",
        "testStrategy": "Verify all memos are linked and marked complete, confirm Task Master dependencies reflect decisions, and solicit stakeholder sign-offs noting any open risks.",
        "priority": "medium",
        "dependencies": [
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Aggregate decisions and action owners",
            "description": "Collect key decisions, owners, and action items from memos 32–39.",
            "dependencies": [],
            "details": "Review completed research memos (tasks 32-39), capture decision summaries, owners, action items, risk notes, and source links into a normalized matrix for downstream use.",
            "status": "pending",
            "testStrategy": "Cross-check each memo to confirm every decision, owner, and action item is captured with links to the original document."
          },
          {
            "id": 2,
            "title": "Update downstream task gating records",
            "description": "Reflect aggregated decisions in Task Master dependencies for tasks 23 and 26–30.",
            "dependencies": [
              1
            ],
            "details": "Use Task Master or issue tracker tooling to add dependency references from tasks 23 and 26-30 to the synthesized decision IDs, ensuring gating prevents implementation without required memos.",
            "status": "pending",
            "testStrategy": "Verify updated tasks show the new dependencies and run `task-master validate-dependencies` to confirm no errors."
          },
          {
            "id": 3,
            "title": "Draft decision roll-up document and approval log",
            "description": "Author docs/research/PRISM_K1_decision_rollup.md with risks, mitigations, and approval tracking.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create the roll-up markdown summarizing the decision matrix, downstream gating impacts, risk mitigations, stakeholder contact list, and async review plan, then share via Slack/email and log approvals.",
            "status": "pending",
            "testStrategy": "Review document for completeness against checklist, confirm stakeholder notifications sent, and record received approvals or open follow-ups."
          }
        ]
      },
      {
        "id": 41,
        "title": "Establish Tauri + React Studio Foundation",
        "description": "Create the PRISM Studio desktop workspace with consistent tooling, cross-platform builds, and shared configuration.",
        "details": "- Use Tauri 2.0.0 with Rust 1.78+, Node 20.x, pnpm 9, Vite 5.2, React 18.2, TypeScript 5.6, and SWC for fast rebuilds.\n- Configure workspace structure per PRD (`apps/studio` for UI, `src-tauri` for backend) and set up shared `eslint@9` + `typescript-eslint` + `prettier` rules with project references.\n- Enable Tauri security best practices: CSP headers, updater disabled (phase 1), `allowlist.fs.scope` limited to project dir, and `tauri-plugin-log` for structured logging.\n- Provision `vitest` with jsdom + happy-dom for UI tests, `playwright@1.45` for E2E, and `cargo-nextest` for Rust tests.\n- CI scaffold: GitHub Actions matrix (macOS 14, windows-2025, ubuntu-24.04) running `pnpm lint`, `pnpm test`, `cargo clippy --all-targets -- -D warnings`, and packaging via `tauri-action@v0`.\nPseudo-code:\n```\npnpm create tauri-app\npnpm add -D @vitejs/plugin-react-swc eslint prettier vitest playwright\ncargo add anyhow tokio --features full thiserror tracing\n```\n- Document developer bootstrap in `docs/CONTRIBUTING.md` and add Husky pre-commit hook running `pnpm lint && pnpm test --runInBand`.",
        "testStrategy": "- Run `pnpm lint` to ensure ESLint/Prettier/TypeScript wiring.\n- Verify `pnpm tauri dev` launches shell window on macOS and Windows runners.\n- CI dry run: execute GitHub Actions workflow locally via `act` or manual triggers to ensure artifacts build.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold Tauri + React workspace",
            "description": "Set up the initial Tauri 2 project with designated app and backend directories using pnpm tooling.",
            "dependencies": [],
            "details": "Use pnpm create tauri-app targeting `apps/studio` UI and `src-tauri` backend, align runtime versions (Node 20, Rust 1.78), and configure Vite + React + TypeScript baseline.",
            "status": "pending",
            "testStrategy": "Run `pnpm tauri dev` to confirm scaffold boots on desktop."
          },
          {
            "id": 2,
            "title": "Configure shared linting and TypeScript rules",
            "description": "Centralize ESLint 9, TypeScript, and Prettier configs with project references for the studio workspace.",
            "dependencies": [
              1
            ],
            "details": "Author shared config files in the repo root, integrate `typescript-eslint`, ensure pnpm workspaces link configs, and align tsconfig references between UI and Rust bindings.",
            "status": "pending",
            "testStrategy": "Execute `pnpm lint` to ensure eslint/prettier/type-check wiring passes."
          },
          {
            "id": 3,
            "title": "Apply Tauri security hardening",
            "description": "Implement security best practices across Tauri configuration files for the studio app.",
            "dependencies": [
              1
            ],
            "details": "Tune `tauri.conf.json` CSP headers, disable updater for phase one, restrict `allowlist.fs.scope` to the project directory, and configure `tauri-plugin-log` for structured logs.",
            "status": "pending",
            "testStrategy": "Launch dev build verifying console logs and inspect generated config for restricted scopes via `pnpm tauri dev`."
          },
          {
            "id": 4,
            "title": "Provision cross-layer test harnesses",
            "description": "Install and configure Vitest, Playwright, and cargo-nextest for UI and Rust testing.",
            "dependencies": [
              1
            ],
            "details": "Add dev dependencies (`vitest`, jsdom, happy-dom, Playwright 1.45), scaffold Vitest config, set up Playwright projects, and integrate cargo-nextest workflow in Rust side.",
            "status": "pending",
            "testStrategy": "Run `pnpm test` and `cargo nextest run` to confirm harnesses execute successfully."
          },
          {
            "id": 5,
            "title": "Set up GitHub Actions CI matrix",
            "description": "Create CI workflow covering linting, tests, and packaging across supported OS platforms.",
            "dependencies": [
              2,
              4
            ],
            "details": "Author workflow YAML running on macOS 14, Windows 2025, and Ubuntu 24.04 executing lint/test targets along with Tauri packaging via `tauri-action@v0`.",
            "status": "pending",
            "testStrategy": "Trigger workflow manually or with `act` dry run to verify all matrix jobs succeed."
          },
          {
            "id": 6,
            "title": "Document developer bootstrap steps",
            "description": "Update CONTRIBUTING guidelines with environment setup and workflow instructions for the studio project.",
            "dependencies": [
              1,
              2,
              4,
              5
            ],
            "details": "Describe tooling prerequisites, pnpm install steps, Rust setup, test commands, and CI expectations in `docs/CONTRIBUTING.md` referencing newly built infrastructure.",
            "status": "pending",
            "testStrategy": "Peer review documentation for completeness and run through instructions on a clean environment sample."
          },
          {
            "id": 7,
            "title": "Configure Husky pre-commit checks",
            "description": "Add Husky hooks enforcing linting and test runs before commits for the studio workspace.",
            "dependencies": [
              2,
              4,
              6
            ],
            "details": "Install Husky, initialize git hooks, and script pre-commit to execute `pnpm lint` followed by `pnpm test --runInBand`, ensuring instructions reference docs guidance.",
            "status": "pending",
            "testStrategy": "Create a test commit verifying Husky hook runs and blocks failures locally."
          }
        ]
      },
      {
        "id": 42,
        "title": "Implement Device Discovery and Connection Services",
        "description": "Deliver cross-platform mDNS discovery, WebSocket session management, and device metadata exchange between Tauri backend and React UI.",
        "details": "- Rust `src-tauri`: add `mdns-sd 0.11`, `tokio-tungstenite 0.23`, `axum 0.7` (for optional mocks), and `serde` for message structs.\n- Implement async task:\n```\npub async fn discover_devices() -> Result<Vec<DeviceInfo>> {\n  let resolver = mdns_sd::ServiceDaemon::new()?;\n  resolver.browse(\"_prism-k1._tcp.local.\")?;\n  while let Ok(event) = rx.recv().await {\n    if let ServiceEvent::ServiceResolved(info) = event {\n      devices.push(DeviceInfo::from(info));\n    }\n  }\n  Ok(devices)\n}\n```\n- Define `HELLO` request via WebSocket TLV (per ADR-010); parse firmware response {fw_version, led_count, storage_total, storage_used, max_chunk} with byte order validation and CRC.\n- Maintain connection pool with reconnection/backoff (100ms→2s) and remember last device via `tauri-plugin-store` persisted in OS keychain.\n- Map errors to actionable UI codes (`NO_DEVICE`, `NETWORK_TIMEOUT`, `HELLO_UNSUPPORTED`) and expose typed IPC commands (`device_discover`, `device_connect`, `device_status`, `device_list`, `device_delete`).\n- Frontend `device/manager.ts`: Zustand slice pushes discovery results, handles connect + status fetch, and emits toasts for troubleshooting.\n- Add network health indicator (latency via ping TLV request every 5s; degrade UI if >150ms).\n",
        "testStrategy": "- Rust: `cargo test -- --nocapture device::tests` covering mDNS parsing, HELLO decode, reconnect logic with `tokio::test` and `assert_matches!` for errors.\n- Integration: Playwright test spins mock WS server (`ws://localhost:8081`) to simulate HELLO/LIST/DELETE flows.\n- Manual QA: throttle/wifi off scenarios to confirm error surfacing and persistence of last-connected device.",
        "priority": "medium",
        "dependencies": [
          41
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Rust mDNS discovery pipeline",
            "description": "Build the async discovery service to enumerate PRISM devices over mDNS.",
            "dependencies": [],
            "details": "Wire mdns-sd ServiceDaemon into a Tokio task that listens on the browse channel, converts ServiceResolved events into DeviceInfo structs, and returns deduplicated results.",
            "status": "pending",
            "testStrategy": "Add tokio::test validating discovered DeviceInfo entries from a mocked mdns_sd::ServiceDaemon channel."
          },
          {
            "id": 2,
            "title": "Handle WebSocket HELLO TLV protocol",
            "description": "Establish WebSocket sessions and parse HELLO responses per ADR-010.",
            "dependencies": [
              1
            ],
            "details": "Use tokio-tungstenite to open device sockets, send HELLO TLV requests, decode firmware TLV payloads into strongly typed structs, and validate byte order plus CRC before persisting metadata.",
            "status": "pending",
            "testStrategy": "Implement unit tests feeding canned HELLO frames to ensure TLV parsing, endianness, and CRC handling behave as expected."
          },
          {
            "id": 3,
            "title": "Implement connection pool with reconnection strategy",
            "description": "Manage reusable WebSocket clients with controlled reconnection and backoff.",
            "dependencies": [
              2
            ],
            "details": "Create a pool tracking active device sessions, implement exponential backoff from 100ms to 2s, trigger reconnect attempts on disconnect, and surface state changes to listeners.",
            "status": "pending",
            "testStrategy": "Use tokio::test with simulated disconnects verifying backoff intervals and pool state transitions."
          },
          {
            "id": 4,
            "title": "Persist device selection and error mapping",
            "description": "Map backend failures to UI codes and store the last connected device.",
            "dependencies": [
              2,
              3
            ],
            "details": "Translate internal errors into NO_DEVICE, NETWORK_TIMEOUT, or HELLO_UNSUPPORTED codes and persist the last successful device via tauri-plugin-store backed by the OS keychain.",
            "status": "pending",
            "testStrategy": "Create unit tests ensuring each error path maps to the correct code and the store writes/reads the expected device identifier."
          },
          {
            "id": 5,
            "title": "Expose typed IPC commands for device lifecycle",
            "description": "Publish IPC endpoints for discovery, connection, status, list, and delete flows.",
            "dependencies": [
              3,
              4
            ],
            "details": "Register Tauri commands device_discover, device_connect, device_status, device_list, and device_delete that call the service layer, enforce type-safe payloads, and deliver actionable error codes.",
            "status": "pending",
            "testStrategy": "Add integration-style rust tests invoking each command and asserting responses and error mappings."
          },
          {
            "id": 6,
            "title": "Integrate discovery state into React Zustand store",
            "description": "Extend the frontend store to manage device discovery and status updates.",
            "dependencies": [
              5
            ],
            "details": "Update device/manager.ts to push discovery results, expose actions for connect/status requests, and coordinate toast notifications for success or troubleshooting events.",
            "status": "pending",
            "testStrategy": "Write Jest tests mocking IPC bridges to confirm the Zustand slice updates state and triggers toasts appropriately."
          },
          {
            "id": 7,
            "title": "Build network health indicator UI",
            "description": "Add UI elements reflecting network latency and degraded states.",
            "dependencies": [
              6
            ],
            "details": "Implement periodic ping TLV checks every 5s, surface latency metrics through the store, and adjust UI styling or banners when latency exceeds 150ms.",
            "status": "pending",
            "testStrategy": "Create frontend tests verifying latency thresholds update the indicator and degrade UI presentation when limits are exceeded."
          },
          {
            "id": 8,
            "title": "Author automated tests and mocks",
            "description": "Cover backend and frontend behaviors with mocks and integration tests.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6,
              7
            ],
            "details": "Develop Rust tests for mDNS, HELLO parsing, reconnection, and IPC plus Playwright scenarios with a mock WebSocket server to validate end-to-end device flows across the UI.",
            "status": "pending",
            "testStrategy": "Run cargo test suites and Playwright E2E scripts against the mocked server to ensure discovery, connect, list, and delete paths all succeed."
          }
        ]
      },
      {
        "id": 43,
        "title": "Design Project Schema, State Management, and Persistence",
        "description": "Define strongly typed project data models, implement global state with undo/redo, and add autosave/versioning to IndexedDB.",
        "details": "- Create `data/models.ts` with Zod 3.23 schemas for `PrismProject`, `Track`, `Clip`, `EffectInstance`, `AutomationCurve`, ensuring compatibility with ADR-010.\n- Zustand store (`useStudioStore`) configured with `immer 10` for immutable drafts and `zundo` for history: keep 50 inverse operations with compression beyond 20.\n- Implement autosave service using IndexedDB via `idb-keyval 7`: every 1s or 10 edits, throttle with `lodash.throttle`, store `project_v{schemaVersion}` wrapped with metadata.\n- Version history: maintain ring buffer of last 10 snapshots (`projectId_timestamp.prismproj`) and prune older entries.\n- Persistence migration pipeline: `migrations/index.ts` mapping `fromVersion -> toVersion` transformations invoked when loading legacy `.prismproj`.\n- Provide selectors for derived data (current playhead, active palettes) and event bus for command pattern (command stack executes do/undo pair).\nPseudo-code:\n```\nconst useStudioStore = create(withZundo((set,get) => ({\n  project: defaultProject(),\n  execute(command) {\n    set(produce(state => command.do(state)));\n    commandStack.push(command.inverse);\n  }\n})));\n```\n- Secure persistence: store device credentials in `@tauri-apps/plugin-secure-store` rather than IndexedDB.\n",
        "testStrategy": "- Vitest unit tests cover schema parsing, migrations, undo stack saturation, and autosave throttling.\n- Jest-like fake timers to assert autosave cadence; ensure version buffer trims at 10 entries.\n- Manual QA: simulate crash (close app) and confirm restore flow recovers last 10 edits without data loss.",
        "priority": "medium",
        "dependencies": [
          41
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Zod project schema suite",
            "description": "Author Zod 3.23 schemas for PrismProject, Track, Clip, EffectInstance, and AutomationCurve per ADR-010.",
            "dependencies": [],
            "details": "Create `data/models.ts` exporting schemas, inferred types, schemaVersion constant, and validation helpers ensuring enum literals and nested refs align with ADR-010.",
            "status": "pending",
            "testStrategy": "Write Vitest cases that parse representative JSON fixtures and assert schema failures on malformed payloads."
          },
          {
            "id": 2,
            "title": "Establish Zustand store with immer drafts",
            "description": "Set up the core `useStudioStore` using Zustand and immer 10 for immutable updates and default project state.",
            "dependencies": [
              1
            ],
            "details": "Implement `useStudioStore` initializer that seeds default project derived from schemas, wires `produce`-based setters, and normalizes state serialization hooks.",
            "status": "pending",
            "testStrategy": "Cover store initialization and basic setters with Vitest to confirm default state shape and immer immutability behavior."
          },
          {
            "id": 3,
            "title": "Integrate zundo-powered undo/redo flow",
            "description": "Layer zundo history management onto the store with 50 inverse ops and compression after 20 actions.",
            "dependencies": [
              2
            ],
            "details": "Wrap the Zustand store with `withZundo`, implement command execution helpers pushing inverse actions, and expose undo/redo selectors respecting history caps.",
            "status": "pending",
            "testStrategy": "Add Vitest tests simulating command sequences to ensure undo/redo stacks cap at 50 and compress beyond 20 operations."
          },
          {
            "id": 4,
            "title": "Build throttled autosave service",
            "description": "Implement autosave pipeline persisting project snapshots to IndexedDB using idb-keyval every 1s or 10 edits with throttling.",
            "dependencies": [
              2,
              3
            ],
            "details": "Create service module that subscribes to store changes, batches mutation counts, uses `lodash.throttle` around idb writes, and stores `project_v{schemaVersion}` metadata payloads.",
            "status": "pending",
            "testStrategy": "Use fake timers to verify one-second throttle behavior, edit batching threshold, and successful storage mocks in Vitest."
          },
          {
            "id": 5,
            "title": "Maintain version history ring buffer",
            "description": "Add ring buffer retention for the last ten project snapshots and prune older autosave entries.",
            "dependencies": [
              4
            ],
            "details": "Extend autosave service to stamp filenames as `projectId_timestamp.prismproj`, manage a ten-item queue, and delete surplus entries via idb-keyval APIs.",
            "status": "pending",
            "testStrategy": "Test buffer rollover ensuring eleventh snapshot removes the oldest entry while preserving metadata ordering."
          },
          {
            "id": 6,
            "title": "Implement migration pipeline for legacy projects",
            "description": "Create migration framework that upgrades loaded `.prismproj` files between schema versions.",
            "dependencies": [
              1
            ],
            "details": "Provide `migrations/index.ts` exporting ordered transforms, dispatcher that detects version gaps, and hooks to apply migrations before hydrating store.",
            "status": "pending",
            "testStrategy": "Mock legacy payloads across version gaps in Vitest to assert sequential migration application and failure reporting on unknown versions."
          },
          {
            "id": 7,
            "title": "Deliver selectors and event bus utilities",
            "description": "Expose derived selectors and a command/event bus to coordinate playhead, palette, and command execution flows.",
            "dependencies": [
              2,
              3
            ],
            "details": "Implement memoized selectors for playhead, active palettes, etc., and an event bus that triggers command pattern handlers while integrating with undo stack.",
            "status": "pending",
            "testStrategy": "Unit test selectors for memoization correctness and event bus command dispatch to ensure undo hooks fire as expected."
          },
          {
            "id": 8,
            "title": "Segregate secure credential storage",
            "description": "Route device credential persistence through Tauri secure store instead of IndexedDB while integrating with autosave pipeline.",
            "dependencies": [
              2,
              4
            ],
            "details": "Introduce secure store service using `@tauri-apps/plugin-secure-store`, ensure credentials bypass autosave serialization, and document contract boundaries.",
            "status": "pending",
            "testStrategy": "Add integration-style tests mocking secure store APIs verifying credentials are written and excluded from IndexedDB payloads."
          },
          {
            "id": 9,
            "title": "Author comprehensive test coverage plan",
            "description": "Consolidate automated tests across schema, store, history, autosave, migrations, and secure storage flows.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6,
              7,
              8
            ],
            "details": "Create test matrix documentation, wire Vitest suites, configure fake timers, and ensure CI scripts run targeted checks for undo saturation and autosave recovery.",
            "status": "pending",
            "testStrategy": "Execute full Vitest run and provide manual QA checklist covering crash recovery restore and credential isolation scenarios."
          }
        ]
      },
      {
        "id": 44,
        "title": "Build Timeline Canvas Infrastructure",
        "description": "Create performant timeline rendering engine with tracks, grid modes, playhead control, and 60 FPS target.",
        "details": "- Use imperative Canvas 2D with `OffscreenCanvas` fallback; for browsers lacking support (Windows WebView2), degrade to main-thread canvas with resolution scaling by `devicePixelRatio`.\n- Implement render loop (`requestAnimationFrame`) orchestrating layers: background grid, tracks, clips, selection overlay, playhead.\n- Grid system: seconds vs beats; maintain BPM state; precompute tick marks to minimize per-frame allocations.\n- Input handling: pointer events for scrub/playhead, `space` toggles playback, `J/K/L` shuttle speeds, `+/-` zoom; use `PointerCapture` for drag interactions.\n- LOD strategy: when zoomed out beyond threshold, collapse clip detail (draw simple bars) to sustain <5ms draw cost.\n- Integrate with state store for track data; subscribe via `useShallow` to avoid re-render storms; render diff-based (only dirty rects).\nPseudo-code:\n```\nfunction renderLoop() {\n  const frame = performance.now();\n  drawGrid(context, frame);\n  tracks.forEach(track => drawTrack(track));\n  drawPlayhead(playhead);\n  requestAnimationFrame(renderLoop);\n}\n```\n- Add keyboard focus ring handling and accessible ARIA mapping (e.g., timeline region labelled).\n",
        "testStrategy": "- Vitest canvas snapshot tests (with `jest-canvas-mock` + pixel diff tolerance) verifying grid/track rendering at key zoom levels.\n- Performance harness: Playwright script triggers heavy scroll/zoom and assert via `performance.measure` that `rafDuration < 16ms` on reference hardware.\n- Accessibility audit: `@axe-core/playwright` ensures focusable controls and ARIA labels.",
        "priority": "medium",
        "dependencies": [
          43
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Establish canvas rendering shell",
            "description": "Create the timeline canvas element, sizing logic, and OffscreenCanvas fallback wiring.",
            "dependencies": [],
            "details": "Implement setup utilities that mount Canvas 2D context, configure devicePixelRatio scaling, and gracefully degrade when OffscreenCanvas is unavailable.",
            "status": "pending",
            "testStrategy": "Author setup smoke test instantiating the canvas in jsdom and verifying fallback selection logic."
          },
          {
            "id": 2,
            "title": "Implement render loop orchestration",
            "description": "Build requestAnimationFrame-driven render loop coordinating layered drawing and lifecycle hooks.",
            "dependencies": [
              1
            ],
            "details": "Create render manager that schedules frames, batches draw calls for grid, tracks, overlays, and exposes hooks for dirty-rect updates and teardown.",
            "status": "pending",
            "testStrategy": "Use Vitest fake timers to ensure the loop schedules successive frames and respects pause/resume controls."
          },
          {
            "id": 3,
            "title": "Design grid and tick precomputation system",
            "description": "Implement beat/seconds grid modes with BPM state and cached tick mark data.",
            "dependencies": [
              1,
              2
            ],
            "details": "Add grid service caching tick positions per zoom level, minimizing allocations by reusing buffers and emitting draw instructions for render loop.",
            "status": "pending",
            "testStrategy": "Snapshot canvas rendering of multiple zoom levels to confirm tick accuracy and reuse statistics via instrumentation."
          },
          {
            "id": 4,
            "title": "Develop input and keyboard interaction layer",
            "description": "Handle pointer scrubbing, keyboard transport controls, and zoom shortcuts on the canvas.",
            "dependencies": [
              2,
              3
            ],
            "details": "Implement pointer event handlers with PointerCapture, map key bindings for playback toggles and zoom, and propagate interactions to state store.",
            "status": "pending",
            "testStrategy": "Write Playwright-driven interaction tests to validate pointer drag, spacebar toggle, and zoom key behavior."
          },
          {
            "id": 5,
            "title": "Add LOD and performance optimization framework",
            "description": "Introduce zoom-level-dependent clip simplification and render budgeting safeguards.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Define thresholds for collapsing clip detail, batch draw operations to keep <5ms render cost, and expose performance metrics for monitoring.",
            "status": "pending",
            "testStrategy": "Automate performance harness measuring rafDuration under heavy clip counts, asserting frame times stay under 16ms."
          },
          {
            "id": 6,
            "title": "Integrate state store subscriptions",
            "description": "Wire timeline renderer to state store using shallow subscriptions and diff-based dirty rect updates.",
            "dependencies": [
              1,
              2,
              4
            ],
            "details": "Create subscription adapters leveraging useShallow to detect changes, compute dirty regions, and trigger selective redraws.",
            "status": "pending",
            "testStrategy": "Unit test store adapters with mocked state transitions ensuring only changed regions trigger redraw callbacks."
          },
          {
            "id": 7,
            "title": "Implement accessibility focus and ARIA support",
            "description": "Provide focus rings, keyboard accessibility, and ARIA roles for the timeline region.",
            "dependencies": [
              4,
              6
            ],
            "details": "Add focus management, synchronized ARIA labels, and visual indicators for focused elements aligning with keyboard interaction model.",
            "status": "pending",
            "testStrategy": "Run axe-core accessibility checks and keyboard navigation tests to verify focus handling and ARIA mappings."
          },
          {
            "id": 8,
            "title": "Set up performance and accessibility testing suite",
            "description": "Establish automated scripts covering frame time metrics, canvas snapshots, and accessibility audits.",
            "dependencies": [
              2,
              5,
              7
            ],
            "details": "Create test harness combining Vitest, Playwright, and axe tooling, integrate with CI to run performance and accessibility checks regularly.",
            "status": "pending",
            "testStrategy": "Execute the composed harness in CI pipelines, capturing performance measurements and accessibility reports for regression tracking."
          }
        ]
      },
      {
        "id": 45,
        "title": "Implement Clip Editing Interactions and Shortcuts",
        "description": "Enable clip CRUD operations, selection mechanics, and keyboard-driven timeline editing per PRD shortcuts.",
        "details": "- Add multi-track clip creation via drag on empty region; persist start/end times snapped to beat/second grid using modular snap service (`snap(time, mode)`).\n- Support drag-move, trim (edges), split (`Cmd/Ctrl+K`), ripple trim (`Q/W`), in/out (`I/O`), zoom handling, and rubber-band selection with Shift+click toggles.\n- Implement command pattern actions for undo/redo with bounding validation (no overlap on same track) and auto ripple when toggled.\n- Visual affordances: show clip ghost while dragging, highlight invalid drop zones, provide timeline tooltip with timestamp.\n- Keyboard navigation: arrow keys cycle selection; ensure accessible tooltips.\nPseudo-code:\n```\nexecute(new SplitClipCommand({clipId, at: playhead}))\nclass SplitClipCommand {\n  do(state) { /* split clip into two, adjust durations */ }\n  inverse(state) { /* merge back */ }\n}\n```\n- Integrate telemetry hooks (opt-in) to log heavy operations for UX metrics.\n",
        "testStrategy": "- Vitest unit tests on command objects verifying state mutations + inverses.\n- Canvas interaction E2E: Playwright uses `page.mouse.drag` to create clip, assert DOM state and store snapshot.\n- Property-based tests with `fast-check` ensure ripple trimming maintains sorted timelines.\n",
        "priority": "medium",
        "dependencies": [
          44
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement snap-aware clip creation",
            "description": "Create multi-track clip creation using drag gestures with snap service integration.",
            "dependencies": [],
            "details": "Wire drag-to-create gesture to instantiate clips, call snap(time, mode) for start/end persistence, and serialize clips per track.",
            "status": "pending",
            "testStrategy": "Unit tests verifying snapped start/end timestamps and multi-track persistence in store."
          },
          {
            "id": 2,
            "title": "Enable drag move and trim interactions",
            "description": "Add move, edge-trim, and ripple-trim behaviors with snapping and overlap prevention.",
            "dependencies": [
              1
            ],
            "details": "Implement drag handlers for clip body and edges, reuse snap service for positioning, and enforce no-overlap constraint during moves and trims.",
            "status": "pending",
            "testStrategy": "Interaction tests simulating drag events confirming position updates and trim bounds."
          },
          {
            "id": 3,
            "title": "Implement split and ripple command actions",
            "description": "Wire keyboard split and ripple trim commands using command pattern infrastructure.",
            "dependencies": [
              2
            ],
            "details": "Create SplitClipCommand and RippleTrimCommand applying state mutations with inverse methods and auto ripple toggle support.",
            "status": "pending",
            "testStrategy": "Unit tests confirming do/inverse mutations keep clips contiguous and respect ripple flag."
          },
          {
            "id": 4,
            "title": "Build selection and rubber-band mechanics",
            "description": "Provide marquee selection, shift toggles, and track focus integration.",
            "dependencies": [
              1
            ],
            "details": "Implement selection manager tracking active clips, marquee rectangle hit testing, and shift-click toggle to update selection set.",
            "status": "pending",
            "testStrategy": "Interaction tests covering multi-select, toggle, and clear behaviors across tracks."
          },
          {
            "id": 5,
            "title": "Map keyboard shortcuts and navigation",
            "description": "Bind PRD shortcuts for split, trim, in/out, and arrow-based navigation.",
            "dependencies": [
              4
            ],
            "details": "Register keymap, route to command actions, ensure arrow keys iterate selection, and guard platform modifier differences.",
            "status": "pending",
            "testStrategy": "Keyboard-driven E2E checks verifying shortcuts trigger expected commands and navigation order."
          },
          {
            "id": 6,
            "title": "Implement undo/redo command stack with validation",
            "description": "Extend command manager for clip operations with bounding validation before commit.",
            "dependencies": [
              3
            ],
            "details": "Add transactional command queue verifying resulting state has no overlaps, and integrate timeline-bound guardrails before push.",
            "status": "pending",
            "testStrategy": "Unit tests asserting invalid moves reject commands and redo restores prior state."
          },
          {
            "id": 7,
            "title": "Add visual feedback and tooltip affordances",
            "description": "Render drag ghosts, invalid drop highlights, and accessible tooltips.",
            "dependencies": [
              2
            ],
            "details": "Update timeline rendering to show ghost clip while dragging, highlight blocked targets, and surface timestamp tooltip with ARIA support.",
            "status": "pending",
            "testStrategy": "Visual regression or DOM snapshot tests ensuring feedback elements appear with correct ARIA roles."
          },
          {
            "id": 8,
            "title": "Integrate telemetry hooks for heavy operations",
            "description": "Emit opt-in telemetry events around expensive clip interactions.",
            "dependencies": [
              7
            ],
            "details": "Wrap operations like split, ripple, and multi-select with telemetry emitters carrying duration metrics and opt-in gating.",
            "status": "pending",
            "testStrategy": "Unit tests stubbing telemetry bus to assert events fire with expected payloads."
          },
          {
            "id": 9,
            "title": "Author automated timeline interaction tests",
            "description": "Cover command objects, property invariants, and canvas E2E flows.",
            "dependencies": [
              1,
              2,
              3,
              6,
              7,
              8
            ],
            "details": "Write Vitest suites for command state transitions, fast-check props for ripple ordering, and Playwright flows for canvas interactions.",
            "status": "pending",
            "testStrategy": "Execute Vitest, fast-check, and Playwright suites validating CRUD, ripple invariants, and UI behaviors."
          }
        ]
      },
      {
        "id": 46,
        "title": "Deliver Effect Library and Palette System",
        "description": "Implement built-in generators/modifiers, parameter schema, presets, OKLab blending, and palette management.",
        "details": "- Define effect registry (`effects/index.ts`) with metadata: id, type, param descriptors (0-255), default preset list (5-10 each) serialized via JSON.\n- Generators: solid, gradient (linear/radial), wave (sine/triangle/saw), noise (use `simplex-noise 4.0`), fire (fire shader approximated via noise + color ramp).\n- Modifiers: brightness, hue shift, saturation, mirror/ripple. Compose modifiers using pipeline function.\n- Implement OKLab color conversions using `oklab 0.2` (TS port) for palette sampling, fallback to sRGB when unsupported.\n- Palette library: 15 built-in palettes stored in structured JSON; custom palette editor with 2-16 color swatches, supporting drag reorder and hex/HSL inputs.\n- Clip parameter UI uses headless components (Radix UI 2.0 sliders) with normalized range mapping to actual units (e.g., frequency Hz).\nPseudo-code:\n```\nconst registry = new Map<string, EffectDefinition>();\nregistry.set('wave', {\n  evaluate(params, t, idx) {\n    const phase = (t * params.frequency) + idx * params.phaseOffset;\n    return oklabToRgb(waveColor(phase, params));\n  }\n});\n```\n- Provide serialization for presets and ensure compatibility with compiler inputs.\n",
        "testStrategy": "- Unit tests on effect evaluators verifying deterministic outputs and param bounds.\n- Color blending regression tests comparing OKLab vs sRGB outputs for gradients.\n- UI tests: Playwright toggles presets, ensures preview thumbnails update without exceeding 16ms render budget.",
        "priority": "medium",
        "dependencies": [
          43,
          44
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design effect registry schema",
            "description": "Define the TypeScript registry structure and metadata shape for effects.",
            "dependencies": [],
            "details": "Specify registry map typing, effect definition interfaces, parameter descriptor ranges, and preset metadata serialization format.",
            "status": "pending",
            "testStrategy": "Type-check registry typings and ensure schema validation passes for sample entries."
          },
          {
            "id": 2,
            "title": "Implement generator effects",
            "description": "Create solid, gradient, wave, noise, and fire generators using the registry.",
            "dependencies": [
              1
            ],
            "details": "Build generator evaluators, integrate simplex-noise 4.0, support linear and radial gradients, and implement wave variants with phase-aware color outputs.",
            "status": "pending",
            "testStrategy": "Unit test generator outputs for deterministic values, noise bounds, and gradient interpolation."
          },
          {
            "id": 3,
            "title": "Implement modifier pipeline",
            "description": "Add brightness, hue shift, saturation, mirror, and ripple modifiers.",
            "dependencies": [
              1
            ],
            "details": "Create reusable pipeline composition utility, ensure modifiers apply sequentially, and expose parameter descriptors compatible with registry metadata.",
            "status": "pending",
            "testStrategy": "Unit test modifier chaining order and validate clamped parameter behaviors across sample frames."
          },
          {
            "id": 4,
            "title": "Implement OKLab utilities",
            "description": "Add OKLab conversion helpers and fallbacks for unsupported contexts.",
            "dependencies": [
              2
            ],
            "details": "Integrate oklab 0.2 TypeScript port, expose rgb⇄oklab helpers, and implement fallback logic to sRGB when OKLab cannot execute.",
            "status": "pending",
            "testStrategy": "Add conversion accuracy tests comparing against reference values and fallback path coverage."
          },
          {
            "id": 5,
            "title": "Build palette library and editor UI",
            "description": "Create built-in palettes and interactive editor supporting customization.",
            "dependencies": [
              4
            ],
            "details": "Author JSON library of 15 palettes, implement palette management services, and create editor UI with drag reordering plus hex/HSL inputs.",
            "status": "pending",
            "testStrategy": "UI regression tests for palette editing workflows and snapshot tests for palette JSON output."
          },
          {
            "id": 6,
            "title": "Wire parameter control UI",
            "description": "Connect headless Radix sliders to effect parameters with normalized ranges.",
            "dependencies": [
              2,
              3
            ],
            "details": "Map normalized slider values to concrete units, ensure bi-directional updates, and synchronize with registry descriptors for live preview updates.",
            "status": "pending",
            "testStrategy": "Component tests verifying slider mappings and interaction latency under 16ms budget."
          },
          {
            "id": 7,
            "title": "Implement preset serialization compatibility",
            "description": "Ensure presets serialize and load cleanly across compiler inputs.",
            "dependencies": [
              2,
              3,
              5
            ],
            "details": "Define preset schema, implement JSON serialization/deserialization routines, and validate compatibility with compiler pipelines.",
            "status": "pending",
            "testStrategy": "Integration tests loading presets through compiler mocks and verifying round-trip fidelity."
          },
          {
            "id": 8,
            "title": "Add comprehensive testing coverage",
            "description": "Expand automated tests for effects, palettes, and UI regressions.",
            "dependencies": [
              2,
              3,
              4,
              5,
              6,
              7
            ],
            "details": "Author unit, integration, and Playwright scenarios covering effect outputs, palette selections, preview updates, and modifier pipelines.",
            "status": "pending",
            "testStrategy": "Execute Playwright suites and automated unit/integration tests ensuring target behaviors and performance thresholds."
          }
        ]
      },
      {
        "id": 47,
        "title": "Build Automation and Modulation System",
        "description": "Add keyframe-based automation tracks, easing controls, and LFO sources targeting effect parameters and global settings.",
        "details": "- Automation model: each curve stores keyframes `{time, value, easing}` with cubic Bezier support; reuse `bezier-easing 3.0` for custom curves.\n- UI: stopwatch arm toggles automation per parameter; when active, display curve overlay in automation track; show bezier handles only on selection to reduce clutter.\n- Implement evaluation pipeline: at render, sample curve -> value; for performance, pre-bake segments into piecewise linear approximations at zoomed-out levels.\n- LFO sources: sine, square, noise; allow routing to parameter via modulation matrix (depth, offset, phase). Provide per-clip LFO frequency sync to BPM.\nPseudo-code:\n```\nfunction sampleAutomation(paramId, time) {\n  const curve = automationIndex[paramId];\n  const base = curve.interpolate(time);\n  const lfo = lfoRegistry[paramId]?.sample(time);\n  return clamp(base + lfo.depth * lfoWave(time), 0, 255);\n}\n```\n- Add F9 shortcut for quick ease-in-out by updating keyframe easing data.\n- Optimize by caching last sample per frame to avoid redundant computations (>320 LEDs).\n",
        "testStrategy": "- Unit tests for interpolation accuracy (linear, bezier, ease-in/out) and LFO phase alignment using Vitest snapshots.\n- Performance benchmark: run evaluation over 10k samples ensuring <2ms per frame.\n- Playwright scenario: user arms automation, adds keys, toggles F9, verifying UI states and store updates.",
        "priority": "medium",
        "dependencies": [
          46,
          44
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define automation curve data model",
            "description": "Establish data structures for automation curves and indexes across parameters.",
            "dependencies": [],
            "details": "Model keyframes as {time,value,easing} with cubic Bezier metadata, build automationIndex registry, and document serialization rules.",
            "status": "pending",
            "testStrategy": "Unit tests ensuring keyframe serialization/deserialization and easing schema validation."
          },
          {
            "id": 2,
            "title": "Implement keyframe CRUD and easing controls",
            "description": "Provide APIs to add, edit, delete, and reorder keyframes with easing presets.",
            "dependencies": [
              1
            ],
            "details": "Expose mutations for keyframes, update easing metadata including F9 ease-in-out shortcut, and enforce clamping and time ordering.",
            "status": "pending",
            "testStrategy": "Unit tests covering CRUD edge cases, easing preset application, and F9 shortcut behavior."
          },
          {
            "id": 3,
            "title": "Design automation UI interactions",
            "description": "Create UI for arming automation, editing curves, and showing bezier handles on selection.",
            "dependencies": [
              1,
              2
            ],
            "details": "Add stopwatch arm toggles per parameter, render overlay tracks when armed, and show editable bezier handles only for selected keyframes.",
            "status": "pending",
            "testStrategy": "Playwright scenario verifying arm toggle state, curve visibility, and handle interactions."
          },
          {
            "id": 4,
            "title": "Develop curve interpolation and easing engine",
            "description": "Implement interpolation engine supporting linear and cubic bezier easing.",
            "dependencies": [
              1
            ],
            "details": "Create interpolate(time) method computing values via bezier-easing 3.0, handle extrapolation, and support ease-in/out presets.",
            "status": "pending",
            "testStrategy": "Unit tests comparing sampled values against known bezier outputs and linear targets."
          },
          {
            "id": 5,
            "title": "Build performance pre-bake sampling strategy",
            "description": "Precompute piecewise linear segments for zoomed-out playback levels.",
            "dependencies": [
              4
            ],
            "details": "Implement LOD baking that caches simplified segments per zoom level, updates on keyframe changes, and reuses interpolation engine.",
            "status": "pending",
            "testStrategy": "Benchmarks measuring bake time and validation that approximations stay within value tolerance."
          },
          {
            "id": 6,
            "title": "Implement LFO sources with BPM sync",
            "description": "Create sine, square, and noise LFO generators with clip-level BPM synchronization.",
            "dependencies": [
              1
            ],
            "details": "Add LFO registry with depth, offset, phase, and tempo sync controls, plus deterministic noise generation options.",
            "status": "pending",
            "testStrategy": "Unit tests verifying LFO waveforms, phase alignment, and BPM-locked frequency ratios."
          },
          {
            "id": 7,
            "title": "Create modulation routing matrix",
            "description": "Route LFO sources to automation targets via modulation matrix controls.",
            "dependencies": [
              6
            ],
            "details": "Implement routing UI/data, depth blending, offset handling, and parameter assignment validation for effect and global settings.",
            "status": "pending",
            "testStrategy": "Integration tests confirming routing updates propagate and depth scaling behaves across multiple targets."
          },
          {
            "id": 8,
            "title": "Integrate evaluation pipeline into playback",
            "description": "Combine automation curves and LFO outputs during render sampling.",
            "dependencies": [
              2,
              4,
              5,
              6,
              7
            ],
            "details": "Implement sampleAutomation that blends base curve with modulation, clamps outputs, and respects cached segment data per frame.",
            "status": "pending",
            "testStrategy": "Integration tests simulating playback over clips to validate final values and modulation stacking."
          },
          {
            "id": 9,
            "title": "Implement caching and performance validation",
            "description": "Add frame-level caching and establish benchmarks for the automation system.",
            "dependencies": [
              5,
              8
            ],
            "details": "Cache last sample per frame to avoid redundant computation, instrument telemetry, and script 10k-sample benchmark under 2ms/frame.",
            "status": "pending",
            "testStrategy": "Performance benchmarks plus regression tests asserting caching reduces repeated calls and meets frame budget."
          }
        ]
      },
      {
        "id": 48,
        "title": "Integrate Real-Time 3D Preview Pipeline",
        "description": "Render LED array with Three.js InstancedMesh, HQ/LQ quality modes, bloom isolation, and <50ms update latency.",
        "details": "- Use Three.js r160 with `EffectComposer`, `RenderPass`, `UnrealBloomPass`, and selective bloom via layer masking; configure OrbitControls with presets (front, side, isometric) saved in state.\n- Instantiate 320 LED spheres using `InstancedMesh` with GPU color updates through `setColorAt` batched buffer updates; throttle updates using `postMessage` to Web Worker (if OffscreenCanvas supported) else fallback to main thread with requestAnimationFrame.\n- Acrylic plate mesh using `MeshPhysicalMaterial` (transmission 0.95, IOR 1.49) and environment map from precomputed HDR.\n- Quality toggle: HQ (bloom + 60fps), LQ (skip bloom, cut to 30fps) triggered during scrubbing or when CPU load high.\n- Integrate with timeline state: subscribe to playhead changes, pass frame buffer from compiler preview service; ensure updates within 50ms by diffing frames and only updating mutated LEDs.\nPseudo-code:\n```\nfunction updatePreview(frame) {\n  frame.leds.forEach((color, index) => instancedMesh.setColorAt(index, color);\n  instancedMesh.instanceColor.needsUpdate = true;\n  composer.render();\n}\n```\n- Add screenshot capture pipeline for templates/thumbnails.\n",
        "testStrategy": "- WebGL headless tests using `vitest-environment-webgl` verifying instanced color updates.\n- Performance profiling: measure latency via `performance.mark` around frame dispatch → render; ensure <50ms average.\n- Visual regression: Playwright with `@animaapp/playwright-testing` capturing preview snapshots (bloom disabled) to compare frames.",
        "priority": "medium",
        "dependencies": [
          46,
          47,
          44
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up Three.js renderer and composer",
            "description": "Establish the base Three.js scene with camera, renderer, and post-processing pipeline.",
            "dependencies": [],
            "details": "Configure WebGLRenderer targeting canvas element, add PerspectiveCamera presets, and assemble EffectComposer with RenderPass plus UnrealBloomPass layered for selective bloom using masking layers and OrbitControls presets persisted in app state.",
            "status": "pending",
            "testStrategy": "Spin up a mocked DOM harness to instantiate the scene and assert composer passes are registered without runtime errors."
          },
          {
            "id": 2,
            "title": "Implement InstancedMesh LED array",
            "description": "Create and configure the instanced LED spheres and their dynamic color buffers.",
            "dependencies": [
              1
            ],
            "details": "Instantiate 320 LED sphere meshes via InstancedMesh, preload per-instance matrices, and wire GPU color updates using setColorAt batching with flagged instanceColor.needsUpdate while ensuring acrylic plate MeshPhysicalMaterial shares scene lighting and environment maps.",
            "status": "pending",
            "testStrategy": "Write vitest-environment-webgl tests that push sample color frames and confirm instance buffers update as expected."
          },
          {
            "id": 3,
            "title": "Add worker and OffscreenCanvas update bridge",
            "description": "Build frame processing pipeline that leverages Web Workers when available.",
            "dependencies": [
              2
            ],
            "details": "Implement postMessage protocol to stream frame diffs to a worker using OffscreenCanvas when supported, fall back to main-thread requestAnimationFrame batching otherwise, and ensure thread-safe message queue draining.",
            "status": "pending",
            "testStrategy": "Unit test worker handshake with mocked postMessage to validate diff batching and fallback path selection."
          },
          {
            "id": 4,
            "title": "Implement adaptive HQ/LQ quality controller",
            "description": "Manage render quality toggles based on interaction and system load.",
            "dependencies": [
              1,
              3
            ],
            "details": "Introduce stateful controller that switches between bloom-enabled 60fps HQ mode and simplified 30fps LQ mode during scrubbing or detected CPU pressure, coordinating composer passes and renderer frame throttling.",
            "status": "pending",
            "testStrategy": "Add integration test covering quality toggles ensuring bloom pass activation and frame interval adjustments occur as configured."
          },
          {
            "id": 5,
            "title": "Integrate timeline frame stream updates",
            "description": "Connect timeline state changes to LED frame updates within latency budget.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Subscribe to playhead and compiler preview service, compute LED diffs per frame, and invoke InstancedMesh updates ensuring render calls complete under 50ms through incremental updates.",
            "status": "pending",
            "testStrategy": "Simulate timeline playback in tests to ensure frame diffs trigger color updates and measured latency stays within budget."
          },
          {
            "id": 6,
            "title": "Instrument performance metrics and safeguards",
            "description": "Add telemetry to monitor and enforce rendering latency goals.",
            "dependencies": [
              5
            ],
            "details": "Wrap frame dispatch and render calls with performance.mark/measure, log metrics via profiler hooks, and expose alerts or automatic degradation when average exceeds 50ms.",
            "status": "pending",
            "testStrategy": "Create automated benchmark test capturing performance entries and asserting latency thresholds with mocked timeline data."
          },
          {
            "id": 7,
            "title": "Build screenshot capture and thumbnail pipeline",
            "description": "Provide tooling to capture high-quality preview snapshots for templates.",
            "dependencies": [
              1,
              5
            ],
            "details": "Implement render-to-texture path that re-renders scene with controlled camera presets, applies necessary post-processing, and exports images for template and thumbnail use while respecting acrylic transmission effects.",
            "status": "pending",
            "testStrategy": "Run Playwright-based capture script validating generated images match expected dimensions and bloom settings."
          },
          {
            "id": 8,
            "title": "Develop WebGL testing and regression harness",
            "description": "Establish automated tests safeguarding rendering and visual output.",
            "dependencies": [
              2,
              5,
              6,
              7
            ],
            "details": "Set up vitest-environment-webgl suites, integrate Playwright visual regression snapshots, and add CI scripts to validate worker pipeline, quality toggles, performance metrics, and screenshot outputs end-to-end.",
            "status": "pending",
            "testStrategy": "Execute combined headless WebGL and Playwright regression runs comparing snapshots and ensuring no critical metrics regress."
          }
        ]
      },
      {
        "id": 49,
        "title": "Implement Pattern Compiler and Segmentation Engine",
        "description": "Convert timeline data into .prism v1.1 binaries with adaptive FPS, segmentation respecting 256 KB limit, and temporal metadata extraction.",
        "details": "- Rust worker (`compile.rs`) executed via `tauri::async_runtime::spawn_blocking`; use `serde_repr` for enum TLV encoding and `byteorder` for endian-safe writes.\n- Evaluation pipeline: for each frame, resolve active clips, evaluate effects + automation into RGB[320]; optimize by precomputing static segments and reusing buffers.\n- Adaptive FPS: analyze temporal variance by computing per-LED delta; if below threshold, quantize to lower FPS (60→30→24→15) while ensuring transitions align with clip boundaries.\n- Segmentation: accumulate frames into chunk until payload size ~240 KB, then finalize file names `PatternName__sNNN.prism`; carry over cross-segment state for seamless playback.\n- Temporal metadata detection: identify motion vectors (LEFT/RIGHT/CENTER/EDGE) by analyzing centroid shifts and write sync mode TLVs.\nPseudo-code:\n```\nfor segment in segments {\n  write_header(&mut buf, header);\n  for frame in segment.frames {\n    buf.extend_from_slice(&frame.rgb);\n  }\n  stream_writer.send(buf).await?;\n}\n```\n- Provide streaming write using `tokio::io::BufWriter` to avoid memory spikes; expose compile progress via IPC events.\n",
        "testStrategy": "- Rust unit tests verifying header composition, CRC, segmentation thresholds, and FPS downsampling correctness.\n- Property tests (`proptest`) on random clip arrangements ensuring file size ≤256 KB and total frame count preserved.\n- Benchmark harness measuring typical 5s pattern compile <500ms on baseline hardware.",
        "priority": "medium",
        "dependencies": [
          46,
          47
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Draft compiler pipeline architecture",
            "description": "Define the Rust worker structure and major subsystems for the pattern compiler.",
            "dependencies": [],
            "details": "Outline module boundaries for compile.rs worker, evaluation, segmentation, metadata, and I/O threads.",
            "status": "pending",
            "testStrategy": "Run architecture review to confirm data flow and module responsibilities."
          },
          {
            "id": 2,
            "title": "Integrate effect evaluation pipeline",
            "description": "Build frame evaluation that resolves clips, applies effects, and reuses buffers.",
            "dependencies": [
              1
            ],
            "details": "Integrate clip resolver and effect evaluators into frame builder while enabling buffer reuse scaffolding.",
            "status": "pending",
            "testStrategy": "Add unit tests for clip resolution ordering and effect blending edge cases."
          },
          {
            "id": 3,
            "title": "Implement adaptive FPS analyzer",
            "description": "Create adaptive frame-rate logic driven by per-LED variance thresholds.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement per-LED delta analysis and FPS quantization ladder while respecting clip boundary constraints.",
            "status": "pending",
            "testStrategy": "Write unit tests covering FPS downshift thresholds and boundary alignment behavior."
          },
          {
            "id": 4,
            "title": "Build segmentation and chunking logic",
            "description": "Assemble frame segments under size limits with correct naming and state carryover.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Create segment accumulator enforcing ~240KB payload limits, PatternName__sNNN naming, and carryover state handling.",
            "status": "pending",
            "testStrategy": "Simulate varied frame counts ensuring segments stay under 256KB and filenames increment correctly."
          },
          {
            "id": 5,
            "title": "Develop temporal metadata extraction",
            "description": "Detect motion vectors and emit TLVs for sync metadata.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Derive motion vectors via centroid shift tracking and encode TLVs using serde_repr enums and byteorder writers.",
            "status": "pending",
            "testStrategy": "Add unit tests verifying motion classification accuracy and TLV byte layouts."
          },
          {
            "id": 6,
            "title": "Implement streaming writer and IPC progress",
            "description": "Stream compiled segments with progress updates from the worker.",
            "dependencies": [
              1,
              4,
              5
            ],
            "details": "Wire BufWriter streaming pipeline with spawn_blocking execution and IPC events reporting compile progress.",
            "status": "pending",
            "testStrategy": "Create integration test mocking IPC listener to assert progress updates and streamed writes."
          },
          {
            "id": 7,
            "title": "Optimize memory usage across pipeline",
            "description": "Tune allocations to prevent spikes during compilation.",
            "dependencies": [
              2,
              3,
              4,
              6
            ],
            "details": "Profile memory usage, introduce buffer pooling, and enforce zero-copy slice reuse to eliminate spikes.",
            "status": "pending",
            "testStrategy": "Use criterion profiling to confirm peak allocations remain within budget compared to baseline."
          },
          {
            "id": 8,
            "title": "Author property and benchmark tests",
            "description": "Add automated validation for correctness and performance targets.",
            "dependencies": [
              2,
              3,
              4,
              5,
              6,
              7
            ],
            "details": "Create proptest suites and benchmark harnesses covering segmentation, FPS logic, and compile timing goals.",
            "status": "pending",
            "testStrategy": "Run proptest cases and criterion benchmarks verifying size limits, frame totals, and <500ms latency."
          },
          {
            "id": 9,
            "title": "Document compiler workflow and usage",
            "description": "Produce comprehensive documentation for the compiler and segmentation engine.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6,
              7,
              8
            ],
            "details": "Document compiler workflow, configuration knobs, and operator guidance within project docs.",
            "status": "pending",
            "testStrategy": "Request peer review of documentation for completeness and accuracy."
          }
        ]
      },
      {
        "id": 50,
        "title": "Deliver Upload, Sync Workflow, and Onboarding Experience",
        "description": "Create end-to-end compile→upload→play pipeline with progress UI, storage management, autosave recovery, and novice onboarding flow.",
        "details": "- Upload manager: use existing WebSocket connection to send segments sequentially (PUT_BEGIN/PUT_DATA/PUT_END) respecting `max_chunk`; show progress bar updating every 100ms with bytes sent.\n- Storage panel: call LIST to display existing patterns, sizes, delete operations; include storage bar indicating remaining capacity.\n- Sync button: orchestrate compile (Task 49) + upload + PLAY first segment; handle errors (storage full, CRC mismatch) with actionable dialogs.\n- Autosave recovery UI: on startup, detect crashes and offer restore; integrate with state from Task 43.\n- Onboarding wizard: steps (discover device → connect → choose template → tweak brightness/speed → sync). Provide 10 starter templates stored as `.prismproj` seeds using effect library, automatically loading preview thumbnails.\n- Tooltips: implement contextual hints with `floating-ui` showing on first interaction, persisted via local preference store.\nPseudo-code:\n```\nasync function syncProject() {\n  setStatus('compiling');\n  const segments = await compileProject(currentProject);\n  setStatus('uploading');\n  for (const segment of segments) {\n    await uploadSegment(ws, segment);\n  }\n  await playSegment(ws, segments[0]);\n}\n```\n- Ensure workflow completes novice path in <2 minutes by minimizing blocking prompts and prefetching templates.\n",
        "testStrategy": "- Playwright E2E scenario covering full wizard flow with mock device, asserting total time under threshold via timers.\n- Integration tests using mocked WebSocket verifying retries on chunk failure and accurate progress updates.\n- User acceptance checklist verifying tooltips only show once and preferences persist across restarts.",
        "priority": "medium",
        "dependencies": [
          42,
          43,
          44,
          46,
          49
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement WebSocket upload manager",
            "description": "Build sequential uploader using existing WebSocket PUT operations and enforce chunk sizing.",
            "dependencies": [],
            "details": "Implement PUT_BEGIN/PUT_DATA/PUT_END pipeline respecting max_chunk, add CRC validation, and expose async API with abort support.",
            "status": "pending",
            "testStrategy": "Write integration test with mocked WebSocket ensuring sequential sends, CRC checks, and abort behavior."
          },
          {
            "id": 2,
            "title": "Add upload progress UI with retry logic",
            "description": "Surface real-time upload progress every 100ms and handle recoverable failures with retries.",
            "dependencies": [
              1
            ],
            "details": "Bind uploader events to progress bar updates, show ETA, queue retry on transient socket errors up to N attempts, and surface final error state.",
            "status": "pending",
            "testStrategy": "Create UI test verifying progress cadence and jest unit testing retry backoff on simulated failures."
          },
          {
            "id": 3,
            "title": "Deliver storage management panel",
            "description": "Expose LIST results with sizes, delete controls, and remaining capacity visualization.",
            "dependencies": [],
            "details": "Call storage LIST endpoint, render sortable table, wire delete confirmations, and compute capacity bar from device quota metadata.",
            "status": "pending",
            "testStrategy": "Add component test with mocked LIST payload and Cypress check for delete action updating capacity bar."
          },
          {
            "id": 4,
            "title": "Implement sync button orchestration",
            "description": "Coordinate compile, upload, and initial playback with error dialogs for common failures.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Chain compileProject output into uploader, launch PLAY on first segment, pre-handle storage full and CRC mismatch via modal dialogs with retry or cleanup actions.",
            "status": "pending",
            "testStrategy": "Integration test mocking compile/upload/play to assert state transitions and error dialog pathways."
          },
          {
            "id": 5,
            "title": "Integrate autosave recovery workflow",
            "description": "Detect crash autosaves on startup and offer restoration before normal sync flow.",
            "dependencies": [
              4
            ],
            "details": "Read autosave state from Task 43 storage, prompt restore vs discard, hydrate project state, and adjust sync button behavior when recovery pending.",
            "status": "pending",
            "testStrategy": "Component test simulating autosave presence ensuring prompt renders and restored state flows into sync pipeline."
          },
          {
            "id": 6,
            "title": "Seed starter templates with thumbnails",
            "description": "Bundle ten `.prismproj` seeds and preload preview images for wizard usage.",
            "dependencies": [],
            "details": "Select effect library presets, serialize projects, store metadata with preview asset URLs, and prefetch thumbnails into cache on app boot.",
            "status": "pending",
            "testStrategy": "Add data integrity test verifying template count, metadata fields, and thumbnail availability."
          },
          {
            "id": 7,
            "title": "Build onboarding wizard experience",
            "description": "Guide novices through discovery, connection, template choice, customization, and sync under two minutes.",
            "dependencies": [
              4,
              6
            ],
            "details": "Implement multi-step wizard with timers, inline validation, brightness/speed controls, template previews, and auto-advance on successful sync.",
            "status": "pending",
            "testStrategy": "Playwright flow test timing total duration with mocked device to ensure completion under two minutes."
          },
          {
            "id": 8,
            "title": "Implement tooltip preference handling",
            "description": "Show contextual hints once using floating-ui and persist dismissal in local preferences.",
            "dependencies": [
              7
            ],
            "details": "Attach floating-ui tooltips to primary controls, track first-interaction display, store flag in preference service, and expose reset toggle.",
            "status": "pending",
            "testStrategy": "UI test verifying tooltip display on first use only and preference reset restores hints."
          },
          {
            "id": 9,
            "title": "Author end-to-end and service tests",
            "description": "Cover full pipeline reliability with automated tests across uploader, wizard, and recovery paths.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6,
              7,
              8
            ],
            "details": "Expand Playwright suite to simulate compile→upload→play success and failure, add mocked WebSocket retry tests, and include onboarding recovery regression case.",
            "status": "pending",
            "testStrategy": "Playwright E2E plus Jest integration ensuring retries, recovery, and onboarding targets stay within SLA."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-10-16T10:53:04.545Z",
      "updated": "2025-10-16T11:36:15.152Z",
      "description": "Tasks for master context"
    }
  }
}