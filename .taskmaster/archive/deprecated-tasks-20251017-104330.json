{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Establish component scaffolding and runtime orchestration",
        "description": "Create ESP-IDF component structure for network, storage, playback, and templates, then wire them into the main firmware entry point with task scheduling and error propagation.",
        "details": "Implementation:\n- Create `firmware/components/{network,storage,playback,templates}` with `CMakeLists.txt`, public headers (e.g., `network_manager.h`, `pattern_storage.h`), and stub source files exposing `*_init()` and FreeRTOS task entry points.\n- Update `firmware/CMakeLists.txt` `EXTRA_COMPONENT_DIRS` to include the new components and ensure include paths export shared headers (`components/include`).\n- Extend `firmware/main/main.c` to include the new headers, call `network_init()`, `storage_init()`, `playback_init()`, `templates_init()` after `system_init()`, and create FreeRTOS tasks using the defined stack sizes and priorities.\n- Add centralized failure handling so any init error routes through `error_handler` once implemented.\nPseudo-code:\n```\nvoid app_main(void) {\n    print_system_info();\n    ESP_ERROR_CHECK(system_init());\n    ESP_ERROR_CHECK(network_init());\n    ESP_ERROR_CHECK(storage_init());\n    ESP_ERROR_CHECK(playback_init());\n    ESP_ERROR_CHECK(templates_init());\n    xTaskCreate(network_task, \"network\", STACK_NETWORK, NULL, PRIORITY_NETWORK, NULL);\n    ...\n}\n```",
        "testStrategy": "Run `idf.py build` to verify new components integrate; add Unity smoke tests that call each `*_init()` stub; flash to hardware and confirm boot log shows all init stages without watchdog resets.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold ESP-IDF component directories",
            "description": "Create initial network, storage, playback, and templates components with headers and stub sources.",
            "dependencies": [],
            "details": "Under `firmware/components`, add folders for network, storage, playback, and templates, each with `CMakeLists.txt`, a public header exposing `*_init()` and FreeRTOS task prototypes, and stub `.c` files returning `ESP_OK`.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Wire new components into build system",
            "description": "Register the new components with the firmware build configuration and shared include paths.",
            "dependencies": [
              1
            ],
            "details": "Update `firmware/CMakeLists.txt` to append the four component directories to `EXTRA_COMPONENT_DIRS`, ensure `components/include` is exported for shared headers, and confirm each component lists its public headers in `idf_component_register`.",
            "status": "done",
            "testStrategy": "Run `idf.py reconfigure` to ensure CMake picks up the new directories without errors.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Extend app_main for initialization and task orchestration",
            "description": "Modify the firmware entry point to initialize components and launch tasks with centralized error handling.",
            "dependencies": [
              1,
              2
            ],
            "details": "Include the new component headers in `firmware/main/main.c`, call each `*_init()` after `system_init()` wrapped in `ESP_ERROR_CHECK`, create FreeRTOS tasks with agreed stack sizes/priorities, and route any init failure through the shared `error_handler`.",
            "status": "done",
            "testStrategy": "Build the project and inspect the `app_main` flow in `idf.py monitor` once tasks are running to verify staged init logs.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add scaffolding smoke tests and build verification",
            "description": "Introduce basic tests and build checks covering the new component scaffolding and orchestrated startup.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Create Unity smoke tests that call each `*_init()` stub to confirm linkage, add a CI or local script target running `idf.py build`, and document the expected boot log checkpoints for manual verification.",
            "status": "done",
            "testStrategy": "Execute Unity smoke tests via `idf.py test` (or equivalent) and run `idf.py build` to ensure the scaffolding integrates cleanly.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Break this work into subtasks covering (1) creating ESP-IDF component skeletons for network/storage/playback/templates with headers and stubs, (2) updating build files and exports, (3) extending app_main to orchestrate init and FreeRTOS tasks with centralized error routing, and (4) adding smoke tests/build verification.",
        "updatedAt": "2025-10-15T17:23:29.510Z"
      },
      {
        "id": 2,
        "title": "Implement WiFi lifecycle, captive portal, and mDNS broadcasting",
        "description": "Develop the network manager component providing AP setup, STA onboarding, credential persistence, captive portal, and mDNS service advertisement per PRD requirements.",
        "details": "Implementation:\n- In `components/network/network_manager.c`, configure dual-mode WiFi: start AP (`PRISM-SETUP`) using `esp_netif_create_default_wifi_ap()`, host captive portal via `esp_http_server`, and transition to STA mode once credentials are submitted, storing them with NVS APIs.\n- Implement exponential backoff reconnect loop (`WIFI_RETRY_MAX`) with event handlers for `WIFI_EVENT` and `IP_EVENT` to maintain uptime.\n- Register mDNS using `mdns_init()` with host `\"prism-k1\"` and service `_prism._tcp`.\n- Expose `network_init()` to set up netifs and `network_task(void*)` to manage portal lifecycle and status broadcasts.\nPseudo-code:\n```\nesp_err_t network_init(void) {\n    wifi_init_config_t wifi_cfg = WIFI_INIT_CONFIG_DEFAULT();\n    ESP_ERROR_CHECK(esp_wifi_init(&wifi_cfg));\n    start_ap_portal();\n    register_event_handlers();\n    mdns_init();\n    return ESP_OK;\n}\n```\n- Ensure memory allocations use `prism_pool_alloc` where possible to avoid fragmentation.",
        "testStrategy": "Add Unity tests with `esp_event_loop_run()` mocked to validate backoff timing; on hardware, run captive portal flow and verify `mdns_query_ptr()` returns `prism-k1.local`; measure reconnect handling by cycling router power.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Establish WiFi dual-mode initialization",
            "description": "Set up foundational WiFi interfaces and event loop enabling AP and STA operation.",
            "dependencies": [],
            "details": "Initialize ESP netifs, configure PRISM-SETUP SSID via esp_netif_create_default_wifi_ap, call esp_wifi_init with default config, and expose network_init while using prism_pool_alloc for dynamic buffers.\n<info added on 2025-10-15T17:58:33.766Z>\nImplemented network_private.h with the WiFi lifecycle state machine scaffolding and declarations, updated components/network/CMakeLists.txt to pull in esp_http_server, mdns, core, and lwip, and added init_wifi_dual_mode() to initialize esp_netif, create the default event loop, bring up AP and STA netifs, set WiFi storage to RAM, and delegate AP startup to start_ap_mode() configured for the PRISM-SETUP open AP. Expanded network_init() to initialize NVS, call init_wifi_dual_mode(), register WIFI_EVENT/IP_EVENT handlers (logging only for now), launch the AP, and chain into start_captive_portal() and load_credentials_from_nvs() placeholders; introduced additional stubs (e.g., mDNS helpers) earmarked for subtasks 2.2–2.5 with build readiness confirmed under the ESP-IDF environment.\n</info added on 2025-10-15T17:58:33.766Z>",
            "status": "done",
            "testStrategy": "Create a Unity test harness that stubs esp_wifi_init and verifies network_init registers both AP and STA netifs.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Build captive portal HTTP workflow",
            "description": "Implement the captive portal server handling credential submission and AP lifecycle.",
            "dependencies": [
              1
            ],
            "details": "Spin up esp_http_server with handlers for credential form, serve minimal assets from flash, and ensure portal teardown triggers STA transition when credentials are posted.\n<info added on 2025-10-15T18:00:05.532Z>\nCaptive portal HTTP server implemented with embedded credential and success HTML forms, GET “/” serving the form, POST “/connect” parsing URL-encoded payloads via parse_form_data, persisting credentials through save_credentials_to_nvs, updating g_net_state, and signaling STA transition while a wildcard GET handler satisfies captive portal probes. start_captive_portal launches esp_http_server on port 80 with four sockets, LRU purge, and 4KB stack; stop_captive_portal performs graceful teardown. Form buffers now come from prism_pool_alloc and are released after use, HTML assets live in firmware, and 400/408/500 responses cover error paths. Success flow leaves the portal with credentials_available set for network_task to continue with Subtask 2.3.\n</info added on 2025-10-15T18:00:05.532Z>",
            "status": "done",
            "testStrategy": "Use Unity plus HTTP client mocks to submit credentials and confirm portal handlers return expected responses and cleanup callbacks run.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement credential persistence with NVS",
            "description": "Store and retrieve WiFi credentials securely using NVS once provided by the portal.",
            "dependencies": [
              2
            ],
            "details": "Leverage nvs_open and nvs_set_str to persist SSID/password, ensure prism_pool_alloc buffers are zeroed after use, and validate credentials before initiating STA connect.\n<info added on 2025-10-15T18:01:26.128Z>\nImplemented load_credentials_from_nvs() to open the prism_wifi namespace in read-only mode, check the u8 configured flag, and hydrate g_net_state SSID/password buffers (33/64 byte limits) with NULL-safe handling for open networks while setting credentials_available when successful. Added save_credentials_to_nvs() that opens prism_wifi in read-write mode, writes ssid/password keys with nvs_set_str (erasing password for open networks), updates configured=1, commits, and always closes the handle with proper error propagation. Documented the prism_wifi schema (configured u8, ssid string, password string), wired load into network_init() and save into portal_post_handler() so network_task can act on credentials_available, and emphasized NVS handle cleanup plus the recommendation to enable flash encryption to protect stored passwords.\n</info added on 2025-10-15T18:01:26.128Z>",
            "status": "done",
            "testStrategy": "Write NVS mock-based tests verifying credentials persist across network_task restarts and that invalid data paths trigger cleanup.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add reconnect backoff and event handlers",
            "description": "Maintain WiFi uptime through exponential backoff reconnect logic tied to system events.",
            "dependencies": [
              1,
              3
            ],
            "details": "Register WIFI_EVENT and IP_EVENT handlers, implement WIFI_RETRY_MAX governed exponential backoff, and ensure timers use prism_pool_alloc allocations while updating status broadcasts.\n<info added on 2025-10-15T18:02:57.812Z>\nImplemented start_sta_connection() to configure the STA with persisted credentials, enforce WPA2-PSK with optional PMF, and enter WIFI_MODE_STA_CONNECTING via esp_wifi_connect(); transition_to_sta_mode() now halts the captive portal while retaining AP fallback, resets retry counters (retry_count=0, retry_delay_ms=1000), and launches the first STA attempt; update_retry_delay() applies capped exponential backoff (1s, 2s, 4s, 8s, 16s, then 30s) with continuous retries after the fifth attempt; wifi_event_handler() covers AP join/leave along with the full STA lifecycle, triggering timed reconnects on disconnect, clearing counters on success, and updating mode state when the STA stops; ip_event_handler() starts or stops mDNS as IP leases are gained or lost and synchronizes mode state accordingly; network_task() now boots into STA when credentials exist, reacts to new portal credentials, and polls every five seconds for mode monitoring, leaving the subtask ready for 2.5 mDNS advertisement work.\n</info added on 2025-10-15T18:02:57.812Z>",
            "status": "done",
            "testStrategy": "Simulate event sequences in Unity to assert backoff timing increases exponentially and resets on successful connection.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Configure mDNS advertisement service",
            "description": "Expose device discovery via mDNS once STA connectivity is established.",
            "dependencies": [
              1,
              4
            ],
            "details": "Call mdns_init after WiFi stack ready, register host prism-k1 and _ws._tcp service with correct port, and ensure lifecycle hooks restart mDNS on reconnect events.\n<info added on 2025-10-15T18:03:59.113Z>\nImplemented start_mdns_service() to call mdns_init(), set hostname prism-k1 (prism-k1.local), assign instance name PRISM K1 LED Controller, and register _http._tcp and _prism._tcp services on port 80 with TXT records version=1.0, device=prism-k1, leds=320. Added stop_mdns_service() that guards with g_net_state.mdns_initialized, invokes mdns_free(), and clears the flag for idempotent teardown. start_mdns_service() now runs from ip_event_handler() on IP_EVENT_STA_GOT_IP, while stop_mdns_service() executes on IP_EVENT_STA_LOST_IP and during network_deinit(), ensuring the service restarts cleanly across reconnects. Error paths propagate mdns_* failures and ensure mdns_free() executes so partial registrations do not leak resources.\n</info added on 2025-10-15T18:03:59.113Z>",
            "status": "done",
            "testStrategy": "Mock mdns APIs to verify service registration parameters and confirm restart occurs after reconnect event sequence.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Define unit and integration validation coverage",
            "description": "Plan and script tests covering WiFi lifecycle, portal flow, persistence, and mDNS discovery.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "Document Unity test cases, hardware-in-loop procedures for captive portal, reconnection cycling, and mdns_query_ptr discovery; integrate into CI runbook.\n<info added on 2025-10-15T18:05:58.853Z>\nCaptured comprehensive Unity suite under components/network/test with test_network_manager.c (23 cases spanning network init, NVS persistence, captive portal HTTP parsing, reconnection backoff, mDNS registration, integration flows, and memory safety) plus test/CMakeLists.txt and test/README.md documenting run steps and >80% coverage goals. Documented required mocks for esp_wifi, esp_netif, nvs, mdns, esp_http_server, and esp_event loop; outlined manual hardware checklists (6-step portal flow, 7-step reconnection timing, 5-step persistence power-cycle, mDNS discovery via avahi-browse/dns-sd) so validation can start immediately while mock implementation and hardware execution remain outstanding.\n</info added on 2025-10-15T18:05:58.853Z>",
            "status": "done",
            "testStrategy": "Consolidate test matrix ensuring continuous integration runs Unity suites and schedules periodic on-device verification.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Decompose into subtasks for WiFi dual-mode setup, captive portal HTTP server, credential persistence via NVS, reconnect/backoff logic with event handlers, mDNS advertisement, and unit/integration test coverage."
      },
      {
        "id": 3,
        "title": "Build WebSocket server with TLV-aware session management",
        "description": "Create a WebSocket handler supporting binary TLV messages, 4KB receive buffer, two concurrent clients, reconnection backoff, and error codes per ADR-002.",
        "details": "Implementation:\n- Under `components/network/websocket_handler.c`, use `httpd_ws_conn` from ESP-IDF to upgrade HTTP connections to WebSocket; allocate a fixed 4KB RX buffer per connection using memory pools.\n- Track active clients in a bounded array, rejecting additional connections with error 0x01.\n- Implement state machine (IDLE→RECEIVING→VALIDATING→STORING) with timers enforcing `WS_TIMEOUT_MS` and resume logic after errors.\n- Encode status frames (type 0x30) reporting heap and cache metrics from `prism_heap_monitor` and storage stats.\nPseudo-code:\n```\nstatic esp_err_t websocket_recv_task(void* arg) {\n    while (1) {\n        size_t len = WS_BUFFER_SIZE;\n        httpd_ws_recv_frame(client->hd, &frame, WS_TIMEOUT_MS);\n        switch (frame.type) {\n            case 0x10: handle_put_begin(frame.payload); break;\n            ...\n        }\n    }\n}\n```\n- Integrate exponential backoff reconnect attempts for clients and propagate errors via `error_handler`.",
        "testStrategy": "Create unit tests using `unity` with mocked `httpd_ws_recv_frame` to validate buffer boundaries and error code responses; run throughput benchmark using `idf.py monitor` with host script pushing 500KB/s payloads verifying sustained rate and no heap growth.",
        "priority": "medium",
        "dependencies": [
          "1",
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement WebSocket upgrade and session registry",
            "description": "Integrate ESP-IDF WebSocket upgrade flow and track connected sessions in the handler entry point.",
            "dependencies": [],
            "details": "Create the initial handler in components/network/websocket_handler.c that upgrades HTTP requests via httpd_ws_conn, persists client metadata, and initializes session bookkeeping structures.",
            "status": "pending",
            "testStrategy": "Add a Unity test with mocked httpd request objects verifying upgrade success and client slot initialization.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Enforce two-client limit with fixed 4KB buffers",
            "description": "Allocate per-client receive buffers and reject excess connection attempts with ADR-002 error codes.",
            "dependencies": [
              1
            ],
            "details": "Attach a 4KB RX buffer from the memory pool to each active client and block additional upgrades by responding with error code 0x01 while freeing any provisional resources.",
            "status": "pending",
            "testStrategy": "Use Unity to simulate three connection attempts and assert only two succeed while the third receives the expected error response.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build TLV-driven session state machine",
            "description": "Implement IDLE→RECEIVING→VALIDATING→STORING states handling TLV frames and timeout enforcement.",
            "dependencies": [
              1,
              2
            ],
            "details": "Design a state machine that reads binary frames, validates TLV payloads, transitions across protocol states, and resets on timeout or validation failure while preserving resume logic.",
            "status": "pending",
            "testStrategy": "Mock httpd_ws_recv_frame delivering ordered and malformed TLVs to ensure state transitions and timeout handling follow ADR-002.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate reconnect backoff and error propagation",
            "description": "Add exponential backoff retry logic per client and route failures through error_handler.",
            "dependencies": [
              3
            ],
            "details": "Implement reconnect scheduling that escalates delays on repeated failures, invokes error_handler with ADR-002 codes, and restores sessions without leaking buffers or dangling timers.",
            "status": "pending",
            "testStrategy": "Simulate repeated disconnects to confirm increasing backoff intervals and verify error_handler captures each failure path.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Execute validation and throughput testing",
            "description": "Run automated checks covering buffer bounds, state transitions, and sustained data rates.",
            "dependencies": [
              3,
              4
            ],
            "details": "Develop Unity suites for buffer overflow prevention and state coverage, then run integration throughput checks driving 500KB/s payloads via idf.py monitor to observe heap and cache stability.",
            "status": "pending",
            "testStrategy": "Leverage existing Unity harness plus manual throughput script to confirm metrics and absence of heap growth during sustained transfers.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Outline subtasks for WebSocket upgrade handling with two-client limit, fixed-buffer management, TLV state machine implementation, reconnect/error propagation, and validation/testing including throughput checks.",
        "updatedAt": "2025-10-16T08:13:17.108Z"
      },
      {
        "id": 4,
        "title": "Implement TLV protocol parser and command dispatcher",
        "description": "Develop a protocol parser that validates TLV payloads, performs CRC checks, and dispatches commands to storage and playback subsystems.",
        "details": "Implementation:\n- Add `components/network/protocol_parser.c` with `protocol_parse_frame(const ws_frame_t*, protocol_context_t*)` that decodes `[TYPE][LEN][PAYLOAD][CRC]` per PRD, using `ws_validate_*` helpers from `prism_secure`.\n- Maintain upload context for PUT_BEGIN/DATA/END with CRC32 accumulation via `esp_rom_crc32`, ensuring 256KB size cap.\n- Map CONTROL commands to playback actions (play, pause, crossfade) and STATUS queries to telemetry assembly.\n- Provide callback hooks (`protocol_handlers_t`) so storage and playback modules register their handlers during init.\nPseudo-code:\n```\nswitch (type) {\n    case MSG_PUT_BEGIN: storage_begin_upload(payload);\n    case MSG_PUT_DATA: storage_write_chunk(offset, data, len);\n    case MSG_PUT_END: storage_finalize_upload(success_flag);\n    case MSG_CONTROL: playback_apply_command(command_id, params);\n}\n```\n- Ensure invalid sequences trigger error frames with codes 0x02/0x03.",
        "testStrategy": "Add parser unit tests feeding crafted frames to verify CRC rejection and size enforcement; run integration test with `idf.py unity` ensuring uploads stream into a mocked storage backend without fragmentation.",
        "priority": "medium",
        "dependencies": [
          "3"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement TLV frame validation and CRC checks",
            "description": "Add TLV parsing routine that validates headers, lengths, and CRC for inbound frames.",
            "dependencies": [],
            "details": "Create protocol_parse_frame to read TYPE/LEN/PAYLOAD/CRC, use ws_validate helpers, and accumulate CRC32 with esp_rom_crc32 while enforcing payload length limits.",
            "status": "pending",
            "testStrategy": "Write unit tests feeding malformed frames to confirm length and CRC failures return expected error codes 0x02 and 0x03.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Manage upload session state with size enforcement",
            "description": "Track PUT upload lifecycle and cap aggregated payload size at 256KB.",
            "dependencies": [
              1
            ],
            "details": "Maintain protocol_context_t fields for PUT_BEGIN/DATA/END, accumulate CRC across chunks, reject out-of-order frames, and abort sessions exceeding 256KB.",
            "status": "pending",
            "testStrategy": "Simulate segmented uploads in tests to verify CRC accumulation, overflow rejection, and invalid sequencing handling.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Wire storage command dispatch handlers",
            "description": "Forward storage-related protocol messages to registered storage callbacks.",
            "dependencies": [
              2
            ],
            "details": "Implement protocol_handlers_t registration and route MSG_PUT_* cases to storage_begin_upload, storage_write_chunk, and storage_finalize_upload with success flag resolution.",
            "status": "pending",
            "testStrategy": "Mock storage handlers in unit tests to assert correct invocation sequence and error handling when callbacks report failures.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate playback control and status dispatch",
            "description": "Handle CONTROL and STATUS frames by invoking playback callbacks and assembling telemetry responses.",
            "dependencies": [
              1
            ],
            "details": "Map MSG_CONTROL frames to playback_apply_command operations, translate payload params, and compose STATUS replies using telemetry helpers exposed via protocol_handlers_t.",
            "status": "pending",
            "testStrategy": "Add tests verifying playback command decoding, telemetry assembly, and error frame emission when handlers decline commands.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Build comprehensive parser test suite",
            "description": "Create unit and integration tests covering parser, storage, and playback interactions.",
            "dependencies": [
              3,
              4
            ],
            "details": "Extend Unity test harness with crafted TLV vectors, end-to-end upload simulations, and playback command scenarios to validate protocol_parser behavior across success and failure cases.",
            "status": "pending",
            "testStrategy": "Run Unity suite and integration flows ensuring PUT uploads reach mock storage, playback commands execute, and status queries return expected telemetry.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Create subtasks for frame validation/CRC logic, upload session management with size enforcement, command-to-storage mapping, playback control hookups, and comprehensive unit/integration tests.",
        "updatedAt": "2025-10-16T08:13:17.843Z"
      },
      {
        "id": 5,
        "title": "Integrate LittleFS storage and pattern persistence APIs",
        "description": "Mount the LittleFS partition, expose pattern CRUD operations, and enforce storage quotas and CRC verification per ADR-001/005.",
        "details": "Implementation:\n- In `components/storage/pattern_storage.c`, call `esp_vfs_littlefs_register` for partition `\"littlefs\"` at mount path `/littlefs`, fail fast if formatting needed.\n- Implement APIs: `storage_init()`, `pattern_storage_open`, `pattern_storage_write_chunk`, `pattern_storage_finalize` (with CRC32), `pattern_storage_list`, and quota checks to maintain 1.5MB limit minus safety margin.\n- Use shared palette files under `/littlefs/templates` and manage atomic writes via temp files and `rename`.\nPseudo-code:\n```\nesp_err_t storage_init(void) {\n    const esp_vfs_littlefs_conf_t conf = { .base_path = STORAGE_PATH, .partition_label = STORAGE_LABEL, ... };\n    ESP_ERROR_CHECK(esp_vfs_littlefs_register(&conf));\n    return storage_verify_templates();\n}\n```\n- Wire into protocol callbacks for PUT_* handling.",
        "testStrategy": "Add Unity tests using `esp_littlefs` host stub to simulate writes and CRC mismatches; run on device with power cycle to ensure remount succeeds and files persist; monitor heap via `prism_heap_monitor_dump_stats` after repeated uploads.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Mount LittleFS partition for pattern storage",
            "description": "Configure and verify the LittleFS partition mount used by pattern storage.",
            "dependencies": [],
            "details": "Define mount constants, call esp_vfs_littlefs_register for label \"littlefs\", ensure format-on-fail is disabled, and return an error if registration fails.\n<info added on 2025-10-15T18:06:58.881Z>\nPre-implementation analysis underway: inventorying all usages of the LittleFS partition offset so the shift from 0x320000 to 0x311000 per ADR-001 updates `firmware/partitions.csv`, build artifacts under `firmware/build/log/`, and any hardcoded mount descriptors without breaking alignment or overlapping OTA slots. Also auditing every reference to `PATTERN_MIN_COUNT` (currently defined in `firmware/components/core/include/prism_config.h`) to confirm dropping the baseline to 15 per ADR-006 stays compatible with quota math, CRC validations, and existing unit/integration tests before touching code.\n</info added on 2025-10-15T18:06:58.881Z>\n<info added on 2025-10-15T18:20:55.422Z>\nIntroduce a static FreeRTOS mutex to guard mount/unmount sequencing; fetch the LittleFS partition via esp_partition_find_first and validate its offset/size against ADR-001 before mounting; call esp_vfs_littlefs_register for label littlefs at /littlefs with format_if_mount_failed kept false; emit detailed ESP_LOGE entries for each failure path (partition lookup, validation, registration, directory creation) capturing esp_err_to_name codes; on success create /littlefs/templates with mkdir and treat any errno other than EEXIST as fatal; ensure every exit path releases the mutex and propagates the precise esp_err_t to callers.\n</info added on 2025-10-15T18:20:55.422Z>\n<info added on 2025-10-15T18:23:45.091Z>\nImplementation finalized: storage_init creates a static FreeRTOS mutex, validates the ADR-007 LittleFS partition (offset 0x320000, size 0x180000) via esp_partition_find_first, mounts at /littlefs with format_if_mount_failed=false, logs detailed ESP_LOGE errors for every failure path, emits partition statistics (total/used/free) each mount, triggers an 80 percent utilization warning, and ensures /littlefs/templates exists; storage_deinit now unmounts and frees resources cleanly. Updated pattern_storage.c to encapsulate this logic and CMakeLists.txt to link esp_partition and esp_littlefs. Pending action: run idf.py build in the ESP-IDF shell to verify the build.\n</info added on 2025-10-15T18:23:45.091Z>\n<info added on 2025-10-15T18:55:56.328Z>\nRecovery plan after losing uncommitted work: re-implement the LittleFS mount flow in storage_init/storage_deinit, rerun idf.py build plus mount verification, then stage and commit the restored files before touching task status; from now on never mark a subtask complete until its git commit exists.\n</info added on 2025-10-15T18:55:56.328Z>\n<info added on 2025-10-15T19:02:44.051Z>\nRecovered implementation finalized and committed in a9e860f: storage_init/storage_deinit mount littlefs at /littlefs per ADR-005, validate the ADR-007 partition offset 0x320000 with a 1.5MB span, auto-format on first boot, log filesystem metrics, and expand pattern_storage.c (122 lines) plus pattern_storage.h (71 lines) while updating idf_component.yml to joltwallet/littlefs ^1.14.8 and adjusting CMakeLists.txt dependencies. Build verification outstanding—Captain to run idf.py build in the ESP-IDF shell. Subtask ready to hand off to 5.2 for CRUD work.\n</info added on 2025-10-15T19:02:44.051Z>",
            "status": "done",
            "testStrategy": "Add a boot-time Unity test that mocks esp_vfs_littlefs_register outcomes to confirm failures propagate.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement pattern storage CRUD APIs with quotas and CRC",
            "description": "Create the core pattern storage APIs handling file lifecycle, quotas, and data integrity checks.",
            "dependencies": [
              1
            ],
            "details": "Implement storage_init, pattern_storage_open, pattern_storage_write_chunk, pattern_storage_finalize, and pattern_storage_list using LittleFS handles, enforce 1.5MB minus safety margin, and compute CRC32 before finalizing writes.\n<info added on 2025-10-15T18:34:26.575Z>\nCompleted LittleFS CRUD module in `components/storage/pattern_storage_crud.c`, providing open/write/finalize/close/read/list/delete/stat APIs with temp-file atomicity, per-write quota checks (1.5MB minus 100KB per ADR-004), hardware-accelerated CRC32 validation, and mutex-guarded operations; added helper routines for ID/path validation and directory bootstrap, plus corresponding declarations/build entries in `pattern_storage.h` and `CMakeLists.txt`, ready for build verification.\n</info added on 2025-10-15T18:34:26.575Z>\n<info added on 2025-10-15T19:05:16.566Z>\nRecovered implementation reinstates pattern_storage_crud.c with storage_pattern_create enforcing 100 KB per pattern and a 25-pattern ceiling, storage_pattern_read validating buffers, storage_pattern_delete removing orphaned files, storage_pattern_list skipping dot entries, and storage_pattern_count reporting totals; pattern_storage.h now provides documented declarations and CMakeLists.txt builds the module. Error handling returns ESP_ERR_INVALID_ARG for null inputs, ESP_ERR_INVALID_SIZE when payloads or buffers exceed limits, ESP_ERR_NO_MEM once the 25 pattern quota is exhausted, and ESP_ERR_NOT_FOUND for missing files. Patterns persist under /littlefs/patterns/ as <pattern_id>.bin with automatic directory creation and ADR-006 bounds enforced. Changes are captured in commit 8f7e2fb and require idf.py build verification before handing off to subtask 5.3.\n</info added on 2025-10-15T19:05:16.566Z>",
            "status": "done",
            "testStrategy": "Use host-based Unity tests to simulate uploads, verify quota enforcement, and exercise CRC mismatch paths.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Handle template assets and atomic write flow",
            "description": "Manage shared template files and ensure atomic persistence semantics for pattern updates.",
            "dependencies": [
              2
            ],
            "details": "Load palette and template data from /littlefs/templates, stage writes into temporary files, perform fsync, and atomically replace targets via rename while cleaning up remnants on error.\n<info added on 2025-10-15T18:38:41.115Z>\nAdd declarations for template read/write/list utilities in pattern_storage.h and implement template_storage_write, template_storage_read, and template_storage_list so palette/template assets under /littlefs/templates use the existing temp-file + fsync + rename flow, guaranteeing temporary artifacts are removed on error paths.\n</info added on 2025-10-15T18:38:41.115Z>\n<info added on 2025-10-15T19:11:38.657Z>\nImplementation underway: add template_storage_write/template_storage_read/template_storage_list declarations to pattern_storage.h and define them in pattern_storage_crud.c so /littlefs/templates assets use the <name>.tmp staging file, call fsync before rename, and unlink any temporary artifacts on failure to keep palette/template data consistent.\n</info added on 2025-10-15T19:11:38.657Z>\n<info added on 2025-10-15T19:13:44.205Z>\nImplemented template_storage_write/read/list/delete in pattern_storage_crud.c with declarations in pattern_storage.h; template_storage_write stages writes through <name>.tmp, flushes, fsyncs via fileno, and atomically renames while every failure path unlinks temps; list skips .tmp files, delete removes residual temps and targets while auto-creating /littlefs/templates; all error exits return ESP_ERR_INVALID_ARG, ESP_ERR_NO_MEM, ESP_ERR_NOT_FOUND, ESP_ERR_INVALID_SIZE, or ESP_FAIL with cleanup; work committed in 0d9998c and the API is ready for 5.4 integration once the Task 3 WebSocket dependency lands.\n</info added on 2025-10-15T19:13:44.205Z>",
            "status": "done",
            "testStrategy": "Extend unit tests to confirm template reads succeed and that interrupted writes leave no partial files.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate storage APIs with protocol callbacks",
            "description": "Wire the new storage functions into protocol upload and control handlers.",
            "dependencies": [
              2,
              3
            ],
            "details": "Update protocol PUT_* handling to call the storage APIs, maintain upload session state, surface storage errors, and ensure quota or CRC failures translate into protocol error responses.\n<info added on 2025-10-15T19:26:00.332Z>\nIntegration plan: create a storage protocol integration layer under components/storage/ with dispatch helpers; add WebSocket command handler stubs and wire storage create/read/delete calls into the protocol callbacks; implement upload session state tracking and map quota/CRC/storage failures to protocol error responses; expose a public API callable from the WebSocket layer; update network_manager.c:1238 to replace the TLV dispatcher TODO with storage_protocol_dispatch(). Starting implementation.\n</info added on 2025-10-15T19:26:00.332Z>\n<info added on 2025-10-15T19:30:25.068Z>\nImplemented storage_protocol.c integration layer with storage_protocol_dispatch handling TLV commands 0x10 PUT_BEGIN, 0x11 PUT_CHUNK, 0x12 PUT_END, 0x20 DELETE, and 0x21 LIST, including TLV frame validation, upload session tracking keyed by pattern_id, and mapping ESP_ERR_* values to protocol error codes 0x01-0x05 with STATUS 0x30 and ERROR 0x40 responses. Added storage_protocol_is_upload_active and storage_protocol_abort_upload helpers, replaced the TLV dispatcher TODO at network_manager.c:1238 with storage_protocol_dispatch, and confirmed the protocol layer is ready for WebSocket integration. Changes committed in b7e6dc8.\n</info added on 2025-10-15T19:30:25.068Z>",
            "status": "done",
            "testStrategy": "Add integration-level tests using mocked protocol frames to verify successful uploads and error propagation.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Execute persistence validation and endurance tests",
            "description": "Plan and run verification covering filesystem persistence, power cycling, and memory usage.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Run Unity tests with esp_littlefs host stub, perform on-device upload cycles with power resets to confirm remount and data persistence, and capture heap metrics after repeated transfers.",
            "status": "pending",
            "testStrategy": "Document and execute the endurance runbook, capturing results and logs for regression tracking.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Split into subtasks covering LittleFS mount/config, CRUD API implementations with quotas/CRC, template file handling and atomic updates, protocol integration points, and test strategy execution.",
        "updatedAt": "2025-10-16T08:13:18.621Z"
      },
      {
        "id": 6,
        "title": "Create .prism pattern format parser and metadata validation",
        "description": "Implement parsing and validation for the 1KB header, shared palettes, and delta-encoded payloads to guarantee instant access and structural efficiency.",
        "details": "Implementation:\n- Introduce `components/storage/pattern_format.c` with `pattern_format_parse(const uint8_t* header, size_t header_len, pattern_descriptor_t* out)` enforcing limits: version 0x01, <=256KB payload, valid palette references.\n- Decode metadata fields (name, category, parameters) using `safe_memcpy` and guard lengths; implement delta decode routines that can stream into cache without extra heap allocations.\n- Provide functions to serialize metadata for STATUS responses and to validate template headers during boot.\nPseudo-code:\n```\nesp_err_t pattern_format_parse(...) {\n    if (header_len != 1024) return ESP_ERR_INVALID_SIZE;\n    parse_fixed_header();\n    parse_palette_table();\n    parse_parameter_blocks();\n}\n```\n- Document struct definitions in `pattern_format.h` for re-use by playback engine.",
        "testStrategy": "Create offline tests feeding golden `.prism` headers to verify parsing correctness; fuzz header parser via Unity with random data ensuring graceful failures; benchmark parsing time to confirm <5ms per pattern using `esp_timer_get_time`.",
        "priority": "medium",
        "dependencies": [
          "5"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement 1KB header parser with strict validation",
            "description": "Create parsing logic that verifies the 1024-byte header, version tag, and payload size caps before populating pattern descriptors.",
            "dependencies": [],
            "details": "Add pattern_format_parse skeleton in components/storage/pattern_format.c that checks header_len, version byte equals 0x01, payload length <= 256KB, and records offsets for later decoding using safe_memcpy.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Decode palette table and metadata fields safely",
            "description": "Parse shared palette references and metadata strings while preventing buffer overruns and invalid indices.",
            "dependencies": [
              1
            ],
            "details": "Extend parser to walk palette table entries, confirm indices within shared palette limits, and decode name/category/parameter blocks with safe_memcpy plus length guards defined in pattern_format.h.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement streaming delta payload decoder routines",
            "description": "Build delta decoding helpers that can stream pattern payloads directly into cache without heap allocations.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create functions that process delta-encoded sections sequentially, reuse small stack buffers, validate segment boundaries, and expose streaming callbacks for the playback engine integration.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add parser regression tests and fuzz harness",
            "description": "Develop automated coverage to validate nominal parsing, edge cases, and failure behavior for malformed headers.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Set up Unity-based golden header tests, random input fuzz seeds, and timing checks ensuring parsing completes under 5ms while asserting deliberate error codes on corrupt data.",
            "status": "pending",
            "testStrategy": "Unity golden-header suite plus fuzz harness injecting random headers to confirm graceful failures and timing assertions.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Break down work for parsing the fixed 1KB header, validating palette tables and metadata bounds, implementing streaming delta decode helpers, adding STATUS/boot-time serialization utilities, and building regression/fuzz/benchmark coverage.",
        "updatedAt": "2025-10-16T15:11:26.996Z"
      },
      {
        "id": 7,
        "title": "Implement RAM hot cache with LRU eviction and preloading",
        "description": "Manage in-memory pattern cache (3-5 entries) to guarantee <100ms switching while respecting the 150KB heap budget.",
        "details": "Implementation:\n- Add `components/storage/cache_manager.c` exposing `cache_init(max_entries)`, `cache_preload(category_defaults)`, `cache_get(pattern_id)`, using memory pools for buffer allocations.\n- Track entries with LRU metadata and preload popular templates at boot; integrate with pattern storage to load headers/payloads once and share palette blocks across cached items.\n- Hook cache lookups into playback control path so template switches reference cached buffers.\nPseudo-code:\n```\ncache_entry_t* cache_get(const char* pattern_id) {\n    entry = lru_find(pattern_id);\n    if (!entry) {\n        entry = cache_load_from_storage(pattern_id);\n    }\n    return entry;\n}\n```\n- Provide metrics to WebSocket STATUS frames (cached count, misses).\n",
        "testStrategy": "Add unit tests that simulate repeated pattern requests to assert LRU eviction order; run long-duration soak test (simulate 24h pattern cycling) while monitoring heap fragmentation via `heap_caps_check_integrity_all` and ensure cache hit rate meets targets.",
        "priority": "medium",
        "dependencies": [
          "5",
          "6"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define cache manager structures and memory pools",
            "description": "Create the cache manager module skeleton with structs for entries, memory pools, and public API in cache_manager.c/.h.",
            "dependencies": [],
            "details": "Set up cache metadata structs, memory pool initialization for 3-5 entries within 150KB, and stub the cache_init/cache_get/cache_preload functions with TODO markers.",
            "status": "pending",
            "testStrategy": "Add initial unit tests that instantiate the cache and confirm pool allocation within budget.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement preload workflow tied to pattern storage",
            "description": "Wire cache_preload to load category defaults from storage templates into shared buffers at boot.",
            "dependencies": [
              1
            ],
            "details": "Use pattern storage APIs to fetch headers/payloads, reuse palette blocks, and ensure preload respects pool limits while flagging loaded entries.",
            "status": "pending",
            "testStrategy": "Write unit tests mocking storage calls to ensure preload populates expected entries and handles storage failures.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Finalize LRU eviction and playback integration",
            "description": "Complete cache_get logic with LRU tracking and connect playback control path to cached buffers.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement LRU queue updates, eviction when pools are full, and hook playback code paths to request entries via cache_get and handle cache misses.",
            "status": "pending",
            "testStrategy": "Create simulated playback sequence tests verifying eviction order, miss handling, and <100ms access via timing mocks.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Expose cache metrics to WebSocket status frames",
            "description": "Add instrumentation reporting cache counts, hits, and misses through existing telemetry channels.",
            "dependencies": [
              3
            ],
            "details": "Track counters inside cache manager, extend status frame assembly to include cache metrics, and ensure thread-safe reads.",
            "status": "pending",
            "testStrategy": "Extend telemetry unit tests to validate metrics payload fields and values after cache operations.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Execute stress and soak testing scenarios",
            "description": "Design and run stress scenarios that validate cache stability, memory integrity, and performance targets.",
            "dependencies": [
              3,
              4
            ],
            "details": "Script 24-hour pattern cycling with varied patterns, check heap integrity via heap_caps_check_integrity_all, and log cache hit/miss ratios.",
            "status": "pending",
            "testStrategy": "Automate soak test harness that verifies integrity checks pass and hit rate maintains required threshold.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Plan subtasks for defining cache data structures and pools, wiring preload against pattern storage, implementing cache_get with LRU eviction, integrating playback lookups, exposing metrics/status reporting, and executing soak/perf testing.",
        "updatedAt": "2025-10-16T16:33:42.847Z"
      },
      {
        "id": 8,
        "title": "Develop RMT-based LED driver with double buffering",
        "description": "Implement a playback driver that streams frames to 320 WS2812B LEDs at 60 FPS using double-buffered DMA-friendly memory.",
        "details": "Implementation:\n- In `components/playback/led_driver.c`, configure RMT TX channel (`rmt_new_tx_channel`) with 3.2MHz clock and install WS2812 encoder (ESP-IDF LED strip driver) or custom translator to meet timing.\n- Allocate two frame buffers via `heap_caps_malloc(MALLOC_CAP_DMA)` and expose APIs `led_driver_submit_frame(const uint8_t* frame)` and `led_driver_swap_buffers()`.\n- Use hardware timer or animation scheduler to trigger frame swaps while ensuring ISR-safe operations.\nPseudo-code:\n```\nstatic void led_refresh_task(void* arg) {\n    while (1) {\n        rmt_transmit(channel, encoder, front_buffer, frame_len, &tx_config);\n        xSemaphoreTake(frame_ready_sem, pdMS_TO_TICKS(frame_period));\n        swap_buffers();\n    }\n}\n```\n- Implement diagnostics for underruns and log if frame time exceeds 16.6ms.",
        "testStrategy": "Create hardware-in-the-loop test sending gradient frames and verifying with logic analyzer that timing meets WS2812 spec; add simulated unit tests using IDF RMT mock to ensure buffer swaps occur within deadline; monitor CPU utilization via `esp_pm_lock_type` metrics.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure RMT channel and WS2812 encoder",
            "description": "Set up the RMT TX peripheral to meet WS2812 timing requirements.",
            "dependencies": [],
            "details": "Configure `rmt_new_tx_channel` at 3.2MHz, install WS2812 encoder or custom translator, and tune timing constants for 320 LEDs.",
            "status": "done",
            "testStrategy": "Unit-test encoder configuration with IDF RMT mock to verify timing parameters.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement DMA-capable double-frame buffers",
            "description": "Create double-buffered LED frame storage using DMA-capable memory.",
            "dependencies": [
              1
            ],
            "details": "Allocate two frame buffers with `heap_caps_malloc(MALLOC_CAP_DMA)`, manage ownership, and ensure alignment for RMT transfers.",
            "status": "done",
            "testStrategy": "Add allocation tests ensuring buffers meet DMA capabilities and verify swap readiness logic in isolation.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Design frame submission and swap APIs",
            "description": "Expose APIs for frame submission and buffer swapping.",
            "dependencies": [
              2
            ],
            "details": "Implement `led_driver_submit_frame` to copy new frames into the back buffer and `led_driver_swap_buffers` to rotate buffers safely.",
            "status": "done",
            "testStrategy": "Mock submit/swap calls to confirm data integrity and buffer state transitions without RMT involvement.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate timing control and ISR-safe workflow",
            "description": "Coordinate frame transmission timing and ISR-safe synchronization.",
            "dependencies": [
              3
            ],
            "details": "Use hardware timer or scheduler to trigger `rmt_transmit`, manage semaphores for frame readiness, and ensure swaps occur within ISR constraints.",
            "status": "done",
            "testStrategy": "Create FreeRTOS timer tests simulating 60 FPS cadence to verify semaphore timing and ISR-safe operations.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add underrun diagnostics and validation tests",
            "description": "Implement runtime diagnostics and verification for frame timing.",
            "dependencies": [
              4
            ],
            "details": "Log underruns when frame time exceeds 16.6ms, expose metrics, and validate behavior via hardware-in-the-loop and simulated tests.",
            "status": "done",
            "testStrategy": "Run HIL gradient playback with logic analyzer plus simulated tests checking logged diagnostics and timing thresholds.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Break down into subtasks for RMT channel/config setup, DMA-capable double-buffer management, frame submission/swap API design, timing/ISR coordination, and validation via hardware and simulated tests."
      },
      {
        "id": 9,
        "title": "Build effect engine with parameter interpolation and crossfade scheduler",
        "description": "Translate parsed pattern instructions into frame buffers with smooth parameter transitions and <100ms switch latency.",
        "details": "Implementation:\n- Implement `components/playback/effect_engine.c` to interpret pattern descriptors, generate frame deltas, and manage crossfades between patterns using eased interpolation (e.g., cubic). Maintain per-pattern state machines.\n- Add `animation_timer.c` to configure a 60 FPS hardware timer (`esp_timer_create_periodic`) that triggers rendering pipelines and interacts with the LED driver.\n- Provide APIs `effect_engine_play(pattern_descriptor_t*, playback_params_t*)`, `effect_engine_set_parameters(...)`, `effect_engine_update()` invoked by the timer callback.\nPseudo-code:\n```\nstatic void animation_tick(void* arg) {\n    blend_progress = compute_easing(step++);\n    generate_frame(active_pattern, blend_progress, scratch_buffer);\n    led_driver_submit_frame(scratch_buffer);\n}\n```\n- Ensure CPU usage stays <50% by profiling loops and using fixed-point math where feasible.",
        "testStrategy": "Create bench tests that render synthetic patterns and measure frame time with `esp_timer_get_time`; validate crossfades by sampling LED buffer outputs; run integration test by issuing CONTROL messages triggering parameter ramps and confirming transitions remain smooth.",
        "priority": "medium",
        "dependencies": [
          "6",
          "7",
          "8"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define effect engine architecture and state flow",
            "description": "Design the effect engine module structure, state machines, and data contracts for pattern playback.",
            "dependencies": [],
            "details": "Outline structs for pattern descriptors, per-pattern state, and frame buffers; document state transitions and public API contracts matching playback requirements.\n<info added on 2025-10-16T16:35:41.863Z>\nScaffold complete: effect engine added at firmware/components/playback/effect_engine.c with brightness ramp + interpolation and exported via firmware/components/playback/include/effect_engine.h; component is linked in firmware/components/playback/CMakeLists.txt.\n\nNext actions (API coverage + pipeline integration):\n- Add generic interpolators in effect_engine.h/effect_engine.c: effect_param8_t and effect_param16_t with fields current,start,target,elapsed_ms,duration_ms,active and functions effect_param8_init, effect_param8_set_target, effect_param8_tick(elapsed_ms), effect_param8_value (same for 16-bit). Add effect_ease_t enum (start with EFFECT_EASE_LINEAR; leave hooks for cubic).\n- Refactor brightness wrapper to use effect_param8_t internally so future params reuse the same tick path.\n- Integrate engine into playback loop:\n  - Include effect_engine in firmware/components/playback/led_playback.c and call effect_engine_init() in playback_init().\n  - In playback_task(), track elapsed using esp_timer_get_time() (static last_tick_us) and call effect_engine_tick(elapsed_ms) once per frame.\n  - After temporal CH2 computation and before led_driver_submit_frames(), apply chain to both channels: effect_chain_apply(frame_ch1, LED_COUNT_PER_CH) and effect_chain_apply(frame_ch2, LED_COUNT_PER_CH).\n- Provide a thin playback-facing hook for runtime ramps: playback_set_brightness(uint8_t target, uint32_t ms) → effect_brightness_set_target(), so control/CLI can trigger transitions without touching engine internals.\n- Crossfade core (MVP plan): introduce a crossfade state in led_playback.c (active,duration_ms,elapsed_ms,param alpha via effect_param8_t). When transitioning, render “current” and “next” patterns into two local buffers per channel, blend per-pixel using alpha (0–255), then run effect_chain_apply on the blended frames. After duration, switch primary state to “next” and clear crossfade. This keeps scheduling in playback while reusing the engine’s interpolation.\n</info added on 2025-10-16T16:35:41.863Z>",
            "status": "pending",
            "testStrategy": "Review design doc with team and validate state diagrams against PRD scenarios",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement pattern interpretation and crossfade core",
            "description": "Code the effect engine logic to interpret descriptors, run state machines, and compute eased crossfades.",
            "dependencies": [
              1
            ],
            "details": "Implement frame delta generation, easing curve calculation, and state transitions in `components/playback/effect_engine.c`, ensuring parameter interpolation hooks are present.",
            "status": "pending",
            "testStrategy": "Add unit tests for easing curves and state transitions using synthetic descriptors",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build 60 FPS animation timer and update loop",
            "description": "Create the animation timer module to drive effect updates and call the engine each frame.",
            "dependencies": [
              1,
              2
            ],
            "details": "Develop `animation_timer.c` using `esp_timer_create_periodic` at 60 FPS, wiring callbacks to `effect_engine_update()` and handling timer lifecycle APIs.",
            "status": "pending",
            "testStrategy": "Write timer mock tests verifying 60 FPS cadence and correct invocation of engine hooks",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate LED driver and cache handoff",
            "description": "Connect the effect engine output with LED driver submission and RAM cache fetch paths.",
            "dependencies": [
              2,
              3
            ],
            "details": "Implement buffer handoff to `led_driver_submit_frame`, ensure cache lookups provide pattern data, and manage scratch buffer reuse with minimal allocations.",
            "status": "pending",
            "testStrategy": "Create integration test stubs that simulate cache hits/misses and assert driver submissions receive expected buffers",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Optimize and profile effect engine performance",
            "description": "Profile the engine loop and apply optimizations to meet CPU budget and latency constraints.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Instrument timing with `esp_timer_get_time`, convert hot paths to fixed-point math, and verify CPU usage remains under 50 percent with representative patterns.",
            "status": "pending",
            "testStrategy": "Add profiling harness measuring frame computation time and CPU load under mixed pattern workloads",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Develop bench and integration testing suite",
            "description": "Assemble bench tests and end-to-end integration validations for the effect engine.",
            "dependencies": [
              2,
              3,
              4,
              5
            ],
            "details": "Implement synthetic pattern benches, parameter ramp tests, and crossfade validation scripts ensuring smooth transitions and <100ms switch latency.",
            "status": "pending",
            "testStrategy": "Run automated bench tests plus hardware-in-loop scenarios sampling LED outputs and verifying timing metrics",
            "parentId": "undefined"
          }
        ],
        "complexity": 9,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Segment tasks across engine architecture design, descriptor interpretation and state machines, eased crossfade generation, 60 FPS timer loop, LED driver/cache handoff, performance profiling, and automated bench/integration testing.",
        "updatedAt": "2025-10-16T16:47:56.480Z"
      },
      {
        "id": 10,
        "title": "Deliver template system with 15 categorized patterns and deployment flow",
        "description": "Ship built-in templates (Ambient, Energy, Special), preload them on first boot, and expose metadata for one-click deployment via WebSocket.",
        "details": "Implementation:\n- Populate `components/templates/template_patterns.c` with 15 template descriptors referencing shared palette data and precomputed parameter curves; ensure total storage fits 1.5MB partition.\n- Implement `template_loader.c` to copy templates into LittleFS on first boot (if absent), register metadata (name, preview hash, category) with cache manager, and provide APIs `templates_init()`, `templates_list(category)`, `templates_deploy(id)`.\n- Integrate with protocol dispatcher so CONTROL commands trigger deployments and with cache to guarantee templates are cached at boot.\nPseudo-code:\n```\nesp_err_t templates_init(void) {\n    for each template_def in builtin_templates {\n        if (!storage_exists(template_def.id)) {\n            storage_write_template(template_def);\n        }\n        cache_preload(template_def.id);\n    }\n    return ESP_OK;\n}\n```\n- Update STATUS payloads to include template metadata snapshots for clients.",
        "testStrategy": "Add unit tests verifying template install idempotency and category counts (5 each); flash firmware and confirm first boot copies occur within 60s; use WebSocket CONTROL `deploy` to measure <2s deployment and <100ms playback switch via logs.",
        "priority": "medium",
        "dependencies": [
          "5",
          "6",
          "7",
          "9"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define built-in template descriptors",
            "description": "Create the 15 categorized template descriptors with shared palette and curve references in template_patterns.c.",
            "dependencies": [],
            "details": "Author Ambient, Energy, and Special template structs referencing shared palette data and precomputed parameter curves while verifying the combined binary payload fits within the 1.5MB partition budget.\n<info added on 2025-10-16T16:51:04.572Z>\nScaffold template_manager to provision 15 presets at first boot and add a console CLI to list them.\n\nImplementation notes:\n- Provisioning logic: implement firmware/components/templates/template_manager.c:11 to enumerate current template count via template_storage_list (see firmware/components/storage/include/pattern_storage.h:186). If fewer than 15 found, iterate a static catalog and write each preset with template_storage_write (firmware/components/storage/include/pattern_storage.h:157). Log success and totals; warn if storage_get_space indicates insufficient headroom against 1.5MB (firmware/components/storage/pattern_storage.c:21,57 and storage_get_space at firmware/components/storage/include/pattern_storage.h:206). Keep templates_task loop, but add a one-shot guard to avoid repeated provisioning.\n- Catalog source: add a descriptor table in firmware/components/templates/template_patterns.c (Task 10.1) exporting const descriptor entries with fields: id, category, size, and a pointer to embedded .prism bytes or a generator callback. Expose accessor const template_desc_t* template_catalog_get(size_t* out_count). Update firmware/components/templates/CMakeLists.txt to include template_patterns.c after 10.1 lands.\n- CLI: register a console command prism_templates inside template_manager.c, mirroring the esp_console pattern used in firmware/components/playback/led_playback.c:323–332. Command impl will:\n  - Call template_storage_list to gather names.\n  - For each template, read first 80 bytes with template_storage_read (firmware/components/storage/include/pattern_storage.h:173) and parse header using parse_prism_header (firmware/components/storage/include/prism_parser.h) to print base.led_count, base.frame_count, base.fps and meta.sync_mode/meta.motion_direction. Fallback to name-only if parse fails.\n  - Print a summary line with total count.\n  Invoke CLI registration from templates_init so the command is available after boot. Main already wires templates_init and templates_task (firmware/main/main.c:172,194).\n- Canvas metadata and temporal examples: ensure each catalog entry’s binary includes a v1.1 header (prism_header_v11_t in firmware/components/storage/include/prism_parser.h) with base.led_count=160, base.frame_count=144, base.fps=24. Populate meta fields per prism_motion.h and prism_temporal_ctx.h:\n  - SYNC: meta.sync_mode=PRISM_SYNC_SYNC, meta.motion_direction as appropriate.\n  - OFFSET: meta.sync_mode=PRISM_SYNC_OFFSET, meta.params.delay_ms=120.\n  - PROGRESSIVE: meta.sync_mode=PRISM_SYNC_PROGRESSIVE, meta.params.progressive_start_ms=0, meta.params.progressive_end_ms=200.\n  - WAVE: meta.sync_mode=PRISM_SYNC_WAVE, meta.params.wave_amplitude_ms=90, meta.params.wave_frequency_hz=1, meta.params.wave_phase_deg=45.\n  - CUSTOM: meta.sync_mode=PRISM_SYNC_CUSTOM; payload must carry a 160-entry delay map (320 bytes) that aligns with prism_temporal_ctx_t.delay_table usage (firmware/components/core/include/prism_temporal_ctx.h:27).\n- Budget enforcement: before writing, compute cumulative catalog size and assert it remains under EXPECTED_PARTITION_SIZE (firmware/components/storage/pattern_storage.c:24,57). If over budget, skip lowest-priority entries and log an actionable warning.\n\nNext step: finalize template_patterns.c with 15 descriptors and embed the Canvas metadata plus the five temporal example variants per above, then re-run prism_templates to validate header parsing output.\n</info added on 2025-10-16T16:51:04.572Z>",
            "status": "pending",
            "testStrategy": "Add static asserts or unit tests verifying descriptor counts per category and aggregate storage footprint under 1.5MB.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement first-boot template provisioning",
            "description": "Build template_loader.c routines to seed LittleFS with built-in templates when missing.",
            "dependencies": [
              1
            ],
            "details": "Write logic to detect absent templates on initial boot, copy compiled descriptors into LittleFS, and ensure idempotent storage writes using existing pattern storage APIs for reliability.",
            "status": "pending",
            "testStrategy": "Create integration-style tests stubbing LittleFS to confirm first boot populates files once and subsequent boots skip rewrites.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Register template metadata and cache preload",
            "description": "Integrate metadata cataloging and cache warming after templates are provisioned.",
            "dependencies": [
              2
            ],
            "details": "Expose templates_init/list/deploy APIs that register name, preview hash, and category with the cache manager and trigger cache_preload calls for all templates during initialization.",
            "status": "pending",
            "testStrategy": "Extend unit tests to assert metadata registry contents and that cache_preload executes for every template id after initialization.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Wire deployment flow through protocol dispatcher",
            "description": "Connect CONTROL/WebSocket commands to template deployment routines and update STATUS payloads.",
            "dependencies": [
              3
            ],
            "details": "Update protocol dispatcher handlers to call templates_deploy on CONTROL commands, stream deployment notifications over WebSocket, and embed template metadata snapshots in STATUS payloads for client discovery.",
            "status": "pending",
            "testStrategy": "Use protocol dispatcher tests that simulate CONTROL deploy commands and verify WebSocket/status messages reflect the selected template id and metadata.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Validate storage size and deployment performance",
            "description": "Measure template storage usage and runtime deployment behavior against targets.",
            "dependencies": [
              4
            ],
            "details": "Instrument measurements ensuring total template data stays under 1.5MB, first-boot provisioning completes within 60 seconds, and WebSocket deployments achieve <2s launch with <100ms playback switch via logs.",
            "status": "pending",
            "testStrategy": "Run on-device tests capturing provisioning timestamps and deployment latency while asserting log-derived metrics meet storage and performance thresholds.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Outline subtasks for authoring template descriptors, provisioning them on first boot, registering metadata and cache warm-up, wiring CONTROL/STATUS protocol integration, adding metrics/performance validation, and verifying storage/latency targets.",
        "updatedAt": "2025-10-16T17:47:44.416Z"
      },
      {
        "id": 11,
        "title": "Create Motion & Sync Enumerations and Temporal Interfaces",
        "description": "Establish the core enums, data structures, and public APIs for motion and sync modes required by the temporal sequencing system.",
        "details": "Files: firmware/components/playback/include/prism_motion.h.\nSteps:\n1. Define `typedef enum` values for `motion_direction_t` {LEFT, RIGHT, CENTER, EDGE, STATIC} and `sync_mode_t` {SYNC, OFFSET, PROGRESSIVE, WAVE, CUSTOM} per ADR-010.\n2. Introduce structs:\n   - `sync_params_t { uint16_t delay_ms; uint16_t progressive_start_ms; uint16_t progressive_end_ms; uint16_t wave_amplitude_ms; uint16_t wave_frequency_hz; uint16_t wave_phase_deg; }`.\n   - `prism_temporal_ctx_t { uint16_t frame_index; const prism_pattern_t *pattern; const sync_params_t *params; }`.\n3. Declare `void prism_motion_init(prism_temporal_ctx_t *ctx);` and `void calculate_ch2_frame(prism_temporal_ctx_t *ctx, uint16_t *ch1_frame, uint16_t *ch2_frame, size_t led_count, TickType_t tick_now);`.\nPseudo-code:\n```\ntypedef struct {\n    motion_direction_t motion;\n    sync_mode_t sync_mode;\n    sync_params_t sync_params;\n} prism_temporal_header_t;\n```\n4. Document API expectations (static allocations, 160 LEDs, 320-byte buffers).\n5. Export constants for timing budgets (e.g., `#define PRISM_LGP_LED_COUNT 160`).",
        "testStrategy": "Author unit test skeleton in test_prism_temporal.c verifying enums map to expected integer values and header structs align with protocol requirements via `sizeof` static assertions.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add prism_motion_t enum and validation macro",
            "description": "Define the motion direction enum alongside its validation helper in the shared playback header.",
            "dependencies": [],
            "details": "Update firmware/components/playback/include/led_playback.h to declare typedef enum prism_motion_t with STATIC=0, LEFT, RIGHT, CENTER, EDGE and add IS_VALID_MOTION macro consistent with ADR-010 direction table.",
            "status": "pending",
            "testStrategy": "Confirm firmware headers compile cleanly by running the existing playback target build or lint step.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Create prism_sync_mode_t enum with validation macro",
            "description": "Introduce sync mode enumeration definitions and validation macro in the playback include file.",
            "dependencies": [
              1
            ],
            "details": "Extend firmware/components/playback/include/led_playback.h with typedef enum prism_sync_mode_t starting at SYNC=0 followed by OFFSET, PROGRESSIVE, WAVE, CUSTOM and implement IS_VALID_SYNC macro mirroring ADR-010 sync specifications.",
            "status": "pending",
            "testStrategy": "Rebuild the playback component to ensure new enum and macro integrate without compiler diagnostics.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add temporal enum validation unit tests",
            "description": "Author unit tests covering enum ordinal values and macro validation behavior.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create firmware/components/tests/test_temporal_enums.c Unity cases asserting motion/sync enum integer values, static_assert bounds, and that IS_VALID_MOTION/IS_VALID_SYNC accept valid constants while rejecting out-of-range inputs.",
            "status": "pending",
            "testStrategy": "Run the Unity test target (e.g., idf.py test playback) to verify the new temporal enum tests execute and pass.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Define motion and sync enums with validation",
            "description": "Create the new prism_motion.h header declaring motion and sync enumerations required per ADR-010.",
            "dependencies": [],
            "details": "Author typedef enums for motion_direction_t and sync_mode_t with five modes plus *_COUNT sentinels, add PRISM_MOTION_IS_VALID-style validation macros, and include static_assert checks for enum widths.",
            "status": "pending",
            "testStrategy": "Add compile-time static_assert checks and a Unity enum-value test skeleton in test_prism_temporal.c verifying ordinal mapping.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add temporal context structs and ownership docs",
            "description": "Implement the shared temporal context and sync parameter structs that consume the new enums.",
            "dependencies": [
              4
            ],
            "details": "Define sync_params_t and prism_temporal_ctx_t with uint16_t fields, include delay_table pointer wiring, and document ownership/lifetime expectations for pattern and params references in the public header.",
            "status": "pending",
            "testStrategy": "Extend test_prism_temporal.c to assert sizeof/layout expectations and validate null/const assumptions in doc comments.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Introduce pattern metadata header aligned with new enums",
            "description": "Create auxiliary pattern_metadata.h to hold packed metadata that leverages the motion/sync enums and parameters.",
            "dependencies": [
              4,
              5
            ],
            "details": "Define prism_pattern_meta_v11_t as a packed struct containing version, motion_direction_t, sync_mode_t, sync_params_t, and CRC fields, integrating with pattern_storage.h contract and documenting serialization expectations.",
            "status": "pending",
            "testStrategy": "Plan alignment and CRC integration checks via sizeof/static_assert coverage and future pattern_storage parsing tests.",
            "parentId": "undefined"
          }
        ],
        "complexity": 3,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down the work into defining enums, declaring shared structs/context headers, and documenting/testing the new public API expectations for motion and sync interfaces.",
        "updatedAt": "2025-10-16T08:45:10.524Z"
      },
      {
        "id": 12,
        "title": "Implement SYNC and OFFSET Temporal Sequencing",
        "description": "Develop the initial calculate_ch2_frame() logic supporting SYNC and OFFSET modes with timing guarantees.",
        "details": "Files: firmware/components/playback/prism_temporal.c.\nSteps:\n1. Implement `prism_motion_init` to zero context and validate pointers.\n2. Implement `calculate_ch2_frame` with early exit for SYNC copying `memcpy(ch2_frame, ch1_frame, led_count * sizeof(*ch1_frame));`.\n3. For OFFSET mode, compute delay buckets:\n```\nstatic inline uint16_t apply_offset(uint16_t base_value, uint16_t delay_ms, uint32_t frame_time_ms){\n    if(frame_time_ms < delay_ms) return 0;\n    return base_value; // simple first-pass all-or-nothing\n}\n```\n4. Use FreeRTOS `xTaskGetTickCount()` passed in to maintain 120 FPS budget; convert delays using `esp_timer_get_time()` if tick resolution insufficient.\n5. Cache previous frame timestamp in static context to maintain 3.38 ms CPU budget (avoid expensive math).\n6. Instrument microsecond timings with `esp_timer_get_time()` under `CONFIG_PRISM_PROFILE_TEMPORAL`.\n7. Guard all operations with static allocations and no heap usage.",
        "testStrategy": "Add unit tests mocking frames: verify SYNC outputs identical arrays; OFFSET with 150ms shift results in expected zero-filled leading frames; confirm processing time <3.38ms via `unity` performance assertions.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement prism_motion_init context validation",
            "description": "Create the motion initialization routine that validates input pointers and zeros the temporal context structure.",
            "dependencies": [],
            "details": "Use PRISM_CHECK_ARG macros to guard null pointers, memset the provided context to zero, initialize cached timestamps, and return esp_err_t codes across firmware/components/playback/prism_temporal.c.",
            "status": "pending",
            "testStrategy": "Add Unity tests that pass null pointers and valid inputs to confirm ESP_ERR_INVALID_ARG handling and full context reset.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add prism_frame_time_ms and apply_offset helpers",
            "description": "Introduce shared inline helpers that compute frame durations and gate delayed output values for temporal sequencing.",
            "dependencies": [
              1
            ],
            "details": "Create static inline functions in prism_temporal.c that convert FreeRTOS tick counts to milliseconds, fall back to esp_timer_get_time when finer resolution is required, and implement apply_offset returning zero until delay_ms elapses.",
            "status": "pending",
            "testStrategy": "Unit-test helper behavior with mocked tick counts and microsecond timers to confirm correct millisecond calculation and delay gating.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement calculate_ch2_frame SYNC branch",
            "description": "Wire up the SYNC path in calculate_ch2_frame to perform an optimized copy from channel 1 to channel 2.",
            "dependencies": [
              1,
              2
            ],
            "details": "Add early exit for SYNC mode using memcpy on restrict-qualified buffers, respect 4-byte alignment optimizations, and integrate optional profiling guards controlled by CONFIG_PRISM_PROFILE_TEMPORAL.",
            "status": "pending",
            "testStrategy": "Create unit coverage ensuring SYNC mode copies all LED values correctly and triggers profiling hooks when enabled.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement calculate_ch2_frame OFFSET branch",
            "description": "Complete the OFFSET mode logic that applies per-LED delay buckets and handles zero-filling before activation.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Iterate LEDs, compute frame_time_ms via helpers, apply delay table values, zero-fill elements when frame_time is below delay, and cache previous frame timestamps in static context to stay within the 3.38 ms budget.",
            "status": "pending",
            "testStrategy": "Verify OFFSET mode with mocked delay tables yields expected zero-fill windows and updates cached timing without exceeding processing budget in unit tests.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create Unity tests for SYNC and OFFSET modes",
            "description": "Author test_prism_temporal.c to validate SYNC copying, OFFSET delay handling, and performance instrumentation requirements.",
            "dependencies": [
              3,
              4
            ],
            "details": "Add Unity cases that mock esp_timer_get_time, assert channel equality for SYNC, confirm OFFSET zero windows at configured delays, and use timing hooks to enforce the <3.38 ms processing target.",
            "status": "pending",
            "testStrategy": "Run new Unity suite focused on prism_temporal.c verifying both functional outputs and instrumentation-driven performance guards.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Separate tasks for context init, SYNC fast path, OFFSET delay handling, performance/timing safeguards, and unit/integration test coverage for both modes.",
        "updatedAt": "2025-10-16T08:45:11.282Z"
      },
      {
        "id": 13,
        "title": "Extend .prism v1.1 Header and Parser",
        "description": "Update storage and protocol parsing to support new motion and sync metadata in .prism v1.1 files.",
        "details": "Files: pattern_storage.h, protocol_parser.c, firmware/components/playback/prism_temporal.c (for struct integration).\nSteps:\n1. Update `prism_header_t` adding fields: `motion_direction_t motion; sync_mode_t sync_mode; sync_params_t sync_params;` ensuring total header size 70 bytes.\n2. Adjust CRC32 computation to include new fields and maintain backward compatibility by zero-filling when absent.\n3. Update `protocol_parser.c` TLV handling to accept `PRISM_VERSION_1_1`, parse motion/sync TLVs, validate range (motion enum bounds, sync modes known, delay <=500ms).\n4. Support fallback for v1.0 patterns by defaulting to `motion=STATIC`, `sync_mode=SYNC`, zeroed params.\n5. Expose helper `bool prism_pattern_is_legacy(const prism_header_t *header);` for migration tooling.\nPseudo-code snippet:\n```\nif (version == 0x0101) {\n    header->motion = read_u8();\n    header->sync_mode = read_u8();\n    header->sync_params.delay_ms = read_u16();\n    // ...\n} else {\n    header->motion = MOTION_STATIC;\n    header->sync_mode = SYNC_MODE_SYNC;\n}\n```\n6. Regenerate binary layout docs in ADR-009 appendix to note offsets.",
        "testStrategy": "Create parser unit tests using golden binaries for v1.0 and v1.1 ensuring CRC acceptance, correct field population, and rejection for out-of-range enums.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Extend prism_header_t for v1.1 motion and sync metadata",
            "description": "Modify the prism_header_t definition so the v1.1 binary header expands to 70 bytes and accommodates motion and sync metadata.",
            "dependencies": [],
            "details": "Insert motion_direction_t, sync_mode_t, and sync_params_t fields at byte offsets 56-63, apply packed alignment pragmas or attributes, and add static_assert checks to guarantee sizeof(prism_header_t)==70.",
            "status": "pending",
            "testStrategy": "Compile-time sizeof assertions and a layout inspection unit test that serializes the header and verifies offsets.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Introduce motion and sync TLVs in protocol_parser.c",
            "description": "Update the TLV parser to recognize the new motion and sync TLVs and populate the extended header fields when version >= 0x0101.",
            "dependencies": [
              1
            ],
            "details": "Define PRISM_TLV_MOTION=0x20 and PRISM_TLV_SYNC=0x21, enforce expected payload lengths, gate parsing to PRISM_VERSION_1_1+, and reject values outside enum bounds or >500 ms delay.",
            "status": "pending",
            "testStrategy": "Parser unit tests feeding crafted TLVs to confirm acceptance of valid frames and rejection of malformed or out-of-range inputs.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement v1.0 fallback and zero-fill compatibility path",
            "description": "Ensure legacy patterns without motion or sync TLVs default to safe values and zeroed fields while staying CRC-compatible.",
            "dependencies": [
              1,
              2
            ],
            "details": "Detect headers/version <0x0101, set motion=MOTION_STATIC, sync_mode=SYNC_MODE_SYNC, zero sync_params, and guarantee padding bytes are cleared before CRC operations or serialization.",
            "status": "pending",
            "testStrategy": "Regression tests loading v1.0 headers to verify default population and that emitted headers remain byte-identical to legacy expectations.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Extend CRC32 computation for new header fields",
            "description": "Adjust CRC accumulation logic so the new motion and sync bytes factor into the checksum without breaking older assets.",
            "dependencies": [
              1,
              3
            ],
            "details": "Update CRC32 routines to include bytes 56-69 for v1.1 headers, zero-initialize missing fields for legacy payloads prior to hashing, and validate endianness when reading multi-byte sync parameters.",
            "status": "pending",
            "testStrategy": "CRC unit tests comparing computed checksums against golden values for both 64-byte v1.0 and 70-byte v1.1 headers, plus tampered-field detection cases.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add regression tests and ADR-009 documentation updates",
            "description": "Create comprehensive tests and documentation artifacts covering the expanded header layout and parser behavior.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Author unit tests using golden binaries for both header versions, cover corrupted CRC and enum range rejections, and regenerate ADR-009 appendix diagrams with updated byte offsets.",
            "status": "pending",
            "testStrategy": "Golden-binary based tests in the playback suite and documentation checks ensuring ADR-009 reflects the new 70-byte layout and TLV handling.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Create subtasks for struct size updates, CRC/backward-compat adjustments, TLV parsing with validation, legacy defaults, and regression tests plus documentation updates.",
        "updatedAt": "2025-10-16T08:42:20.971Z"
      },
      {
        "id": 14,
        "title": "Integrate Temporal Calculation with Playback Task",
        "description": "Wire the new calculation logic into led_playback.c and generate baseline sample patterns.",
        "details": "Files: firmware/components/playback/led_playback.c, firmware/components/playback/prism_temporal.c, pattern files in assets/.\nSteps:\n1. Update `playback_task()` to construct `prism_temporal_ctx_t` from loaded pattern header and call `calculate_ch2_frame()` each frame.\n2. Ensure double-buffer safety: `uint16_t ch2_frame[PRISM_LGP_LED_COUNT]` allocated static per task.\n3. Add switch over motion enum to handle direction-specific indexing (LEFT/RIGHT etc.) for future modes (stub now but return input unchanged).\n4. Create 3 demo patterns (.prism) for SYNC, OFFSET rising (delay 0→150ms), OFFSET falling (150→0ms) stored under `.taskmaster/docs/patterns/phase1/`.\n5. Include event logging `ESP_LOGD(TAG, \"temporal mode=%d motion=%d frame=%u\", ...)` guarded by debug flag.",
        "testStrategy": "Run integration unit test with simulated playback loop verifying ch2 buffer updates and that log instrumentation toggles with config flag; confirm patterns load successfully via existing playback regression test harness.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add static ch2 buffer lifecycle hooks",
            "description": "Introduce a persistent channel 2 frame buffer in led_playback.c and manage its initialization.",
            "dependencies": [],
            "details": "Declare static uint16_t ch2_frame[PRISM_LGP_LED_COUNT] within led_playback.c, ensure it zeroes when playback_task swaps patterns, and only write to it inside frame calculation routines to maintain double-buffer safety.",
            "status": "pending",
            "testStrategy": "Add unit coverage ensuring buffer zeros on pattern changes and is untouched by unrelated code paths.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Build prism_temporal context from pattern headers",
            "description": "Populate prism_temporal_ctx_t fields using parsed pattern metadata and verify motion init behavior.",
            "dependencies": [
              1
            ],
            "details": "Extract temporal mode, timing parameters, and motion metadata from the loaded .prism pattern header, cache the resulting prism_temporal_ctx_t on the playback descriptor, and validate the structure through prism_motion_init to catch invalid fields early.",
            "status": "pending",
            "testStrategy": "Create a mocked pattern header test confirming context fields match expected values and motion init rejects malformed data.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate calculate_ch2_frame with RMT flow",
            "description": "Invoke calculate_ch2_frame ahead of RMT transmission while respecting FreeRTOS synchronization needs.",
            "dependencies": [
              1,
              2
            ],
            "details": "Trigger calculate_ch2_frame() just before rmt_write_items(), gate the send path so the buffer is ready, and coordinate completion via rmt_wait_tx_done plus the existing ISR semaphore to avoid frame overlap.",
            "status": "pending",
            "testStrategy": "Use the playback regression harness to simulate successive frames and assert RMT writes observe updated ch2 buffer contents without timing violations.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement esp_timer driven frame timing",
            "description": "Track playback timestamps with esp_timer to compute accurate per-frame timing and handle reference updates.",
            "dependencies": [
              2,
              3
            ],
            "details": "Store pattern start ticks via esp_timer_get_time(), derive frame_time_ms each loop, and honor TLV set_reference commands by resetting the baseline so temporal calculations stay synchronized.",
            "status": "pending",
            "testStrategy": "Add an integration test that fakes esp_timer readings to confirm frame timing reacts to reference resets and produces expected deltas for the temporal calculator.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Plan subtasks for wiring context construction, channel buffering, motion switch scaffolding, demo pattern generation, and integration test/logging validation.",
        "updatedAt": "2025-10-16T08:45:12.012Z"
      },
      {
        "id": 15,
        "title": "Implement PROGRESSIVE Mode with Shape Presets",
        "description": "Add linear interpolation temporal delays enabling progressive shapes and provide preset pattern definitions.",
        "details": "Files: prism_temporal.c, new preset files under assets/presets/progressive/.\nSteps:\n1. Extend `calculate_ch2_frame()` to handle `SYNC_MODE_PROGRESSIVE` using formula `delay[i] = start_ms + ((end_ms - start_ms) * i) / 159` (precomputed into static array on pattern load).\n2. Support motion direction by swapping LED index iteration for LEFT vs RIGHT and mirroring for EDGE vs CENTER.\n3. Define shape preset generator helper:\n```\nstatic void prism_build_shape(shape_t type, uint16_t *start, uint16_t *end){\n    switch(type){\n        case SHAPE_RIGHT_TRIANGLE: *start=0; *end=200; break;\n        // etc.\n    }\n}\n```\n4. Produce 5 presets (right triangle, left triangle, diamond, chevron, gradient) with metadata stored in pattern repository.\n5. Ensure per-LED counters stored in `uint16_t progressive_delay_table[160]` within context (static allocation).",
        "testStrategy": "Unit tests validating interpolation endpoints, monotonicity for triangles, and symmetry for diamond; snapshot tests comparing generated preset delay tables against golden arrays.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement progressive ramp generator",
            "description": "Add a build_progressive_ramp helper that fills delay tables with linear interpolation math.",
            "dependencies": [],
            "details": "Use fixed-point int32_t math to compute delay[i] = start_ms + span * i / 159, writing into the static uint16_t progressive_delay_table[160] allocated in prism_temporal.c and enforce monotonic increase with guard checks.",
            "status": "pending",
            "testStrategy": "Add focused unit coverage that feeds known start/end pairs to validate endpoints, monotonicity, and overflow handling for build_progressive_ramp.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add motion direction handling to progressive frames",
            "description": "Update calculate_ch2_frame to respect LEFT/RIGHT direction and EDGE/CENTER mirroring when populating progressive delays.",
            "dependencies": [
              1
            ],
            "details": "Integrate direction flags so LEFT iterates LEDs 0→159, RIGHT iterates 159→0, and EDGE/CENTER patterns mirror indices around midpoint while reusing the populated progressive_delay_table values when emitting ch2 frames.",
            "status": "pending",
            "testStrategy": "Extend existing temporal tests to confirm direction swaps and mirroring yield expected index ordering for representative presets.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Create prism_build_shape dispatcher",
            "description": "Introduce prism_build_shape that routes shape_t enums to specific preset builders and annotates pattern metadata.",
            "dependencies": [
              1
            ],
            "details": "Implement a switch-based dispatcher in prism_temporal.c that selects triangle, wedge, diamond, chevron, and gradient builders, populates start/end ranges via prism_build_shape helpers, and records direction flags for downstream rendering.",
            "status": "pending",
            "testStrategy": "Add lightweight dispatcher tests that mock shape_t inputs to confirm correct function pointers and metadata fields are selected.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement triangle preset builder",
            "description": "Author the triangle preset builder producing symmetric progressive ramps with seamless midpoint transition.",
            "dependencies": [
              1,
              3
            ],
            "details": "Use build_progressive_ramp to generate a two-phase ramp: indices 0-79 ascend toward peak_ms and 80-159 descend while ensuring continuity at index 79/80, storing metadata for LEFT/RIGHT variants in assets/presets/progressive/triangle files.",
            "status": "pending",
            "testStrategy": "Create golden delay arrays verifying peak alignment and symmetry checks for triangle presets within the new unit test suite.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement wedge preset builder",
            "description": "Develop wedge preset preset generating edge-biased plateau shapes using the progressive delay table infrastructure.",
            "dependencies": [
              1,
              3
            ],
            "details": "Produce an ascending ramp up to a configurable plateau_index then fill remaining LEDs with end_ms values, supporting edge-biased peaks and exporting metadata for chevron, diamond, and gradient variants in preset assets.",
            "status": "pending",
            "testStrategy": "Capture golden outputs for representative wedge configurations and assert plateau sections remain constant while ramps stay monotonic.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Add progressive temporal unit tests",
            "description": "Create test_prism_temporal_progressive.c covering ramp math, direction handling, and preset outputs using golden tables.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "Author Unity tests that validate delay[0]==start_ms, delay[159]==end_ms, monotonic properties for ramps, symmetry for triangle/diamond presets, and compare generated tables against stored golden snapshots.",
            "status": "pending",
            "testStrategy": "Integrate the new test module into firmware tests and run it in CI to guard against regressions in interpolation, direction logic, and preset builders.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Define subtasks covering delay table generation, motion-direction handling, preset builders, static allocation management, firmware logic updates, and verification tests with goldens.",
        "updatedAt": "2025-10-16T08:42:21.657Z"
      },
      {
        "id": 16,
        "title": "Execute Progressive Mode Hardware Validation & Performance Profiling",
        "description": "Validate visual correctness of progressive shapes on hardware and capture performance data at 120 FPS.",
        "details": "Steps:\n1. Deploy firmware to three ESP32-S3 units attached to dual-edge LGP rig.\n2. Capture high-speed (240 FPS) video for each preset; extract frame-by-frame delay measurements using Python script + OpenCV to compute LED activation timing.\n3. Record observer feedback confirming phi phenomenon (triangles perceived smoothly).\n4. Use ESP-IDF `esp_timer` tracing to measure per-frame temporal compute time (<0.1% CPU budget) and generate profiling report.\n5. Store hardware photos and performance graphs in `docs/phase2/` and update ADR-010 appendix.\n6. File bug reports if any flicker or over-budget frames detected.",
        "testStrategy": "Review captured media vs expected shape outlines, compare timer logs against threshold, and run automated script ensuring frame variance <±5ms across LED indices.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure Chronos 2.1 high-speed capture rig",
            "description": "Prepare Chronos 2.1 camera for 240 FPS progressive LED capture on the dual-edge rig.",
            "dependencies": [],
            "details": "Mount the camera on the rig, place calibration grid, set 240 FPS with 1/1000s shutter, balance lighting, and document lens and exposure parameters.",
            "status": "pending",
            "testStrategy": "Record a calibration clip and verify frame metadata plus grid alignment in review software.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Develop analyze_progressive.py timing extractor",
            "description": "Implement OpenCV timing analyzer for progressive LED activation footage.",
            "dependencies": [
              1
            ],
            "details": "Build analyze_progressive.py to load Chronos videos, segment LED regions, track luminance per frame, calculate activation latency, and output CSV summaries with plots.",
            "status": "pending",
            "testStrategy": "Run the script on the calibration capture and confirm CSV latency traces match expected sequencing.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Conduct phi phenomenon observer trials",
            "description": "Run observer validation sessions to confirm smooth progressive motion perception.",
            "dependencies": [
              1,
              2
            ],
            "details": "Recruit 3-5 testers, brief them on rating scales, play processed sequences at 120 FPS, capture 60-150 ms smoothness ratings, and log qualitative comments.",
            "status": "pending",
            "testStrategy": "Collect signed observation forms and check all ratings meet the acceptance threshold without missing entries.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Instrument firmware with esp_timer profiling",
            "description": "Add esp_timer-based profiling hooks to measure progressive mode CPU usage.",
            "dependencies": [
              1
            ],
            "details": "Wrap progressive rendering routines with esp_timer_get_time, aggregate microsecond timings, guard with config flag, and ensure compute budget stays under 0.1 percent CPU.",
            "status": "pending",
            "testStrategy": "Flash instrumented firmware and review serial logs confirming per-frame averages remain within the CPU budget.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Execute visual shape verification analytics",
            "description": "Quantify shape fidelity using jitter and CAD overlay comparisons.",
            "dependencies": [
              2,
              4
            ],
            "details": "Post-process LED timing data to compute RMS deviations versus CAD overlays, measure peak-to-peak jitter, and generate visual reports comparing expected and observed shapes.",
            "status": "pending",
            "testStrategy": "Automate the analytics routine to flag deviations beyond ±5 ms or geometry limits and validate on a sample dataset.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Archive validation artifacts and update Task Master records",
            "description": "Consolidate validation outputs and document results in project systems.",
            "dependencies": [
              2,
              3,
              4,
              5
            ],
            "details": "Store CSVs, videos, observer notes, profiling logs, and graphs under docs/phase2/, update ADR-010 appendix, and link artifacts within Task Master entries.",
            "status": "pending",
            "testStrategy": "Confirm repository updates include new docs paths and Task Master references to each archived artifact.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Outline subtasks for firmware deployment, high-speed capture workflow, quantitative analysis scripts, performance logging, documentation updates, and bug triage/reporting.",
        "updatedAt": "2025-10-16T08:42:22.333Z"
      },
      {
        "id": 17,
        "title": "Add WAVE Mode with Lookup Tables",
        "description": "Introduce WAVE sync mode using precomputed delay lookup tables and generate sine, triangle, and sawtooth presets.",
        "details": "Files: prism_temporal.c, new module `firmware/components/playback/wave_lut.c`.\nSteps:\n1. Create lookup generator `void prism_wave_build_table(waveform_t type, uint16_t amplitude_ms, uint16_t frequency_fp8, uint16_t phase_deg, uint16_t *out_table)` producing 160 entries.\n2. Precompute tables on pattern load (effect start) storing in static `uint16_t wave_delay_table[160]`.\n3. Implement WAVE branch in `calculate_ch2_frame()` fetching `delay = wave_delay_table[index];` and applying motion direction transforms.\n4. Inline hot-path helpers with `static inline` or `ESP_FORCE_INLINE` to cut call overhead.\n5. Create presets for sine, sawtooth, triangle waves with amplitude/frequency param sets aligned to spec.\nPseudo-code:\n```\nfor i in 0..159:\n    float theta = (i / 160.0f) * 2π * frequency + phase;\n    switch(type){\n        case SINE: delay[i] = base + amplitude * (sin_table[theta_fp] + 1)/2;\n        ...\n    }\n```\n6. Ensure tables use ADR-009 sin8() for fixed-point math (no floating point in render loop).",
        "testStrategy": "Unit tests ensuring LUT generation matches expected waveform math, verifying execution time <0.5µs using cycle counter, and checking presets produce correct amplitude extrema.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Build wave LUT generator module",
            "description": "Implement the prism_wave_build_table function to emit 160-entry fixed-point lookup tables.",
            "dependencies": [],
            "details": "Create firmware/components/playback/wave_lut.c and header defining waveform_t enum usage, implement prism_wave_build_table using ADR-009 sin8() helpers, fixed-point arithmetic, and ESP_FORCE_INLINE utility helpers.",
            "status": "pending",
            "testStrategy": "Add unit coverage in test_wave_lut.c comparing generated sine and triangle tables against precalculated fixtures for multiple amplitudes and phases.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Precompute wave delay table on pattern load",
            "description": "Integrate table allocation and generation during pattern initialization to populate the static cache.",
            "dependencies": [
              1
            ],
            "details": "Extend prism_temporal.c pattern load path to declare static uint16_t wave_delay_table[160], invoke prism_wave_build_table with current sync parameters, and ensure memory lifetime spans effect duration while guarding against re-entry.",
            "status": "pending",
            "testStrategy": "Add integration test in test_prism_temporal.c verifying wave_delay_table populates with non-zero values after mock pattern load and that repeated loads refresh contents.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add WAVE branch to calculate_ch2_frame",
            "description": "Update the temporal rendering loop to consume the precomputed wave table for delay selection.",
            "dependencies": [
              2
            ],
            "details": "Modify calculate_ch2_frame() to recognize sync mode WAVE, compute table index from frame counter, fetch delay from wave_delay_table, and maintain existing behavior for other modes.",
            "status": "pending",
            "testStrategy": "Extend temporal loop unit tests to assert WAVE mode reads expected indices and preserves baseline behavior for SYNC/PROGRESSIVE paths.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement motion direction transforms for WAVE mode",
            "description": "Apply motion-direction-specific adjustments to wave-based delays using inlined helpers.",
            "dependencies": [
              3
            ],
            "details": "Introduce static inline helpers in prism_temporal.c mapping wave_delay_table outputs through LEFT/RIGHT/CENTER/EDGE/STANDARD transforms, leveraging ESP_FORCE_INLINE where needed to avoid call overhead.",
            "status": "pending",
            "testStrategy": "Add focused tests verifying each motion direction produces expected mirrored or shifted indices, plus review assembly output to confirm helpers inline.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create sine, triangle, sawtooth presets",
            "description": "Define preset parameter sets and hook them into the effect pipeline.",
            "dependencies": [
              4
            ],
            "details": "Implement preset factory routines selecting waveform type, amplitude, frequency, and phase per spec, wire into pattern loader so WAVE mode selects presets by name, and document options in playback headers.",
            "status": "pending",
            "testStrategy": "Add preset unit tests ensuring each preset yields expected min/max delay extremes and correct waveform type routing.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Add LUT regression and performance tests",
            "description": "Validate waveform accuracy and execution timing for the completed WAVE implementation.",
            "dependencies": [
              5
            ],
            "details": "Author regression tests comparing generated tables against golden vectors, integrate cycle-counter measurement to assert calculate_ch2_frame WAVE path stays under 0.5µs, and include basic fuzz inputs for amplitude/frequency bounds.",
            "status": "pending",
            "testStrategy": "Extend Unity harness with timing assertions using esp_clk_cpu_freq(), run tests under CI profile, and capture perf metrics for documentation.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Split into subtasks for LUT generator module, table allocation/loading, calculate_ch2_frame wave branch, motion transforms, preset creation, and unit/perf testing.",
        "updatedAt": "2025-10-16T08:37:04.824Z"
      },
      {
        "id": 18,
        "title": "Profile and Optimize WAVE Mode Execution",
        "description": "Benchmark LUT vs realtime sinusoid calculations and ensure CPU utilization remains within budget.",
        "details": "Steps:\n1. Implement profiling hooks toggled via `CONFIG_PRISM_PROFILE_TEMPORAL` measuring cycle counts for LUT lookup vs `sinf` baseline.\n2. Compare average runtime across 10k frames, target reduction from ~80µs to <1µs.\n3. Document cache effects: ensure tables placed in DRAM with `DRAM_ATTR` to avoid flash latency.\n4. Validate no heap fragmentation by inspecting `heap_caps_get_free_size(MALLOC_CAP_8BIT)` before/after wave mode run.\n5. Publish report `docs/phase3/wave_performance.md` with table of results and optimization notes.",
        "testStrategy": "Automated profiling test harness asserting LUT path <1µs median runtime, verifying no heap usage via custom allocator hooks, and ensuring wave visuals remain artifact-free under 120 FPS playback in simulation.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Enable CONFIG_PRISM_PROFILE_TEMPORAL profiling framework",
            "description": "Add the configurable profiling framework for wave mode so temporal hooks can be toggled at build time.",
            "dependencies": [],
            "details": "Define CONFIG_PRISM_PROFILE_TEMPORAL in Kconfig, add wave_profiler_begin/end inline helpers, and schedule a ring-buffer drain task that writes CSV rows to /spiffs/profile_wave.csv.",
            "status": "done",
            "testStrategy": "Toggle the config in idf.py menuconfig and confirm the CSV writer task emits entries during a simulated wave run.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T08:38:12.667Z"
          },
          {
            "id": 2,
            "title": "Instrument wave execution with esp_cpu_get_cycle_count",
            "description": "Capture precise cycle counts for LUT and sinf paths to compare execution cost.",
            "dependencies": [
              1
            ],
            "details": "Wrap wave sections with portENTER_CRITICAL/portEXIT_CRITICAL, invoke esp_cpu_get_cycle_count with rollover handling, convert cycles to nanoseconds, and pin the profiler task to core 0.",
            "status": "done",
            "testStrategy": "Run the profiler under load and verify cycle deltas remain stable across iterations and that rollover logic preserves monotonic timings.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T08:38:14.078Z"
          },
          {
            "id": 3,
            "title": "Integrate Xtensa PMU cache profiling and DRAM audits",
            "description": "Measure cache behavior and ensure lookup tables stay in DRAM to avoid flash latency.",
            "dependencies": [
              1,
              2
            ],
            "details": "Configure perfmon_config_t for PM_CYCLES and PM_DCACHE_MISS, log miss ratios alongside timings, and validate DRAM_ATTR placement and 64-byte alignment via build/prism.map inspection.",
            "status": "done",
            "testStrategy": "Enable PMU counters during the profiling run and confirm logged miss counts drop when DRAM_ATTR placement is correct.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T08:38:49.734Z"
          },
          {
            "id": 4,
            "title": "Optimize LUT access path for wave mode",
            "description": "Refine the LUT code path to minimize instruction count and memory stalls.",
            "dependencies": [
              2,
              3
            ],
            "details": "Introduce branchless phase-to-index masking, apply ESP_FORCE_INLINE to phase helpers, locate hot kernels in IRAM_ATTR, and store a 1024-entry sin8 table in DRAM.",
            "status": "done",
            "testStrategy": "Benchmark the optimized LUT path against the baseline and confirm the median runtime approaches the <1µs target.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T08:38:50.506Z"
          },
          {
            "id": 5,
            "title": "Build wave profiling harness and generate validation artifacts",
            "description": "Create the automated harness to validate performance, heap health, and reporting outputs.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Implement tests/profile_wave_mode.c to run 10k frames, emit JSON results to .taskmaster/reports/, assert median runtime <1µs, and check heap_caps_get_minimum_free_size for fragmentation.",
            "status": "done",
            "testStrategy": "Execute the harness on hardware, review JSON output for pass criteria, and ensure heap metrics remain unchanged pre/post run.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T08:38:51.292Z"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Create subtasks for profiling hook implementation, benchmark harness, memory placement audits, heap diagnostics, and report generation with recommendations.",
        "updatedAt": "2025-10-16T08:38:51.292Z"
      },
      {
        "id": 19,
        "title": "Implement CUSTOM Mode and Web-Based Delay Map Editor",
        "description": "Deliver CUSTOM sync mode with arbitrary delay maps and a web editor for authoring .prism v1.1 patterns.",
        "details": "Steps:\n1. Extend `calculate_ch2_frame()` for CUSTOM mode loading 320-byte delay map into static array `custom_delay_map[160]` and reading per LED.\n2. Add validation during pattern upload ensuring delay range 0-500ms and map size correct; reject invalid TLVs.\n3. Build web editor (React or Svelte per existing stack) in `tools/custom-delay-editor/` with:\n   - Canvas preview of 160 LEDs (top/bottom channels).\n   - Drag control points generating cubic spline curve mapped to delay values.\n   - Import/export `.prism` via WebUSB or file download.\n4. Implement export pipeline: serialize header + delay map using WebAssembly helper reusing existing C structs compiled via Emscripten.\n5. Seed preset library with triangle/diamond/wave templates.\nPseudo-code (CUSTOM evaluation):\n```\nfor i in 0..159:\n    uint16_t delay = custom_delay_map[i];\n    if (frame_elapsed_ms < delay) ch2[i] = 0;\n    else ch2[i] = ch1[i];\n```\n6. Provide documentation `docs/phase4/custom_mode.md` describing workflow.",
        "testStrategy": "Unit tests for delay map parsing, web editor Jest tests validating curve-to-delay conversion, end-to-end test exporting pattern and verifying firmware playback matches authored delay map using hardware loopback harness.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up WebAssembly serializer build",
            "description": "Establish the emscripten build pipeline for the shared .prism serializer module.",
            "dependencies": [],
            "details": "Create emcc configuration, integrate existing C structs, and produce reusable WASM/JS glue exposing serialization APIs for the web tool.",
            "status": "pending",
            "testStrategy": "Add CI step invoking emcc build and verify exported functions via wasm-smoke tests.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement spline-based curve editor UI",
            "description": "Build interactive curve editor interface supporting control point manipulation.",
            "dependencies": [
              1
            ],
            "details": "Use existing frontend stack to create canvas UI with draggable Bezier/spline handles, dual-channel LED layout, and state management for 160-point curve authoring.",
            "status": "pending",
            "testStrategy": "Jest + React Testing Library checks for control point interactions and state persistence.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Create curve-to-delay sampling engine",
            "description": "Convert authored curves into 160 delay samples between 0 and 500 ms.",
            "dependencies": [
              2
            ],
            "details": "Implement sampling routine that evaluates spline geometry, clamps values within allowed bounds, and outputs 320-byte delay map ready for firmware consumption.",
            "status": "pending",
            "testStrategy": "Unit tests comparing sampled arrays against analytic references and boundary conditions.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add firmware delay map validation",
            "description": "Extend firmware upload validation for CUSTOM delay maps and constraints.",
            "dependencies": [
              3
            ],
            "details": "Update pattern ingestion to enforce TLV size of 320 bytes, validate each delay within 0-500 ms, and reject malformed payloads before storage.",
            "status": "pending",
            "testStrategy": "Unity tests feeding valid/invalid TLVs verifying acceptance, rejection codes, and error logging.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement real-time LED preview renderer",
            "description": "Render dual-channel LED preview reflecting sampled delays in the browser.",
            "dependencies": [
              3
            ],
            "details": "Build WebGL or Canvas2D renderer that simulates top/bottom LED playback using incoming ch1 data and computed ch2 delays for live visualization.",
            "status": "pending",
            "testStrategy": "Visual regression via Jest canvas snapshots and manual QA checklist for playback timing.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": ".prism export and TLV integration",
            "description": "Wire WebAssembly serializer into export flow for .prism files.",
            "dependencies": [
              1,
              3,
              5
            ],
            "details": "Connect sampling output to WASM serializer, package header and delay map into TLV-compliant .prism payload, and support WebUSB download/upload flows.",
            "status": "pending",
            "testStrategy": "End-to-end browser tests verifying generated files load in firmware harness and pass TLV checks.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Seed preset library with CUSTOM patterns",
            "description": "Author preset delay maps (triangle, diamond, wave) leveraging prior tasks.",
            "dependencies": [
              3,
              6
            ],
            "details": "Use curve editor and serialization path to create preset JSON/.prism assets, cross-reference Task 15 shapes, and register them in preset catalog.",
            "status": "pending",
            "testStrategy": "Snapshot tests ensuring preset delay arrays match expected shapes and metadata integrity checks.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Build comprehensive CUSTOM mode test suite",
            "description": "Develop automated tests covering web tool, serialization, and firmware integration.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6,
              7
            ],
            "details": "Expand Jest suites for UI/sampling, add integration tests for export/import, and create Unity firmware tests validating runtime playback with seeded presets.",
            "status": "pending",
            "testStrategy": "Run combined Jest suite and Unity hardware-in-the-loop regression verifying outputs align with reference delay maps.",
            "parentId": "undefined"
          }
        ],
        "complexity": 9,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Plan subtasks spanning firmware support for custom maps, validation logic, web editor UI/UX, curve-to-delay algorithms, import/export tooling, WASM glue, preset seeding, and documentation/tests.",
        "updatedAt": "2025-10-16T09:01:10.918Z"
      },
      {
        "id": 20,
        "title": "Explore repo and verify referenced files",
        "description": "I’ll scan the repo for the referenced docs, tools and artifacts, then open any key files to align task updates with the actual codebase.",
        "status": "in-progress",
        "dependencies": [],
        "priority": "high",
        "details": "Using ripgrep to locate migration scripts, docs, release notes, validation tools, and artifacts. Then I’ll read relevant files in chunks to confirm entrypoints and paths for accurate references.",
        "testStrategy": "Cross-check that every path mentioned in the task exists and reflects current content; adjust task details accordingly.",
        "subtasks": [
          {
            "id": 7,
            "title": "Finalize v1.1 release notes",
            "description": "Polish and finalize release notes with software deliverables captured; mark all hardware-dependent validations as deferred.",
            "dependencies": [],
            "details": "Update and finalize `docs/release/v1.1_release_notes.md` to include firmware binary path `firmware/build/prism-k1.bin`, preset bundle `out/presets_v1.1.zip`, migration references (`MIGRATION.md`, `tools/migrate_prism.py:53`), and ensure the \"Pending Hardware Validation\" section clearly defers soak and OTA. Align with `CHANGELOG.md` and local `firmware-v1.1` tag.",
            "status": "done",
            "testStrategy": "Open `docs/release/v1.1_release_notes.md` and verify: correct artifact paths, migration references, presence of the \"Pending Hardware Validation\" section, and consistency with `CHANGELOG.md`. Confirm readiness to publish when hardware validation resumes.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Assemble pattern preset library",
            "description": "Curate and package patterns showcasing all mode combinations.",
            "dependencies": [
              1
            ],
            "details": "Design 20+ presets as `.prism` files with metadata covering motion and sync permutations, bundle artifacts with release package.",
            "status": "done",
            "testStrategy": "Load presets on hardware to verify metadata recognition and playback quality.','parentId':'undefined'\",\"parentId\":\"undefined\",\"updatedAt\":\"2025-10-16T17:19:27.617Z\"}]}}} }",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Assemble pattern preset library",
            "description": "Curate and package patterns showcasing all mode combinations.",
            "dependencies": [
              1
            ],
            "details": "Design 20+ presets as `.prism` files with metadata covering motion and sync permutations, bundle artifacts with release package.",
            "status": "done",
            "testStrategy": "Load presets on hardware to verify metadata recognition and playback quality.','parentId':'undefined'",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Assemble pattern preset library",
            "description": "Curate and package patterns showcasing all mode combinations.",
            "dependencies": [
              1
            ],
            "details": "Design 20+ presets as `.prism` files with metadata covering motion and sync permutations, bundle artifacts with release package.",
            "status": "done",
            "testStrategy": "Load presets on hardware to verify metadata recognition and playback quality.','parentId':'undefined'\",\"parentId\":\"undefined\",\"updatedAt\":\"2025-10-16T17:19:27.617Z\"}]}}} }",
            "parentId": "undefined"
          },
          {
            "id": 1,
            "title": "Implement v1.0→v1.1 migration CLI",
            "description": "Create the `tools/prism-migrate` CLI to upgrade legacy pattern packs to firmware v1.1 format.",
            "dependencies": [],
            "details": "Build parser for v1.0 headers, enforce CRC validation, inject default motion and sync metadata, and ensure repeated runs remain idempotent.",
            "status": "done",
            "testStrategy": "Add regression suite comparing source and migrated pattern CRCs and verifying metadata defaults.','parentId':'undefined'",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Write comprehensive user manual",
            "description": "Author Markdown documentation covering firmware v1.1 concepts and workflows.",
            "dependencies": [],
            "details": "Organize docs in `docs/user-manual/`, explain temporal sequencing, motion directions, sync modes, advanced techniques, and include phi phenomenon discussion.",
            "status": "done",
            "testStrategy": "Peer review against PRD checklist and lint Markdown for broken links.','parentId':'undefined'",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Assemble pattern preset library",
            "description": "Curate and package patterns showcasing all mode combinations.",
            "dependencies": [
              1
            ],
            "details": "Design 20+ presets as `.prism` files with metadata covering motion and sync permutations, bundle artifacts with release package.",
            "status": "done",
            "testStrategy": "Load presets on hardware to verify metadata recognition and playback quality.','parentId':'undefined'",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T17:19:27.617Z"
          }
        ],
        "complexity": 9,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Detail steps for tutorial video production, long-run soak testing with telemetry analysis, preset library assembly, release notes and artifact packaging, OTA validation, and stakeholder approvals."
      },
      {
        "id": 21,
        "title": "Establish CLI tooling core",
        "description": "Create shared CLI scaffolding and deterministic JSON/CSV writers for PRISM authoring tools.",
        "details": "Implementation:\n- Add `tools/tooling_core.py` housing argparse helpers, stdout/stderr logging, and deterministic JSON/CSV writers (ensure UTF-8, sorted keys, newline termination).\n- Provide reusable `write_json(output_path, payload, metadata)` and `write_csv(output_path, rows, headers)` utilities that include metadata blocks as required by PRD.\n- Expose base `build_parser(description)` that injects common arguments (`--output`, optional `--csv`, `--meta` seed info) and validates writable paths.\n- Ensure CLI entrypoints in `tools/__main__.py` or module-level guards call these helpers.\nPseudo-code:\n```python\n# tools/tooling_core.py\ndef build_parser(description: str) -> argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(description=description)\n    parser.add_argument(\"--output\", required=True)\n    parser.add_argument(\"--csv\")\n    parser.add_argument(\"--meta\", help=\"Path to optional metadata JSON\")\n    return parser\n\ndef write_json(path, rgb_frames, metadata):\n    payload = {\"data\": rgb_frames, \"meta\": metadata, \"version\": \"1.0\"}\n    with open(path, \"w\", encoding=\"utf-8\") as fh:\n        json.dump(payload, fh, indent=2, sort_keys=True)\n        fh.write(\"\\n\")\n```\n",
        "testStrategy": "Unit:\n- Writer tests verifying stable key ordering, newline termination, and metadata merge.\n- Parser smoke tests covering help output and required arguments.\nIntegration:\n- CLI stub that invokes writers and asserts file creation in tmpdir.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design shared CLI parser scaffolding",
            "description": "Create argparse utilities that enforce common CLI options and path validation.",
            "dependencies": [],
            "details": "Implement tools/tooling_core.py with build_parser(description) returning an ArgumentParser that registers --output, optional --csv, and --meta arguments, validates writable paths, and hooks shared stdout/stderr logging helpers for downstream CLIs.",
            "status": "pending",
            "testStrategy": "Unit smoke tests asserting parser enforces required --output, optional flags, and help text formatting.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement deterministic JSON and CSV writers",
            "description": "Provide reusable writer helpers ensuring stable output for PRISM tools.",
            "dependencies": [
              1
            ],
            "details": "Add write_json(output_path, payload, metadata) and write_csv(output_path, rows, headers) in tools/tooling_core.py to merge metadata blocks, emit UTF-8 files with sorted keys, newline termination, and deterministic column ordering, sharing logging from the parser scaffolding.",
            "status": "pending",
            "testStrategy": "Unit tests that write to tmp paths, verify newline termination, key ordering, encoded metadata blocks, and deterministic CSV header ordering.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add tests and CLI integration harness",
            "description": "Create automated validation covering parser and writer behaviors via CLI entrypoints.",
            "dependencies": [
              1,
              2
            ],
            "details": "Introduce tools/__main__.py or module guard that wires build_parser and writer helpers into a stub CLI command, plus dedicated pytest modules exercising integration flows in temp directories to ensure files create correctly and errors surface via logging.",
            "status": "pending",
            "testStrategy": "Integration tests invoking python -m tools with sample arguments plus unit coverage for log output and failure modes.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Plan work for creating shared argparse/logging helpers, implementing deterministic JSON/CSV writers, and adding unit/integration tests via a stub CLI entry point.",
        "updatedAt": "2025-10-16T13:28:50.311Z"
      },
      {
        "id": 22,
        "title": "Configure color library dependencies",
        "description": "Add and validate third-party color dependencies required for HSLuv and RGBW conversions.",
        "details": "Implementation:\n- Update `tools/requirements.txt` to include pinned versions of `hsluv>=0.1.2`, `rgbw-colorspace-converter` (latest stable), `colr`, `ansi2html`, and `aha`.\n- Add dependency availability checks in a lightweight `tools/check_deps.py` to import each library and raise actionable errors.\n- Document installation instructions and virtualenv guidance in `tools/README.md`.\nPseudo-code:\n```python\n# tools/check_deps.py\nREQUIRED = [\"hsluv\", \"rgbw_colorspace_converter\", \"colr\", \"ansi2html\", \"aha\"]\nfor name in REQUIRED:\n    try:\n        importlib.import_module(name)\n    except ImportError as exc:\n        raise SystemExit(f\"Missing dependency {name}: {exc}\")\n```\n",
        "testStrategy": "Unit:\n- Run `python -m tools.check_deps` in CI to confirm imports succeed.\n- Verify requirements hash lock (if using pip-tools) regenerates cleanly.\nDocumentation:\n- Manual validation by following README steps in a fresh venv.",
        "priority": "high",
        "dependencies": [
          "21"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Pin required color libraries in tooling manifests",
            "description": "Add the new color dependencies to the tooling requirements files with appropriate version pins and refresh any generated lock artifacts.",
            "dependencies": [],
            "details": "Update `tools/requirements.txt` with pinned entries for hsluv>=0.1.2, rgbw-colorspace-converter (latest stable), colr, ansi2html, and aha, then regenerate and stage any lockfile or hashes workflow expects so downstream installs pull the exact versions.",
            "status": "done",
            "testStrategy": "Re-run the project’s dependency lock workflow (e.g., `pip-compile` or hash regeneration) to confirm the manifest resolves cleanly and `pip install -r tools/requirements.txt` succeeds in a clean virtualenv.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T14:07:06.314Z"
          },
          {
            "id": 2,
            "title": "Add dependency verification script and contributor setup docs",
            "description": "Implement the lightweight dependency import checker and document installation guidance for developers.",
            "dependencies": [
              1
            ],
            "details": "Create `tools/check_deps.py` that imports each required library and raises friendly SystemExit errors when missing, then expand `tools/README.md` with virtualenv setup and instructions for running the checker after installing requirements.\n<info added on 2025-10-16T14:19:01.273Z>\nConfirmed tools/check_deps.py performs required import checks plus aha CLI verification, and the Tooling Environment Setup section in tools/README.md covers virtualenv guidance and running the checker as specified.\n</info added on 2025-10-16T14:19:01.273Z>",
            "status": "done",
            "testStrategy": "Run `python -m tools.check_deps` in a clean environment to ensure success with installed deps and verify it exits with actionable messaging when a library is removed temporarily.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T14:19:06.717Z"
          }
        ],
        "complexity": 3,
        "recommendedSubtasks": 2,
        "expansionPrompt": "Outline subtasks for updating requirements/lock artifacts with the new color packages and creating a dependency check script with README setup instructions.",
        "updatedAt": "2025-10-16T14:19:06.717Z"
      },
      {
        "id": 23,
        "title": "Implement HSLuv and baseline palette interpolation",
        "description": "Build palette generation core supporting HSLuv, HSV, and HSL interpolation with perceptual hue wrapping.",
        "details": "Implementation:\n- Extend `tools/palette_to_prism.py` with interpolation utilities converting HEX stops to RGB tuples via hsluv for `--space hsluv`, and Python colorsys for HSV/HSL.\n- Implement hue wrapping logic to always choose shortest angular distance across 0/360.\n- Support arbitrary LED counts by distributing segments with remainder handling.\n- Expose reusable `interpolate_palette(stops, led_count, space, easing=\"linear\")` returning list of RGB floats normalized to [0,1].\nPseudo-code:\n```python\ndef interpolate_palette(hex_stops: list[str], led_count: int, space: str) -> list[tuple[float,float,float]]:\n    stops = [hex_to_space(stop, space) for stop in hex_stops]\n    ramp = []\n    for idx in range(led_count):\n        t = idx / (led_count - 1)\n        seg_idx = locate_segment(t, len(stops))\n        local_t = compute_local_t(t, seg_idx, len(stops))\n        blended = blend(stops[seg_idx], stops[seg_idx + 1], local_t, wrap_hue=True)\n        ramp.append(space_to_rgb(blended, space))\n    return ramp\n```\n",
        "testStrategy": "Unit:\n- Golden tests comparing generated RGB arrays against fixtures for known palettes (2-stop and 3-stop).\n- Edge-case tests for hue wrapping across 0° and LED counts smaller than stop count.\n- Property tests ensuring RGB outputs stay within [0,255] after scaling.\nIntegration:\n- Smoke CLI run generating JSON for sample palette.",
        "priority": "high",
        "dependencies": [
          "21",
          "22",
          "33"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Build color space conversion helpers",
            "description": "Implement reusable conversions between HEX, HSLuv, HSV, HSL, and RGB tuples.",
            "dependencies": [],
            "details": "Add helper functions in tools/palette_to_prism.py to decode hex stops, call hsluv library, and normalize RGB floats for each supported color space.",
            "status": "pending",
            "testStrategy": "Unit tests covering round-trip HEX ↔ RGB for HSLuv, HSV, and HSL using known fixtures.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement hue-aware interpolation core",
            "description": "Create interpolation pipeline that blends stops with perceptual hue wrapping.",
            "dependencies": [
              1
            ],
            "details": "Develop interpolate_palette logic that maps to color space values, locates segment indices, computes local t, and blends hues using shortest angular distance across 0/360 with optional easing hooks.",
            "status": "pending",
            "testStrategy": "Unit tests verifying hue wrapping across 359°→1° cases and linear blending accuracy for 2- and 3-stop palettes.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Handle LED distribution and API exposure",
            "description": "Support arbitrary LED counts and expose the reusable interpolation API.",
            "dependencies": [
              2
            ],
            "details": "Implement LED segment distribution with remainder handling, ensure RGB outputs stay normalized, and surface interpolate_palette(stops, led_count, space, easing) from tools/palette_to_prism.py.",
            "status": "pending",
            "testStrategy": "Unit tests confirming segment allocation for uneven LED counts and correct output length/value ranges.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Author comprehensive regression tests",
            "description": "Add golden fixtures and property checks for the palette interpolation workflow.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Create golden RGB arrays for reference palettes, add regression tests for edge cases, and include property tests ensuring outputs remain in range and consistent across spaces.",
            "status": "pending",
            "testStrategy": "Integration tests generating palettes against fixtures plus property tests validating RGB bounds and consistency.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Define work to add color-conversion helpers, implement hue-aware interpolation with LED distribution, expose the reusable API, and build regression/property tests.",
        "updatedAt": "2025-10-16T12:23:17.292Z"
      },
      {
        "id": 24,
        "title": "Finalize palette_to_prism CLI and metadata output",
        "description": "Wire CLI arguments for palette generation and write deterministic JSON/CSV payloads with metadata.",
        "details": "Implementation:\n- Use tooling core parser to accept `--palette`, `--led-count`, `--space`, `--include-rgbw`, optional `--seed`, and output paths.\n- Parse comma-separated HEX list, validate format, and call interpolation logic from Task 23.\n- Attach metadata capturing inputs (palette stops, space, timestamp, software version, random seed).\n- Ensure CSV writing supports optional RGBW columns but is gated by `--include-rgbw`.\nPseudo-code:\n```python\ndef main():\n    parser = build_parser(\"Generate PRISM palette payload\")\n    parser.add_argument(\"--palette\", required=True)\n    parser.add_argument(\"--led-count\", type=int, required=True)\n    parser.add_argument(\"--space\", choices=[\"hsv\",\"hsl\",\"hsluv\"], default=\"hsluv\")\n    parser.add_argument(\"--include-rgbw\", action=\"store_true\")\n    args = parser.parse_args()\n    rgb = interpolate_palette(args.palette.split(','), args.led_count, args.space)\n    rgbw = compute_rgbw(rgb) if args.include_rgbw else None\n    write_outputs(args, rgb, rgbw)\n```\n",
        "testStrategy": "Unit:\n- Argument parsing tests covering default values, error cases, and help text.\n- Verify metadata contains all expected keys and matches inputs.\nIntegration:\n- CLI end-to-end test writing JSON and CSV fixtures compared against goldens.\nRegression:\n- Ensure unicode/hex parsing works on CI (UTF-8).",
        "priority": "medium",
        "dependencies": [
          "21",
          "22",
          "23"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement palette_to_prism CLI argument handling",
            "description": "Wire up CLI parser options and validations for palette generation.",
            "dependencies": [],
            "details": "Add required arguments including palette list, led count, color space, include-rgbw toggle, optional seed, and output paths with robust validation.",
            "status": "pending",
            "testStrategy": "Unit test parser to cover required/optional flags, defaults, and failure cases.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate palette parsing and interpolation logic",
            "description": "Parse palette input and connect interpolation functions.",
            "dependencies": [
              1
            ],
            "details": "Split comma-separated hex inputs, validate formatting, convert to RGB tuples, and invoke Task 23 interpolation respecting selected color space.",
            "status": "pending",
            "testStrategy": "Unit test parsing acceptance of valid palettes, rejection of malformed entries, and correctness of interpolation calls.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Generate deterministic JSON and CSV payloads with metadata",
            "description": "Produce serialized outputs with deterministic ordering and metadata capture.",
            "dependencies": [
              1,
              2
            ],
            "details": "Emit JSON and CSV files with stable key ordering, include metadata for inputs, timestamps, versions, seeds, and guard RGBW columns behind include-rgbw flag.",
            "status": "pending",
            "testStrategy": "Unit tests verifying metadata completeness, deterministic ordering, and CSV schema with/without RGBW.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Run end-to-end palette_to_prism CLI validation",
            "description": "Execute CLI flow to confirm full pipeline behavior.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Craft integration fixture invoking CLI to produce JSON/CSV outputs, verify against goldens, and ensure exit codes and logging align with expectations.",
            "status": "pending",
            "testStrategy": "Integration test invoking CLI, diff outputs with fixtures, assert deterministic behavior across repeated runs.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Break down tasks for enhancing CLI argument handling, validating/normalizing palette input, generating deterministic JSON/CSV with metadata via the tooling core, and adding end-to-end CLI tests.",
        "updatedAt": "2025-10-16T13:46:50.644Z"
      },
      {
        "id": 25,
        "title": "Implement RGBW offline emission pipeline",
        "description": "Add RGBW tuple generation leveraging rgbw_colorspace_converter for authoring-only payloads.",
        "details": "Implementation:\n- Integrate `rgbw_colorspace_converter` to map RGB values to RGBW using HSI-based algorithm tuned for authoring.\n- Provide configurable white channel scaling (0–1) and clamp outputs to 8-bit integers.\n- Extend metadata to flag RGBW inclusion and transformation parameters.\n- Ensure RGBW arrays align index-wise with RGB arrays for downstream shows.\nPseudo-code:\n```python\ndef compute_rgbw(rgb_values: list[tuple[int,int,int]], white_shift=0.0) -> list[tuple[int,int,int,int]]:\n    converter = RGBWConverter(white_point=\"D65\", white_shift=white_shift)\n    rgbw = []\n    for rgb in rgb_values:\n        r, g, b, w = converter.rgb_to_rgbw(*rgb)\n        rgbw.append(tuple(int(round(channel)) for channel in (r, g, b, w)))\n    return rgbw\n```\n",
        "testStrategy": "Unit:\n- Property tests verifying each component remains within 0–255 and sums do not exceed expected ranges.\n- Compare converter output against known fixtures from rgbw_colorspace_converter repo.\nIntegration:\n- CLI run with `--include-rgbw` producing JSON/CSV validated for correct schema.\nPerformance:\n- Benchmark on 1000 LEDs to ensure runtime within acceptable bounds (<100ms).",
        "priority": "high",
        "dependencies": [
          "21",
          "22",
          "23",
          "24"
        ],
        "status": "cancelled",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate rgbw_colorspace_converter core",
            "description": "Wire the rgbw_colorspace_converter into the offline emission pipeline to translate RGB tuples into RGBW outputs.",
            "dependencies": [],
            "details": "Add converter initialization, call rgb_to_rgbw for each frame payload, and ensure the converter uses the authoring-tuned HSI algorithm.",
            "status": "pending",
            "testStrategy": "Create unit tests comparing converter outputs against fixtures supplied by rgbw_colorspace_converter to validate baseline accuracy.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement white channel scaling and clamping",
            "description": "Expose configurable white channel scaling and clamp resulting RGBW channels to 8-bit integer bounds.",
            "dependencies": [
              1
            ],
            "details": "Introduce parameters for white channel scaling (0-1), apply scaling before finalizing tuples, and clamp all channels to 0-255 integers before serialization.",
            "status": "pending",
            "testStrategy": "Add parameterized unit tests covering edge scaling values (0, 0.5, 1) and verifying clamped outputs never exceed 0-255.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Extend metadata and array alignment",
            "description": "Update payload metadata to include RGBW transformation flags and guarantee RGBW arrays stay index-aligned with RGB data.",
            "dependencies": [
              1,
              2
            ],
            "details": "Augment metadata schemas with RGBW enablement and converter settings, propagate through serializers, and validate array ordering remains consistent for downstream show processors.",
            "status": "pending",
            "testStrategy": "Write integration tests that serialize sample payloads and assert metadata fields plus per-index RGB↔RGBW alignment are correct.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add performance and regression coverage",
            "description": "Profile the RGBW pipeline and implement regression tests guarding against performance or numerical drift.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Benchmark converter execution on representative payload sizes, set performance thresholds, and add regression tests comparing outputs to stored baselines to detect drift.",
            "status": "pending",
            "testStrategy": "Introduce performance benchmarks with assertions on max runtime and add regression comparisons against golden RGBW snapshots to detect deviations.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Plan subtasks for integrating the RGBW converter, adding scaling/clamping controls, extending metadata with RGBW flags, and supplying regression/performance coverage.",
        "updatedAt": "2025-10-16T14:33:02.213Z"
      },
      {
        "id": 26,
        "title": "Build terminal preview renderer",
        "description": "Create `previews/terminal_preview.py` to render palettes and shows in ANSI using colr.",
        "details": "Implementation:\n- Add `render_terminal(rgb_frames, fps)` that down-samples frames if necessary and prints ANSI blocks using `colr` with configurable width.\n- Support both palette (single frame) and show sequences (timed playback with sleep respecting fps +/- tolerance).\n- Provide CLI hook (e.g., `python -m tools.previews.terminal_preview --input palette.json`).\n- Include options for static preview (no animation) for docs.\nPseudo-code:\n```python\ndef render_terminal(rgb_frames, fps=30, loop=False):\n    interval = 1.0 / fps\n    for frame in rgb_frames:\n        line = ''.join(colr.rgb(*pixel)('█') for pixel in frame)\n        print(line)\n        time.sleep(interval)\n    if loop:\n        render_terminal(rgb_frames, fps, loop=True)\n```\n",
        "testStrategy": "Unit:\n- Use monkeypatch to assert `time.sleep` call frequency and ANSI escape sequences for sample frame.\n- Snapshot test comparing generated line strings against expected ANSI codes.\nIntegration:\n- Manual smoke run verifying playback smoothness and fallback in non-TTY environments.",
        "priority": "medium",
        "dependencies": [
          "23",
          "24",
          "37"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement ANSI frame rendering utilities",
            "description": "Build the core terminal renderer that converts RGB pixel grids into ANSI strings using colr.",
            "dependencies": [],
            "details": "Create previews/terminal_preview.py with render_terminal accepting rgb_frames, optional width, and downsampling logic that maps RGB tuples to colr-colored block characters while handling palette-only inputs and non-TTY fallbacks.",
            "status": "pending",
            "testStrategy": "Add isolated tests for render_terminal that assert generated ANSI strings for small sample frames and verify downsampling behavior without performing sleeps.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add playback control and CLI interface",
            "description": "Layer timing, looping, and command-line entry point on top of the renderer.",
            "dependencies": [
              1
            ],
            "details": "Introduce timed playback that respects fps tolerance via time.sleep, implement looping/static preview flags, and expose python -m tools.previews.terminal_preview CLI accepting palette or show JSON inputs with safe error reporting.",
            "status": "pending",
            "testStrategy": "Use monkeypatched time.sleep to confirm interval calculations, and run CLI invocation in dry-run mode to ensure argument parsing and non-TTY fallbacks behave.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Author snapshot tests and documentation hooks",
            "description": "Create automated checks and doc-friendly outputs for the terminal preview.",
            "dependencies": [
              1,
              2
            ],
            "details": "Capture deterministic snapshots of ANSI frames for regression tests, cover non-TTY behavior via buffered outputs, and document static preview usage for docs workflows.",
            "status": "pending",
            "testStrategy": "Implement snapshot comparisons of rendered lines, add unit coverage for non-TTY branches, and document manual verification steps for documentation builds.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Lay out work for ANSI rendering utilities, playback/CLI orchestration with timing controls, and snapshot plus time-mocked tests/documentation hooks.",
        "updatedAt": "2025-10-16T13:54:08.908Z"
      },
      {
        "id": 27,
        "title": "Implement HTML preview exporter",
        "description": "Generate HTML previews by piping ANSI output through ansi2html/aha for embeddable docs.",
        "details": "Implementation:\n- Create `previews/html_preview.py` that accepts RGB frames, calls `render_terminal` to produce ANSI stream (without sleeps), captures it, and converts via `ansi2html.Ansi2HTMLConverter` or `aha` CLI fallback.\n- Output standalone HTML file with embedded CSS and optional autoplay using `<meta http-equiv=\"refresh\">` or JavaScript for sequence playback.\n- Provide CLI interface for specifying output path and frame rate metadata.\nPseudo-code:\n```python\ndef render_html(rgb_frames, fps, out_html):\n    ansi_stream = capture_ansi(rgb_frames)\n    converter = ansi2html.Ansi2HTMLConverter(inline=True)\n    html_body = converter.convert(ansi_stream, full=True)\n    with open(out_html, \"w\", encoding=\"utf-8\") as fh:\n        fh.write(html_body)\n```\n",
        "testStrategy": "Unit:\n- Mock converter to assert HTML contains expected inline styles and frame markers.\n- Validate generated HTML passes basic parsing via `html5lib`.\nIntegration:\n- End-to-end test producing HTML from sample palette and verifying file size/contents.\nRegression:\n- Ensure fallback path using `aha` binary is covered when ansi2html unavailable.",
        "priority": "medium",
        "dependencies": [
          "26",
          "37"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate ANSI stream capture pipeline",
            "description": "Wire the HTML exporter to capture ANSI output from RGB frames via the terminal renderer.",
            "dependencies": [],
            "details": "Implement `capture_ansi` helper that invokes `render_terminal` without delays, captures output using pseudo-terminal or io stream, and normalizes line endings for downstream converters.",
            "status": "pending",
            "testStrategy": "Unit test the capture helper with mocked `render_terminal` to ensure the ANSI buffer matches expected escape sequences and no sleeps are triggered.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Convert ANSI stream to standalone HTML preview",
            "description": "Transform captured ANSI into embeddable HTML with inline assets and CLI fallbacks.",
            "dependencies": [
              1
            ],
            "details": "Create `previews/html_preview.py` logic that prefers `ansi2html.Ansi2HTMLConverter(inline=True)` while falling back to the `aha` CLI, embeds CSS, supports optional autoplay tags, and exposes CLI parameters for output path and frame metadata.",
            "status": "pending",
            "testStrategy": "Integration test that feeds a sample ANSI stream, verifies HTML contains inline styles or fallback markup, and confirms CLI arguments map to output metadata.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Automate HTML preview validation",
            "description": "Ensure generated HTML documents are portable and regressions are caught automatically.",
            "dependencies": [
              2
            ],
            "details": "Add tests or scripts that parse produced HTML via `html5lib`, assert presence of expected frames and metadata, and exercise both converter paths for coverage.",
            "status": "pending",
            "testStrategy": "Automated regression test verifying generated HTML passes parsing, includes required tags, and that fallback path produces structurally valid output.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Define steps to capture ANSI output, convert it to standalone HTML with ansi2html/aha fallbacks, and add validation/snapshot tests for both conversion paths.",
        "updatedAt": "2025-10-16T13:59:26.585Z"
      },
      {
        "id": 28,
        "title": "Develop minimal show engine for sine and morph presets",
        "description": "Implement CPU-side frame generator producing reference sine-wave and morphing gradient shows within existing RGB pipeline.",
        "status": "done",
        "dependencies": [
          "23",
          "24",
          "35"
        ],
        "priority": "high",
        "details": "Implementation:\n- Add `tools/show_to_prism.py` with classes for `SineWaveShow` and `MorphGradientShow` that accept palette, led count, fps, duration, and optional seed.\n- For sine show, modulate brightness per LED using temporal sine with phase offset; map palette index via normalized value.\n- For morph show, interpolate between multiple palette frames using easing controlling speed.\n- Reuse palette interpolation to map palette stops to frames per tick.\n- Keep the implementation RGB-only; do not introduce dependencies on the RGBW pipeline.\nPseudo-code:\n```python\nclass SineWaveShow:\n    def __init__(self, palette, led_count, speed, amplitude, fps):\n        self.palette = palette\n        ...\n    def frame_at(self, t):\n        frame = []\n        for idx in range(self.led_count):\n            phase = (idx / self.led_count) * 2 * math.pi\n            value = 0.5 + self.amplitude * math.sin(phase + self.speed * t)\n            frame.append(sample_palette(self.palette, value))\n        return frame\n\ndef generate_frames(show, duration, fps):\n    return [show.frame_at(i / fps) for i in range(int(duration * fps))]\n```",
        "testStrategy": "Unit:\n- Deterministic tests verifying frame counts and RGB shapes for fixed seeds and parameters.\n- Numerical assertions comparing sample frames to expected sine values within tolerance.\n- Confirm outputs remain RGB-only and independent of any RGBW pipeline code paths.\nIntegration:\n- CLI smoke test generating JSON/CSV frames and checking metadata for show parameters.",
        "subtasks": [
          {
            "id": 3,
            "title": "Implement palette sampling and frame generator scaffold",
            "description": "Create shared utilities for palette sampling and time-stepped frame generation used by both show types.",
            "dependencies": [],
            "details": "Add helper functions for normalized palette lookup, easing selection, and a deterministic generate_frames(show, duration, fps) routine with seeded RNG wiring.",
            "status": "done",
            "testStrategy": "Write unit tests ensuring palette sampling returns expected RGB tuples for edge values and frame counts match duration*fps.','parentId':'undefined','updatedAt':'2025-10-16T14:14:54.471Z",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Build SineWaveShow with temporal brightness modulation",
            "description": "Define SineWaveShow producing sine-modulated frames using palette mapping and deterministic seeding.",
            "dependencies": [
              1
            ],
            "details": "Implement constructor capturing palette, led_count, fps, amplitude, speed, duration, optional seed, and frame_at() computing per-LED sine phase with normalized brightness mapped via palette helpers.\n<info added on 2025-10-16T14:28:58.317Z>\nExtend SineWaveShow to honor an optional seed by deriving per-LED phase offsets with hash_int/random_float so identical seeds remain deterministic while different seeds yield distinct brightness evolution; update frame_at to enumerate LEDs with the seeded offsets; thread the CLI seed through generate_show; add tests in tools/tests/test_show_to_prism.py validating seeded variability.\n</info added on 2025-10-16T14:28:58.317Z>",
            "status": "done",
            "testStrategy": "Validate frame_at() against known sine samples, asserting max/min brightness and palette index continuity for small led_counts.','parentId':'undefined','updatedAt':'2025-10-16T14:29:05.789Z",
            "parentId": "undefined"
          },
          {
            "id": 1,
            "title": "Implement palette sampling and frame generator scaffold",
            "description": "Create shared utilities for palette sampling and time-stepped frame generation used by both show types.",
            "dependencies": [],
            "details": "Add helper functions for normalized palette lookup, easing selection, and a deterministic generate_frames(show, duration, fps) routine with seeded RNG wiring.",
            "status": "done",
            "testStrategy": "Write unit tests ensuring palette sampling returns expected RGB tuples for edge values and frame counts match duration*fps.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T14:14:54.471Z"
          },
          {
            "id": 2,
            "title": "Build SineWaveShow with temporal brightness modulation",
            "description": "Define SineWaveShow producing sine-modulated frames using palette mapping and deterministic seeding.",
            "dependencies": [
              1
            ],
            "details": "Implement constructor capturing palette, led_count, fps, amplitude, speed, duration, optional seed, and frame_at() computing per-LED sine phase with normalized brightness mapped via palette helpers.\n<info added on 2025-10-16T14:28:58.317Z>\nExtend SineWaveShow to honor an optional seed by deriving per-LED phase offsets with hash_int/random_float so identical seeds remain deterministic while different seeds yield distinct brightness evolution; update frame_at to enumerate LEDs with the seeded offsets; thread the CLI seed through generate_show; add tests in tools/tests/test_show_to_prism.py validating seeded variability.\n</info added on 2025-10-16T14:28:58.317Z>",
            "status": "done",
            "testStrategy": "Validate frame_at() against known sine samples, asserting max/min brightness and palette index continuity for small led_counts.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T14:29:05.789Z"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Plan subtasks for shared frame-generation utilities, implementing sine and morph show classes, handling deterministic seeding/output, and creating regression plus CLI smoke tests.",
        "updatedAt": "2025-10-16T14:57:00.001Z"
      },
      {
        "id": 29,
        "title": "Expose parameterized show CLI with validation",
        "description": "Add robust CLI parameter handling, validation, and metadata recording for show generation.",
        "status": "done",
        "dependencies": [
          "21",
          "22",
          "23",
          "24",
          "28",
          "35"
        ],
        "priority": "medium",
        "details": "Implementation:\n- Extend show CLI to accept `--show`, `--duration`, `--fps`, `--palette`, `--speed`, `--amplitude`, `--seed`, ensuring sensible defaults and bounds.\n- Validate parameter ranges (e.g., fps 1–120, duration >0, amplitude 0–1) with helpful error messages.\n- Record metadata capturing parameter values, generator version, and random seed.\n- Support reproducibility by seeding RNG for morph transitions.\nPseudo-code:\n```python\ndef main():\n    parser = build_parser(\"Generate PRISM show frames\")\n    parser.add_argument(\"--show\", choices=[\"sine\",\"morph\"], required=True)\n    parser.add_argument(\"--duration\", type=float, default=10.0)\n    parser.add_argument(\"--fps\", type=int, default=30)\n    parser.add_argument(\"--speed\", type=float, default=1.0)\n    parser.add_argument(\"--amplitude\", type=float, default=0.5)\n    args = parser.parse_args()\n    validate(args)\n    show = SHOW_FACTORY[args.show](args)\n    frames = generate_frames(show, args.duration, args.fps)\n    write_json(args.output, frames, metadata=args.__dict__)\n```\n",
        "testStrategy": "Unit:\n- Argument parsing tests covering defaults, invalid ranges, and enum validation.\n- Metadata snapshot tests ensuring reproducible output given fixed seed.\nIntegration:\n- End-to-end CLI run verifying generated frames respect fps/duration (frame count = fps*duration).\nRegression:\n- Fuzzer-style test feeding random parameter combinations within bounds to ensure no crashes.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement CLI argument parsing and validation",
            "description": "Extend the show CLI to accept new parameters and enforce required constraints.",
            "dependencies": [],
            "details": "Add parser options for show selection, timing, palette, speed, amplitude, and seed, then guard each with range checks and descriptive error messages.",
            "status": "pending",
            "testStrategy": "Add unit coverage for defaults, enum enforcement, and invalid boundary cases.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Persist metadata and seed controlled RNG",
            "description": "Ensure the CLI records execution metadata and uses deterministic random seeding for reproducible shows.",
            "dependencies": [
              1
            ],
            "details": "Capture parsed argument values plus generator version into the metadata payload and initialize RNG from the provided seed before morph generation executes.",
            "status": "pending",
            "testStrategy": "Create metadata serialization tests confirming seed and version fields are stored and RNG seeding produces stable sequences.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Author integration tests for frame generation reproducibility",
            "description": "Verify end-to-end CLI behavior for frame counts and deterministic output with seeding.",
            "dependencies": [
              1,
              2
            ],
            "details": "Run the CLI in test mode to confirm output frame count equals fps times duration and that identical seeds produce matching frame data runs.",
            "status": "pending",
            "testStrategy": "Add integration scenario invoking the CLI twice with the same seed, asserting identical outputs and correct frame totals.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Outline tasks for expanding CLI argument parsing/validation, persisting metadata with deterministic RNG seeding, and adding integration tests that confirm reproducible frame generation.",
        "updatedAt": "2025-10-16T14:57:00.790Z"
      },
      {
        "id": 30,
        "title": "Prototype .prism v1.1 packaging pipeline",
        "description": "Convert generated frame sequences into .prism v1.1 files with headers and CRC checks.",
        "status": "done",
        "dependencies": [
          "21",
          "22",
          "23",
          "24",
          "28",
          "29",
          "36",
          "39"
        ],
        "priority": "medium",
        "details": "Implementation:\n- Implement `tools/prism_packaging.py` to read JSON frame payloads and serialize into .prism format per firmware spec (header, payload length, CRC32).\n- Enforce size caps and align frames to expected byte ordering (RGB or RGBW depending on metadata).\n- Add CLI (`--input`, `--output`, `--format prism11`) and update README for workflow.\n- Provide pluggable checksum strategy to stay firmware-agnostic.\nPseudo-code:\n```python\ndef write_prism(input_json, out_path):\n    data = load_json(input_json)\n    header = struct.pack(\"<4sIHH\", b\"PRSM\", VERSION, frame_count, led_count)\n    payload = encode_frames(data[\"data\"])\n    crc = zlib.crc32(header + payload) & 0xFFFFFFFF\n    with open(out_path, \"wb\") as fh:\n        fh.write(header)\n        fh.write(payload)\n        fh.write(struct.pack(\"<I\", crc))\n```\n",
        "testStrategy": "Unit:\n- Header parsing tests ensuring correct magic, version, and CRC calculation using fixture frames.\n- Negative tests for oversized payloads and unsupported channel counts.\nIntegration:\n- Round-trip test reading produced .prism file with firmware parser stub to confirm compatibility.\nRegression:\n- Binary diff tests verifying determinism across repeated runs with same inputs.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement frame payload encoder",
            "description": "Build payload encoder converting JSON frame arrays into binary buffers that follow .prism v1.1 channel layout rules.",
            "dependencies": [],
            "details": "Parse metadata to detect RGB versus RGBW frames, enforce per-frame size limits, pack color tuples into contiguous little-endian byte streams, and expose helpers for alignment padding.",
            "status": "pending",
            "testStrategy": "Create unit fixtures for RGB/RGBW frames and assert packed bytes match expected ordering and size caps.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement header and CRC writer",
            "description": "Create header serialization and CRC32 routines for .prism v1.1 output files.",
            "dependencies": [
              1
            ],
            "details": "Assemble magic, version, frame count, and LED count into the prescribed little-endian struct, append payload length metadata, then compute and append CRC32 using pluggable checksum implementations.",
            "status": "pending",
            "testStrategy": "Write unit tests confirming header fields, payload length, and CRC outputs align with known-good vectors and that alternate checksum strategies plug in cleanly.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add CLI wrapper and documentation updates",
            "description": "Expose packaging functionality through CLI flags and document the workflow updates.",
            "dependencies": [
              1,
              2
            ],
            "details": "Add argparse entry point in tools CLI supporting --input, --output, --format prism11, integrate encoder and serializer modules, and refresh README with usage steps and checksum strategy notes.",
            "status": "pending",
            "testStrategy": "Run CLI integration tests invoking the command with sample JSON inputs to verify output file creation and argument validation.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Validate round-trip against parser fixtures",
            "description": "Confirm generated .prism files deserialize correctly using existing parser fixtures.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Generate sample packages via CLI, feed them through firmware parser stubs or fixture scripts, and compare recovered headers and frames against originals to ensure deterministic results.",
            "status": "pending",
            "testStrategy": "Add regression test that builds a sample file, parses it with the fixture reader, and asserts header values, frame payloads, and CRC checks all match expected data.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Sequence subtasks for frame payload encoding, header/CRC serialization, CLI wiring/documentation, and round-trip validation against firmware parsers.",
        "updatedAt": "2025-10-16T15:01:37.365Z"
      },
      {
        "id": 31,
        "title": "Set Up Research Memo Framework",
        "description": "Create reusable structure and tooling for PRISM K1 research memos and source logging.",
        "details": "Deliverable: docs/research/_template.md plus README guidance.\nImplementation outline:\n- Review existing docs/research/ layout and confirm file naming conventions from PRD.\n- Author Markdown template capturing sections: Problem, Options, Evaluation (quant + qual), Decision, Migration Plan, Action Items, Source Log (with provider/date fields).\n- Add checklist for scope/timeboxing and risk notes.\nPseudo-code:\n```\npseudo:\nif not exists(\"docs/research/_template.md\"):\n    write_template()\nupdate_readme(sections=[\"How to instantiate memo\", \"Source logging policy\"])\n```\n- Document workflow in docs/research/README.md including command snippet for copying template before starting each memo.\n- Record catalog of preferred 2024+ references (OKLab updates, LED calibration papers, ESP32-S3 benchmarks).",
        "testStrategy": "Run doc linting (markdownlint) on new template and README, verify sections match PRD validation checklist, and dry-run template instantiation via copy command.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Author research memo template markdown",
            "description": "Draft the reusable docs/research memo template with required sections and checklists.",
            "dependencies": [],
            "details": "Create docs/research/_template.md capturing Problem, Options, Evaluation (quant+qual), Decision, Migration Plan, Action Items, and Source Log fields plus scope/timeboxing and risk checklists.",
            "status": "done",
            "testStrategy": "Run markdownlint on docs/research/_template.md to confirm formatting and section headings meet PRD checklist.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T12:20:57.697Z"
          },
          {
            "id": 2,
            "title": "Document memo workflow and references in README",
            "description": "Update docs/research/README.md with template usage instructions and reference catalog.",
            "dependencies": [
              1
            ],
            "details": "Describe how to instantiate new memos via copy command, outline source logging policy, include workflow notes, and add catalog of preferred 2024+ references for OKLab, LED calibration, and ESP32-S3 benchmarks.",
            "status": "pending",
            "testStrategy": "Lint updated README with markdownlint and verify copy command and reference list render correctly in preview.",
            "parentId": "undefined"
          }
        ],
        "complexity": 3,
        "recommendedSubtasks": 2,
        "expansionPrompt": "Plan subtasks for drafting the reusable memo template and documenting the workflow/reference catalog in the research README.",
        "updatedAt": "2025-10-16T12:20:59.502Z"
      },
      {
        "id": 32,
        "title": "Research Firmware Decode Budget Envelope (R1.1)",
        "description": "Measure safe per-frame decode CPU and memory budgets on target S3 hardware.",
        "details": "Deliverable: docs/research/R1.1_firmware_decode_budget.md with benchmarks.\nImplementation outline:\n- Assemble minimal decode harness on ESP32-S3 with FreeRTOS timers emulating 120 FPS loop and 160 LED buffer.\n- Profile CPU cycles, heap usage, and flash bandwidth for representative decode kernels (palette lookup, delta+rle decode) using ESP-IDF 5.x perf counters.\nPseudo-code:\n```\nsetup_decoder_harness()\nfor payload in test_payloads:\n    start_timer(120fps)\n    cycles = measure_cycles(run_decode(payload))\n    record(payload.name, cycles, heap_free())\n```\n- Compare results against 8.33 ms/frame budget and annotate headroom for future features.\n- Summarize calibration methodology, toolchain versions, and measurement limitations.",
        "testStrategy": "Repeat measurements across at least three runs, export CSV of cycles/heap, validate variance <5%, attach profiler screenshots/logs to memo, and peer review numbers with firmware engineer.",
        "priority": "medium",
        "dependencies": [
          "31"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement ESP32-S3 decode benchmarking harness",
            "description": "Create firmware harness that emulates 120 FPS loop and captures perf counters.",
            "dependencies": [],
            "details": "Set up FreeRTOS timer, allocate 160 LED buffer, integrate ESP-IDF 5.x perf counters, and stub payload loader.",
            "status": "pending",
            "testStrategy": "Run `idf.py build flash monitor` confirming loop timing and perf counter outputs match expected cadence.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Profile representative payload decodes",
            "description": "Execute benchmarking harness across palette and delta RLE payload sets.",
            "dependencies": [
              1
            ],
            "details": "Load curated payload set, capture CPU cycles, heap usage, and flash bandwidth over three runs, export raw readings to CSV.",
            "status": "pending",
            "testStrategy": "Automate three-run sampling script verifying variance under 5% and spot-check profiler logs for each payload class.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Compile firmware decode budget memo",
            "description": "Synthesize collected data into research memo with methodology and findings.",
            "dependencies": [
              1,
              2
            ],
            "details": "Summarize harness setup, toolchain versions, calibration method, analyze headroom versus 8.33 ms budget, attach CSV and logs.",
            "status": "pending",
            "testStrategy": "Peer review memo against template, verify referenced data artifacts exist, and lint Markdown before submission.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break work into building the ESP32-S3 benchmarking harness, capturing/aggregating decode metrics across payloads, and authoring the research memo with methodology and findings.",
        "updatedAt": "2025-10-16T12:21:01.811Z"
      },
      {
        "id": 33,
        "title": "Decide PRISM v1 Color Space & Palette Authoring Strategy (R3.1)",
        "description": "Evaluate candidate perceptual color spaces and recommend migration plan for palette tooling.",
        "details": "Deliverable: docs/research/R3.1_color_space_decision.md.\nImplementation outline:\n- Compare OKLab/OKLCH, HSLuv, HSV/HSL using sample 2–3 stop ramps at 160 LEDs, measuring ΔE, hue constancy, and UX implications.\n- Benchmark performance in TypeScript (tooling) and microcontroller conversions; document licensing constraints.\nPseudo-code:\n```\nfor space in [OKLCH, HSLuv, HSV]:\n    palette = generate_ramp(space, stops)\n    metrics = compute_delta_e(palette)\n    render_preview(space, palette)\n    log(space, metrics)\n```\n- Provide migration plan outlining palette storage, conversion helpers, and fallback strategy.\n- Include recommended libraries (latest OKLab refs, 2024 updates) and testing hooks for presets.",
        "testStrategy": "Validate ΔE calculations with unit tests, review renders in tooling preview, solicit sign-off from palette tooling owner, and ensure memo includes Pros/Cons matrix plus migration steps.",
        "priority": "medium",
        "dependencies": [
          "31"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Evaluate color ramps across candidate spaces",
            "description": "Generate sample ramps and capture perceptual metrics for OKLCH, HSLuv, and HSV.",
            "dependencies": [],
            "details": "Produce 2-3 stop ramps at 160 LEDs per space, record ΔE, hue drift, UX notes, and archive visual previews.",
            "status": "pending",
            "testStrategy": "Validate ΔE computations against trusted colorimetry library and have tooling lead review preview captures.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Benchmark tooling and firmware conversions",
            "description": "Measure palette conversion performance and review licensing constraints.",
            "dependencies": [
              1
            ],
            "details": "Profile TypeScript and microcontroller conversions using gathered ramps, note memory/CPU budgets, and document library licensing or patent risks.",
            "status": "pending",
            "testStrategy": "Compare measured timings with prior firmware budgets and confirm licensing conclusions with legal checklist.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Draft migration strategy and recommendation memo",
            "description": "Synthesize findings into the color space decision document with migration plan.",
            "dependencies": [
              1,
              2
            ],
            "details": "Author docs/research/R3.1_color_space_decision.md covering metrics summary, pros/cons matrix, storage plan, helper APIs, fallbacks, and testing hooks.",
            "status": "pending",
            "testStrategy": "Peer review memo outline with palette tooling owner and verify checklist covers migration steps before sign-off.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Lay out tasks for evaluating color ramps across candidate spaces, benchmarking tooling/firmware performance plus licensing, and drafting the recommendation memo with migration steps.",
        "updatedAt": "2025-10-16T12:21:00.315Z"
      },
      {
        "id": 34,
        "title": "Define RGB→RGBW Mapping Strategy (R3.2)",
        "description": "Select baseline RGBW conversion and calibration roadmap aligned with color decision.",
        "details": "Deliverable: docs/research/R3.2_rgbw_strategy.md.\nImplementation outline:\n- Evaluate HSI-based mapping vs whiteness extraction + SK6812 calibration for pastel and saturated samples using outputs from task 33.\n- Model luminous efficiency and CCT options (e.g., 4500K, 6000K) considering firmware cost.\nPseudo-code:\n```\nfor method in [HSI_map, whiteness_extract]:\n    for color in sample_palette:\n        rgbw = method(color)\n        error = compare_to_target(rgbw)\n        record(method, color, error)\n```\n- Propose staged calibration plan (lab jig, factory QC) with tooling hooks.\n- Document integration points for dev tools and firmware runtime, referencing latest SK6812 datasheets.",
        "testStrategy": "Run comparative plots of luminance error, validate mapping with lab measurements or calibrated photodiode data, and peer review roadmap with hardware team.",
        "priority": "medium",
        "dependencies": [
          "31",
          "33"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Assemble RGB→RGBW evaluation harness",
            "description": "Consolidate task 33 palette outputs and build scripts to compare HSI versus whiteness extraction mappings.",
            "dependencies": [],
            "details": "Gather pastel and saturated samples, implement looping harness matching provided pseudocode, and log per-method color error metrics.",
            "status": "pending",
            "testStrategy": "Run harness on a small palette subset and confirm error logging matches manual calculations for at least two colors.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Model luminous efficiency and CCT options",
            "description": "Quantify luminous flux and firmware cost impacts for candidate CCTs using the evaluation results.",
            "dependencies": [
              1
            ],
            "details": "Use recorded RGBW errors to evaluate 4500K and 6000K configurations, estimate power budgets, and note firmware compute/storage overheads for each mapping.",
            "status": "pending",
            "testStrategy": "Cross-check modeled efficiency numbers against existing SK6812 datasheet curves and flag discrepancies beyond 5%.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Document RGBW mapping strategy and calibration plan",
            "description": "Produce the deliverable detailing the chosen mapping approach, calibration stages, and integration hooks.",
            "dependencies": [
              1,
              2
            ],
            "details": "Summarize findings in docs/research/R3.2_rgbw_strategy.md, outline lab jig and factory QC steps, and list firmware/tooling integration touchpoints with references.",
            "status": "pending",
            "testStrategy": "Peer review document with hardware team to ensure calibration roadmap and integration notes cover lab and production needs.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Plan subtasks to build the RGB→RGBW evaluation harness, model luminous efficiency/CCT trade-offs, and write the strategy plus calibration roadmap memo.",
        "updatedAt": "2025-10-16T12:21:05.696Z"
      },
      {
        "id": 35,
        "title": "Select Launch Show Generator Families (R3.3)",
        "description": "Identify 2–3 show algorithm families optimized for 160 LEDs and compression.",
        "details": "Deliverable: docs/research/R3.3_show_families.md.\nImplementation outline:\n- Survey literature/repos (2024 best-of) for phase waves, noise morphs, flow fields with strong compression traits.\n- Prototype small generators in Python/TypeScript, evaluating parameter richness, memory footprint, and visual fidelity.\nPseudo-code:\n```\nfor family in candidate_families:\n    params = sample_parameters(family)\n    frames = simulate_show(family, params, led_count=160)\n    score = evaluate_visual_and_size(frames)\n    log_result(family, score)\n```\n- Define parameter schema JSON for each selected family and outline preset starter pack.\n- Include compression test results using planned packaging options.",
        "testStrategy": "Collect subjective review clips, compute compression ratio vs SSIM, and run design critique with tooling + content teams before finalizing memo.",
        "priority": "medium",
        "dependencies": [
          "31"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Survey compression-friendly show generators",
            "description": "Compile candidate show algorithm families optimized for 160-LED compression use.",
            "dependencies": [],
            "details": "Review 2024 literature, repos, and demo showcases for phase waves, noise morphs, and flow fields noting compression traits and parameter richness.",
            "status": "pending",
            "testStrategy": "Log all sources and selection criteria; peer review list for coverage gaps.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Prototype and score candidate families",
            "description": "Implement lightweight prototypes to evaluate visual quality, parameter range, and compression metrics.",
            "dependencies": [
              1
            ],
            "details": "Build Python/TypeScript harness that samples parameters, simulates 160-LED frames, runs compression tests, and records size, SSIM, and subjective notes per family.",
            "status": "pending",
            "testStrategy": "Automate harness to output metric tables; verify repeatability on at least two machines.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Document selected families and schemas",
            "description": "Summarize chosen generator families, parameter schemas, and starter presets in deliverable file.",
            "dependencies": [
              1,
              2
            ],
            "details": "Draft docs/research/R3.3_show_families.md capturing top families, JSON schema definitions, recommended presets, and compression findings with rationale.",
            "status": "pending",
            "testStrategy": "Run documentation lint/format check and request cross-team review for clarity and completeness.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Outline work for surveying candidate generator families, prototyping/scoring them for compression and fidelity, and documenting schemas plus starter presets in the memo.",
        "updatedAt": "2025-10-16T12:21:01.071Z"
      },
      {
        "id": 36,
        "title": "Analyze Packaging Trade-offs for .prism Sequences (R3.4)",
        "description": "Compare encoding approaches for palette+indices, delta encoding, and RLE under firmware constraints.",
        "details": "Deliverable: docs/research/R3.4_packaging_tradeoffs.md.\nImplementation outline:\n- Use outcomes from tasks 32 and 35 to model data rates for 16s @120 FPS, 160 LEDs.\n- Prototype encoders in Python to measure size vs decode cycles.\nPseudo-code:\n```\nfor codec in [palette_indices, delta, rle, hybrid]:\n    compressed = codec.encode(sample_frames)\n    cycles = measure_decode_cycles(codec, sample_frames)\n    report(codec, len(compressed), cycles)\n```\n- Evaluate streaming feasibility on ESP32-S3 with buffer constraints and document guardrails (max frame size, burst limits).\n- Recommend encoding(s) and enforcement rules for tooling export.",
        "testStrategy": "Unit test encoder prototypes, run timing harness on hardware or simulator, verify results align with budget from task 32, and capture benchmark tables/plots in memo.",
        "priority": "medium",
        "dependencies": [
          "32",
          "35"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Prototype candidate sequence encoders in Python",
            "description": "Build working palette+indices, delta, RLE, and hybrid encoder/decoder stubs using shared sample frames.",
            "dependencies": [],
            "details": "Implement codec classes covering encode/decode paths, reuse data gathered in tasks 32 and 35, and prepare hooks for instrumentation and cycle measurement.",
            "status": "pending",
            "testStrategy": "Create unit tests ensuring round-trip fidelity for each codec on representative sample frame sets.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Benchmark compression ratios and decode cycle budgets",
            "description": "Measure output sizes and decode performance of each codec against ESP32-S3 budget targets.",
            "dependencies": [
              1
            ],
            "details": "Integrate timing and size logging into prototypes, collect decode cycle counts, memory usage, and buffer behavior to compare with task 32 firmware envelopes.",
            "status": "pending",
            "testStrategy": "Run automated benchmark harness across multiple frame captures, export CSV summaries, and verify values stay within task 32 limits.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Draft packaging trade-off memo with enforcement rules",
            "description": "Document comparative analysis, streaming guardrails, and recommended tooling policies in the required memo.",
            "dependencies": [
              1,
              2
            ],
            "details": "Summarize benchmark findings, highlight feasible codecs, specify frame size/burst guardrails, and capture enforcement rules in docs/research/R3.4_packaging_tradeoffs.md.",
            "status": "pending",
            "testStrategy": "Conduct peer review of the memo and double-check calculations against benchmark data before finalization.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Plan tasks for prototyping candidate encoders/decoders, benchmarking compression and decode cycles against budget envelopes, and authoring the trade-off memo with enforcement guidance.",
        "updatedAt": "2025-10-16T12:21:03.332Z"
      },
      {
        "id": 37,
        "title": "Develop Preview Mapping Guidelines (R3.5)",
        "description": "Define gamma and saturation adjustments so terminal/HTML previews match LED output.",
        "details": "Deliverable: docs/research/R3.5_preview_guidelines.md.\nImplementation outline:\n- Analyze LED gamma curves (from calibration data) and compare to sRGB/linear previews.\n- Evaluate tone-mapping and saturation strategies for different browsers/terminal color spaces.\nPseudo-code:\n```\nfor mapping in candidate_mappings:\n    preview = apply_mapping(mapping, sample_frames)\n    delta = compare_led_capture(preview, led_capture)\n    record(mapping, delta)\n```\n- Recommend preview pipeline parameters and fallback path when hardware measurements unavailable.\n- Provide doc snippet for tooling integration tasks 26/27.",
        "testStrategy": "Cross-check preview frames against HDR photos/video of actual LEDs, collect feedback from tooling/QA, and ensure memo includes parameter tables plus validation methodology.",
        "priority": "medium",
        "dependencies": [
          "33"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Aggregate LED calibration datasets",
            "description": "Collect and summarize LED calibration curves alongside preview reference baselines for comparison.",
            "dependencies": [],
            "details": "Pull recent photometric captures, normalize gamma curves against sRGB and linear preview references, and archive comparison plots for later analysis.",
            "status": "pending",
            "testStrategy": "Verify extracted curves match source calibration logs by spot-checking sample timestamps and luminance values.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Prototype preview gamma and saturation mappings",
            "description": "Experiment with candidate tone-mapping and saturation pipelines using sample frames and measure error to LED captures.",
            "dependencies": [
              1
            ],
            "details": "Implement evaluation loop that applies candidate mappings to representative frames, computes LED delta metrics per browser/terminal color space, and ranks results.",
            "status": "pending",
            "testStrategy": "Plot delta metrics and confirm the selected mapping improves error versus the baseline preview configuration.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Document recommended preview parameters and fallback flow",
            "description": "Write guidelines summarizing recommended parameters, fallback assumptions, and cross-team integration notes.",
            "dependencies": [
              1,
              2
            ],
            "details": "Draft docs/research/R3.5_preview_guidelines.md with gamma and saturation tables, fallback procedure when measurements are unavailable, and integration snippet for tooling tasks 26 and 27.",
            "status": "pending",
            "testStrategy": "Request tooling team review to confirm parameter tables, fallback instructions, and integration notes address their requirements.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Define subtasks for aggregating LED calibration datasets, prototyping gamma/saturation mappings across preview targets, and documenting recommended parameters plus fallbacks.",
        "updatedAt": "2025-10-16T12:21:02.589Z"
      },
      {
        "id": 38,
        "title": "Specify Parser Metadata Extensions v1.1 (R2.1)",
        "description": "Propose new metadata tags to capture palette/ramp details and show parameters.",
        "details": "Deliverable: docs/research/R2.1_metadata_extensions.md.\nImplementation outline:\n- Use outputs from tasks 33 and 35 to define `palette_id`, `ramp_space`, and show parameter encoding structures.\n- Draft JSON schema fragments and backward compatibility notes.\nPseudo-code:\n```\nspec = Schema()\nspec.add_field(\"palette_id\", type=\"string\", required=True)\nspec.add_field(\"ramp_space\", enum=[\"oklch\",\"hsluv\"], default=\"oklch\")\nspec.extend(\"show_params\", schema=family_param_schemas)\n```\n- Evaluate tooling impact (serialization/deserialization) and migration plan for existing assets.\n- Document any interaction with research provider metadata logging.",
        "testStrategy": "Validate schema with sample files using JSON Schema validator, run round-trip parse tests in parser prototype, and review memo with Agent 2 (parser/format owner).",
        "priority": "medium",
        "dependencies": [
          "33",
          "35"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Draft palette and show metadata schema fragments",
            "description": "Consolidate outputs from tasks 33 and 35 to define palette and show parameter metadata additions for v1.1.",
            "dependencies": [],
            "details": "Author JSON schema fragments for palette_id, ramp_space, and show_params fields, including required flags, enums, defaults, and inline compatibility annotations with v1.0.",
            "status": "pending",
            "testStrategy": "Validate the draft fragments with the project JSON Schema validator and ensure they load alongside existing v1.0 definitions.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Validate backward compatibility with sample assets",
            "description": "Exercise draft schema against representative legacy and new sample assets to confirm compatibility.",
            "dependencies": [
              1
            ],
            "details": "Apply the updated schema to a curated set of legacy show files and newly generated palettes to confirm required fields and defaults align with migration expectations.",
            "status": "pending",
            "testStrategy": "Run round-trip parse and serialize tests on sample assets and capture any mismatches or validation errors.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Document tooling and firmware impact in memo",
            "description": "Summarize schema changes, parser implications, and migration steps in the R2.1 memo.",
            "dependencies": [
              1,
              2
            ],
            "details": "Update docs/research/R2.1_metadata_extensions.md with schema rationale, serialization/deserialization updates, firmware parser adjustments, and migration guidance referencing validation outcomes.",
            "status": "pending",
            "testStrategy": "Peer-review the memo with firmware and tooling stakeholders to confirm accuracy and completeness.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Plan work to draft the JSON schema fragments for new metadata, validate them against sample assets, and document tooling/firmware impacts with migration guidance.",
        "updatedAt": "2025-10-16T12:21:04.107Z"
      },
      {
        "id": 39,
        "title": "Assess Header and CRC Implications for v1.1 Format (R2.2)",
        "description": "Confirm header layout supports new metadata fields and ensure CRC coverage and streaming remain valid.",
        "details": "Deliverable: docs/research/R2.2_header_crc_implications.md.\nImplementation outline:\n- Extend existing v1.0 header diagram with new offsets for metadata from task 38.\n- Simulate streaming scenarios with partial frames to ensure CRC coverage protects new fields without regressions.\nPseudo-code:\n```\nheader = build_header(v1_1_fields)\ncrc = compute_crc(header + payload)\nassert validate_streaming(header, crc) == True\n```\n- Evaluate impact on tooling exporters and firmware parsers; recommend guardrails or version bump strategy.\n- Document compatibility with existing CRC polynomial and suggest tests for future implementations.",
        "testStrategy": "Run parser unit tests with mutated headers, confirm CRC failure cases trigger expected errors, and obtain sign-off from firmware + parser stakeholders.",
        "priority": "medium",
        "dependencies": [
          "38"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Model v1.1 header layout offsets",
            "description": "Review the v1.0 header map and new metadata definitions to draft an updated v1.1 header layout.",
            "dependencies": [],
            "details": "Pull field requirements from task 38 outputs and extend the existing diagram with byte offsets, reserved gaps, and alignment notes, ensuring the total size constraint still holds.",
            "status": "pending",
            "testStrategy": "Cross-check computed offsets against struct layouts in pattern_storage.h and protocol_parser.c to confirm consistent packing.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Simulate streaming CRC coverage paths",
            "description": "Design streaming scenarios to verify CRC coverage over new metadata during partial frame transfers.",
            "dependencies": [
              1
            ],
            "details": "Generate sample headers using the v1.1 layout, mutate payload segments, and run compute_crc plus validate_streaming routines to observe protection of new fields under staggered delivery.",
            "status": "pending",
            "testStrategy": "Automate simulations that compare expected CRC failures and successes, and log any regression versus v1.0 baselines.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Document compatibility and testing guidance",
            "description": "Summarize tooling and firmware impacts and outline guardrails plus regression tests for v1.1 adoption.",
            "dependencies": [
              1,
              2
            ],
            "details": "Capture exporter/parser adjustments, recommend versioning or feature flags, and describe future validation suites in docs/research/R2.2_header_crc_implications.md.",
            "status": "pending",
            "testStrategy": "Request review from firmware and tooling stakeholders and ensure recommended tests cover parser regression, CRC failure handling, and new metadata acceptance.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break work into modeling the updated header layout, simulating streaming/CRC coverage scenarios, and documenting compatibility plus recommended regression tests.",
        "updatedAt": "2025-10-16T12:21:04.882Z"
      },
      {
        "id": 40,
        "title": "Synthesize Cross-Track Decisions and Gating Actions",
        "description": "Consolidate research outputs into release-ready checklist and update downstream task gating.",
        "details": "Deliverable: docs/research/PRISM_K1_decision_rollup.md plus task gating updates.\nImplementation outline:\n- Aggregate recommendations from tasks 32–39 into summary matrix highlighting decisions, owners, and action items for tasks 23, 26–30.\n- Update Task Master/issue tracker notes to gate implementation on completed memos.\nPseudo-code:\n```\nrollup = collect_decisions(tasks=[32,33,34,35,36,37,38,39])\nfor gate in downstream_tasks:\n    gate.dependencies.add(rollup.decision_ids)\nwrite_rollup_doc(rollup)\n```\n- Include risk mitigation follow-ups and reference links to source memos.\n- Share with stakeholders via async review (Slack/email) and capture approvals.",
        "testStrategy": "Verify all memos are linked and marked complete, confirm Task Master dependencies reflect decisions, and solicit stakeholder sign-offs noting any open risks.",
        "priority": "medium",
        "dependencies": [
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Aggregate decisions and action owners",
            "description": "Collect key decisions, owners, and action items from memos 32–39.",
            "dependencies": [],
            "details": "Review completed research memos (tasks 32-39), capture decision summaries, owners, action items, risk notes, and source links into a normalized matrix for downstream use.",
            "status": "pending",
            "testStrategy": "Cross-check each memo to confirm every decision, owner, and action item is captured with links to the original document.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update downstream task gating records",
            "description": "Reflect aggregated decisions in Task Master dependencies for tasks 23 and 26–30.",
            "dependencies": [
              1
            ],
            "details": "Use Task Master or issue tracker tooling to add dependency references from tasks 23 and 26-30 to the synthesized decision IDs, ensuring gating prevents implementation without required memos.",
            "status": "pending",
            "testStrategy": "Verify updated tasks show the new dependencies and run `task-master validate-dependencies` to confirm no errors.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Draft decision roll-up document and approval log",
            "description": "Author docs/research/PRISM_K1_decision_rollup.md with risks, mitigations, and approval tracking.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create the roll-up markdown summarizing the decision matrix, downstream gating impacts, risk mitigations, stakeholder contact list, and async review plan, then share via Slack/email and log approvals.",
            "status": "pending",
            "testStrategy": "Review document for completeness against checklist, confirm stakeholder notifications sent, and record received approvals or open follow-ups.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Plan subtasks for aggregating decisions/action owners from completed memos, updating Task Master dependencies for gated implementation tasks, and writing the decision roll-up with approvals.",
        "updatedAt": "2025-10-16T12:21:06.524Z"
      },
      {
        "id": 41,
        "title": "Establish Tauri + React Studio Foundation",
        "description": "Create the PRISM Studio desktop workspace with consistent tooling, cross-platform builds, and shared configuration.",
        "details": "- Use Tauri 2.0.0 with Rust 1.78+, Node 20.x, pnpm 9, Vite 5.2, React 18.2, TypeScript 5.6, and SWC for fast rebuilds.\n- Configure workspace structure per PRD (`apps/studio` for UI, `src-tauri` for backend) and set up shared `eslint@9` + `typescript-eslint` + `prettier` rules with project references.\n- Enable Tauri security best practices: CSP headers, updater disabled (phase 1), `allowlist.fs.scope` limited to project dir, and `tauri-plugin-log` for structured logging.\n- Provision `vitest` with jsdom + happy-dom for UI tests, `playwright@1.45` for E2E, and `cargo-nextest` for Rust tests.\n- CI scaffold: GitHub Actions matrix (macOS 14, windows-2025, ubuntu-24.04) running `pnpm lint`, `pnpm test`, `cargo clippy --all-targets -- -D warnings`, and packaging via `tauri-action@v0`.\nPseudo-code:\n```\npnpm create tauri-app\npnpm add -D @vitejs/plugin-react-swc eslint prettier vitest playwright\ncargo add anyhow tokio --features full thiserror tracing\n```\n- Document developer bootstrap in `docs/CONTRIBUTING.md` and add Husky pre-commit hook running `pnpm lint && pnpm test --runInBand`.",
        "testStrategy": "- Run `pnpm lint` to ensure ESLint/Prettier/TypeScript wiring.\n- Verify `pnpm tauri dev` launches shell window on macOS and Windows runners.\n- CI dry run: execute GitHub Actions workflow locally via `act` or manual triggers to ensure artifacts build.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold Tauri and React workspace",
            "description": "Initialize the PRISM Studio desktop project structure with the required Tauri, React, and pnpm foundations.",
            "dependencies": [],
            "details": "Run the Tauri 2 scaffolding commands to generate `apps/studio` and `src-tauri`, align versions to the PRD, and commit baseline config files.",
            "status": "done",
            "testStrategy": "Execute `pnpm tauri dev` to confirm the shell app launches with the generated scaffold.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T17:48:23.329Z"
          },
          {
            "id": 2,
            "title": "Configure shared linting and TypeScript rules",
            "description": "Establish unified ESLint, TypeScript, and Prettier settings reused across the workspace.",
            "dependencies": [
              1
            ],
            "details": "Add workspace-level ESLint 9 + typescript-eslint presets, share TS project references, and ensure Vite/React SWC tooling consumes the shared configs.",
            "status": "done",
            "testStrategy": "Run `pnpm lint` inside the workspace to verify the shared configuration applies without errors.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T18:11:35.875Z"
          },
          {
            "id": 3,
            "title": "Apply Tauri security baseline",
            "description": "Implement the phase-one security hardening items for the Tauri backend.",
            "dependencies": [
              1
            ],
            "details": "Set CSP headers, disable the updater, constrain `allowlist.fs.scope`, and integrate `tauri-plugin-log` with structured output per PRD guidance.",
            "status": "done",
            "testStrategy": "Launch the app and inspect generated `tauri.conf.json` plus runtime logs to ensure the security constraints are active.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T18:24:05.086Z"
          },
          {
            "id": 4,
            "title": "Provision JavaScript and Rust test harnesses",
            "description": "Install and configure Vitest, Playwright, and cargo-nextest for Studio testing.",
            "dependencies": [
              1,
              2
            ],
            "details": "Wire Vitest with jsdom and happy-dom, add Playwright E2E scaffolding, and enable cargo-nextest in `src-tauri` with sample smoke tests.",
            "status": "pending",
            "testStrategy": "Run `pnpm test`, `pnpm playwright test --list`, and `cargo nextest run` to confirm each harness executes.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Set up cross-platform CI matrix",
            "description": "Create the GitHub Actions workflow that builds and tests the Studio across supported OS targets.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Define matrix jobs for macOS 14, windows-2025, ubuntu-24.04 running lint, JS/Rust tests, Clippy, and package builds via `tauri-action@v0`.",
            "status": "pending",
            "testStrategy": "Trigger the workflow (or dry-run with `act`) to ensure each matrix job installs deps and completes successfully.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Document developer bootstrap workflow",
            "description": "Capture setup steps and tooling usage in `docs/CONTRIBUTING.md`.",
            "dependencies": [
              1,
              2,
              4,
              5
            ],
            "details": "Outline prerequisites, install commands, testing instructions, and CI expectations so contributors can reproduce the environment locally.",
            "status": "pending",
            "testStrategy": "Have a teammate follow the documented steps on a clean machine to validate clarity and completeness.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Configure Husky pre-commit guard",
            "description": "Add Husky hooks enforcing linting and testing before commits.",
            "dependencies": [
              2,
              4,
              6
            ],
            "details": "Install Husky, create `.husky/pre-commit` running `pnpm lint && pnpm test -- --runInBand`, and ensure scripts integrate with pnpm lifecycle hooks.",
            "status": "pending",
            "testStrategy": "Run `HUSKY=1 pnpm lint && pnpm test` via a simulated commit (`pnpm husky run pre-commit`) to confirm the hook blocks failures.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Lay out steps for scaffolding the Tauri workspace, configuring shared lint/TypeScript tooling, applying security hardening, provisioning test harnesses, setting up CI, documenting contributor onboarding, and adding Husky hooks.",
        "updatedAt": "2025-10-16T18:25:29.944Z"
      },
      {
        "id": 42,
        "title": "Implement Device Discovery and Connection Services",
        "description": "Deliver cross-platform mDNS discovery, WebSocket session management, and device metadata exchange between Tauri backend and React UI, leveraging the completed firmware command set (55-58) and the `prism-k1.local` mDNS host.",
        "status": "done",
        "dependencies": [
          "41",
          "56",
          "58"
        ],
        "priority": "medium",
        "details": "- Rust `src-tauri`: keep `mdns-sd 0.11`, `tokio-tungstenite 0.23`, `axum 0.7`, and `serde` for message structs; ensure workspace build flags align with firmware protocol enums 55-58.\n- Implement async discovery task targeting the published `_prism-k1._tcp.local.` service and resolving hostnames/IPs for `prism-k1.local`, yielding `DeviceInfo` entries enriched with firmware readiness flags.\n- Define `HELLO` request via WebSocket TLV per ADR-010; chain STATUS, LIST, and DELETE command helpers using the finalized firmware payload formats with byte-order validation and CRC checks.\n- Maintain connection pool with reconnection/backoff (100ms→2s), reuse live STATUS polling to detect stale sessions, and persist the last responsive device via `tauri-plugin-store` (OS keychain backed).\n- Map errors to actionable UI codes (`NO_DEVICE`, `NETWORK_TIMEOUT`, `HELLO_UNSUPPORTED`, `STATUS_UNAVAILABLE`) and expose typed IPC commands (`device_discover`, `device_connect`, `device_status`, `device_list`, `device_delete`).\n- Frontend `device/manager.ts`: Zustand slice pushes discovery results, issues connect + status/list/delete calls, and emits toasts for troubleshooting based on firmware command responses.\n- Add network health indicator (latency via ping TLV request every 5s; degrade UI if >150ms) and surface reconnect CTA when STATUS polling fails.",
        "testStrategy": "- Rust: `cargo test -- --nocapture device::tests` covering mDNS discovery against `prism-k1.local`, HELLO/STATUS/LIST decode, and reconnect logic with `tokio::test` + `assert_matches!` for error codes.\n- Integration: Playwright test spins mock WS server (`ws://localhost:8081`) exercising HELLO→STATUS→LIST→DELETE flows using current firmware TLV schemas.\n- Manual QA: validate discovery on LAN with real firmware, confirm STATUS/LIST/DELETE command handling, and throttle/wifi-off scenarios to ensure error surfacing and last-connected device persistence.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Rust mDNS discovery service",
            "description": "Create async discovery flow to enumerate `_prism-k1._tcp.local` devices via mdns-sd and expose DeviceInfo structures.",
            "dependencies": [],
            "details": "Add mdns-sd dependency usage to resolve `prism-k1.local` hosts, wire ServiceDaemon browse loop, collect resolved records into strongly typed DeviceInfo list with firmware capability flags, and ensure resolver teardown.",
            "status": "pending",
            "testStrategy": "Rust unit test simulating mdns ServiceEvent stream that yields `prism-k1.local` entries to confirm DeviceInfo conversion and loop termination when discovery is ready-state verified.\n\n",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Handle WebSocket HELLO negotiation",
            "description": "Establish WebSocket session handling that performs ADR-010 HELLO TLV exchange and parses firmware metadata response.",
            "dependencies": [
              1
            ],
            "details": "Use tokio-tungstenite to initiate session, send HELLO payload, then chain STATUS/LIST readiness probes with byte-order and CRC validation, serializing metadata via serde.",
            "status": "pending",
            "testStrategy": "Rust async test using mock ws server to assert HELLO, STATUS, and LIST request bytes and parsed firmware structures for the completed firmware command set.\n\n",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Persist device metadata and error mapping",
            "description": "Map backend errors to defined UI codes and persist last successful device info using tauri-plugin-store.",
            "dependencies": [
              2
            ],
            "details": "Implement error enum translations (`NO_DEVICE`, `NETWORK_TIMEOUT`, `HELLO_UNSUPPORTED`, `STATUS_UNAVAILABLE`), store last device credentials securely, and expose retrieval helpers using the firmware-provided status payloads.",
            "status": "pending",
            "testStrategy": "Rust unit tests verifying error mapping paths and persistence roundtrip through plugin store mock populated with STATUS results.\n\n",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement connection pooling and backoff",
            "description": "Create connection manager that pools active devices, handles reconnection with exponential backoff, and coordinates session lifecycle.",
            "dependencies": [
              2
            ],
            "details": "Maintain async tasks per device with 100ms→2s backoff, track pool state using STATUS health checks, and surface events for reconnect success, delete confirmations, or exhaustion.",
            "status": "pending",
            "testStrategy": "Rust tokio test asserting backoff progression, pool updates, STATUS-triggered reconnect behavior, and delete callback handling.\n\n",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Expose typed IPC commands in Tauri",
            "description": "Add Tauri commands for device discovery, connection, status, listing, and deletion wired to backend logic.",
            "dependencies": [
              3,
              4
            ],
            "details": "Register IPC routes (`device_discover`, `device_connect`, `device_status`, `device_list`, `device_delete`), marshal inputs/outputs via serde types that mirror firmware commands 55-58, and propagate structured errors to UI.",
            "status": "pending",
            "testStrategy": "Rust integration test invoking commands via tauri::test harness to ensure responses and firmware error codes align with UI expectations.\n\n",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Integrate React Zustand device manager",
            "description": "Update frontend `device/manager.ts` slice to consume IPC results, manage discover/connect state, and emit troubleshooting toasts.",
            "dependencies": [
              5
            ],
            "details": "Define Zustand state for device list, active session, STATUS metadata, and toast triggers sourced from IPC error codes, while ensuring React components subscribe correctly.",
            "status": "pending",
            "testStrategy": "Frontend unit test with Zustand store harness validating state transitions and toast emission on HELLO/STATUS/LIST outcomes.\n\n",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Add network health indicator UI",
            "description": "Implement latency monitoring via periodic ping TLV requests and degrade UI when round-trip exceeds threshold.",
            "dependencies": [
              6
            ],
            "details": "Schedule 5s ping requests, update Zustand metrics based on ping TLV latency, render indicator component with >150ms degradation styling, and surface reconnect guidance when STATUS polling warns.",
            "status": "pending",
            "testStrategy": "Frontend integration test mocking latency responses and STATUS failures to assert indicator state changes and UI feedback.\n\n",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Create automated tests and mocks",
            "description": "Build supporting test fixtures and mock services covering discovery, WebSocket flows, and frontend integration.",
            "dependencies": [
              1,
              2,
              5,
              6,
              7
            ],
            "details": "Add mock mDNS events resolving `prism-k1.local`, mock WebSocket server helpers for HELLO/STATUS/LIST/DELETE, shared TLV fixtures, and Playwright scenario validating end-to-end device lifecycle.",
            "status": "pending",
            "testStrategy": "Combined cargo test suite with mocked services plus Playwright run against mock WS server to confirm HELLO→STATUS→LIST→DELETE workflow and frontend indicator updates.\n\n",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Plan subtasks for Rust mDNS discovery, WebSocket HELLO parsing, connection pooling with backoff, error mapping and persistence, typed IPC commands, React store integration, latency indicators, and backend/frontend automated tests.",
        "updatedAt": "2025-10-16T18:18:35.747Z"
      },
      {
        "id": 43,
        "title": "Design Project Schema, State Management, and Persistence",
        "description": "Define strongly typed project data models, implement global state with undo/redo, and add autosave/versioning to IndexedDB.",
        "status": "in-progress",
        "dependencies": [
          "41"
        ],
        "priority": "medium",
        "details": "Align with docs/research/PRISM_Studio_Architecture_Research.md (Section 1: State Management; Sections 5–9 supporting). Implement Zustand + Immer with Temporal middleware for history (replacing zundo) and expose a typed command pattern with inverse ops for undo/redo. Persistence uses IndexedDB with an autosave ring buffer retaining the last 10 snapshots and hybrid throttling (>=250ms burst throttle; idle flush at 2s). Schemas include explicit Zod versioning and a migrations pipeline; persist and check schemaVersion on load. Secrets move to the Tauri keyring plugin and are never stored in IndexedDB. Performance targets: undo/redo <5ms under 500 clips; compressed snapshot ~= <200KB.",
        "testStrategy": "Point tests to concrete modules (e.g., data/models.ts for schemas; store hooks; autosave and migrations). Add property-based tests for command inverses and migration correctness. Measure worst-case undo/redo latency with 500 clips and enforce <5ms. Use fake timers to validate hybrid autosave cadence and ring buffer pruning. Add crash-recovery test ensuring restart reloads the last valid autosave snapshot. Preserve completed subtasks; add a new subtask to replace zundo with Temporal rather than modifying completed work.",
        "subtasks": [
          {
            "id": 2,
            "title": "Implement throttled autosave service",
            "description": "Add autosave pipeline persisting projects to IndexedDB using idb-keyval.",
            "dependencies": [],
            "details": "Listen to store changes and apply hybrid throttling: minimum interval >=250ms during bursts plus an idle flush at 2s. Persist serialized project_v{schemaVersion} with metadata (timestamp, size, checksum) to IndexedDB. Provide loadLatestValidSnapshot() for startup hydration and coordinate with ring buffer pruning (task 5).",
            "status": "pending",
            "testStrategy": "Use fake timers to assert 250ms throttle and 2s idle flush; mock idb-keyval to verify writes and snapshot metadata."
          },
          {
            "id": 4,
            "title": "Build migration pipeline for legacy projects",
            "description": "Create migration orchestrator for loading older project versions.",
            "dependencies": [
              1
            ],
            "details": "Add migrations/index.ts registering ordered transforms vN → vN+1 with Zod-validated input/output. On load, read schemaVersion, run sequential migrations to current, validate final shape, then persist upgraded version prior to hydration.",
            "status": "pending",
            "testStrategy": "Property-based tests generate legacy-shaped payloads and assert convergence to current schema; verify idempotence when data is already current."
          },
          {
            "id": 5,
            "title": "Provide selectors and command event bus",
            "description": "Expose derived selectors and command execution events.",
            "dependencies": [
              2,
              3
            ],
            "details": "Add memoized selectors (playhead, active palettes, clip collections) and a command event bus that publishes do/undo events. Integrate with Temporal-backed history so each command registers its inverse operation and emits typed notifications for UI consumers.",
            "status": "pending",
            "testStrategy": "Validate selector outputs with mocked store state; ensure bus emits expected do/undo events and ordering alongside history updates."
          },
          {
            "id": 6,
            "title": "Segregate secure credential storage",
            "description": "Move device credentials to Tauri secure store outside IndexedDB.",
            "dependencies": [
              4,
              5
            ],
            "details": "Introduce a keyring adapter using the Tauri keyring plugin for credentials/tokens. Integrate into persistence flows to keep secrets out of IndexedDB payloads; add clear error surfacing and fallback handling.",
            "status": "pending",
            "testStrategy": "Mock keyring APIs to confirm secrets never serialize into IndexedDB; verify failures propagate without corrupting project saves."
          },
          {
            "id": 7,
            "title": "Author comprehensive validation tests",
            "description": "Plan and implement holistic testing for schema, store, and persistence.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6
            ],
            "details": "Create Vitest suites for: schema parsing; property-based command inverse correctness; undo saturation with 500 clips meeting <5ms; autosave hybrid cadence and ring buffer pruning; migration chains; selector accuracy; secure storage segregation; and documented manual QA aligned to the research doc.",
            "status": "pending",
            "testStrategy": "Run aggregated Vitest with fake timers; benchmark undo/redo and enforce <5ms; simulate crash-recovery to ensure the last valid snapshot reloads."
          },
          {
            "id": 8,
            "title": "Define Zod project schemas per ADR-010",
            "description": "Create strongly typed project entities using Zod 3.23.",
            "dependencies": [],
            "details": "Author `data/models.ts` with Zod schemas covering PrismProject, Track, Clip, EffectInstance, and AutomationCurve plus supporting enums so outputs meet ADR-010 compatibility commitments.",
            "status": "done",
            "testStrategy": "Add Vitest schema parsing specs checking valid/invalid project payloads and schemaVersion tagging."
          },
          {
            "id": 9,
            "title": "Integrate zundo undo/redo command history",
            "description": "Wire zundo middleware to manage 50-step history and command stack.",
            "dependencies": [
              2
            ],
            "details": "Compose `withZundo` around the store, configure inverse history limit and compression past 20 actions, and implement `execute(command)` helper pushing inverse closures onto a managed stack.",
            "status": "done",
            "testStrategy": "Simulate sequences of commands verifying undo/redo restores state and history trims after exceeding 50 entries."
          },
          {
            "id": 10,
            "title": "Replace zundo with Temporal history + typed commands",
            "description": "Adopt Temporal middleware for history, exposing typed command pattern with inverse ops while preserving existing done work.",
            "dependencies": [
              2,
              3
            ],
            "details": "Per docs/research/PRISM_Studio_Architecture_Research.md Section 1, integrate Temporal middleware into the Zustand store to manage history. Implement a typed execute(command) API where each command declares do and inverse operations. Target <5ms undo/redo under 500 clips; provide shims to transition from existing zundo usage without altering the completed subtask.",
            "status": "pending",
            "testStrategy": "Property-based tests generate random command sequences and verify repeated undo/redo cycles restore state exactly; measure latency to enforce the <5ms budget."
          },
          {
            "id": 1,
            "title": "Define Zod project schemas per ADR-010",
            "description": "Create strongly typed project entities using Zod 3.23.",
            "dependencies": [],
            "details": "Author `data/models.ts` with Zod schemas covering PrismProject, Track, Clip, EffectInstance, and AutomationCurve plus supporting enums so outputs meet ADR-010 compatibility commitments.",
            "status": "done",
            "testStrategy": "Add Vitest schema parsing specs checking valid/invalid project payloads and schemaVersion tagging.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T18:13:16.339Z"
          },
          {
            "id": 3,
            "title": "Integrate zundo undo/redo command history",
            "description": "Wire zundo middleware to manage 50-step history and command stack.",
            "dependencies": [
              2
            ],
            "details": "Compose `withZundo` around the store, configure inverse history limit and compression past 20 actions, and implement `execute(command)` helper pushing inverse closures onto a managed stack.",
            "status": "done",
            "testStrategy": "Simulate sequences of commands verifying undo/redo restores state and history trims after exceeding 50 entries.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T18:23:31.201Z"
          }
        ]
      },
      {
        "id": 44,
        "title": "Build Timeline Canvas Infrastructure",
        "description": "Create performant timeline rendering engine with tracks, grid modes, playhead control, and 60 FPS target.",
        "details": "- Use imperative Canvas 2D with `OffscreenCanvas` fallback; for browsers lacking support (Windows WebView2), degrade to main-thread canvas with resolution scaling by `devicePixelRatio`.\n- Implement render loop (`requestAnimationFrame`) orchestrating layers: background grid, tracks, clips, selection overlay, playhead.\n- Grid system: seconds vs beats; maintain BPM state; precompute tick marks to minimize per-frame allocations.\n- Input handling: pointer events for scrub/playhead, `space` toggles playback, `J/K/L` shuttle speeds, `+/-` zoom; use `PointerCapture` for drag interactions.\n- LOD strategy: when zoomed out beyond threshold, collapse clip detail (draw simple bars) to sustain <5ms draw cost.\n- Integrate with state store for track data; subscribe via `useShallow` to avoid re-render storms; render diff-based (only dirty rects).\nPseudo-code:\n```\nfunction renderLoop() {\n  const frame = performance.now();\n  drawGrid(context, frame);\n  tracks.forEach(track => drawTrack(track));\n  drawPlayhead(playhead);\n  requestAnimationFrame(renderLoop);\n}\n```\n- Add keyboard focus ring handling and accessible ARIA mapping (e.g., timeline region labelled).\n",
        "testStrategy": "- Vitest canvas snapshot tests (with `jest-canvas-mock` + pixel diff tolerance) verifying grid/track rendering at key zoom levels.\n- Performance harness: Playwright script triggers heavy scroll/zoom and assert via `performance.measure` that `rafDuration < 16ms` on reference hardware.\n- Accessibility audit: `@axe-core/playwright` ensures focusable controls and ARIA labels.",
        "priority": "medium",
        "dependencies": [
          "43"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create canvas context factory with OffscreenCanvas worker fallback and DPR scaling",
            "description": "Build a factory that returns a performant 2D context using OffscreenCanvas when available, with devicePixelRatio scaling and a robust main‑thread fallback.",
            "dependencies": [],
            "details": "Provide createCanvasContext({width,height}) that detects OffscreenCanvas support, transfers control to a Worker when possible, and otherwise initializes a main‑thread canvas. Implement DPR scaling (backing store size = cssSize * devicePixelRatio), resize handling, memory guards for WebView2, and lifecycle methods (setSize, dispose). Expose a consistent API for postMessage when running in a worker and no‑op stubs on main thread.",
            "status": "done",
            "testStrategy": "Unit: mock OffscreenCanvas presence/absence and verify DPR scaling, resize, and fallback. Integration smoke: draw a rect and validate pixels via canvas mock.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T19:30:27.045Z"
          },
          {
            "id": 2,
            "title": "Implement requestAnimationFrame scheduler orchestrating layers with pause and visibility handling",
            "description": "Create a RAF-driven loop that orders rendering of grid, tracks/clips, overlays, and playhead, with start/stop, pause, and page visibility support.",
            "dependencies": [
              1
            ],
            "details": "Add a scheduler module exposing start(), stop(), setPaused(), and onFrame(cb). Use requestAnimationFrame, performance.now, and Page Visibility API to skip frames when hidden. Maintain deterministic layer order: grid -> tracks -> selection overlay -> playhead. Track frame budget metrics and coalesce redundant redraws. Provide hooks for resize and DPR changes.",
            "status": "pending",
            "testStrategy": "Unit with fake timers: verify start/stop, pause on hidden, and layer invocation order. Record RAF durations to ensure stable cadence under light load.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build grid and tick system for seconds and beats with BPM-aware, zoom-memoized caches",
            "description": "Implement a grid generator that supports seconds and beat modes using project BPM, memoizing ticks per zoom level and laying out readable labels.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create computeTicks(viewStart, viewEnd, zoom, mode, bpm) returning major/minor ticks and label metadata. Memoize by mode+BPM+zoom bucket to minimize allocations per frame. Implement label collision avoidance, time/beat formatting helpers, and precomputation windows to warm caches during idle frames. Provide drawGrid(ctx, frameTime, caches) that reads from the memoized data.",
            "status": "pending",
            "testStrategy": "Canvas snapshot tests at multiple zooms for both modes; unit tests for memoization hit rate and label spacing (no overlaps beyond tolerance).",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add input handling for pointer scrubbing, keyboard shuttle/playback, and zoom with PointerCapture",
            "description": "Wire pointerdown/move/up scrubbing using PointerCapture and keyboard controls (space, J/K/L, +/-) to control playback speed and zoom state.",
            "dependencies": [
              2
            ],
            "details": "Implement event handlers that map clientX to timeline time using zoom and scroll offsets. Use setPointerCapture for drags, handle cancel/out-of-bounds, and update playhead position in the store. Keyboard: space toggles play/pause; J/K/L set shuttle speeds (reverse/stop/forward); +/- adjust zoom with clamped bounds. Add Ctrl/Cmd+wheel zoom and prevent default where appropriate. Respect focus and modifier keys for accessibility.",
            "status": "pending",
            "testStrategy": "DOM-level tests simulating pointer capture flow and keyboard sequences; ensure correct time mapping and state transitions. Playwright smoke: drag to scrub and verify playhead updates.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement track and clip drawing with LOD thresholds and cached measurements (<5ms when zoomed out)",
            "description": "Render tracks/clips efficiently using level-of-detail rules and cached measurements to keep draw costs under budget at low zoom.",
            "dependencies": [
              2,
              3
            ],
            "details": "Add drawTrack(track, zoom, ctx) with LOD: collapsed bars when zoomed out, detailed shapes and labels when zoomed in. Cache Path2D shapes, text measurements, and color brushes. Batch fills/strokes, minimize state changes, and avoid per-frame allocations. Use clipping regions and offscreen static layers for track chrome. Apply selection overlay blending and hysteresis around LOD thresholds to prevent flicker.",
            "status": "pending",
            "testStrategy": "Snapshot tests for near/far zooms confirming LOD output. Micro-bench unit estimating draw cost with mocked performance.now to ensure <5ms at low zoom. Verify LOD hysteresis switching.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Wire rendering to Zustand with shallow selectors, dirty-rect diffing, and worker messaging",
            "description": "Connect to existing state using shallow selectors, compute dirty rectangles to limit redraws, and define a worker message protocol for OffscreenCanvas mode.",
            "dependencies": [
              1,
              2,
              5
            ],
            "details": "Use Zustand selectors with useShallow to subscribe to bpm, zoom, tracks, and playhead changes. Implement diff utilities to compute dirty rects from previous vs current item bounds and schedule partial redraws. Define postMessage channels: updateTracks, updateZoom, updatePlayhead, drawDirtyRects, and ack/backpressure handling. Coalesce rapid updates and fall back to full redraw if rect count exceeds threshold.",
            "status": "pending",
            "testStrategy": "Unit: verify diff produces expected dirty rects for edits/moves. Integration: simulate store updates and assert only affected regions are redrawn. Worker contract test with a fake Worker capturing messages.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Add accessibility: focus management, ARIA roles/labels, and visible focus rings for the timeline",
            "description": "Ensure the timeline is keyboard navigable with proper ARIA semantics, labeled region, and clearly visible focus indicators integrated with the overlay layer.",
            "dependencies": [
              2,
              4
            ],
            "details": "Wrap canvas in a focusable container with role=\"region\" and aria-label bound to project context. Implement focus ring drawing in the overlay when container is focused. Map keyboard shortcuts only when focused, respect system reduced motion, and add polite live region updates of current time during scrubbing. Provide high-contrast colors and ensure tab order and escape hatches for users.",
            "status": "pending",
            "testStrategy": "Playwright + axe-core checks for ARIA and contrast; keyboard navigation tests verifying focus ring and shortcut scoping; snapshot of focus overlay state.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Set up tests: Vitest canvas mocking, Playwright performance harness, and axe-core a11y checks",
            "description": "Establish testing infrastructure with jest-canvas-mock for snapshots, Playwright scripts measuring rafDuration, and automated accessibility assertions using axe-core.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6,
              7
            ],
            "details": "Configure Vitest (happy-dom) to load jest-canvas-mock and add pixel-diff snapshot helpers with tolerance. Write grid/track snapshot suites at key zoom levels. Add Playwright perf spec that drives scroll/zoom/play interactions and asserts mean rafDuration < 16ms on baseline. Integrate axe-core into Playwright to fail on a11y violations. Provide npm scripts and CI gating for performance and a11y budgets.",
            "status": "pending",
            "testStrategy": "Vitest: snapshot and unit coverage for grid, LOD, and diffing. Playwright: perf budget and interaction flows. Axe-core: a11y violations cause test failures.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Design subtasks to: 1) create a canvas context factory with OffscreenCanvas worker fallback and DPR scaling; 2) implement a requestAnimationFrame scheduler orchestrating background grid, tracks/clips, overlays, and playhead with pause/visibility handling; 3) build a grid/tick system supporting seconds and beats using project BPM, with per-zoom memoized tick caches and label layout; 4) add input handling for pointer scrubbing (PointerCapture), keyboard controls (space, J/K/L, +/-), and zoom state; 5) implement track/clip drawing with level-of-detail thresholds and cached measurements to sustain <5ms draw time when zoomed out; 6) wire to Zustand stores using shallow selectors and track dirty rectangles to redraw only changed regions (and support worker messaging when OffscreenCanvas is used); 7) add accessibility: focus management, ARIA roles/labels for the timeline region, and visible focus rings; 8) set up tests: Vitest + canvas mocking for snapshots, Playwright performance scripts measuring rafDuration, and axe-core checks.",
        "updatedAt": "2025-10-16T19:39:49.281Z"
      },
      {
        "id": 45,
        "title": "Implement Clip Editing Interactions and Shortcuts",
        "description": "Enable clip CRUD operations, selection mechanics, and keyboard-driven timeline editing per PRD shortcuts.",
        "status": "pending",
        "dependencies": [
          "44"
        ],
        "priority": "medium",
        "details": "Research-aligned implementation per docs/research/PRISM_Studio_Architecture_Research.md — Section 2: Timeline Editing (2.1 Canvas2D rendering, 2.2 Snap Service, 2.3 Shortcuts, 2.4 fast-check) with supporting guidance in Sections 5–9 (performance, libraries, pitfalls).\n\nRenderer & Performance (Section 2.1 + Sec. 5.2):\n- Use Canvas2D with OffscreenCanvas + virtual scrolling to sustain 60 FPS with 1000 clips. In Studio, extend studio/src/features/timeline/TimelineCanvas.tsx:28 (existing double-buffer scroll-blit via maybeRebuildStatic) to optionally use OffscreenCanvas when available and keep current on-main double-buffer fallback via studio/src/lib/canvas.ts helpers. Target ~6ms average render with 1000 clips in view; avoid GC churn by reusing paths and minimizing allocations per frame.\n- Keep single-blit copy from offscreen to onscreen each frame; maintain dirty-region/scroll-blit behavior already scaffolded in maybeRebuildStatic().\n\nSnap Service (Section 2.2):\n- Introduce grid/clip/magnetic snap modes with tolerance and combined behavior: snap(timeMs, modes: ('grid'|'clips'|'magnetic')[], options: { tolerancePx, gridSizeSec, zoomPxPerSec }). Place in studio/src/features/timeline/snap.ts and wire into interactions (create/move/trim/split) and playhead updates. Use project tracks/clips from studio/src/stores/project.ts and timeline zoom from studio/src/stores/timeline.ts.\n\nKeyboard/UX (Section 2.3):\n- Map shortcuts: Cmd/Ctrl+K split, Q/W ripple trim, I/O in/out, J/K/L shuttle (rewind/pause/forward), arrows for selection focus. Centralize in studio/src/features/timeline/shortcuts.ts, imported by TimelineCanvas or parent editor component; ensure focus management and preventDefault where appropriate.\n- Selection: rubber-band marquee + Shift toggles; arrow keys cycle focused clip. Implement selection manager in studio/src/features/timeline/selection.ts maintaining selectedClipIds and focusedClipId consistent with accessibility.\n\nCommand Pattern + Undo/Redo (Section 1.3 referenced by Section 2):\n- Implement command objects for editing ops with precise inverses (execute/undo) and integrate with zundo temporal history already present in studio/src/stores/project.ts (useProjectStore.temporal). New files: studio/src/features/timeline/commands/SplitClipCommand.ts, RippleTrimCommand.ts, MoveClipCommand.ts, TrimClipCommand.ts, plus index.ts with executeCommand(state, command) guard + telemetry hooks.\n\nValidation & Constraints:\n- Enforce per-track no-overlap and sorted timelines (validators in studio/src/features/timeline/validation.ts). On updates, auto-ripple when toggled (for Q/W) and keep trims within [0, duration].\n\nVisual Affordances:\n- While dragging/creating, show clip ghost, highlight invalid drop zones, and show timestamp tooltip near cursor. Implement lightweight overlays in TimelineCanvas (or tiny DOM overlay) while keeping draw calls bounded. Tooltips must be accessible with aria-live updates.\n\nTelemetry Hooks:\n- Use studio/src/lib/logger.ts to emit optional telemetry for heavy operations (split, ripple, bulk trims). Guard emissions behind a settings flag exposed in UI (see LoggerPanel wiring in studio/src/App.tsx and features/settings/SecureSettings.tsx).",
        "testStrategy": "- Unit (Vitest):\n  - Command inverses: For SplitClipCommand, RippleTrimCommand, MoveClipCommand, TrimClipCommand (studio/src/features/timeline/commands/*.test.ts). Execute then undo returns to deep-equal state; cover edge cases at clip edges and near tolerance thresholds.\n  - Snap invariants: studio/src/features/timeline/snap.test.ts property-based tests (fast-check) for grid/clip/magnetic modes: snapping is idempotent; magnetic prefers edges within tolerance; combined modes never increase error beyond best constituent.\n  - Validators: studio/src/features/timeline/validation.test.ts ensures per-track non-overlap after operations; maintain sorted order.\n- Interaction (Playwright):\n  - studio/e2e/timeline-editing.spec.ts: drag-to-create on empty region across multiple tracks, move + trim with snap alignment, split via Cmd/Ctrl+K, ripple via Q/W, set I/O markers, marquee selection with Shift toggles. Use page.mouse drag + keyboard events against Timeline canvas (role=\"application\"). Assert DOM overlays/tooltips and project store changes via exposed test IDs.\n- Rendering performance (Vitest w/ fake 2D context):\n  - studio/src/features/timeline/TimelineRenderer.perf.test.ts: seed 1000 clips across ~50 tracks, call render loop for 60 frames with mocked CanvasRenderingContext2D; measure average frame time using performance.now(). Assert avg < ~6ms on CI hardware stub and stable allocations (no large spikes). Also assert draw call counts remain bounded (per Sec. 5.2 targets).\n- Accessibility:\n  - Keyboard navigation tests for arrow cycling and focus management; verify aria-labels/tooltips update timestamps accurately.\n- Regression:\n  - Ensure undo/redo via useProjectStore.temporal works with command executions (studio/src/stores/project.test.ts extension), preserving history limits and not logging telemetry when disabled.",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate snap service into timeline editing core",
            "description": "Wire the snap(time, mode) service into the clip editor foundation.",
            "dependencies": [],
            "details": "Create studio/src/features/timeline/snap.ts implementing snap(timeMs, modes: ('grid'|'clips'|'magnetic')[], { tolerancePx, gridSizeSec, zoomPxPerSec }, deps: { clips: Clip[] }). Follow docs/research/PRISM_Studio_Architecture_Research.md#L544 (Section 2.2). Use timeline zoom from studio/src/stores/timeline.ts and clip edges from studio/src/stores/project.ts. Expose helpers for creation/move/trim flows and playhead snapping. Add hooks for configurable tolerance and grid (beats vs seconds) and ensure idempotent snapping.",
            "status": "pending",
            "testStrategy": "Vitest + fast-check in studio/src/features/timeline/snap.test.ts: property tests for idempotence, nearest-edge preference under tolerance, magnetic combining behavior. Unit cases for beat/second grid sizes."
          },
          {
            "id": 2,
            "title": "Enable multi-track clip creation with snapped persistence",
            "description": "Support drag-to-create clips on empty regions with snap alignment.",
            "dependencies": [
              1
            ],
            "details": "Add a DragCreateController in studio/src/features/timeline/interactions/create.ts. Hook TimelineCanvas.tsx pointer handlers to start/end drag, compute start/end via snap() using modes ['grid','clips','magnetic'], infer track from Y coordinate, and persist to store with useProjectStore.getState().addClip(). Respect studio/src/lib/projectSchema.ts clip shape. Use virtual scrolling extents already in TimelineCanvas.tsx to limit queries. Show ghost rect + timestamp tooltip during drag.",
            "status": "pending",
            "testStrategy": "- Vitest: interaction unit with mocked canvas rect to simulate pointer down/move/up and assert created clip bounds match expected snapped intervals.\n- Playwright: e2e create across 2 tracks and verify clip appears with snapped start/end; snapshot DOM overlay state."
          },
          {
            "id": 3,
            "title": "Implement clip drag-move and edge trim interactions",
            "description": "Allow repositioning and trimming clips with grid snapping and overlap checks.",
            "dependencies": [
              2
            ],
            "details": "Add MoveTrimController in studio/src/features/timeline/interactions/moveTrim.ts using snap() for deltas; implement trim-left/right with tolerance at min duration. Enforce per-track no-overlap in studio/src/features/timeline/validation.ts (binary-search neighbor clips and clamp). Update TimelineCanvas.tsx to render move/trim ghosts and invalid highlights.",
            "status": "pending",
            "testStrategy": "Vitest: delta math for move/trim including snap rounding; validation unit ensuring collisions are prevented. Playwright: drag-move and edge-trim interactions respecting snap and no-overlap."
          },
          {
            "id": 4,
            "title": "Build split and ripple trim command objects",
            "description": "Provide command pattern actions for split, ripple trim, and merge inverses.",
            "dependencies": [
              3
            ],
            "details": "Implement commands in studio/src/features/timeline/commands/: SplitClipCommand.ts, RippleTrimCommand.ts, plus index.ts with executeCommand() that integrates with useProjectStore.temporal (zundo) per Section 1.3 and Section 2 guidance. Split creates right-hand clip and adjusts left; undo removes new clip and restores original. Ripple trims shift adjacent clips on same track (Q/W) and maintain ordering. Add guards and canExecute validation.",
            "status": "pending",
            "testStrategy": "Vitest suites for do/undo round-trip equality and ripple propagation correctness. fast-check command sequences (studio/src/features/timeline/commands/commands.property.test.ts) verifying inverses and sorted, non-overlapping invariants."
          },
          {
            "id": 5,
            "title": "Add ripple, in/out, and zoom shortcut behaviors",
            "description": "Hook Q/W ripple trims, I/O range markers, and zoom keyboard controls.",
            "dependencies": [
              4
            ],
            "details": "Create studio/src/features/timeline/shortcuts.ts mapping: mod+k split; q/w ripple trim; i/o set in/out; j/k/l shuttle; arrows for selection + playhead nudge; mod+=/- zoom. Wire into TimelineCanvas host via effect listener. Keep focusable canvas role=\"application\" with preventDefault for handled keys. Sync range markers to timeline store and renderer.",
            "status": "pending",
            "testStrategy": "@testing-library/react + Vitest to dispatch KeyboardEvent and assert store changes (e.g., selection, in/out, zoom). Playwright to verify key-driven split/trim behaviors invoke underlying commands and update canvas overlays."
          },
          {
            "id": 6,
            "title": "Implement selection and rubber-band mechanics",
            "description": "Create multi-select, shift-toggled, and arrow navigation selection logic.",
            "dependencies": [
              3
            ],
            "details": "Add SelectionManager in studio/src/features/timeline/selection.ts supporting marquee selection, Shift toggles, and arrow key focus cycling. Expose selectedClipIds and focusedClipId. Ensure accessible aria-label updates. Integrate hit-testing against visible clips only for performance with current virtual scrolling.",
            "status": "pending",
            "testStrategy": "Vitest: selection state transitions for click, Shift+click, marquee, and arrow traversal order. Ensure stability with large (1000 clip) sets."
          },
          {
            "id": 7,
            "title": "Integrate undo/redo command stack with editing actions",
            "description": "Tie all edit commands into centralized undo/redo stack with telemetry hooks.",
            "dependencies": [
              4,
              6
            ],
            "details": "Ensure command executions funnel through executeCommand() and record in zundo temporal history (studio/src/stores/project.ts). Respect history limit=50 and emit telemetry via studio/src/lib/logger.ts when opt-in flag is enabled (toggle via settings). Verify undo/redo hotkeys (Cmd/Ctrl+Z/Shift+Z) already wired in studio/src/App.tsx call temporal.undo/redo; extend to cover new commands.",
            "status": "pending",
            "testStrategy": "Vitest: regression on stack push/pop order, bounded history, and telemetry emission mock assertions. Simulate command sequences and validate undo restores pre-state."
          },
          {
            "id": 8,
            "title": "Provide visual affordances for editing feedback",
            "description": "Display clip ghosts, invalid drop highlights, and timeline tooltips.",
            "dependencies": [
              3,
              6,
              7
            ],
            "details": "In TimelineCanvas.tsx, render drag-ghost (semi-transparent rect), invalid drop highlights (red stroke) when validation fails, and tooltip with timestamp following cursor (DOM overlay or lightweight canvas text) with accessible aria-live. Keep draw calls minimal and reuse paths to avoid GC; keep compatible with OffscreenCanvas pipeline.",
            "status": "pending",
            "testStrategy": "Vitest: UI rendering tests by spying mocked 2D context draw calls and verifying ghost visibility/highlight draws under specific interaction states. Playwright: assert tooltip text updates and invalid states on overlaps."
          },
          {
            "id": 9,
            "title": "Enforce validation rules and automated test coverage",
            "description": "Finalize validators and comprehensive unit, E2E, and property tests.",
            "dependencies": [
              1,
              3,
              4,
              7,
              8
            ],
            "details": "Consolidate studio/src/features/timeline/validation.ts for no-overlap and bounds. Expand unit + property tests (fast-check) covering CRUD + command flows. Add performance-oriented tests ensuring average render under ~6ms for 1000 clips with mocked 2D context (per research Sec. 5.2).",
            "status": "pending",
            "testStrategy": "Run combined Vitest + fast-check and Playwright suites. Include perf assertions for render budget and absence of large allocations/jank during interaction."
          }
        ]
      },
      {
        "id": 46,
        "title": "Deliver Effect Library and Palette System",
        "description": "Implement plugin-style effect registry, built-in generators/modifiers, Culori-based color tooling (OKLab/OKLCH/sRGB), parameter schema + UI mapping, palette management, and preset serialization with performance targets.",
        "status": "pending",
        "dependencies": [
          "43",
          "44"
        ],
        "priority": "medium",
        "details": "Align with research doc docs/research/PRISM_Studio_Architecture_Research.md (Section 3: Effect System; Sections 5–9 supporting).\n\n- Effect registry: Implement a plugin-style registry with typed interfaces and UI schema in `studio/src/lib/effects/registry.ts`. Include fields: `id`, `kind: 'generator' | 'modifier'`, `parameters` (typed descriptors with range/default/unit), `evaluate(params, time, ledIndex, ctx)`, `presets`, and optional `ui` schema for control rendering. Ensure integration with `ClipSchema.effect` and `ClipSchema.params` in `studio/src/lib/projectSchema.ts:80` for per-clip effect selection and parameter storage.\n\n- Generators: Implement `solid`, `wave` (sine/triangle/saw), `noise` (using `simplex-noise@^4.0`), and `fire` (noise + color ramp) in `studio/src/lib/effects/generators/{solid,wave,noise,fire}.ts`. Remove prior gradient generator requirement; gradients can be produced via palette ramps or Culori interpolation when needed. Target ~1.8ms evaluation for 320 LEDs; avoid per-frame allocations by reusing typed buffers and precomputing invariants (e.g., phase increment, noise instances).\n\n- Modifiers: Implement `brightness`, `hueShift`, and `saturation` in `studio/src/lib/effects/modifiers/{brightness,hueShift,saturation}.ts`. Compose via a lightweight pipeline helper in `studio/src/lib/effects/pipeline.ts` that applies modifiers sequentially to generator output. Drop mirror/ripple from this scope per updated spec.\n\n- Color tooling: Replace any `oklab 0.2` references with Culori. Add a small wrapper in `studio/src/lib/color/index.ts` that exports `toOklab`, `toOklch`, `toRgb`, `formatHex`, and `interpolateOkLab/OkLch` using `culori` converters/interpolators. Prefer OKLCH for palette ramps; fall back to sRGB formatting for device output. Ensure all generators/modifiers use the shared color utils.\n\n- Palette library: Store 15 curated palettes and support custom palettes with 2–16 swatches. Use `studio/src/lib/palette/palettes.json` for built-ins (id, name, colors as `#RRGGBB`, optional interpolation mode). Provide APIs in `studio/src/lib/palette/index.ts` for list/get/add/update of palettes and palette-based sampling using Culori OKLCH interpolation.\n\n- UI: Implement custom palette editor with drag reorder and HEX/HSL inputs in `studio/src/features/palette/PaletteEditor.tsx` (research Section 3.3 example). Parameter controls use Radix sliders normalized 0–1 mapping to physical units (e.g., exponential mapping for Hz) in `studio/src/features/timeline/ParameterControls.tsx` (see Section 3.4). Ensure `App.tsx` wires selected clip to effect registry, parameters, and palette preview.\n\n- Presets: Ensure presets are serializable/deserializable JSON on registry entries and compatible with compiler/renderer inputs. Provide preset import/export helpers in `studio/src/lib/effects/presets.ts`.\n\n- Performance: Meet ~1.8ms wave evaluation for 320 LEDs; maintain <16ms UI update budget. Avoid per-frame allocations; pre-allocate evaluation buffers and reuse Culori conversion functions.\n\n- Dependencies (studio): add `culori` and `@radix-ui/react-slider`; confirm `simplex-noise@^4.0` is available for noise. Document versions in `studio/package.json`.",
        "testStrategy": "- Unit tests (Vitest) for each generator and modifier in `studio/src/lib/effects/**`: deterministic outputs at fixed params/seeds; parameter bounds respected and clamped; identity checks at neutral modifier settings (e.g., brightness=100%, hueShift=0°, saturation=1.0).\n- Property checks: random param sampling within ranges to verify outputs remain within [0..255] and no exceptions; idempotency/identity at neutral parameters.\n- Color utilities: regression tests comparing OKLab/OKLCH vs sRGB interpolation results using Culori wrappers in `studio/src/lib/color/index.ts`; verify formatHex round-trip.\n- Palette: snapshot tests for built-in `palettes.json` shape and custom palette round-trip serialization/deserialization in `studio/src/lib/palette/index.ts` (2–16 swatches enforced).\n- UI tests (Playwright): preset toggle flows and parameter slider interactions update previews in under 16ms budget; palette editor drag-reorder, HEX/HSL inputs reflect in preview.\n- Performance microbench (Vitest): wave generator evaluation over 320 LEDs for 100 iterations stays near ~1.8ms per frame on dev profile; verify no per-frame allocations via stable memory usage across iterations.",
        "subtasks": [
          {
            "id": 1,
            "title": "Architect effect registry with metadata schema",
            "description": "Define TypeScript plugin-style registry structure for effect definitions and UI schema.",
            "dependencies": [],
            "details": "Create `studio/src/lib/effects/registry.ts` exporting a typed registry with `id`, `kind`, `parameters` (range/default/unit), `evaluate(params, time, ledIndex, ctx)`, `presets`, and optional `ui` hints. Integrate with `ClipSchema.effect`/`params` in `studio/src/lib/projectSchema.ts:80` and add simple type guards or zod schemas. Reference research Section 3.1 for structure.",
            "status": "pending",
            "testStrategy": "Vitest: registry can register/resolve effects; parameters validate against descriptors; evaluate throws for unknown ids; presets serialize/deserialize."
          },
          {
            "id": 2,
            "title": "Implement core generator evaluators",
            "description": "Build runtime implementations for solid, wave, noise, and fire generators.",
            "dependencies": [
              1
            ],
            "details": "Add `studio/src/lib/effects/generators/{solid,wave,noise,fire}.ts`. Use `simplex-noise@^4.0` for noise; implement `fire` as animated noise mapped through a color ramp sampled in OKLCH. Remove gradient generator. Ensure no per-frame allocations and precompute invariants for ~1.8ms/320 LEDs target.",
            "status": "pending",
            "testStrategy": "Deterministic tests for each generator at fixed params and seeds; bounds checks ensure RGB in [0..255]; performance microbench validates average eval time per frame; seed noise for repeatability."
          },
          {
            "id": 3,
            "title": "Develop modifier composition pipeline",
            "description": "Create reusable pipeline to apply brightness, hue shift, and saturation modifiers.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement modifiers in `studio/src/lib/effects/modifiers/{brightness,hueShift,saturation}.ts` operating on generator RGB outputs via Culori conversions where needed. Compose via `studio/src/lib/effects/pipeline.ts` with ordered application and clamping rules. Mirror/ripple excluded per updated scope.",
            "status": "pending",
            "testStrategy": "Unit-test chaining order and clamping on sample frames; identity at neutral params (brightness 100%, hueShift 0°, saturation 1.0). Snapshot resulting colors for baseline comparisons."
          },
          {
            "id": 4,
            "title": "Integrate OKLab color utilities",
            "description": "Add Culori-based conversion helpers and fallbacks.",
            "dependencies": [
              2,
              3
            ],
            "details": "Implement `studio/src/lib/color/index.ts` using `culori` converters/interpolators for OKLab/OKLCH/sRGB and gradient helpers. Replace any oklab-0.2 assumptions; use OKLCH for palette ramps with sRGB output formatting. Ensure utilities integrate with generators/modifiers without precision loss.",
            "status": "pending",
            "testStrategy": "Regression tests comparing OKLCH vs sRGB gradient interpolation using fixed endpoints; verify converter round-trips and that neutral conversions preserve identity within tolerance."
          },
          {
            "id": 5,
            "title": "Build palette library and JSON storage",
            "description": "Create built-in palette definitions and management APIs.",
            "dependencies": [
              4
            ],
            "details": "Author 15 curated palettes under `studio/src/lib/palette/palettes.json` with 2–16 swatches each; expose APIs in `studio/src/lib/palette/index.ts` for retrieval, validation, and Culori-based sampling. Support interpolation mode metadata and integrate with effect presets.",
            "status": "pending",
            "testStrategy": "Unit tests validating palette counts, schema conformance (2–16), and OKLCH sampling produces valid RGB; snapshot built-in palettes and round-trip serialization."
          },
          {
            "id": 6,
            "title": "Implement custom palette editor UI",
            "description": "Deliver editor interface for custom user palettes.",
            "dependencies": [
              5
            ],
            "details": "Build `studio/src/features/palette/PaletteEditor.tsx` with drag-reorderable swatches, HEX/HSL inputs, and OKLCH previews powered by Culori. Keep state in sync with `palette/index.ts` APIs. Use Radix-compatible, accessible controls per research Section 3.3.",
            "status": "pending",
            "testStrategy": "Playwright/component tests for swatch reorder, value edits (HEX/HSL), and preview updates; verify constraints (min 2, max 16) are enforced."
          },
          {
            "id": 7,
            "title": "Wire parameter controls to clip UI",
            "description": "Connect headless sliders to effect parameters.",
            "dependencies": [
              3,
              6
            ],
            "details": "Implement `studio/src/features/timeline/ParameterControls.tsx` using `@radix-ui/react-slider` normalized 0–1 mapping to physical units (e.g., exponential mapping for Hz). Synchronize with registry parameter descriptors and update previews without exceeding the UI budget; integrate with `App.tsx` selection and `projectSchema` clip params.",
            "status": "pending",
            "testStrategy": "Integration tests: parameter changes propagate to effect evaluation; Radix slider mapping respects ranges/units; UI remains responsive with updates <16ms."
          },
          {
            "id": 8,
            "title": "Finalize preset serialization and validation suite",
            "description": "Ensure presets serialize, load, and pass tests.",
            "dependencies": [
              2,
              3,
              5,
              7
            ],
            "details": "Implement JSON serialization/deserialization for registry presets in `studio/src/lib/effects/presets.ts`; verify compatibility with renderer/compiler inputs and palette references. Assemble regression suite spanning generator outputs, modifier sequencing, palette usage, and UI flows.",
            "status": "pending",
            "testStrategy": "Comprehensive unit + UI regression plus snapshot comparisons to confirm preset integrity across reloads; property checks on preset params; round-trip tests for palette/editor interactions."
          }
        ]
      },
      {
        "id": 47,
        "title": "Build Automation and Modulation System",
        "description": "Add keyframe-based automation tracks, easing controls, and LFO sources targeting effect parameters and global settings.",
        "details": "- Automation model: each curve stores keyframes `{time, value, easing}` with cubic Bezier support; reuse `bezier-easing 3.0` for custom curves.\n- UI: stopwatch arm toggles automation per parameter; when active, display curve overlay in automation track; show bezier handles only on selection to reduce clutter.\n- Implement evaluation pipeline: at render, sample curve -> value; for performance, pre-bake segments into piecewise linear approximations at zoomed-out levels.\n- LFO sources: sine, square, noise; allow routing to parameter via modulation matrix (depth, offset, phase). Provide per-clip LFO frequency sync to BPM.\nPseudo-code:\n```\nfunction sampleAutomation(paramId, time) {\n  const curve = automationIndex[paramId];\n  const base = curve.interpolate(time);\n  const lfo = lfoRegistry[paramId]?.sample(time);\n  return clamp(base + lfo.depth * lfoWave(time), 0, 255);\n}\n```\n- Add F9 shortcut for quick ease-in-out by updating keyframe easing data.\n- Optimize by caching last sample per frame to avoid redundant computations (>320 LEDs).\n",
        "testStrategy": "- Unit tests for interpolation accuracy (linear, bezier, ease-in/out) and LFO phase alignment using Vitest snapshots.\n- Performance benchmark: run evaluation over 10k samples ensuring <2ms per frame.\n- Playwright scenario: user arms automation, adds keys, toggles F9, verifying UI states and store updates.",
        "priority": "medium",
        "dependencies": [
          "46",
          "44"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Automation Curve Data Model",
            "description": "Define the automation curve structures for parameters and global settings.",
            "dependencies": [],
            "details": "Specify data schemas for keyframes with time, value, easing metadata, reuse bezier-easing 3.0, and model indexes for parameter lookup.",
            "status": "pending",
            "testStrategy": "Author schema-focused unit tests ensuring serialization, deserialization, and validation of curve definitions.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Keyframe CRUD and Easing Controls",
            "description": "Provide APIs to create, edit, delete, and reorder keyframes with easing options including F9 shortcut.",
            "dependencies": [
              1
            ],
            "details": "Build parameter automation services handling keyframe mutations, apply cubic Bezier easing updates, and wire F9 shortcut to toggle ease-in-out presets.",
            "status": "pending",
            "testStrategy": "Write unit tests covering add/update/delete flows, easing selection, and F9 shortcut behavior.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build Automation UI Toggles and Overlays",
            "description": "Create UI interactions for arming automation and visualizing curves within tracks.",
            "dependencies": [
              2
            ],
            "details": "Implement stopwatch arm toggles per parameter, render automation tracks with curve overlays, and show Bezier handles conditionally on selection to reduce clutter.",
            "status": "pending",
            "testStrategy": "Use Playwright scenarios verifying arm toggles, overlay visibility, and handle display rules.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Develop Curve Interpolation and Bezier Engine",
            "description": "Implement runtime interpolation for automation curves with cubic Bezier support.",
            "dependencies": [
              1
            ],
            "details": "Construct interpolation utilities evaluating keyframes, mix linear and Bezier easing paths, and expose sampling APIs for render-time consumption.",
            "status": "pending",
            "testStrategy": "Add unit tests validating interpolation accuracy across linear, ease-in, ease-out, and custom Bezier keys.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add Pre-Bake Sampling and Level-of-Detail Pipeline",
            "description": "Optimize automation sampling by precomputing approximations for zoomed-out views.",
            "dependencies": [
              4
            ],
            "details": "Generate piecewise linear segments per curve at multiple resolutions, cache them for timeline rendering, and handle invalidation when keyframes mutate.",
            "status": "pending",
            "testStrategy": "Benchmark pre-bake routines over large curves and assert approximation error stays within defined tolerances.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Implement LFO Source Generators with BPM Sync",
            "description": "Create sine, square, and noise LFO generators with per-clip BPM synchronization.",
            "dependencies": [
              1
            ],
            "details": "Develop LFO waveforms supporting depth, offset, and phase, and add tempo-aware frequency control tied to clip metadata.",
            "status": "pending",
            "testStrategy": "Cover waveform generation and BPM sync via unit tests comparing sampled outputs against expected phase-aligned values.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Create Modulation Routing Matrix and Parameter Mapping",
            "description": "Wire LFO outputs into automation targets using a modulation matrix.",
            "dependencies": [
              6
            ],
            "details": "Implement routing data structures linking LFO sources to parameters with depth scaling, offsets, and runtime enable/disable controls.",
            "status": "pending",
            "testStrategy": "Add integration tests confirming routing assignments apply correct modulation depths and respect enable states.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Integrate Automation Evaluation into Render Loop",
            "description": "Combine automation curves and LFO modulation during playback rendering.",
            "dependencies": [
              2,
              4,
              5,
              6,
              7
            ],
            "details": "Invoke automation sampling and LFO mixers per frame, clamp outputs, and ensure modulation respects parameter ranges for >320 LED channels.",
            "status": "pending",
            "testStrategy": "Run render-loop integration tests verifying sampled values, clamping, and modulation blending across multiple parameters.",
            "parentId": "undefined"
          },
          {
            "id": 9,
            "title": "Add Caching Layer and Performance Validation",
            "description": "Cache last rendered values and validate performance budgets.",
            "dependencies": [
              5,
              8
            ],
            "details": "Implement frame-level caching to avoid redundant sampling, add instrumentation, and run benchmarks ensuring evaluation stays within <2ms per frame.",
            "status": "pending",
            "testStrategy": "Execute automated benchmarks plus regression alarms to confirm caching effectiveness and frame-time targets.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 9,
        "expansionPrompt": "Break work into defining automation data models, implementing keyframe CRUD/easing, building UI interactions, creating interpolation engines, adding pre-bake performance strategies, implementing LFO sources, wiring modulation routing, integrating evaluation into playback, and adding caching/performance validation.",
        "updatedAt": "2025-10-16T18:41:37.290Z"
      },
      {
        "id": 48,
        "title": "Integrate Real-Time 3D Preview Pipeline",
        "description": "Render LED array with Three.js InstancedMesh, HQ/LQ quality modes, bloom isolation, and <50ms update latency.",
        "details": "- Use Three.js r160 with `EffectComposer`, `RenderPass`, `UnrealBloomPass`, and selective bloom via layer masking; configure OrbitControls with presets (front, side, isometric) saved in state.\n- Instantiate 320 LED spheres using `InstancedMesh` with GPU color updates through `setColorAt` batched buffer updates; throttle updates using `postMessage` to Web Worker (if OffscreenCanvas supported) else fallback to main thread with requestAnimationFrame.\n- Acrylic plate mesh using `MeshPhysicalMaterial` (transmission 0.95, IOR 1.49) and environment map from precomputed HDR.\n- Quality toggle: HQ (bloom + 60fps), LQ (skip bloom, cut to 30fps) triggered during scrubbing or when CPU load high.\n- Integrate with timeline state: subscribe to playhead changes, pass frame buffer from compiler preview service; ensure updates within 50ms by diffing frames and only updating mutated LEDs.\nPseudo-code:\n```\nfunction updatePreview(frame) {\n  frame.leds.forEach((color, index) => instancedMesh.setColorAt(index, color);\n  instancedMesh.instanceColor.needsUpdate = true;\n  composer.render();\n}\n```\n- Add screenshot capture pipeline for templates/thumbnails.\n",
        "testStrategy": "- WebGL headless tests using `vitest-environment-webgl` verifying instanced color updates.\n- Performance profiling: measure latency via `performance.mark` around frame dispatch → render; ensure <50ms average.\n- Visual regression: Playwright with `@animaapp/playwright-testing` capturing preview snapshots (bloom disabled) to compare frames.",
        "priority": "medium",
        "dependencies": [
          "46",
          "47",
          "44"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure Three.js renderer and composer",
            "description": "Set up the Three.js r160 renderer, composer, passes, and camera controls for the preview scene.",
            "dependencies": [],
            "details": "Initialize WebGLRenderer with proper pixel ratio, create EffectComposer with RenderPass and UnrealBloomPass, and wire OrbitControls presets persisted in shared state.",
            "status": "pending",
            "testStrategy": "Add renderer initialization unit test that ensures passes and controls mount without throwing in jsdom + webgl shim.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Build InstancedMesh LED grid infrastructure",
            "description": "Create the 320 LED InstancedMesh, geometry, materials, and color buffer plumbing.",
            "dependencies": [
              1
            ],
            "details": "Instantiate spheres with InstancedMesh, preload transforms, and expose helper to batch apply LED color updates via setColorAt and instanceColor.needsUpdate toggling.",
            "status": "pending",
            "testStrategy": "Write WebGL headless test that feeds synthetic color data and asserts instanceColor buffer updates.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement worker and OffscreenCanvas bridge",
            "description": "Establish worker messaging pipeline for frame color updates with main-thread fallback.",
            "dependencies": [
              2
            ],
            "details": "Create Web Worker that receives frame payloads, applies throttling, and posts structured color buffers; detect OffscreenCanvas support and transfer renderer context when available, else schedule requestAnimationFrame updates.",
            "status": "pending",
            "testStrategy": "Add worker integration test mocking postMessage to confirm throttling cadence and fallback path selection.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate timeline-driven frame diff updates",
            "description": "Wire preview updates to timeline subscriptions with frame diffing to minimize InstancedMesh writes.",
            "dependencies": [
              2,
              3
            ],
            "details": "Subscribe to compiler preview service, compute diffs between successive LED frames, and call instanced color updater only for mutated indices while ensuring overall update time stays below 50ms.",
            "status": "pending",
            "testStrategy": "Create timeline simulator test verifying diff logic skips unchanged LEDs and meets latency budget under mocked performance marks.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Develop adaptive HQ/LQ quality controller",
            "description": "Build logic switching between HQ and LQ rendering modes based on scrubbing and performance signals.",
            "dependencies": [
              1,
              3,
              4
            ],
            "details": "Monitor playhead state and CPU metrics to toggle bloom pass enablement and frame rate cap, adjusting composer pipeline and requestAnimationFrame interval accordingly.",
            "status": "pending",
            "testStrategy": "Add unit test that simulates load events and asserts mode toggles propagate to bloom enablement and frame scheduling hooks.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Add performance instrumentation and telemetry hooks",
            "description": "Instrument the rendering pipeline to capture latency metrics and expose them for monitoring.",
            "dependencies": [
              4,
              5
            ],
            "details": "Place performance.mark/measure around frame ingest and render, aggregate moving averages, and emit telemetry events for profiling overlays or logging sinks.",
            "status": "pending",
            "testStrategy": "Implement automated test verifying metrics buffer records samples and surfaces warning when thresholds exceeded.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Implement screenshot capture pipeline",
            "description": "Enable capturing preview snapshots for templates and thumbnails without disrupting live rendering.",
            "dependencies": [
              1,
              2,
              5
            ],
            "details": "Add offscreen render target workflow or temporary resize to capture high-resolution frames, ensure composer state restores after capture, and expose API for snapshot requests.",
            "status": "pending",
            "testStrategy": "Create Playwright-based test invoking capture API and validating image buffer dimensions and bloom isolation.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Establish WebGL and visual regression test suite",
            "description": "Configure automated tests validating rendering fidelity and regressions.",
            "dependencies": [
              6,
              7
            ],
            "details": "Set up vitest with webgl environment for unit coverage, Playwright visual baselines with anima plugin, and CI scripts to compare snapshot diffs for InstancedMesh scenes.",
            "status": "pending",
            "testStrategy": "Hook vitest and Playwright commands into CI to run headless WebGL cases and visual diffs, failing builds on drift.",
            "parentId": "undefined"
          }
        ],
        "complexity": 9,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Plan steps for Three.js renderer/composer setup, InstancedMesh LED array updates, worker/offscreen bridges, adaptive quality control, timeline frame integration, performance instrumentation, screenshot capture, and WebGL plus visual regression testing."
      },
      {
        "id": 49,
        "title": "Implement Pattern Compiler and Segmentation Engine",
        "description": "Convert timeline data into .prism v1.1 binaries with adaptive FPS, segmentation respecting 256 KB limit, and temporal metadata extraction.",
        "details": "- Rust worker (`compile.rs`) executed via `tauri::async_runtime::spawn_blocking`; use `serde_repr` for enum TLV encoding and `byteorder` for endian-safe writes.\n- Evaluation pipeline: for each frame, resolve active clips, evaluate effects + automation into RGB[320]; optimize by precomputing static segments and reusing buffers.\n- Adaptive FPS: analyze temporal variance by computing per-LED delta; if below threshold, quantize to lower FPS (60→30→24→15) while ensuring transitions align with clip boundaries.\n- Segmentation: accumulate frames into chunk until payload size ~240 KB, then finalize file names `PatternName__sNNN.prism`; carry over cross-segment state for seamless playback.\n- Temporal metadata detection: identify motion vectors (LEFT/RIGHT/CENTER/EDGE) by analyzing centroid shifts and write sync mode TLVs.\nPseudo-code:\n```\nfor segment in segments {\n  write_header(&mut buf, header);\n  for frame in segment.frames {\n    buf.extend_from_slice(&frame.rgb);\n  }\n  stream_writer.send(buf).await?;\n}\n```\n- Provide streaming write using `tokio::io::BufWriter` to avoid memory spikes; expose compile progress via IPC events.\n",
        "testStrategy": "- Rust unit tests verifying header composition, CRC, segmentation thresholds, and FPS downsampling correctness.\n- Property tests (`proptest`) on random clip arrangements ensuring file size ≤256 KB and total frame count preserved.\n- Benchmark harness measuring typical 5s pattern compile <500ms on baseline hardware.",
        "priority": "medium",
        "dependencies": [
          "46",
          "47"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design pattern compiler worker architecture",
            "description": "Outline module responsibilities and threading for compile.rs worker supporting the pattern compiler.",
            "dependencies": [],
            "details": "Produce diagrams covering spawn_blocking orchestration, TLV serialization boundaries, IPC progress channels, and error flow.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement effect evaluation pipeline with reusable buffers",
            "description": "Build frame evaluation loop resolving clips, running effects, and reusing RGB buffers for efficiency.",
            "dependencies": [
              1
            ],
            "details": "Code routines to precompute static clip spans, seed reusable RGB[320] buffers, and enforce endian-safe writing via byteorder integration.",
            "status": "pending",
            "testStrategy": "Add unit tests asserting effect outputs reuse buffers and match expected RGB frames for fixture timelines.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Develop adaptive FPS analysis module",
            "description": "Create per-LED delta analysis to downsample frame rate while preserving clip-aligned transitions.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement variance tracking, threshold comparison, and quantization ladder (60→30→24→15) ensuring decisions respect clip boundaries.",
            "status": "pending",
            "testStrategy": "Use targeted unit tests covering high-motion, low-motion, and boundary cases to verify FPS selection logic.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Build segmentation and chunk finalization logic",
            "description": "Accumulate frames into segments respecting 256 KB payload limit and emit chunk metadata.",
            "dependencies": [
              2,
              3
            ],
            "details": "Implement rolling payload estimator, chunk rollover at ~240 KB, filename generation PatternName__sNNN, and cross-segment state carryover.",
            "status": "pending",
            "testStrategy": "Add integration tests verifying segment sizes, filename sequencing, and seamless playback across segment boundaries.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement temporal metadata extraction",
            "description": "Detect motion vectors and sync modes from centroid shifts and embed TLVs in segment output.",
            "dependencies": [
              2,
              3
            ],
            "details": "Analyse frame centroids to classify LEFT/RIGHT/CENTER/EDGE motion, build TLV records via serde_repr, and attach per-segment metadata.",
            "status": "pending",
            "testStrategy": "Create analytical tests using synthetic motion patterns to validate TLV encoding and classification accuracy.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Add streaming writer with IPC progress updates",
            "description": "Stream compiled segments via BufWriter and broadcast incremental progress through IPC events.",
            "dependencies": [
              4,
              5
            ],
            "details": "Wire tokio::io::BufWriter streaming to async channel, handle backpressure, and emit progress payloads consumable by frontend.",
            "status": "pending",
            "testStrategy": "Write async integration test capturing progress events while ensuring streamed output matches expected byte sequences.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Optimize pipeline memory usage",
            "description": "Reduce peak allocations by reusing buffers and tuning segment lifecycle management.",
            "dependencies": [
              2,
              4,
              6
            ],
            "details": "Profile allocations, implement buffer pools, adjust segment finalize timing, and guard against unnecessary cloning throughout pipeline.",
            "status": "pending",
            "testStrategy": "Run profiling harness to compare peak heap usage before and after optimizations across representative timelines.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Create property and benchmark test suite",
            "description": "Establish automated checks covering segmentation, FPS heuristics, and performance targets.",
            "dependencies": [
              2,
              3,
              4,
              5,
              6,
              7
            ],
            "details": "Author proptest cases for random clip arrangements, add CRC and size assertions, and build criterion benchmarks hitting <500ms goal.",
            "status": "pending",
            "testStrategy": "Execute proptest-based suites and criterion benchmarks validating size limits, frame counts, and runtime thresholds.",
            "parentId": "undefined"
          },
          {
            "id": 9,
            "title": "Document compiler workflow and operational guidance",
            "description": "Capture architecture, CLI usage, and troubleshooting steps for the pattern compiler.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6,
              7,
              8
            ],
            "details": "Update engineering docs explaining pipeline stages, configuration flags, monitoring hooks, and testing strategy for ongoing maintenance.",
            "status": "pending",
            "testStrategy": "Perform documentation review ensuring accuracy, completeness, and alignment with implemented compiler behavior.",
            "parentId": "undefined"
          }
        ],
        "complexity": 9,
        "recommendedSubtasks": 9,
        "expansionPrompt": "Outline tasks for architecting the compiler worker, integrating effect evaluation buffers, implementing adaptive FPS analysis, building segmentation/chunking, extracting temporal metadata, streaming writes with IPC progress, optimizing memory use, adding property/benchmark tests, and documenting the workflow."
      },
      {
        "id": 50,
        "title": "Deliver Upload, Sync Workflow, and Onboarding Experience",
        "description": "Create end-to-end compile→upload→play pipeline with progress UI, storage management, autosave recovery, and novice onboarding flow, leveraging firmware TLV commands now available for LIST/DELETE/STATUS.",
        "status": "pending",
        "dependencies": [
          "42",
          "43",
          "44",
          "46",
          "49",
          "55",
          "57"
        ],
        "priority": "medium",
        "details": "- Upload manager: use existing WebSocket TLV channel to send segments sequentially (PUT_BEGIN/PUT_DATA/PUT_END) respecting `max_chunk`; show progress bar updating every 100ms with bytes sent and surface firmware ACK TLVs.\n- Storage panel: call ready LIST/DELETE TLVs to display existing patterns, sizes, delete operations; include storage bar indicating remaining capacity based on STATUS metadata.\n- Sync button: orchestrate compile (Task 49) + upload + PLAY first segment; run STATUS TLV preflight, and handle errors (storage full, CRC mismatch, TLV version mismatch) with actionable dialogs.\n- Autosave recovery UI: on startup, detect crashes and offer restore; integrate with state from Task 43.\n- Onboarding wizard: steps (discover device → connect → choose template → tweak brightness/speed → sync). Provide 10 starter templates stored as `.prismproj` seeds using effect library, automatically loading preview thumbnails.\n- Tooltips: implement contextual hints with `floating-ui` showing on first interaction, persisted via local preference store.\nPseudo-code:\n```\nasync function syncProject() {\n  await assertDeviceReady(await fetchStatusTLV());\n  setStatus('compiling');\n  const segments = await compileProject(currentProject);\n  setStatus('uploading');\n  for (const segment of segments) {\n    await uploadSegment(ws, segment);\n  }\n  await playSegment(ws, segments[0]);\n}\n```\n- Ensure workflow completes novice path in <2 minutes by minimizing blocking prompts and prefetching templates.",
        "testStrategy": "- Playwright E2E scenario covering full wizard flow with mock device, asserting total time under threshold via timers and verifying STATUS preflight gates sync attempts.\n- Integration tests using mocked WebSocket verifying TLV framing, retries on chunk failure, and accurate progress updates.\n- User acceptance checklist verifying tooltips only show once and preferences persist across restarts, plus confirmation that LIST/DELETE TLVs reflect storage updates.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement WebSocket upload manager",
            "description": "Build the upload manager that streams compiled segments over the existing device WebSocket using PUT_BEGIN/PUT_DATA/PUT_END operations.",
            "dependencies": [],
            "details": "Respect max_chunk sizing, emit per-segment lifecycle events, handle TLV-based server ACK/NAK messages, and expose promises for sequential upload completion.",
            "status": "pending",
            "testStrategy": "Add mocked WebSocket unit tests that assert TLV chunk slicing, sequential PUT commands, and retryable NAK handling.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add upload progress UI with retry handling",
            "description": "Create a responsive progress interface that tracks upload bytes, updates every 100ms, and surfaces retry/backoff states to the user.",
            "dependencies": [
              1
            ],
            "details": "Wire UI to upload manager events, show aggregate and per-segment progress, display remaining time, and model exponential backoff retries with inline guidance.",
            "status": "pending",
            "testStrategy": "Write integration tests mounting the UI with fake upload events to verify 100ms updates, retry indicators, and correct completion messaging.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build storage management panel",
            "description": "Implement the storage view listing device patterns, file sizes, delete controls, and remaining capacity bar using LIST responses.",
            "dependencies": [
              1
            ],
            "details": "Call ready LIST TLVs over the WebSocket, render sortable table, show storage bar tied to STATUS capacity metadata, and confirm delete confirmations update the view without reload.",
            "status": "pending",
            "testStrategy": "Create UI tests stubbing LIST/DELETE TLVs to verify rendering, capacity calculations, and state refresh after removal.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Orchestrate compile→upload→play sync flow",
            "description": "Implement the Sync button flow that triggers compile, uploads segments, plays the first segment, and handles error dialogs.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Integrate Task 49 compiler API, chain upload manager, issue PLAY command on first segment, and run STATUS/PLAY TLVs with actionable dialogs for storage full, CRC mismatch, or protocol incompatibility.",
            "status": "pending",
            "testStrategy": "Author integration tests mocking compiler and WebSocket to confirm happy path execution plus error dialog coverage for storage, CRC, and STATUS failures.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Integrate autosave recovery experience",
            "description": "Add startup autosave detection that surfaces crash recovery options and restores state from Task 43 if the user opts in.",
            "dependencies": [
              4
            ],
            "details": "Check persisted autosave metadata on launch, render recovery modal with diff preview, handle accept/skip paths, and clear autosave once restoration completes.",
            "status": "pending",
            "testStrategy": "Implement React component tests simulating crash flags to ensure restore modal appears, applies state, and clears autosave markers on dismissal.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Seed starter templates and thumbnails",
            "description": "Provision ten `.prismproj` starter templates with effect-based presets, ensure metadata loads quickly, and prefetch thumbnails.",
            "dependencies": [],
            "details": "Serialize template seeds, bundle thumbnail assets, index metadata for search, and preload templates into cache so onboarding and library views load instantly.",
            "status": "pending",
            "testStrategy": "Add data validation tests checking template metadata completeness and thumbnail availability, plus smoke test ensuring preload finishes under budget.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Craft onboarding wizard for novice flow",
            "description": "Deliver the guided onboarding wizard covering discovery, connection, template choice, tweaking, and sync within the two-minute target.",
            "dependencies": [
              4,
              6
            ],
            "details": "Compose stepper UI, hook into device discovery APIs, surface template previews, expose live brightness/speed controls, and auto-trigger sync on completion.",
            "status": "pending",
            "testStrategy": "Build Playwright wizard tests using mock devices to verify step progression, template selection, and total completion time stays below two minutes.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Implement contextual tooltip preference system",
            "description": "Add floating-ui based tooltips that appear on first interaction and persist their dismissed state in the local preference store.",
            "dependencies": [
              7
            ],
            "details": "Configure floating-ui positioning, map tooltips to wizard and storage hotspots, record dismissals in preferences, and expose reset hook for support needs.",
            "status": "pending",
            "testStrategy": "Write unit tests for the preference store ensuring tooltip flags persist, plus visual regression tests confirming tooltip placement and dismissal.",
            "parentId": "undefined"
          },
          {
            "id": 9,
            "title": "Ship end-to-end workflow tests",
            "description": "Create comprehensive automated tests covering compile→upload→play, storage management, autosave recovery, onboarding, and tooltips.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6,
              7,
              8
            ],
            "details": "Extend Playwright suite with mocked device backends, measure total sync time, assert autosave restore path, verify tooltips show once, validate LIST/DELETE/STATUS TLVs, and confirm storage operations.",
            "status": "pending",
            "testStrategy": "Implement Playwright scenarios with timing assertions, mocked TLV failures, and CI smoke run to guard the full novice pipeline.",
            "parentId": "undefined"
          }
        ],
        "complexity": 9,
        "recommendedSubtasks": 9,
        "expansionPrompt": "Break work into creating the WebSocket upload manager, adding progress UI with retries, building the storage management panel, orchestrating compile→upload→play sync flows, integrating autosave recovery, seeding starter templates/thumbnails, crafting the onboarding wizard, implementing tooltip preferences, and shipping end-to-end tests."
      },
      {
        "id": 51,
        "title": "Implement decode microbenchmark harness",
        "description": "Build an ESP-IDF microbenchmark harness that drives synthetic palette+indices frames at 120 FPS while logging cycle and memory metrics for the packaging decode path.",
        "details": "- Create `firmware/components/bench/` with a FreeRTOS-compatible harness that schedules a 120 FPS loop via `esp_timer` and records timestamps, cycle counts (`esp_cpu_cycle_count()`), and heap deltas (`heap_caps_get_free_size`).\n- Implement configuration for synthetic frame generators covering baseline palette+indices, XOR delta, and simple RLE payloads; expose knobs for frame size, duration, and pattern mixes without allocating per frame (reuse ≤4 KB working buffers).\n- Define an abstract decode callback interface that accepts palette metadata plus frame payload descriptors; stub handlers that simulate decode latency so real decode from Task #30 can be dropped in later.\n- Aggregate per-interval metrics (avg/p99 latency, heap usage) and emit deterministic JSON using existing writer utilities into `docs/bench/metrics_sample.json`; document harness usage and expected outputs in `docs/bench/README.md`.\n- Ensure harness integrates with ESP-IDF build system (component CMakeLists) and can be invoked from the console to print JSON metrics for retrieval.",
        "testStrategy": "- Run `idf.py build` for the project and confirm the benchmark component compiles without warnings.\n- Flash to target hardware, execute the harness for multiple runs, and capture UART logs verifying 120 FPS cadence, cycle-count packets, and bounded heap usage.\n- Parse emitted JSON metrics to ensure schema includes avg/p99 latency and heap figures, and validate values stay within the decode envelope established in Task 32.\n- Spot check that enabling/disabling XOR and RLE generators alters the reported metrics as expected and that no additional heap allocations occur per frame (monitor `heap_caps_get_minimum_free_size`).",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-10-16T18:13:04.841Z"
      },
      {
        "id": 52,
        "title": "Implement v1.1 Metadata Parser Test Harness",
        "description": "Create a standalone host-side parser harness for v1.1 metadata headers that runs entirely on synthetic vectors (per R2.1/R2.2), exercises CRC coverage permutations, and documents methodology for firmware consumers without relying on prior packaging tasks.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "- Stand up `tools/parser-testbed/` with a Python entrypoint (e.g., `runner.py`) leveraging common CLI utilities from `tools/tooling_core.py` for consistent arguments, logging, and deterministic output; expose subcommands for vector generation, mutation sweeps, and regression runs.\n- Implement header builders that populate required v1.1 fields (`palette_id`, `ramp_space`, `show_params`) and optional/unknown fields, emitting binary blobs and companion JSON manifests to ease diffing; generate all vectors internally so the harness remains independent of packaging artifacts.\n- Encode CRC evaluation routines that mirror firmware expectations: compute base CRC over header bytes up to `crc32`, then validate the reduced coverage spanning only the first 6 metadata bytes; add assertions for boundary cases (minimum payload, max payload, missing fields) aligned with R2.1/R2.2 coverage requirements.\n- Generate mutation strategies (bit flips, field truncation, invalid enum values) to stress parser resilience; automate production of both malformed and golden headers under `tools/parser-testbed/vectors/` with clear naming (e.g., `golden/default_palette.bin`, `mutations/bitflip_byte05.bin`).\n- Author `docs/research/parser_harness.md` summarizing architecture, CRC rationale, and usage instructions; document how to integrate firmware parser outputs and future artifacts from Task 30 while keeping current runs self-contained.\n- Provide a lightweight Makefile or shell wrapper to run the harness locally, capture pass/fail reports, and integrate with CI once available.",
        "testStrategy": "- Run the harness locally against golden vectors to confirm pass results and generate a consolidated report (stdout and JSON artifact) showing CRC verification steps with no external dependencies.\n- Execute mutation suites ensuring each malformed header raises the expected failure code or diagnostic message; include automated checks that unknown optional fields are ignored without aborting.\n- Perform a regression that feeds Task 6 parser APIs (or stubs when unavailable) via FFI/CLI bridge, validating decoded metadata matches the generated manifests while confirming the harness still operates solely on synthetic inputs.\n- Sanity-check documentation links and example commands by running `markdownlint` (if configured) and manually following setup instructions on a clean environment snapshot.",
        "subtasks": [],
        "updatedAt": "2025-10-16T13:54:47.495Z"
      },
      {
        "id": 53,
        "title": "Build ESP32-S3 Decode Benchmark Harness",
        "description": "Create an ESP-IDF microbenchmark component that exercises a stubbed decoder at 120 FPS with deterministic timing and reports detailed latency metrics.",
        "details": "- Add `firmware/components/bench/` with a FreeRTOS task or `esp_timer` periodic callback that enforces an ~8.33 ms (120 FPS) loop using `esp_timer_start_periodic`, captures start/end timestamps via `esp_timer_get_time()`, and samples CPU cycles with `esp_cpu_get_cycle_count()`.\n- Allocate a single static working arena (≤4 KB) shared across frames; forbid `malloc`/`free` in the hot loop and surface CI asserts for heap deltas using `heap_caps_get_free_size(MALLOC_CAP_8BIT)` before/after each frame.\n- Implement synthetic frame generators that cover: (a) raw palette+index buffers of varying resolutions, (b) XOR-delta streams that flip high-entropy regions, and (c) simple RLE bursts that alternate compressed/expanded spans; each generator should report bytes touched so the harness can tally workload size.\n- Define and document the stubbed entry point `decode_frame(const uint8_t *index_buffer, const uint32_t *palette, decoder_state_t *prev_state)` (exact signature per code style) that receives reused state buffers, applies generator-selected transform branches, and returns status so the harness can plug in the eventual Task 30 decoder.\n- Track per-frame latency, cycle counts, and bytes processed in ring buffers; after N frames compute aggregates (avg, min/max, p95/p99) and emit structured JSON blobs via `ESP_LOGI` and a persistent log file (e.g., SPIFFS/LittleFS using `esp_vfs_spiffs_register`) with run metadata, configuration, and summaries.\n- Ensure UART output is line-delimited JSON and the file writer batches flushes outside the timing-critical section to avoid jitter; expose menuconfig/CLI hooks to select generator mix, frame count, and output destination paths.\n- Produce `docs/bench/README.md` detailing menuconfig prerequisites, build/flash instructions (`idf.py build`, `idf.py -p <PORT> flash monitor`), expected JSON schema, and guidelines for swapping in the real decoder implementation from Task 30.",
        "testStrategy": "- Run `idf.py build` for the benchmark target and confirm the component links cleanly with stub decoder symbols resolved.\n- Execute unit tests (Unity or host-based) for synthetic generators verifying byte-count accounting, XOR/RLE edge cases, and invariants (no heap growth) using `idf.py unity test` or equivalent.\n- Flash to an ESP32-S3 dev board, stream logs with `idf.py -p <PORT> flash monitor`, and capture emitted JSON ensuring 120 FPS cadence, average/p99 latency fields, and byte metrics match manual calculations for known frame sets.\n- Retrieve the on-device metrics file (SPIFFS/LittleFS readback) and validate it contains well-formed JSON matching the documented schema; confirm repeated runs do not leak memory and the working buffer remains within the ≤4 KB limit.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold bench component and 120 FPS loop",
            "description": "Create the decode benchmark component foundation with deterministic scheduling.",
            "dependencies": [],
            "details": "Add firmware/components/bench/ with component CMake/Kconfig glue, headers, and bench_harness.c; register init in firmware/main/main.c so esp_timer_start_periodic drives an ~8333 µs loop that reuses a static ≤4 KB arena, wraps decode calls with prism_decode_begin/end, forbids heap operations in the callback, and asserts heap_caps_get_free_size before/after each frame.\n<info added on 2025-10-16T13:48:03.142Z>\nImplemented firmware/components/bench/{CMakeLists.txt,Kconfig,include/bench_decode.h,bench_decode.c} with a CONFIG_PRISM_BENCH_PERIOD_US-driven esp_timer_start_periodic loop, registered prism_decode_hooks that capture esp_cpu_get_cycle_count and esp_timer_get_time metrics, reuse a static ≤4 KB arena with heap_caps_get_free_size guards, stream line-delimited JSON summaries to UART, and expose PRISM_BENCH_ENABLE_FILE/PATH and PRISM_BENCH_AUTORUN Kconfig toggles.\n</info added on 2025-10-16T13:48:03.142Z>",
            "status": "done",
            "testStrategy": "Run idf.py build and a smoke unity target to confirm the bench component links and the timer task boots without heap drift.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T13:48:10.171Z"
          },
          {
            "id": 2,
            "title": "Implement synthetic frame generators",
            "description": "Provide workload generators covering palette, XOR delta, and RLE patterns.",
            "dependencies": [
              1
            ],
            "details": "Create firmware/components/bench/frame_generators.c/h exposing APIs to seed raw palette+index frames, XOR high-entropy deltas, and alternating RLE bursts using the shared arena; report bytes touched per frame, support configurable resolutions, and follow existing prism_* naming and logging conventions.\n<info added on 2025-10-16T14:10:16.294Z>\nImplemented the arena-bounded palette, XOR-delta, and alternating RLE frame generators in `firmware/components/bench/frame_generators.c`/`.h`, wired them into the benchmark loop, and exercised the new APIs via Unity coverage in `firmware/components/tests/test_decode_microbench.c`.\n</info added on 2025-10-16T14:10:16.294Z>",
            "status": "done",
            "testStrategy": "Extend firmware/components/tests/test_decode_microbench.c to validate each generator’s byte counts, deterministic seeds, and arena bounds.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T14:10:22.453Z"
          },
          {
            "id": 3,
            "title": "Define stub decode_frame API and state handling",
            "description": "Add the reusable decoder stub entry point that exercises generator variants.",
            "dependencies": [
              1,
              2
            ],
            "details": "Introduce firmware/components/bench/decode_stub.c/h defining decoder_state_t and the stubbed decode_frame(const uint8_t *index_buffer, const uint32_t *palette, decoder_state_t *prev_state) signature; select generator-specific branches, simulate work without allocations, surface status codes, and keep structures aligned with future Task 30 integration.\n<info added on 2025-10-16T14:10:33.848Z>\nStub now exposes `bench_decode_state_t` capturing prior frame, resolved palette entries, XOR mask, and RLE stream cursors, and the benchmark loop invokes `bench_decode_apply` to translate generator descriptors before metrics sampling.\n</info added on 2025-10-16T14:10:33.848Z>",
            "status": "done",
            "testStrategy": "Unit-test decode_frame via new Unity cases to ensure state reuse, branch coverage, and consistent return codes across generator inputs.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T14:10:38.399Z"
          },
          {
            "id": 4,
            "title": "Integrate metrics buffers and structured logging",
            "description": "Capture per-frame stats, aggregate, and emit JSON metadata.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Implement firmware/components/bench/metrics.c collecting per-frame timestamps, esp_cpu_get_cycle_count results, and byte counts into ring buffers; after configurable N frames compute avg/min/max/p95/p99, emit line-delimited JSON via ESP_LOGI, and spool batches to SPIFFS/LittleFS using esp_vfs_spiffs_register outside the critical timer context to avoid jitter.\n<info added on 2025-10-16T13:48:18.399Z>\nPer-frame samples aggregated in the ring buffer, with avg/min/max/p99 computed once after N frames, then emitted as line-delimited JSON via ESP_LOGI; if PRISM_BENCH_ENABLE_FILE is set the run summary is appended to the metrics file after completion to keep the hot loop jitter-free. Reference usage notes in docs/bench/README.md.\n</info added on 2025-10-16T13:48:18.399Z>",
            "status": "done",
            "testStrategy": "Add Unity/host tests for the metrics math and run idf.py monitor on hardware to confirm JSON output structure and file persistence without timing regressions.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T13:48:19.112Z"
          },
          {
            "id": 5,
            "title": "Expose configuration knobs and document harness usage",
            "description": "Wire menuconfig/CLI options and publish operator guidance.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Add bench Kconfig entries plus optional CLI hooks selecting generator mix, frame count, and log paths; ensure defaults register with sdkconfig. Produce docs/bench/README.md covering menuconfig prerequisites, idf.py build/flash/monitor workflow, emitted JSON schema, and instructions for swapping in the Task 30 decoder.\n<info added on 2025-10-16T14:10:50.106Z>\nExtended bench Kconfig options covering generator pattern selection and enabling CLI overrides, registered the bench console command, wired runtime arguments for frame count, LED count, loop period, and metrics file path, and refreshed docs/bench/README.md with updated menuconfig prerequisites and CLI usage guidance.\n</info added on 2025-10-16T14:10:50.106Z>",
            "status": "done",
            "testStrategy": "Verify new menuconfig options via idf.py menuconfig and review README for accuracy and complete flashing steps.",
            "parentId": "undefined",
            "updatedAt": "2025-10-16T14:10:58.410Z"
          }
        ],
        "updatedAt": "2025-10-16T14:10:58.410Z"
      },
      {
        "id": 54,
        "title": "Run hardware decode benchmark and publish metrics",
        "description": "Execute the ESP32-S3 decode bench harness at 120 FPS—coordinating with Agent 1 to run the suite when the shared hardware fixture is available—capture telemetry across palette/xor/rle patterns, and publish the resulting metrics and summary once collected (task is non-blocking for the release). Schedule this opportunistically only after Tasks 7, 9, and 10 are complete; Agent 1 will coordinate exact timing.",
        "status": "deferred",
        "dependencies": [
          "32",
          "53"
        ],
        "priority": "medium",
        "details": "- Scheduling: Treat this as deferred and non-gating. Run only when Agent 1 confirms the shared S3 fixture is free, and after Tasks 7, 9, and 10 have completed; record the agreed window in the handoff log.\n- Harness location and entry points:\n  - Component: `firmware/components/bench/` (see docs reference `docs/bench/README.md:3`).\n  - Call to run: `bench_decode_run()` (`firmware/components/bench/include/bench_decode.h:24`).\n  - Optional autorun on boot controlled in Kconfig (see `firmware/components/bench/Kconfig:4`) and invoked in `app_main` (`firmware/main/main.c:163`, `firmware/main/main.c:164`).\n  - CLI command (if enabled): `bench_decode …` (`docs/bench/README.md:27`), enable via `PRISM_BENCH_REGISTER_CLI` (`firmware/components/bench/Kconfig:45`).\n- Build/flash/monitor:\n  - Build from `firmware/`: `idf.py -C firmware build`.\n  - Flash + monitor: `idf.py -C firmware -p <PORT> flash monitor`.\n  - FPS timing: default 8333 µs period is 120 FPS (`firmware/components/bench/Kconfig:24`).\n- Run patterns and capture logs:\n  - Run palette, XOR, and RLE workloads at 120 FPS either by:\n    - Toggling `PRISM_BENCH_PATTERN` (menuconfig) or\n    - Issuing three CLI runs: `bench_decode pattern=palette …`, `bench_decode pattern=xor …`, `bench_decode pattern=rle …` (`docs/bench/README.md:27`).\n  - The harness emits a JSON summary line to UART (see example fields in `docs/bench/README.md:30`). Capture each run’s UART output to host files under `logs/bench/` (e.g., `logs/bench/decode-<pattern>-<timestamp>.jsonl`).\n  - Optional device file output: enable `PRISM_BENCH_ENABLE_FILE` and set `PRISM_BENCH_FILE_PATH` (default `/spiffs/bench_decode.jsonl`, `firmware/components/bench/Kconfig:38`) to append the run summary on-device. If enabled, pull this file for archival alongside the host-captured `.jsonl`.\n- Metrics and budget checks:\n  - From the JSON summary, extract `avg_us`, `p99_us`, `max_us`, `avg_cycles`, `p99_cycles`, and heap fields `heap_free_before/after` and `workset_bytes` (per `docs/bench/README.md:30`).\n  - Compare against the envelope from `docs/research/R1.1_decode_budget.md` for 120 FPS and 160 LEDs; confirm zero net heap drift and ≤4 KB working set.\n- Documentation:\n  - Append a new entry to `docs/bench/README.md` summarizing each pattern’s results, dates, device/commit, links to `logs/bench/*.jsonl` (and `/spiffs/…` if used), and note that execution followed Agent 1’s deferred schedule after Tasks 7/9/10.",
        "testStrategy": "- Scheduling and scope:\n  - Verify run occurred only after Tasks 7, 9, and 10, and that Agent 1’s coordination window is recorded. Confirm the task remains non-gating for the release.\n- Execution correctness:\n  - With `idf.py -C firmware -p <PORT> flash monitor`, observe a full run completes per pattern at ~120 FPS with no watchdog resets. If using autorun, confirm `app_main` path was taken (`firmware/main/main.c:163`, `firmware/main/main.c:164`); otherwise call `bench_decode_run()` or use the `bench_decode` CLI per `docs/bench/README.md:27`.\n- Metrics validation:\n  - For each pattern’s `.jsonl`, verify the summary line includes `avg_us`, `p99_us`, `max_us`, `avg_cycles`, `p99_cycles`. Check values align with `docs/research/R1.1_decode_budget.md` or include annotated variance and rationale.\n  - Memory invariants: confirm `heap_free_before == heap_free_after` within instrumentation noise (<1% baseline) and `workset_bytes ≤ 4096`.\n  - If `PRISM_BENCH_ENABLE_FILE` was used, ensure the summary was appended at `/spiffs/bench_decode.jsonl` (`firmware/components/bench/Kconfig:38`) and that it matches the UART-captured host log.\n- Documentation completeness:\n  - Confirm `docs/bench/README.md` references exact host log paths under `logs/bench/`, includes key metrics per pattern, and notes deferred execution after Tasks 7/9/10 with Agent 1 coordination.",
        "subtasks": []
      },
      {
        "id": 55,
        "title": "Implement MSG_TYPE_LIST pattern enumeration",
        "description": "Wire up the LIST (0x22) firmware command so the websocket TLV protocol can return the catalog of stored .prism patterns with metadata needed by Studio.",
        "details": "- Replace the stub in `firmware/components/network/protocol_parser.c:664` with logic that gathers LittleFS metadata, assembles the TLV payload, and sends it back to the requesting socket. Define the payload as `[count:1][entries…]`, where each entry packs `name_len:1`, the UTF-8 filename without extension, followed by big-endian `uint32_t` size and `uint64_t` Unix timestamp; clamp the response so it never exceeds `TLV_MAX_PAYLOAD_SIZE` and surface `ESP_ERR_NO_MEM`/`ESP_ERR_INVALID_SIZE` through `MSG_TYPE_ERROR` if the catalog will not fit. Use defensive bounds checks against `PATTERN_MAX_FILENAME` and reuse the `PRISM_MAGIC` header check to skip corrupt files.\n- Extend the storage layer to expose detailed enumeration. Update `firmware/components/storage/pattern_storage_crud.c:205` to treat `.prism` as the canonical extension (drop the legacy `.bin` filter), enrich the loop to populate `{name,size,mtime}` structs with `stat()` (LittleFS supports `CONFIG_LITTLEFS_TIME`; otherwise return 0 and document the fallback), and add a helper such as `storage_pattern_enumerate()` that allocates caller-supplied buffers for the strings while guarding against >25 files per ADR-006. Keep file-system access under the existing mutexes and ensure `closedir()`/`free()` paths are leak-free.\n- Introduce a targeted websocket send helper so protocol handlers can reply to a single client. Add `ws_send_binary_to_fd(int client_fd, const uint8_t *data, size_t len)` beside the existing broadcast routine in `firmware/components/network/network_manager.c:1318`, export it via the private header, and implement it with `httpd_ws_send_frame_async(g_net_state.http_server, client_fd, …)` queued via `httpd_queue_work` to stay within ESP-IDF best practices. Update `protocol_parser.c:664` to call the helper and surface transport errors.\n- Document the TLV schema for Studio by annotating the new constants/macros (e.g., `LIST_ENTRY_SIZE_BYTES`) in `protocol_parser.h:54` so downstream tasks (Task 50) can decode without guessing, and add brief comments outlining the reason for big-endian packing to keep parity with the existing TLV spec.\n- Bench check heap usage: reuse a static scratch buffer (≤4 KB) or allocate from `heap_caps_malloc(MALLOC_CAP_INTERNAL)` and free after the send to avoid fragmenting the PSRAM pool used by uploads.",
        "testStrategy": "- Add Unity coverage in `firmware/components/network/test/test_protocol_parser.c` that stubs `storage_pattern_enumerate()` (weak symbol) to return two synthetic records and asserts that `handle_list()` emits the expected TLV layout, including big-endian size/timestamp; capture the bytes by overriding `ws_send_binary_to_fd` with a test shim.\n- Create a storage regression test (new `firmware/components/storage/test/test_pattern_storage_list.c`) that seeds a temporary directory with sample `.prism` headers, invokes `storage_pattern_enumerate()`, and checks filtering, sort order, and timestamp fallback when `stat().st_mtime` is zero.\n- Run `idf.py build` followed by `idf.py unity -T network` to ensure the parser and websocket changes compile and pass on the host harness; execute `idf.py flash monitor` on hardware to manually verify that sending MSG_TYPE_LIST returns the expected TLV blob when real `.prism` files exist.",
        "status": "done",
        "dependencies": [
          "4",
          "6"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-10-16T16:20:15.476Z"
      },
      {
        "id": 56,
        "title": "Implement MSG_TYPE_STATUS device info response",
        "description": "Add firmware handling for the STATUS/HELLO (0x30) command so the websocket TLV protocol returns device metadata required by Studio discovery.",
        "details": "- Extend `firmware/components/network/protocol_parser.c` to register a handler for `MSG_TYPE_STATUS (0x30)` that packages a device-info TLV containing: firmware version (ASCII, pulled via `esp_ota_get_app_description()`), LED count (uint16, fixed at 320), storage free space (uint32 or uint64 depending on LittleFS query), and max chunk size (uint16 = 4089).\n- Create a helper that builds the payload as a TLV sequence: `[FW_VERSION_LEN][FW_VERSION_ASCII][LED_COUNT_BE][STORAGE_FREE_BE][MAX_CHUNK_BE]`, respecting the existing TLV framing helpers and `TLV_MAX_PAYLOAD_SIZE` limits; ensure alignment and endian conversions use shared protocol utilities.\n- Wire the handler into the dispatcher from Task 4 so the response reuses the existing websocket send path, returning `ESP_ERR_INVALID_SIZE` or `ESP_ERR_NOT_FOUND` if required components fail; log failures with `ESP_LOGW` but keep the device discoverable.\n- Expose or reuse storage APIs (e.g., `storage_get_free_bytes()` from Task 6 context) to fetch free space, guarding against negative/overflow conditions and defaulting to zero when unavailable.\n- Document the payload structure in the protocol header comments so the desktop Studio team can parse it, and update any TLV enum definitions if a new subtype is introduced.",
        "testStrategy": "- Add a Unity test in `firmware/components/network/test/test_protocol_parser.c` that stubs version and storage helpers, invokes the new handler with a fake websocket context, and asserts the emitted payload bytes match the expected TLV layout and big-endian encoding.\n- Extend an integration smoke test (existing discovery test or new one) to simulate a STATUS request over the dispatcher and confirm the handler returns `ESP_OK` and the framed response fits under `TLV_MAX_PAYLOAD_SIZE`.\n- Perform a hardware sanity check (manual) by issuing the HELLO command via the Studio discovery tool and verifying firmware version, LED count, storage free, and chunk size populate correctly.",
        "status": "done",
        "dependencies": [
          "4",
          "6"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-10-16T16:20:16.350Z"
      },
      {
        "id": 57,
        "title": "Implement MSG_TYPE_LIST handler for pattern enumeration",
        "description": "Wire the firmware LIST (0x22) TLV command to enumerate stored .prism patterns and return metadata for Studio.",
        "details": "- Update `firmware/components/network/protocol_parser.c` to register and implement `handle_msg_type_list()` that opens `/littlefs/patterns/`, iterates `.prism` files, and accumulates metadata until `TLV_MAX_PAYLOAD_SIZE` is reached.\n- For each entry, allocate a scratch struct (stack or static) capturing filename (sans directory, optional `.prism` trimmed), file size (via `stat`), and POSIX mtime converted to big-endian `uint64_t`; encode as `[name_len:1][name_bytes][size_be:4][mtime_be:8]` and prefix the payload with `[entry_count:1]`.\n- Use existing storage abstraction helpers if available (e.g., `storage_pattern_enumerate`); otherwise add a static iterator that filters extensions and guards against LittleFS errors, returning `ESP_ERR_INVALID_SIZE` when the payload would overflow.\n- Surface filesystem and allocation failures through protocol error responses and ensure the websocket reply uses the existing TLV framing utilities so callers receive a single LIST response frame.",
        "testStrategy": "- Add a Unity test in `firmware/components/network/test/test_protocol_parser.c` that stubs the filesystem layer to return two synthetic `.prism` records and asserts the produced TLV byte sequence matches the expected layout, including big-endian fields and entry count.\n- Add a negative-unit test forcing the payload buffer near `TLV_MAX_PAYLOAD_SIZE` to confirm the handler sends an error status (e.g., `ESP_ERR_INVALID_SIZE`).\n- Perform an ESP-IDF integration test on hardware or simulator with three sample `.prism` files to confirm filenames, sizes, and mtimes match `ls -l` output and that Studio receives the correct pattern catalog.",
        "status": "done",
        "dependencies": [
          "4",
          "6"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-10-16T16:20:17.179Z"
      },
      {
        "id": 58,
        "title": "Add Dedicated mDNS Responder Service",
        "description": "Augment the firmware network stack so the device advertises `prism-k1.local` with a `_prism._tcp` service exposing TXT fields for version, LED count, and capability flags using ESP-IDF’s mDNS component.",
        "details": "- Extend `components/network/network_manager.c` (or its initialization helpers) to initialize the ESP-IDF mDNS stack once Wi-Fi STA acquires an IP, ensuring `mdns_init()`, `mdns_hostname_set(\"prism-k1\")`, and `mdns_instance_name_set()` are invoked safely even after reconnects.\n- Register a `_prism._tcp` service on the discovery port defined in configuration (reuse existing websocket/Studio port constant) and populate TXT items: `version=<fw_semver>` pulled from `esp_ota_get_app_description()`, `led_count=320`, and `capabilities=<comma-separated flags>` synthesized from available features (e.g., `patterns,list,status`).\n- Add utility functions to refresh TXT metadata when firmware capabilities change or configuration updates occur (e.g., new LED count or capability toggles), guarding calls with `ESP_ERROR_CHECK` and logging failures.\n- Ensure coexistence with legacy mDNS host announcement implemented in Task 2: avoid duplicate initialization, consolidate into a single responder routine, and gate calls behind network connectivity events (IP_EVENT_STA_GOT_IP) with teardown on disconnect.\n- Document the new responder behavior and TXT schema in the network component README or inline comments for Studio integration reference.",
        "testStrategy": "- Add a Unity test using `idf_component_get_mock('mdns')` or linker-substituted stubs to assert `network_manager_mdns_init()` registers the `_prism._tcp` service and invokes TXT setter APIs with expected key/value pairs.\n- Run on-device verification: flash firmware, connect to the same network, execute `dns-sd -B _prism._tcp` (macOS) or `avahi-browse -rt _prism._tcp` (Linux) to confirm the service appears with correct TXT records.\n- Perform regression check for Wi-Fi reconnect: simulate a disconnect/reconnect cycle (e.g., `wifi_station_disconnect`) and ensure mDNS service re-registers without duplicate handles or crashes via serial logs.",
        "status": "done",
        "dependencies": [
          "2"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-10-16T16:20:18.001Z"
      },
      {
        "id": 59,
        "title": "Harden Tauri security and capabilities",
        "description": "Tighten desktop app security to meet PRD/ADR requirements (CSP, filesystem scope, TLS-only WebSocket policy), aligning with existing Tauri v2 project.",
        "details": "Current state: studio/src-tauri/tauri.conf.json uses a permissive connect-src that includes ws:// and localhost; capabilities/default.json allows broad fs read/write. Implement: 1) CSP: set app.security.csp to default-src 'self'; connect-src 'self' wss://prism-k1.local wss://*.local; in dev, allow ws://localhost:1420 only via TAURI_DEV flag; style-src 'self' 'unsafe-inline' acceptable for Tailwind; object-src/frame-ancestors none remain. 2) Capabilities: define a dedicated capability file (e.g., studio/src-tauri/capabilities/fs-project.json) narrowing file system to project directory only using fs: { scope: [\"$APPDATA/prism\",\"$HOME/PRISM\",\"$DOWNLOAD/prism\",\"$RESOURCE/prism\"] } and reference from tauri.conf.json; keep dialog:allow-open/save and opener minimal. 3) TLS enforcement: in Rust, add a config guard to reject non-TLS hosts in production: if !cfg!(debug_assertions) and url.scheme() != \"wss\" then return Err; provide user guidance to configure device certs later; support dev override via env. 4) Update connect-src and device URLs in UI code to prefer wss:// with fallback to ws:// only when DEV or a test flag is set. 5) Keep freezePrototype=true (already set). 6) CI matrix: add GitHub Actions with macOS-latest, windows-latest, ubuntu-latest building cargo tauri build; run vitest and playwright with xvfb-run. Library versions: Tauri 2.x already, keep @tauri-apps/cli ^2.0.0, Rust 1.77+, TypeScript ~5.9, ESLint ^9, Prettier ^3, Vitest ^2, Playwright ^1.56. Pseudo-code (Rust): if !cfg!(debug_assertions) && !url.starts_with(\"wss://\") { return Err(\"TLS_REQUIRED\") }. Pseudo-code (config): { app.security.csp: \"default-src 'self'; connect-src 'self' wss://*.local\" }",
        "testStrategy": "- Config tests: parse tauri.conf.json and ensure connect-src lacks ws:// in production build. - Rust unit test: attempt device_connect(\"ws://x\") in release cfg path returns TLS_REQUIRED. - E2E smoke: in dev, ws://localhost allowed; in CI production build, connection to ws:// should fail. - Security lint: manual review that fs capability scopes exist and default.json does not include wildcard fs anymore.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 60,
        "title": "Device discovery + manual IP entry UX",
        "description": "Finish device discovery UX with mDNS + manual IP entry, strict validation, deduplication, and persistence of recent devices; align Security (Sec.4) and Next Steps (Sec.8) from docs/research/PRISM_Studio_Architecture_Research.md.",
        "status": "pending",
        "dependencies": [
          "59"
        ],
        "priority": "medium",
        "details": "Codebase alignment and scope:\n- UI entry point: studio/src/App.tsx:4, studio/src/App.tsx:167 renders <DevicePanel />\n- Device panel implementation: studio/src/features/devices/DevicePanel.tsx (scan() at :43, connect() at :63, fetchStatus() at :99)\n- Tauri backend: studio/src-tauri/src/lib.rs:268 (invoke handlers), device_connect at studio/src-tauri/src/lib.rs:313, device_discover at :274\n- Logger util: studio/src/lib/logger.ts:1\n- Current tests: studio/src/features/devices/DevicePanel.test.tsx:1, DevicePanel.upgrade.test.tsx:1\n- Security config: studio/src-tauri/tauri.conf.json (CSP connect-src currently allows ws:// in prod; Task 59 will harden per research Sec.4)\n\nWhat to implement (aligned to Research Sec.4 Security, Sec.8 Actions):\n1) Discovery + Manual Add\n- In DevicePanel (studio/src/features/devices/DevicePanel.tsx), add a small form to manually add IPv4/hostname and port. Validate with:\n  - Host regex: ^(([0-9]{1,3}\\.){3}[0-9]{1,3}|[a-zA-Z0-9.-]+)$\n  - Port: 1–65535\n- Provide two primary buttons: Scan (mDNS refresh using invoke('device_discover')) and Add (manual). Merge results with dedupe on host:port (use a key `${host}:${port}`).\n- On selection, continue to reuse fetchStatus() to compute latency and derive netHealth; thresholds: good <=50ms, ok <=150ms, otherwise poor (already partially present in DevicePanel; formalize display near the Scan button).\n\n2) Security gating (Sec.4)\n- Enforce scheme intent in UI before calling invoke('device_connect'):\n  - DEV (import.meta.env.DEV): allow ws://localhost:<port> only for localhost/127.0.0.1; prefer wss:// for others.\n  - PROD: require wss:// for any non-local host. If user attempts non‑TLS in PROD, block locally and show an error banner.\n- Surface TLS/handshake errors distinctly in UI: map common failures to friendly messages (e.g., TLS required, handshake failed, TIMEOUT, NO_DEVICE, HELLO_UNSUPPORTED; last three will be mapped by Rust in Task 61). Present errors via the existing toast system and connectState state.\n- Note: device_connect (studio/src-tauri/src/lib.rs:313) currently composes ws://. This task gates in UI while Task 59 updates CSP and Task 61 adds richer error codes; do not modify Rust in this task.\n\n3) Recents persistence (no secrets)\n- Store recent devices with metadata in persistent storage:\n  - For Tauri: use @tauri-apps/plugin-store to save under a key like 'devices.recents' in a store file 'recents.bin'.\n  - For web: fallback to IndexedDB (new helper module, see below). Do not store secrets; only { host, port, name?, lastSeenAt, pinned }.\n- Implement a small storage adapter with a consistent API across environments, e.g.:\n  - studio/src/features/devices/recents.ts: load(), upsert({host,port,name?}), pin(host,port), unpin(host,port), list() ordered by pinned desc then lastSeenAt desc, clear().\n  - Optional one-time migration from localStorage if legacy keys exist.\n- Manage dates and a pin toggle in UI; show recent list with most recent first, using the adapter above.\n\n4) UX polish\n- Buttons: Scan + Add grouped with manual form; disable Add when invalid input; inline validation messages below fields.\n- Dedupe: prevent duplicate entries between mDNS and manual by host:port.\n- When connecting, build a display message showing which scheme is intended (WS in DEV for localhost, else WSS) and why; if blocked by security gating, show actionable guidance.\n\n5) Helper utilities\n- Add validators and URL helper in studio/src/features/devices/validators.ts:\n  - isValidHost(str), isValidPort(n), isLocalhost(str)\n  - buildWsUrlForEnv({host,port}): string that selects ws:// for DEV localhost, otherwise wss://; used only for display and gating in UI (actual socket connection is still in Rust until Task 59/61 changes).\n\nExample snippets (TypeScript):\n- Validation and scheme selection\n  function isValidHost(h: string) { return /^(([0-9]{1,3}\\.){3}[0-9]{1,3}|[a-zA-Z0-9.-]+)$/.test(h); }\n  function isValidPort(p: number) { return Number.isInteger(p) && p >= 1 && p <= 65535; }\n  function isLocalhost(h: string) { return ['localhost','127.0.0.1','::1'].includes(h) || h.endsWith('.local'); }\n  function buildWsUrlForEnv(h: string, p: number) {\n    const isDev = !!import.meta.env.DEV;\n    const local = isLocalhost(h) && (h === 'localhost' || h === '127.0.0.1' || h === '::1');\n    if (!isDev) return `wss://${h}:${p}/`;\n    return local ? `ws://${h}:${p}/` : `wss://${h}:${p}/`;\n  }\n- Add handler: setDevices((d) => uniqBy([...d, { name: host, host, port }], (x) => `${x.host}:${x.port}`)); recents.upsert({ host, port, name: host, lastSeenAt: Date.now(), pinned: false });\n\nNotes on related files and future coordination:\n- CSP should be tightened per docs/research/PRISM_Studio_Architecture_Research.md Sec.4 (connect-src wss:// in PROD, ws://localhost only in DEV) in studio/src-tauri/tauri.conf.json; tracked under Task 59.\n- When Task 61 maps backend error codes (e.g., TLS errors, TIMEOUT, HELLO_UNSUPPORTED), wire them to friendly UI messages in DevicePanel connect flow.\n",
        "testStrategy": "Unit (Vitest)\n- validators.ts: host regex, port bounds, isLocalhost(), buildWsUrlForEnv() behavior for DEV vs PROD.\n- recents.ts adapter: upsert, list ordering (pinned first, then lastSeenAt desc), pin/unpin, clear; mock @tauri-apps/plugin-store in Tauri env and use fake IndexedDB in web env.\n- dedupe logic: merging discovered + manual lists unique by host:port.\n\nComponent (Testing Library)\n- DevicePanel manual add: invalid input shows errors and disables Add; valid add updates list with dedupe; pin/unpin toggles ordering; latency and netHealth display when selecting a device.\n- Connect gating: in DEV, ws://localhost allowed and attempted; in PROD, ws:// is blocked (non-local) with explicit error; show TLS/handshake errors distinctly when mocked invoke('device_connect') rejects.\n\nE2E (Playwright)\n- DEV mode: add manual localhost:8081, connect attempts via mocked @tauri-apps/api/core; verify recents persist across reload (Tauri Store present) and pin state retained; Scan + Add buttons functional.\n- PROD mode (build or env shim): non-local host requires wss://; a forced ws:// attempt is blocked in UI with an actionable error.\n\nAcceptance\n- DEV allows ws://localhost only; PROD requires wss://. No secrets stored in recents. Recents survive reload in Tauri (plugin-store) and in web (IndexedDB).",
        "subtasks": [
          {
            "id": 1,
            "title": "Add manual add form + validation",
            "description": "Add IPv4/hostname + port inputs to DevicePanel with regex and bounds validation; disable Add if invalid; merge into list with host:port dedupe.",
            "dependencies": [],
            "details": "Implement in studio/src/features/devices/DevicePanel.tsx near Scan button; reuse existing table rendering; compute unique key `${host}:${port}`; inline error text on invalid.",
            "status": "pending",
            "testStrategy": "Unit: validators.ts; Component: invalid→error, valid→list updated; Dedupe enforced."
          },
          {
            "id": 2,
            "title": "Persist recents (Tauri + web)",
            "description": "Create recents storage adapter (Tauri plugin-store and web IndexedDB) to retain recent devices with lastSeenAt and pinned.",
            "dependencies": [],
            "details": "Add studio/src/features/devices/recents.ts with load/upsert/pin/unpin/clear; store name 'recents.bin' and key 'devices.recents'; order by pinned desc then lastSeenAt desc; optional migration from localStorage.",
            "status": "pending",
            "testStrategy": "Unit: adapter methods; E2E: recents survive reload and pin state retained."
          },
          {
            "id": 3,
            "title": "Security gating + error UX",
            "description": "Gate connect flow per Sec.4: DEV allows ws://localhost, PROD requires wss://; surface TLS errors clearly and block insecure attempts in PROD.",
            "dependencies": [],
            "details": "In DevicePanel connect path (studio/src/features/devices/DevicePanel.tsx:63), use buildWsUrlForEnv() for display and gating; still call invoke('device_connect') but pre-block disallowed combos and show toast with guidance. Map common error strings to user-friendly messages.",
            "status": "pending",
            "testStrategy": "Component: enforce DEV/PROD rules; show distinct TLS vs generic errors; Acceptance: DEV ws://localhost allowed, PROD non-wss blocked."
          },
          {
            "id": 4,
            "title": "Latency/net health polish",
            "description": "Show ping latency and derive net health on selection; keep periodic refresh.",
            "dependencies": [],
            "details": "Leverage existing fetchStatus() timings (DevicePanel.tsx:99) and thresholds (good<=50ms, ok<=150ms, else poor); render near Scan button and in device header.",
            "status": "pending",
            "testStrategy": "Component: after connect, status call sets latency and health; UI reflects thresholds."
          },
          {
            "id": 5,
            "title": "Tests: unit + component + E2E",
            "description": "Add/extend tests covering validators, dedupe, persistence, gating, and end-to-end flows.",
            "dependencies": [],
            "details": "Add studio/src/features/devices/validators.test.ts, recents.test.ts; extend DevicePanel tests; E2E in studio/playwright.config.ts suite to check manual add + recents persistence.",
            "status": "pending",
            "testStrategy": "Run vitest for unit/component; Playwright for E2E with mocked @tauri-apps/api/core."
          },
          {
            "id": 6,
            "title": "Coordination with Task 59/61",
            "description": "Reference CSP hardening and Rust URL enforcement; UI work here assumes those follow-ups.",
            "dependencies": [],
            "details": "Note CSP changes in studio/src-tauri/tauri.conf.json and potential device_connect URL handling updates are part of Task 59 (Security) and Task 61 (error mapping). Do not modify Rust in this task.",
            "status": "pending",
            "testStrategy": "N/A (documentation/coordination)"
          }
        ]
      },
      {
        "id": 61,
        "title": "WebSocket TLV streaming protocol + connection pool",
        "description": "Implement ADR-002-compliant 4KB TLV upload (PUT_BEGIN → PUT_DATA → PUT_END), per-host WebSocket connection pool with jittered backoff, security-aligned TLS policy (wss in release; ws://localhost only in dev), error mapping, and throughput telemetry in the Tauri backend.",
        "status": "pending",
        "dependencies": [
          "59",
          "60"
        ],
        "priority": "medium",
        "details": "Codebase alignment and targets:\n- Current backend: `studio/src-tauri/src/lib.rs:22` defines `ConnPool` as a placeholder; `tlv_request` sends one frame and reads one reply in `studio/src-tauri/src/lib.rs:360`. Dependencies already include `tokio-tungstenite` and `crc32fast` (see `studio/src-tauri/Cargo.toml:34,40`). Frontend device actions live in `studio/src/features/devices/DevicePanel.tsx` and tests mock `@tauri-apps/api/core` (`studio/src/stores/device.test.ts`). Research references: Security section at `docs/research/PRISM_Studio_Architecture_Research.md:1144` and Benchmarks at `docs/research/PRISM_Studio_Architecture_Research.md:1462`. CSP currently allows ws in dev in `studio/src-tauri/tauri.conf.json`.\n\nProtocol constants (ADR-002):\n- `MAX_FRAME=4096`, header = 1(type)+2(len)+4(crc)=7, `MAX_PAYLOAD=4089`.\n- Timeout per operation: 5s.\n- Backoff: 100ms, 200ms, 400ms, 800ms, 1600ms, max cap 2000ms; 20% jitter; up to N=6 attempts.\n\nSecurity alignment (Sec. 4):\n- Enforce TLS-only in release builds for WS connections; allow `ws://localhost:*` only in dev.\n  - In `studio/src-tauri/src/lib.rs`, when forming URLs for pooled clients: if `cfg!(debug_assertions)` allow `ws://localhost` (or host resolves to localhost); otherwise require `wss://` and fail fast with `Err(\"TLS required in production\")` (similar to research sample at `docs/research/PRISM_Studio_Architecture_Research.md:1175`).\n  - Ensure CSP matches: in release builds `connect-src` should include `wss://*.local` (devCsp can include `ws://localhost:*`), see `studio/src-tauri/tauri.conf.json` and research guidance.\n\nConnection pool (per-host):\n- Replace placeholder `ConnPool(Mutex<HashMap<String, ()>>)` with a real pool storing one active client per host: `HashMap<String, WsClient>`, where `WsClient` wraps a `WebSocketStream` split into sender/receiver plus bookkeeping for timeouts and metrics.\n  - Pseudocode: `struct WsClient{ tx: SplitSink<WS, Message>, rx: SplitStream<WS>, last_used: Instant }`.\n  - `async fn pool.get(host: &str) -> Result<WsClient, String>` creates or reuses a connection using `tokio_tungstenite::connect_async` with `wss://` in release, `ws://` permitted for localhost in dev. Apply jittered backoff on connect failures.\n\nTLV upload commands (Rust Tauri commands):\n- Add new commands in `studio/src-tauri/src/lib.rs`:\n  - `#[tauri::command] async fn put_begin(host: String, id: String, size: u32, crc32: u32) -> Result<(), String>`: Builds a TLV frame type `0x10` with payload `[idLen(1), id bytes, size(u32 BE), crc(u32 BE)]`, sends via pooled client, waits for ACK (non-error frame) with 5s timeout.\n  - `#[tauri::command] async fn put_data(host: String, id: String, chunk_idx: u32, bytes: Vec<u8>) -> Result<(), String>`: Sends TLV type `0x11` with payload `[offset(u32 BE), chunk...]`; ensure a full frame never exceeds 4096 (split earlier so `3 + len + 4 <= 4096`). Wait for ACK with 5s timeout.\n  - `#[tauri::command] async fn put_end(host: String, id: String) -> Result<(), String>`: Sends TLV type `0x12` with empty payload and waits for ACK.\n- Upload helper: `async fn upload(host: &str, id: &str, bytes: &[u8]) -> Result<UploadStats, String>` that calls begin → loop PUT_DATA with `MAX_PAYLOAD=4089` → end; verifies ACKs and aborts/close on CRC or length mismatch. Use `tokio::time::timeout` around send/recv (5s) and apply backoff on transient failures.\n\nError handling and mapping:\n- Device error frames: treat TLV type `0xFF` as error with UTF‑8 text payload (consistent with existing `tlv_request` at `studio/src-tauri/src/lib.rs:382`). Map to canonical strings:\n  - `NO_DEVICE` (DNS/connect errors, pool connect failures), `TIMEOUT` (send/recv timeout), `HELLO_UNSUPPORTED` (if device returns that string), `STORAGE_FULL` (payload contains `storage-full`), `CRC_INVALID` (local or device CRC mismatch), `LENGTH_MISMATCH` (frame length mismatch).\n- Preserve existing internal errors like `TLV_CRC_INVALID`/`TLV_LENGTH_MISMATCH` but translate at command boundaries to the above canonical strings.\n\nThroughput telemetry (Sec. 5 alignment):\n- Track metrics per upload: total bytes, duration, bytes/s, chunk count, retry count, success flag. Return `UploadStats` from `upload()` and also emit a Tauri event (e.g., `upload:metrics`) for UI benchmarks.\n  - Example fields: `{ bytes: u64, elapsed_ms: u64, bytes_per_sec: f64, chunks: u32, retries: u32, success: bool }`.\n  - Use `tauri_plugin_log` (already initialized in dev) to log summary; in release, emit event only.\n\nFrontend integration touchpoint:\n- Future Task 67: Wire `DevicePanel` to new upload API (`put_begin/put_data/put_end` or a single `upload()` command). File: `studio/src/features/devices/DevicePanel.tsx`. Keep this task backend-only but emit `upload:metrics` for UI to display.\n\nFraming/CRC implementation notes:\n- Build frames as in existing `tlv_request` and Node helper `studio/scripts/upload-pattern.mjs` (use BE length and CRC placement). Compute CRC32 over `[type, len, payload]` and append u32 BE.\n- On any `CRC_INVALID` or `LENGTH_MISMATCH`, close and evict the pooled client for that host.\n",
        "testStrategy": "- Rust unit tests (src-tauri):\n  - Framing and CRC: Given payloads, verify `1+2+len+4` framing and `crc32fast` hash matches known vectors. File: `studio/src-tauri/src/lib.rs` tests module.\n  - Chunking property tests: for random lengths up to 1MB, ensure each PUT_DATA frame satisfies `3 + payload_len + 4 <= 4096` and `payload_len <= 4089`.\n  - Backoff: simulate connect failures and assert delays follow 100→200→400→800→1600→2000ms with ~±20% jitter.\n  - Error mapping: simulate error frames (type `0xFF`, various payload strings) and transport errors to assert mapping to `NO_DEVICE`, `TIMEOUT`, `HELLO_UNSUPPORTED`, `STORAGE_FULL`, `CRC_INVALID`, `LENGTH_MISMATCH`.\n- Integration tests (tokio):\n  - Mock WS server using `tokio_tungstenite` that validates PUT_BEGIN/DATA/END frames, acks each, and can inject CRC/length mismatches and timeouts. Verify client aborts and evicts pool on mismatch.\n  - Throughput telemetry: upload 1MB and assert reported `bytes_per_sec` > 0 and `chunks` matches ceiling(bytes/4089).\n- Acceptance criteria:\n  - Release build enforces `wss://` only; `ws://` is rejected with a clear error. Dev build allows `ws://localhost` connections.\n  - Upload of 256KB splits into 4KB TLV frames (payload 4089B max), receives ACK per chunk, and completes successfully.\n  - Frontend mock integration: use `vi.mock('@tauri-apps/api/core')` (see `studio/src/stores/device.test.ts`) to assert DevicePanel issues begin/data/end (or single upload) calls for small payloads.\n",
        "subtasks": []
      },
      {
        "id": 62,
        "title": "State architecture: command pattern + temporal history",
        "description": "Extend existing Zustand + Immer to a command-pattern layer with inverse ops and shared Temporal middleware history (50 states) across editing actions, replacing zundo per research Section 1.",
        "status": "pending",
        "dependencies": [
          "60"
        ],
        "priority": "medium",
        "details": "Align with docs/research/PRISM_Studio_Architecture_Research.md (Sec.1 State; Sec.5 Benchmarks). Replace zundo with a custom Temporal middleware and add a typed command pattern, coordinated via a shared root history across stores.\n\nCurrent codebase hot spots to update:\n- zundo usage in stores:\n  - studio/src/stores/project.ts:4 (import { temporal } from 'zundo') and temporal(...) wrapper\n  - studio/src/stores/device.ts:4 (import { temporal } from 'zundo') and temporal(...) wrapper\n  - Undo/redo accessors used in:\n    - studio/src/App.tsx:39, 43, 81 (useProjectStore.temporal.getState().undo/redo)\n    - studio/src/stores/project.test.ts:50, 53\n    - studio/src/stores/device.test.ts:51, 55\n- Timeline state (no temporal today): studio/src/stores/timeline.ts\n- Space bar shortcut is handled in studio/src/features/timeline/TimelineCanvas.tsx:18–36 (local key handler)\n\nImplement:\n1) Temporal middleware (custom) + root controller\n- Add studio/src/state/temporal.ts exporting createTemporalHistory({ limit: 50, partialize?, equality? }) and a RootTemporal controller with: mark(desc?: string), undo(), redo(), canUndo(), canRedo(), clear(), registerStore(name, get, set, options?) to coordinate cross-store snapshots.\n- Replace zundo wrappers in project/device stores with the custom temporal middleware. Ensure one mark per logical command. Keep limit: 50 and partialize to minimize snapshot size (track only project in project store; selected/devices in device store) to stay within the <200KB compressed snapshot budget.\n\n2) Command pattern layer\n- Add studio/src/state/commands.ts defining:\n  type Command<TCtx = void> = { desc: string; do(ctx?: TCtx): void; undo(ctx?: TCtx): void; invariants?: () => void }.\n  export function issueCommand(cmd: Command) { cmd.invariants?.(); cmd.do(); RootTemporal.mark(cmd.desc); }\n- Provide command builders for key mutations used today:\n  - addTrack, addClip in project store (wrap current immer mutations from studio/src/stores/project.ts:45–70)\n  - rename (setName), moveClip, trimClip (move/trim will be used by timeline features)\n- Ensure each command batches a single Immer produce/set to keep a single temporal step.\n\n3) Store integrations\n- studio/src/stores/project.ts: remove zundo import, wrap create() with devtools(immer(...)) and integrate temporal via RootTemporal.registerStore('project', get, set, { partialize: (s) => ({ project: s.project }) }). Update action creators to call issueCommand(command) instead of directly mutating where appropriate (e.g., addClip/addTrack/rename).\n- studio/src/stores/device.ts: remove zundo import; register with RootTemporal only the fields relevant for undo (devices/selected). Keep async TAURI calls outside of temporal marks; mark only when local state transitions.\n- studio/src/stores/timeline.ts: keep as lightweight UI transport store; do not record to temporal by default (decouples playback/transport from edit history). If needed, expose read-only selectors to reduce rerenders.\n\n4) App-level undo/redo wiring\n- studio/src/App.tsx: replace (useProjectStore.temporal.getState().undo/redo) with RootTemporal.undo()/redo() to drive cross-store history. Keep Cmd/Ctrl+Z and Shift+Cmd/Ctrl+Z behavior identical.\n\n5) Keyboard shortcuts J/K/L/Space\n- Add studio/src/hooks/useKeyboardShortcuts.ts to centralize shortcut wiring:\n  - Space: toggle play/pause via timeline store (useTimeline.getState().togglePlay())\n  - J/K/L: shuttle controls (Task 64) via requestAnimationFrame scheduling to avoid coupling shortcut latency to mutation cost\n  - Use passive listeners; ensure shortcuts do not create temporal marks\n- Update studio/src/features/timeline/TimelineCanvas.tsx (currently handles Space locally) to rely on the hook to avoid duplicate listeners.\n\n6) Performance & memory\n- Target undo/redo <5ms with a 500-clip project (Sec.5 Benchmarks). Keep objects flat and use a single Immer produce per command; avoid nested set calls. Continue using selectors/memoization where necessary to minimize rerenders.\n- Maintain a 50-step history and a <200KB compressed snapshot budget upstream by partializing tracked state and ensuring structural sharing across snapshots.\n\nExamples (TypeScript, pseudo):\n- studio/src/state/temporal.ts\n  export const RootTemporal = createTemporalHistory({ limit: 50 });\n  export function issueCommand(cmd: Command) { cmd.invariants?.(); cmd.do(); RootTemporal.mark(cmd.desc); }\n  export function undo() { if (RootTemporal.canUndo()) RootTemporal.undo(); }\n\n- studio/src/stores/project.ts (sketch)\n  import { RootTemporal, issueCommand } from '../state/temporal';\n  const useProjectStore = create<ProjectState>()(devtools(immer((set, get) => ({\n    addClip: (clip) => issueCommand(makeAddClipCommand(set, get, clip)),\n  }))));\n  RootTemporal.registerStore('project', useProjectStore.getState, useProjectStore.setState, { partialize: (s) => ({ project: s.project }) });\n\nMigration notes:\n- Remove zundo-specific temporal.getState() calls; replace with RootTemporal methods.\n- Keep existing action names/signatures to minimize downstream changes.\n- Ensure each command calls RootTemporal.mark once after mutation.\n",
        "testStrategy": "- Property-based tests (command inverses): Using fast-check or similar with Vitest, generate random clips/tracks and assert for each command that applying do then undo returns the store to deepEqual state. Place in studio/src/state/commands.test.ts.\n- Temporal history tests (50-step truncation): Execute 60 commands across both project and device stores; assert RootTemporal.canUndo() becomes false after 50 undos and that oldest steps are dropped. Verify redo stack behavior after issuing a new command. Update existing tests:\n  - studio/src/stores/project.test.ts: replace useProjectStore.temporal.getState().undo/redo with RootTemporal.undo/redo.\n  - studio/src/stores/device.test.ts: same replacement and rename test title to no longer mention zundo.\n- Performance microbench: Create a 500-clip fixture in studio/src/state/perf/addClip.perf.test.ts. Time addClip do/undo over 200 iterations using performance.now; assert mean < 5ms and p95 < 5ms. Ensure tests run without rendering and with minimized observers.\n- Memory footprint check: Validate that partialized snapshots for project/device stay under budget by estimating JSON byte size of partialized state per mark; warn if projected compressed size would exceed ~200KB.\n",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Temporal middleware and RootTemporal controller",
            "description": "Add custom temporal middleware (limit: 50) and RootTemporal with mark/undo/redo/registerStore.",
            "dependencies": [],
            "details": "File: studio/src/state/temporal.ts; expose shared history and store registration.",
            "status": "pending",
            "testStrategy": "Unit tests for undo/redo stack behavior and registerStore fan-out."
          },
          {
            "id": 2,
            "title": "Replace zundo in project store",
            "description": "Swap zundo for custom temporal; partialize to project; wire issueCommand for mutating actions.",
            "dependencies": [
              1
            ],
            "details": "Edit studio/src/stores/project.ts: remove zundo import and temporal wrapper; register with RootTemporal.",
            "status": "pending",
            "testStrategy": "Update project.test.ts to call RootTemporal; ensure undo/redo restores previous names."
          },
          {
            "id": 3,
            "title": "Replace zundo in device store",
            "description": "Swap zundo for custom temporal; track selected/devices; maintain async TAURI calls.",
            "dependencies": [
              1
            ],
            "details": "Edit studio/src/stores/device.ts; update device.test.ts to use RootTemporal API.",
            "status": "pending",
            "testStrategy": "Ensure undo/redo toggles selected device as before."
          },
          {
            "id": 4,
            "title": "Introduce command builders and issueCommand",
            "description": "Add command implementations for addTrack/addClip/rename/move/trim using single Immer produce per command.",
            "dependencies": [
              1,
              2
            ],
            "details": "File: studio/src/state/commands.ts; integrate from project store actions.",
            "status": "pending",
            "testStrategy": "Property-based tests asserting do/undo inverses."
          },
          {
            "id": 5,
            "title": "App-level undo/redo to RootTemporal",
            "description": "Replace useProjectStore.temporal calls with RootTemporal.undo/redo in App.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Edit studio/src/App.tsx lines invoking temporal.getState().",
            "status": "pending",
            "testStrategy": "E2E smoke: simulate Cmd/Ctrl+Z/Y triggers RootTemporal and state changes back/forth."
          },
          {
            "id": 6,
            "title": "Keyboard shortcuts hook (J/K/L/Space)",
            "description": "Add useKeyboardShortcuts hook; decouple from temporal; schedule via rAF.",
            "dependencies": [],
            "details": "File: studio/src/hooks/useKeyboardShortcuts.ts; update TimelineCanvas to rely on the hook.",
            "status": "pending",
            "testStrategy": "Unit: handlers called; Integration: space toggles play without temporal marks."
          },
          {
            "id": 7,
            "title": "Temporal history tests (truncation + redo)",
            "description": "Cross-store sequence of >50 commands; assert truncation and redo semantics.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "Place tests under studio/src/state/temporal.test.ts.",
            "status": "pending",
            "testStrategy": "Vitest: deterministic sequence; verify canUndo/canRedo across stores."
          },
          {
            "id": 8,
            "title": "Perf microbench for addClip do/undo",
            "description": "Measure p95 latency <5ms with 500 clips.",
            "dependencies": [
              2,
              4
            ],
            "details": "File: studio/src/state/perf/addClip.perf.test.ts; use performance.now and a headless store instance.",
            "status": "pending",
            "testStrategy": "Fail test if mean or p95 exceed targets; output timing summary."
          }
        ]
      },
      {
        "id": 63,
        "title": "Persistence layer: autosave, snapshots, migration",
        "description": "Align persistence with research: hybrid autosave (>=250ms throttle, idle flush at 2s, or 10 edits), last-10 per-project snapshot ring buffer with compression (~<200KB), and Zod-based migration pipeline (v1→v2) persisting schemaVersion; scope desktop file paths under Tauri capabilities and use IndexedDB fallback on web; never persist secrets (use keyring/secure store).",
        "status": "pending",
        "dependencies": [
          "62"
        ],
        "priority": "medium",
        "details": "Codebase alignment and targets (Research Sec.1 State/Persistence; Sec.5 Benchmarks):\n\n- Autosave cadence (Studio): Replace 5s throttle with hybrid strategy: >=250ms throttle, idle flush at 2s, and editCount threshold=10.\n  - Current implementation location: `studio/src/stores/project.ts:43` defines the autosave path (added hybrid throttle/idle logic and counter). Hook remains via `markDirty()` wrappers at `studio/src/stores/project.ts:35`.\n  - Behavior: increment `editCount` on mutating actions; if `editCount >= 10` or throttle window >=250ms, trigger `saveProject()`; always schedule an idle flush at 2s to catch last changes. Reset `editCount` after save.\n  - Desktop vs Web: keep using `@tauri-apps/plugin-fs` for desktop files; on web, still save to a storage fallback, but snapshot ring buffer (below) should use IndexedDB.\n\n- Snapshot ring buffer (10 per project, compressed):\n  - Tauri (desktop): write snapshots alongside app data, e.g., `${appDataDir}/prism/autosave/<projectId>/` using `@tauri-apps/api/path` (`appDataDir`) and `@tauri-apps/plugin-fs`. Name files `.prismproj.swp` with timestamp, keep last 10 per `project.id` (sorted by mtime or numeric suffix). Target compressed snapshot size <200KB (Research Sec.5.1 table). Suggested compression: `CompressionStream('gzip')` in WebView or `pako` if needed.\n  - Web fallback: store ring buffer arrays in IndexedDB via `idb-keyval@^6` under key `project:${projectId}:snapshots`. Maintain size by pruning oldest; consider total quota using `navigator.storage.estimate()`.\n  - UI: expose a minimal restore surface (e.g., \"Restore last autosave\") in project/open flow; restoring should pick the newest valid snapshot.\n\n- Migrations (Zod versioning pipeline v1→v2):\n  - Add `studio/src/data/migrations/index.ts` exporting `migrate(data: unknown): ProjectV2` that safe-parses and transforms legacy payloads. Implement discriminated versioning with zod schemas: `ProjectV1` (existing) and `ProjectV2` with `version: 2` and any added defaults (device/sync already present in v1 here, but preserve and normalize).\n  - Update `deserializeProject` in `studio/src/stores/project.ts:199` to call `migrate(JSON.parse(json))` instead of parsing directly with `ProjectSchema`.\n  - Update schema file `studio/src/lib/projectSchema.ts:95` by introducing a new `ProjectV2Schema` (with `version: z.literal(2)`) and keeping the current v1 as `ProjectV1Schema`. Persist `version` when saving.\n  - Secrets hygiene: ensure project JSON never includes credentials; route secrets through `studio/src/lib/secure.ts:1` helpers (Stronghold/Store), not the project payload.\n\n- Storage scoping (Tauri):\n  - Restrict filesystem scope for autosave/snapshots to a dedicated directory via Tauri v2 capabilities (tauri.conf or capabilities file). Keep project save/open paths user-selected, but autosave path should be within app data dir only.\n\n- File touchpoints to modify/create:\n  - Modify: `studio/src/stores/project.ts:43`, `studio/src/stores/project.ts:199` (deserialize to call migrate), `studio/src/lib/projectSchema.ts:95` (introduce versioned schemas, keep v1 for backward parse).\n  - Add: `studio/src/data/migrations/index.ts` (zod safeParse + transform v1→v2), optionally `studio/src/lib/autosave.ts` (shared ring-buffer/compression helpers), IndexedDB adapter (`idb-keyval`).\n  - Keep: `studio/src/lib/secure.ts` for secret storage and ensure project payload omits secrets.\n\n- Size/perf targets (Research Sec.5): compressed snapshot <200KB; autosave non-blocking under ~8ms typical; ring buffer prune to 10; desktop path I/O scoped to app data. Enforce per-snapshot practical limits and validate before writing.",
        "testStrategy": "- Property tests (Vitest + fast-check):\n  - Migration round-trip invariants: for arbitrary valid v1 payloads, `migrate(v1) -> v2` satisfies `ProjectV2Schema.parse(v2)` and preserves intended fields (name/id/timings), adding defaults for new fields. Additionally, `serializeProject(deserializeProject(json))` is idempotent for v2.\n- Autosave cadence (fake timers):\n  - Simulate 12 edits within <250ms windows and assert 2 saves (count-trigger) using spies around `saveProjectToPath`. Simulate idle (no edits) and confirm a flush save occurs at ~2s. Confirm throttling enforces no more than one save within <250ms burst.\n- Snapshot ring buffer:\n  - Desktop: stub fs to create 12 snapshots and assert pruning keeps 10 newest; verify compressed size metadata <200KB (use mocked compressor). Web: with `idb-keyval` mock, push >10 entries and ensure oldest pruned.\n- Crash-recovery:\n  - Corrupt the newest snapshot; restore should choose the last valid one and pass schema parse. Verify UI restore hook loads the recovered project into store.\n- Security hygiene:\n  - Assert that serialization never includes secret fields and that secret read/write occurs only via `secure.ts` helpers.\n",
        "subtasks": [
          {
            "id": 1,
            "title": "Update autosave cadence (hybrid throttle + idle flush + 10 edits)",
            "description": "Replace 5s throttle with >=250ms throttle, 2s idle flush, and editCount>=10 trigger; integrate with existing markDirty hooks.",
            "dependencies": [],
            "details": "Touch `studio/src/stores/project.ts:43` and related helpers; maintain behavior across desktop/web. Ensure edits reset counter and lastSaveAt on save.",
            "status": "pending",
            "testStrategy": "Vitest with fake timers validating save counts and idle flush."
          },
          {
            "id": 2,
            "title": "Implement snapshot ring buffer with compression",
            "description": "Add last-10 per-project snapshots with compression. Desktop: Tauri app data dir; Web: IndexedDB via idb-keyval.",
            "dependencies": [],
            "details": "Add helpers (e.g., `studio/src/lib/autosave.ts`) handling gzip (CompressionStream/pako), filenameing, pruning, and validation.",
            "status": "pending",
            "testStrategy": "Unit tests cover pruning, size metadata, and newest-valid restore selection."
          },
          {
            "id": 3,
            "title": "Introduce versioned Zod schemas and migration pipeline v1→v2",
            "description": "Create `ProjectV1` and `ProjectV2` schemas, implement `migrate()` and wire `deserializeProject` to route through it; persist version 2 on save.",
            "dependencies": [],
            "details": "Add `studio/src/data/migrations/index.ts`; update `studio/src/lib/projectSchema.ts` to export V1/V2 schemas and inferred types; keep backward-compatible parsing.",
            "status": "pending",
            "testStrategy": "Property-based tests ensure migration preserves invariants and v2 parses."
          },
          {
            "id": 4,
            "title": "Add IndexedDB fallback for web autosave/snapshots",
            "description": "Use `idb-keyval@^6` to store ring buffer snapshots per project when running in browser (no Tauri).",
            "dependencies": [],
            "details": "Key format `project:${id}:snapshots`; implement quota checks with `navigator.storage.estimate()`; prune oldest entries over 10 or quota threshold.",
            "status": "pending",
            "testStrategy": "Mock idb-keyval to assert writes, pruning, and quota handling."
          },
          {
            "id": 5,
            "title": "Scope Tauri filesystem paths for autosave",
            "description": "Restrict autosave directory to app data via capabilities and use `@tauri-apps/api/path` to resolve paths.",
            "dependencies": [],
            "details": "Update Tauri capabilities and use a scoped path like `${appDataDir}/prism/autosave/<projectId>`; do not autosave outside scoped dir.",
            "status": "pending",
            "testStrategy": "Config/unit tests validate path resolution and deny writes outside scope; smoke test on desktop build."
          }
        ]
      },
      {
        "id": 64,
        "title": "Timeline renderer (Canvas2D + OffscreenCanvas fallback)",
        "description": "Build 60 FPS timeline canvas with grid/tracks/clips/playhead, LOD optimizations, and pointer/keyboard interactions per PRD.",
        "status": "pending",
        "dependencies": [
          "62"
        ],
        "priority": "medium",
        "details": "Align with research doc (docs/research/PRISM_Studio_Architecture_Research.md: Sec.2 Timeline, Sec.5 Performance) and current Studio code:\n\nCore renderer\n- Extend existing component studio/src/features/timeline/TimelineCanvas.tsx to render via a single offscreen buffer per frame, then one blit to the onscreen canvas. Prefer OffscreenCanvas on capable browsers to enable worker rendering; fall back to the current DOM offscreen buffer (already used via bufferRef) on main thread.\n- Implement virtual scrolling: only rasterize visible time window and track rows each frame. Use the existing pan blit optimization in maybeRebuildStatic(...) and augment with visible-window culling in drawTracks(...).\n- Keep DPR handling via studio/src/lib/canvas.ts (setupDprCanvas, resizeIfNeeded). Maintain pause/idle behavior when tab is hidden and skip frames when nothing is dirty.\n\nWorker + fallback\n- Add studio/src/features/timeline/timeline.worker.ts to host OffscreenCanvas rendering for heavy scenes (e.g., >= N clips). Detect support with HTMLCanvasElement.transferControlToOffscreen() and move static-layer drawing (grid, tracks, clips) into the worker. Keep main thread to orchestrate state changes and a single drawImage(offscreen, 0, 0) blit.\n- Fallback: retain current double-buffer DOM canvas in TimelineCanvas.tsx when OffscreenCanvas/worker is unavailable.\n\nLOD, dirty rects, caching\n- LOD thresholds based on px-per-second (use useTimeline.zoom):\n  - Far zoom: aggregate clip bars (no labels); Mid: clip rects; Near: rects + labels.\n- Dirty-rect redraws: on scroll (offset changes), clip mutations, or selection changes, compute invalidated regions and redraw only affected strips. Leverage existing scroll-blit in maybeRebuildStatic for horizontal pans and add revealed-strip redraw only.\n- Cache Path2D for common shapes (rounded clip rects) and precompute bar/beat tick Path2D for reuse to minimize GC churn. Maintain small in-memory thumbnail/canvas caches for clip artwork if needed.\n\nState, math, snapping\n- Integrate stores in studio/src/stores/timeline.ts (useTimeline) and its helpers secToPx, pxToSec, beatLengthSec. Continue reading tracks from studio/src/stores/project.ts (useProjectStore).\n- Expose snap/quantize service hooks: add studio/src/features/timeline/snap.ts exporting useSnapToGrid(enabled) and quantizeTime(t, bpm, division=1/16) using beatLengthSec(bpm)/4. Apply snapping for seek and marquee endpoints when enabled.\n\nInteractions\n- Keyboard: Space toggles play/pause (exists), add J/K/L shuttle (J=-1x, K=pause, L=+1x) affecting tick() behavior; keep +/- zoom. Pointer: click to seek (exists), add shift+drag marquee selection with pointer capture, drawing selection overlay in the dynamic layer; snap to grid when enabled.\n\nPerformance target\n- Target ~6ms median render time at 60 FPS with ~1000 clips visible window (see research Sec.5.2). Minimize allocations per frame, coalesce drawing, and ensure exactly one onscreen blit per frame.\n\nKey file references\n- Renderer: studio/src/features/timeline/TimelineCanvas.tsx (extends: buffer blit, OffscreenCanvas path, virtual culling) and new studio/src/features/timeline/timeline.worker.ts\n- Canvas helpers: studio/src/lib/canvas.ts (setupDprCanvas, resizeIfNeeded)\n- State/math: studio/src/stores/timeline.ts (useTimeline, secToPx, pxToSec, beatLengthSec)\n- Tracks source: studio/src/stores/project.ts (useProjectStore)\n- Research: docs/research/PRISM_Studio_Architecture_Research.md (Sec.2, Sec.5)\n\nNotes\n- Preserve buildStaticKey and buffer pan-blit behavior; extend with dirty-rect invalidation and LOD thresholds. Move playhead rendering into the offscreen path when targeting single-blit; or draw a minimal dynamic overlay buffer and still blit once.",
        "testStrategy": "Performance\n- Add a perf harness (studio/src/features/timeline/__perf__/timeline_perf.spec.ts) using rAF to sample per-frame render cost over 5s on a synthetic 1000-clip, 50-track dataset; assert median ≈ 6ms and P95 < 10ms. Log draw call counts where practical.\n\nUnit (Vitest)\n- studio/src/stores/timeline.ts: tests for secToPx/pxToSec and beatLengthSec.\n- studio/src/features/timeline/snap.ts: quantizeTime to 1/16th note across multiple BPMs; on/off snapping behavior.\n- LOD selection and dirty-rect computation utilities (extract from TimelineCanvas.tsx where feasible) with thresholds tied to zoom (px/s).\n- Preserve and extend existing tests studio/src/features/timeline/TimelineCanvas.test.tsx and TimelineCanvas.key.test.ts.\n\nE2E (Playwright)\n- Add studio/e2e/timeline.spec.ts: seek, play/pause, zoom (+/−), marquee selection with shift+drag. Use data-testid on the canvas and controls (e.g., data-testid=\"timeline-canvas\", \"play-toggle\"). Include timing assertions for playhead advancement when playing and snapping verification when enabled.\n\nArtifacts\n- Report median/P95 frame render times in CI logs; gate regressions via thresholds from research Sec.5.2.",
        "subtasks": []
      },
      {
        "id": 65,
        "title": "Clip editing interactions",
        "description": "Add drag-create/move/snap/trim/split/ripple trim and rubber-band selection to timeline with command-backed undo/redo; align shortcuts with research (Cmd/Ctrl+K split, Q/W ripple trim, I/O in/out, J/K/L shuttle).",
        "status": "pending",
        "dependencies": [
          "64"
        ],
        "priority": "medium",
        "details": "Align implementation with docs/research/PRISM_Studio_Architecture_Research.md: Sec.2 (Timeline Editing) and Sec.5 (Performance), integrating with existing Canvas timeline and stores.\n\nScope and anchors\n- Renderer: extend overlays/interaction atop existing canvas in studio/src/features/timeline/TimelineCanvas.tsx:23. Use the existing offscreen buffer + single blit pattern for static layers; render drag ghosts/selection/invalid zones as lightweight dynamic overlays.\n- Stores: reuse studio/src/stores/timeline.ts for viewport/playhead and studio/src/stores/project.ts (zundo temporal) for project state + undo/redo. Add UI selection to timeline store or a small co-located UI module (selectedClipIds[], lastFocusedClipId, marqueeRect).\n\nEditing operations\n- Drag-create: mousedown on empty region enters creating mode; new Clip start = pointer→time, duration from drag delta; snap via SnapService; ESC cancels. Constrain to track bounds; min duration ≥ one grid tick.\n- Move: drag existing clip; draw ghost rect; snap to grid/clip/magnetic; prevent overlap on same track; keep start ≥ 0. Update via command.\n- Trim: drag left/right edges; enforce min duration ≥ one tick; preserve snapped edges; invalid drag zones tinted.\n- Split: Cmd/Ctrl+K at playhead splits selected clip(s) at exact playhead time. Create two clips preserving params; command must be exactly invertible.\n- Ripple trim: Q trims left edge to playhead and shifts subsequent clips on the same track left by trimmed duration; W trims right edge to playhead and shifts subsequent clips right accordingly. Ensure no overlap and maintain ordering invariants.\n- Selection: Shift+drag marquee selects multiple clips; maintain last-focused clip for keyboard ops; click toggles selection with modifiers.\n- In/Out points: I/O set timeline in/out on useTimeline store for range operations.\n- Shuttle: J/K/L set playback speed -1/0/+1 on useTimeline; integrate with existing play/tick logic.\n\nSnap service\n- Create studio/src/features/timeline/snap.ts implementing grid/clip/magnetic modes per research Sec.2.2.\n  - API: export type SnapMode = 'grid'|'clips'|'magnetic';\n    export function snap(timeMs: number, modes: SnapMode[], opts: { gridMs: number; tolerancePx: number; magneticRangePx: number; zoom: number; clips: { start: number; duration: number; }[] }): number;\n  - Behavior: grid rounds to nearest gridMs; clips snaps to nearest visible clip edge within tolerancePx (px computed from ms via zoom); magnetic prefers clip edge if closer than 0.5× distance to grid, otherwise grid.\n\nCommand-backed actions (exact inverses)\n- Add commands under studio/src/features/timeline/commands/:\n  - CreateClipCommand, DeleteClipCommand, MoveClipCommand, TrimClipCommand (left/right), SplitClipCommand, RippleTrimCommand.\n  - Each exposes execute(state) and undo(state) with full preimage data captured so that execute→undo yields deep-equal project state. Wire dispatch through useProjectStore and rely on zundo temporal history for global undo/redo hooks (studio/src/stores/project.ts:224).\n\nKeyboard shortcuts and UI affordances\n- Extend TimelineCanvas.tsx key handling to support: 'mod+k' split; 'q'/'w' ripple trim; 'i'/'o' in/out; 'j'/'k'/'l' shuttle; retain existing space/+/-. Prefer react-hotkeys-hook if available; otherwise expand current window keydown handler with preventDefault where needed. Show tooltips on hover for edges/handles; show ghost rect during drag; tint invalid zones.\n\nState machine and rendering hooks\n- Pointer state in TimelineCanvas.tsx: { mode: 'idle'|'creating'|'moving'|'trimming'|'marquee', activeClipId?, edge?: 'left'|'right', startPx, lastPx }. Use requestAnimationFrame to coalesce pointermove updates and avoid per-event allocations. Draw overlays after blitting static buffer (already done around TimelineCanvas.tsx:63).\n\nPerformance (Sec.5)\n- No GC-induced jank during drag: reuse arrays/objects for hit-testing; pool overlay paths; throttle expensive computations to rAF; avoid capturing large closures per event; keep per-frame ≤ ~6ms on 1000 clips. Leverage existing static-buffer scroll blit (TimelineCanvas.tsx:154–195) and only redraw exposed strips on pan.",
        "testStrategy": "- Property-based (fast-check):\n  - Snap invariants (studio/src/features/timeline/__tests__/snap.fast-check.spec.ts): grid rounding, clip-edge tolerance, magnetic preference; idempotence under stable inputs; continuity near thresholds.\n  - Command inverses (studio/src/features/timeline/__tests__/commands.inverse.fast-check.spec.ts): generate sequences of Create/Move/Trim/Split/RippleTrim then undo all; assert deep equality to initial project (serializeProject) and non-overlap invariants per track.\n- Interaction (Vitest + @testing-library/react + @testing-library/user-event):\n  - studio/src/features/timeline/TimelineInteractions.test.tsx: drag-create, move with snap, left/right trim with min-tick enforcement, split at playhead via 'mod+k', ripple trim via 'q'/'w', marquee selection with Shift+drag, Delete removes selection. Use existing TimelineCanvas harness and mocks (see studio/src/features/timeline/TimelineCanvas.test.tsx:1).\n  - Keyboard shortcuts: verify I/O set range in useTimeline; J/K/L shuttle speed; space toggles play remains intact.\n- Performance guards:\n  - Reuse/extend Task 64 perf harness (studio/src/features/timeline/__perf__/timeline_perf.spec.ts): synthetic 1000-clip dataset; assert median rAF work ≈ 6ms and P95 < 10ms during continuous drag/trim; monitor allocation rate (where measurable) to avoid GC spikes.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement SnapService",
            "description": "Add grid/clip/magnetic snapping in snap.ts with snap(timeMs,modes,opts).",
            "dependencies": [],
            "details": "File: studio/src/features/timeline/snap.ts; include unit tests for edge cases per research Sec.2.2.",
            "status": "pending",
            "testStrategy": "Vitest + fast-check properties for rounding/tolerance/magnetic preference."
          },
          {
            "id": 2,
            "title": "Add command objects",
            "description": "Create timeline commands with exact inverses (execute/undo).",
            "dependencies": [
              1
            ],
            "details": "Folder: studio/src/features/timeline/commands/*.ts; implement Create/Move/Trim/Split/RippleTrim; integrate with zundo temporal.",
            "status": "pending",
            "testStrategy": "Unit tests asserting execute→undo deep-equals initial project; randomized sequences."
          },
          {
            "id": 3,
            "title": "Pointer state machine",
            "description": "Wire create/move/trim/marquee interactions with snap + ghosts.",
            "dependencies": [
              1,
              2
            ],
            "details": "Extend studio/src/features/timeline/TimelineCanvas.tsx overlays and pointer handlers; add invalid zone tinting and tooltips.",
            "status": "pending",
            "testStrategy": "Interaction tests simulating mouse down/move/up across modes; visual assertions via DOM roles/aria as feasible."
          },
          {
            "id": 4,
            "title": "Split + ripple trim",
            "description": "Implement Cmd/Ctrl+K split and Q/W ripple trim.",
            "dependencies": [
              2,
              3
            ],
            "details": "Dispatch SplitClipCommand and RippleTrimCommand using playhead from useTimeline; preserve selection context.",
            "status": "pending",
            "testStrategy": "Keyboard-driven interaction tests; unit tests for boundary conditions at edges."
          },
          {
            "id": 5,
            "title": "Selection + marquee",
            "description": "Add selection model and Shift+drag rubber-band.",
            "dependencies": [
              3
            ],
            "details": "Add selectedClipIds[], lastFocusedClipId; update hit-testing and overlay rendering; respect modifiers.",
            "status": "pending",
            "testStrategy": "Interaction tests: multi-select, toggle, preserve last-focused for operations."
          },
          {
            "id": 6,
            "title": "In/Out + shuttle",
            "description": "Wire I/O and J/K/L shortcuts into timeline store.",
            "dependencies": [
              3
            ],
            "details": "Extend key handling in TimelineCanvas.tsx to set in/out and playback speed; preventDefault where needed.",
            "status": "pending",
            "testStrategy": "Keyboard tests asserting state changes in useTimeline; ensure space/zoom keys unaffected."
          },
          {
            "id": 7,
            "title": "Property-based tests",
            "description": "Add fast-check suites for snap + command inverses.",
            "dependencies": [
              1,
              2,
              4
            ],
            "details": "Place under studio/src/features/timeline/__tests__/; cover invariants and undo/redo sequences.",
            "status": "pending",
            "testStrategy": "fast-check with bounded seeds and shrinking; report minimal counterexamples."
          },
          {
            "id": 8,
            "title": "Perf guardrails",
            "description": "Instrument drag paths; verify frame budget on 1000 clips.",
            "dependencies": [
              3,
              4,
              5
            ],
            "details": "Leverage Task 64 perf harness; coalesce pointermove to rAF; avoid allocations in hot paths.",
            "status": "pending",
            "testStrategy": "Perf spec asserting median ≈ 6ms, P95 < 10ms; inspect allocation where measurable."
          }
        ]
      },
      {
        "id": 66,
        "title": "Effect system registry + OKLab blending",
        "description": "Refactor effect system into a plugin-style registry aligned with research Section 3 (Effects) and Section 6 (Libraries). Adapt K1AnimationEngine as a future plugin adapter. Implement Culori-backed color tooling (OKLab/OKLCH/sRGB) and a palette manager (2–16 swatches) with presets and editor. Provide built-in generators (solid, wave, noise, fire) and modifiers (brightness, hueShift, saturation) composed in a pipeline. Ensure performance targets (~1.8ms wave eval @320 LEDs) by reusing buffers and minimizing allocations.",
        "status": "pending",
        "dependencies": [
          "64",
          "62"
        ],
        "priority": "medium",
        "details": "Align with docs/research/PRISM_Studio_Architecture_Research.md (Sec.3 Effects; Sec.5.3 performance; Sec.6.3 Effect System Stack). Implement a plugin registry and Culori-based color tools integrated into the Studio codebase.\n\nRegistry and plugin model\n- Create EffectPlugin interface and registry in `studio/src/lib/effects/registry.ts` with fields: `id`, `kind: 'generator' | 'modifier'`, `parameters` (Zod schema or typed descriptors), `evaluate(params, t, i, ctx)` returning a color for LED `i` at time `t`, optional `presets` and `ui` schema. Provide `register()`, `get(id)`, and `list(kind)` APIs.\n- Plan an adapter for K1AnimationEngine when source becomes available (external plugin), but focus initial delivery on built-ins loaded from `studio/src/lib/effects/plugins/*`.\n\nBuilt-in effects\n- Generators in `studio/src/lib/effects/plugins/`: `solid.ts`, `wave.ts`, `noise.ts` (simplex-noise^4), `fire.ts` (noise + ramp). Each exports `EffectPlugin` and reuses shared buffers to avoid per-frame allocations. Target: ~1.8ms for wave at 320 LEDs (Sec.5.3).\n- Modifiers in `studio/src/lib/effects/modifiers/`: `brightness.ts`, `hueShift.ts`, `saturation.ts`. Compose as a pipeline: generator -> modifiers[]. Ensure neutral/idempotent behavior at defaults (brightness=1, hueShift=0, saturation=1).\n\nColor tooling (Culori)\n- Replace any oklab 0.2 notions with Culori utilities in `studio/src/lib/color/culori.ts`: helpers for `toRgb`, `toOklab`, `toOklch`, `blendOKLab(a,b,w)` (via Culori conversions), `clampRgb`, and `srgbToUint8`. Keep a fast sRGB blend fallback for hot paths.\n- Use Culori exclusively for OKLab/OKLCH/sRGB conversions (docs Sec.6.3). No hard dependency on `oklab` package.\n\nPalette manager\n- Persist palette in project state. Update schema bounds to 2–16 swatches: modify `PaletteSchema` in `studio/src/lib/projectSchema.ts` to `.min(2).max(16)` and keep type `string[]` `#RRGGBB` (currently at `studio/src/lib/projectSchema.ts: ColorHex, PaletteSchema, createEmptyProject`).\n- Add `studio/src/lib/palettes/presets.json` for built-in palette sets used by effects UI. Palette editor UI (drag reorder, HEX/HSL inputs) can live in `studio/src/features/palette/PaletteEditor.tsx` and interact with `useProjectStore` in `studio/src/stores/project.ts`.\n- For export, support optional quantization to ≤64 colors before packaging (see README.md and `tools/prism_packaging.py` note). Keep initial implementation simple (uniform sampling), defer dithering.\n\nEvaluator/compositor\n- Implement `studio/src/lib/effects/evaluator.ts` to evaluate active clips at time `t` based on `useProjectStore().project.tracks` and `device.fps` from `studio/src/lib/projectSchema.ts`. Composite by track order using `blendOKLab` from Culori utilities. Reuse typed arrays (Float32Array/Uint8Array) for frame buffers to minimize GC.\n- Integration point for UI preview is separate from `studio/src/features/timeline/TimelineCanvas.tsx`, which currently renders the editor timeline only. The evaluator can be invoked by a preview panel component later.\n\nDependencies\n- Add NPM deps in `studio/package.json`: `culori@^4`, `simplex-noise@^4`, and (for property tests) `fast-check@^3` (devDependency).",
        "testStrategy": "- Unit tests (Vitest):\n  - Color utilities in `studio/src/lib/color/culori.test.ts`: OKLab/OKLCH/sRGB round-trips with Culori; `blendOKLab` monotonicity on simple ramps; clamping and uint8 packing.\n  - Generators in `studio/src/lib/effects/plugins/*.test.ts`: deterministic outputs for fixed params/seeds; wave frequency/phase correctness; fire mapping bounds.\n  - Modifiers in `studio/src/lib/effects/modifiers/*.test.ts`: neutral/idempotent at defaults; bounds respected and clamped.\n- Property tests (fast-check): parameter bounds never produce NaN/Inf; modifiers idempotent at neutral settings; hue wrapping remains within domain.\n- Snapshot tests: palette serialize/round-trip via `serializeProject`/`deserializeProject` (studio/src/stores/project.ts) and loading of `studio/src/lib/palettes/presets.json`.\n- Integration: evaluator pipeline in `studio/src/lib/effects/evaluator.test.ts` renders overlapping clips and asserts deterministic frame hashes. Use 320 LEDs at 120 FPS for short bursts.\n- Performance checks: micro-benchmark for `wave` generator confirms ~1.8ms per frame at 320 LEDs with buffer reuse; verify no per-frame allocations by tracking object counts and heap snapshots (where available).",
        "subtasks": [
          {
            "id": 1,
            "title": "Define plugin interfaces and registry",
            "description": "Create EffectPlugin types and EffectRegistry with register/get/list; load built-ins from plugins folder.",
            "dependencies": [],
            "details": "File: studio/src/lib/effects/registry.ts; fields include id, kind, parameters, evaluate, optional presets/ui.",
            "status": "pending",
            "testStrategy": "Unit tests for registry add/get and type conformance."
          },
          {
            "id": 2,
            "title": "Implement Culori color utilities",
            "description": "Add OKLab/OKLCH/sRGB helpers and blendOKLab using Culori; provide sRGB fallback and uint8 packing.",
            "dependencies": [],
            "details": "File: studio/src/lib/color/culori.ts; export conversions and clamp helpers.",
            "status": "pending",
            "testStrategy": "Unit tests for round-trips and blend correctness."
          },
          {
            "id": 3,
            "title": "Add built-in generators",
            "description": "Implement solid, wave, noise (simplex-noise^4), fire; reuse buffers and support palette sampling.",
            "dependencies": [],
            "details": "Files: studio/src/lib/effects/plugins/{solid,wave,noise,fire}.ts; ensure deterministic seeding for tests.",
            "status": "pending",
            "testStrategy": "Unit tests per generator; perf micro-bench for wave."
          },
          {
            "id": 4,
            "title": "Add built-in modifiers",
            "description": "Implement brightness, hueShift, saturation modifiers with proper clamping and neutral defaults.",
            "dependencies": [],
            "details": "Files: studio/src/lib/effects/modifiers/{brightness,hueShift,saturation}.ts.",
            "status": "pending",
            "testStrategy": "Unit tests for idempotence and bounds."
          },
          {
            "id": 5,
            "title": "Build evaluator/compositor",
            "description": "Evaluate active clips at time t and composite by track order using OKLab blending.",
            "dependencies": [],
            "details": "File: studio/src/lib/effects/evaluator.ts; integrate device.fps from project schema.",
            "status": "pending",
            "testStrategy": "Integration test with overlapping clips; deterministic frame hashes."
          },
          {
            "id": 6,
            "title": "Update palette schema and presets",
            "description": "Enforce 2–16 swatches, add presets JSON, and expose palette to effects via ctx.",
            "dependencies": [],
            "details": "Update studio/src/lib/projectSchema.ts; add studio/src/lib/palettes/presets.json; optional PaletteEditor UI.",
            "status": "pending",
            "testStrategy": "Snapshot tests for palette serialize/round-trip and preset load."
          },
          {
            "id": 7,
            "title": "Wire NPM dependencies",
            "description": "Add culori^4, simplex-noise^4 and fast-check (dev) to studio/package.json and lockfile.",
            "dependencies": [],
            "details": "Ensure tree-shakable imports and stable seeds in tests.",
            "status": "pending",
            "testStrategy": "CI build passes; unit tests use Culori + simplex-noise successfully."
          },
          {
            "id": 8,
            "title": "Author tests and perf checks",
            "description": "Create Vitest suites for color, generators, modifiers, evaluator; add perf micro-bench for wave.",
            "dependencies": [],
            "details": "Place tests under studio/src/lib/** with .test.ts naming; use happy-dom env.",
            "status": "pending",
            "testStrategy": "All tests pass; wave eval ~1.8ms @320 LEDs."
          }
        ]
      },
      {
        "id": 67,
        "title": "Pattern compiler and upload pipeline",
        "description": "Compile timeline to .prism binary (Culori-based color pipeline; header includes version/fps/ledCount) and upload via TLV streaming with 4KB frames to device per ADR-002/003/008; enforce 256KB limit and target <3s compile+upload on dev HW.",
        "status": "pending",
        "dependencies": [
          "61",
          "64",
          "66",
          "63"
        ],
        "priority": "medium",
        "details": "Align with research Sec.3 (Effects pipeline), Sec.4 (Security), Sec.5 (Benchmarks).\n\n1) Compiler\n- Source: consume Effects pipeline output generated with Culori color utilities (OKLab/OKLCH to sRGB) per Research Sec.3. Pack frames using the .prism v1 header and payload layout defined in taskmaster/decisions/009-prism-format-specification.md and 009-prism-format-QUICKREF.md. Required header fields: version=0x01, fps=120 (ADR-008; see .taskmaster/decisions/008-led-fps-increase.md), ledCount=320 (ADR-003), plus any palette TLVs as spec says.\n- Palette strategy: quantize to ≤64 unique colors when needed (examples in out/tutorial_sync/wave_report.json show palette reduction). Write indexed color frames if palette is active; otherwise emit raw RGB per spec. Ensure the packed pattern payload (excluding filesystem metadata) stays ≤256KB (firmware/components/core/include/prism_config.h:35 PATTERN_MAX_SIZE=262144 and firmware/components/network/include/protocol_parser.h:83 mirrors this constant).\n- Implementation sketch (TS):\n  const bin = await compile(project)  // evaluates effects with Culori, builds header {version,fps=120,ledCount=320}\n  // returns ArrayBuffer with .prism bytes ready for upload\n- If Task 49 introduces a Rust compile worker (studio/src-tauri/compile.rs), expose compile(project) over Tauri IPC and reuse its evaluation/packing to hit performance targets.\n\n2) Upload integration (Task 61 TLV)\n- On user action (UI: \"Upload to Device\"), sequence: STATUS → PUT_BEGIN → multiple PUT_DATA (chunked) → PUT_END.\n- Chunk sizing: request STATUS and honor maxChunk returned (firmware/components/network/protocol_parser.c:916 handle_status returns TLV_MAX_PAYLOAD_SIZE). Limit each PUT_DATA payload to 4KB−7=4089 bytes (firmware/components/network/include/protocol_parser.h:82 TLV_MAX_PAYLOAD_SIZE).\n- PUT_BEGIN payload must include filename, size, CRC32 (see protocol_parser.c parse_put_begin_payload and PRD .taskmaster/docs/prism-firmware-prd.txt). Abort client-side if size > 256KB before sending. Compute CRC32 over the entire .prism buffer to match device validation in PUT_END (protocol_parser.c handle_put_end recalculates CRC).\n- Implement progress UI with bytes sent/total, percentage, and throughput (KB/s). Add retries with exponential backoff for transient send/ACK failures; surface friendly error messages for oversize, CRC mismatch, or device busy.\n- Security alignment (Research Sec.4): sanitize filename, bound-check all offsets, use zero-copy views when slicing chunks, and ensure timeouts/abort clean up state. Do not exceed device limits: PATTERN_MAX_SIZE and TLV_MAX_PAYLOAD_SIZE.\n\n3) Constraints & acceptance (Research Sec.5)\n- Size: enforce ≤256KB pattern payload; show descriptive error if exceeded (reference CANON in .taskmaster/TASK_REGENERATION_REPORT.md and prism_config.h).\n- Performance: compile+upload a small project completes <3s on dev HW (e.g., ≤300–500ms compile in worker, ≥500KB/s effective upload using 4KB frames to meet PRD throughput targets).\n\nCode references to align implementation:\n- Format/header/palette: .taskmaster/decisions/009-prism-format-specification.md, .taskmaster/decisions/009-prism-format-QUICKREF.md\n- FPS 120 & LED count: .taskmaster/decisions/008-led-fps-increase.md, .taskmaster/docs/prism-firmware-prd.txt\n- Device limits: firmware/components/core/include/prism_config.h:35 (PATTERN_MAX_SIZE), firmware/components/network/include/protocol_parser.h:82 (TLV_MAX_PAYLOAD_SIZE), :83 (PATTERN_MAX_SIZE)\n- STATUS with maxChunk: firmware/components/network/protocol_parser.c:916\n- Upload flow/validation: firmware/components/network/protocol_parser.c (PUT_BEGIN/PUT_DATA/PUT_END handlers and CRC checks)\n\nPseudo-code (TS):\n  const bin = await compile(project); // Culori → sRGB frames, header {v,fps=120,ledCount=320}\n  const crc = crc32(new Uint8Array(bin));\n  const status = await invoke('device_status');\n  const maxChunk = Math.min(status.maxChunk, 4089);\n  await invoke('device_put_begin', { name: project.id, size: bin.byteLength, crc });\n  for (let off=0; off<bin.byteLength; off+=maxChunk) {\n    const slice = new Uint8Array(bin, off, Math.min(maxChunk, bin.byteLength-off));\n    await invoke('device_put_data', { offset: off, data: Array.from(slice) }); // retry/backoff on failure\n  }\n  await invoke('device_put_end', { success: true });\n  // Update UI progress/throughput throughout",
        "testStrategy": "- Unit\n  - Header fields: verify .prism header writes version=0x01, fps=120, ledCount=320 per ADR-008.\n  - Palette quantization: given >64 unique colors from Culori pipeline, quantize to ≤64; validate palette table and indexed data are consistent.\n  - CRC: crc32(bin) matches value sent in PUT_BEGIN and what device recalculates on PUT_END.\n- Integration\n  - Mock device WebSocket/TLV endpoint: STATUS returns maxChunk, PUT_BEGIN enforces size ≤256KB, and acknowledges each PUT_DATA chunk; verify client respects 4089-byte max and retries/backoff on injected transient failures.\n  - Validate that oversize patterns are rejected client-side with friendly error; CRC mismatch path shows actionable message.\n- E2E\n  - Create a small project, click \"Upload to Device\": compile via worker then stream TLV chunks; progress UI shows percentage and throughput; completes <3s on dev hardware.\n  - Failure paths (disconnect mid-stream, device busy) present user-friendly recovery guidance and leave system consistent (no partial pattern registered).",
        "subtasks": []
      },
      {
        "id": 68,
        "title": "3D Preview with Three.js",
        "description": "Add a Three.js-based 3D LED preview (InstancedMesh of 320 LEDs) with HQ/LQ postprocessing toggle, OrbitControls camera presets, and screenshot capture via Tauri; keep render loop decoupled from React UI and meet <50ms update latency with HQ off per research Sec.5.",
        "status": "pending",
        "dependencies": [
          "66",
          "64"
        ],
        "priority": "medium",
        "details": "Align with research Sec.5 (Performance) and Sec.6 (Libraries) and the existing Tauri + React TypeScript architecture under `studio/`.\n\nImplementation plan (codebase-specific):\n- Dependencies (Sec.6 alignment):\n  - Add to `studio/package.json`: `three@^0.167.x`, `three-stdlib@^2.x` (for `OrbitControls`, `EffectComposer`, `RenderPass`, `UnrealBloomPass`). Keep using existing stacks from research Sec.6 (Zustand, Immer, Zundo) already present in `studio/package.json`.\n- Component scaffold:\n  - Create `studio/src/features/preview/Preview3D.tsx` exporting `<Preview3D />` with props `{ seed?: number }` (for deterministic frames) and internal HQ/LQ toggle and screenshot button UI.\n  - Integration: mount in `studio/src/App.tsx` below devices panel behind a simple section. Follow `DevicePanel`’s Tauri detection pattern via `window.__TAURI_INTERNALS__` (see `studio/src/features/devices/DevicePanel.tsx:16-18`).\n- LED instancing and colors:\n  - Use `InstancedMesh` with `MeshBasicMaterial` and 320 instances: positions for two rows of 160 (top/bottom). Pull LED count/fps from store: `useProjectStore((s)=>s.project.device.ledCount /* default 320 */)` and `fps` from `studio/src/lib/projectSchema.ts` (defaults to 120) to size arrays.\n  - Maintain a Float32Array/Color buffer and update per frame using `instancedMesh.setColorAt(i, color)`; set `instancedMesh.instanceColor.needsUpdate = true` and `instancedMesh.instanceMatrix.needsUpdate = true` when transforms change.\n  - Color source: read from a placeholder effect evaluator hook (to be provided by Task 46); for now, implement an internal `evaluateColor(ledIndex, t, seed)` that’s deterministic and swappable with the real evaluator. Keep the render loop decoupled from React state (use refs and `requestAnimationFrame`).\n- Postprocessing and quality toggle:\n  - Build a composer with `RenderPass` + `UnrealBloomPass` from `three-stdlib`. Wire an HQ/LQ toggle that disables bloom in LQ and reduces instance color updates (e.g., skip `setColorAt` every other frame or batch update at 30 FPS while still rendering at display FPS).\n  - Respect research Sec.5 targets: with HQ off (LQ), ensure update latency (effect evaluation + color upload + render) <50ms on baseline hardware (M1 MBP), measured over 200 frames.\n- Camera and controls:\n  - Add `OrbitControls` from `three-stdlib` to allow interaction.\n  - Provide preset buttons: front, side, isometric. Implement by setting camera position/target, then calling `controls.update()`.\n- Screenshot capture (Tauri-first, web fallback):\n  - Use `renderer.domElement.toDataURL('image/png')` to get PNG data.\n  - If Tauri detected: `@tauri-apps/plugin-dialog` `save()` to choose path, then decode base64 to `Uint8Array` and write with `@tauri-apps/plugin-fs.writeFile(path, bytes)`. Follow patterns in `studio/src/features/devices/DevicePanel.tsx` for dialog/FS usage and robust path handling.\n  - If not Tauri (tests/web): expose the data URL to the caller or trigger a browser download (anchor click) so E2E can verify content without native FS.\n- Perf logging and metrics:\n  - Use `studio/src/lib/logger.ts` to log frame timing: per-frame evaluation time, color upload time, total update latency (HQ on/off). Keep rolling averages and emit a summary after N frames.\n- UI and structure:\n  - Use CSS consistent with existing inline style approach in `App.tsx` for now; no global CSS required.\n\nKey file references:\n- `studio/package.json` (add libs)\n- `studio/src/features/preview/Preview3D.tsx` (new component)\n- `studio/src/App.tsx` (mount component)\n- `studio/src/lib/logger.ts` (perf logs)\n- `studio/src/stores/project.ts` and `studio/src/lib/projectSchema.ts` (read `ledCount` and `fps`)\n- `studio/src-tauri/tauri.conf.json` (capabilities already include dialog/fs plugins)\n\nExample loop sketch (within `Preview3D.tsx`):\n- Setup: create renderer, scene, camera, instanced mesh, composer (HQ), controls; precompute instance transforms.\n- RAF: t = now; if LQ and frame % 2 !== 0, skip color updates; else for i in 0..ledCount-1: color = evaluator(i, t, seed); mesh.setColorAt(i, color); mesh.instanceColor.needsUpdate = true; composer.render() if HQ else renderer.render(scene,camera); measure durations and log via `log('info', ...)`.\n- Screenshot: capture `toDataURL()`, save via Tauri or return URL in web.\n",
        "testStrategy": "- Visual determinism (Playwright):\n  - Add `studio/e2e/preview.spec.ts` to mount `<Preview3D seed=42 />`, wait 10 frames, take a screenshot of the canvas area, compute perceptual hash or pixel hash, and assert within tolerance across runs. Use LQ off (HQ on) and LQ on for two baselines.\n- Performance (Sec.5 alignment):\n  - Instrument `Preview3D` to log average update latency (eval + color upload + render) every 200 frames using `studio/src/lib/logger.ts`. In E2E, read the exposed metric (e.g., window hook or DOM data attribute) and assert `< 50ms` with HQ off, and record (non-failing) the HQ-on latency for reporting.\n- E2E UX:\n  - Toggle HQ/LQ via UI button and verify bloom visually (difference in screenshot; or CSS data attribute indicating composer state).\n  - Trigger screenshot: in web fallback (no Tauri), intercept the data URL (exposed on window or returned via callback) and assert PNG header and byte length > 0. In Tauri runs, mock `@tauri-apps/plugin-fs` to avoid actual disk writes and assert `writeFile` called with non-empty bytes.\n- Unit coverage (Vitest):\n  - Seeded evaluator correctness (pure function) and deterministic color array for a fixed time.\n  - Camera preset helpers set expected camera positions and update controls.\n",
        "subtasks": [
          {
            "id": 1,
            "title": "Add three.js dependencies and scaffold component",
            "description": "Add `three` and `three-stdlib` to `studio/package.json`; create `studio/src/features/preview/Preview3D.tsx` with canvas, HQ/LQ toggle, and buttons for camera presets and screenshot.",
            "dependencies": [],
            "details": "Follow project’s TypeScript/React setup and patterns used in `DevicePanel`. Import `OrbitControls`, `EffectComposer`, `RenderPass`, and `UnrealBloomPass` from `three-stdlib`.",
            "status": "pending",
            "testStrategy": "Run type-check and ensure the component mounts in a stub page; no WebGL work yet."
          },
          {
            "id": 2,
            "title": "Implement InstancedMesh and color updates",
            "description": "Render 320 LED instances (two rows of 160) using `InstancedMesh` and update per-frame colors from a deterministic evaluator; decouple from React state.",
            "dependencies": [
              1
            ],
            "details": "Use `useProjectStore` to read `ledCount`/`fps`; update colors via `setColorAt` with `instanceColor.needsUpdate=true`. Keep RAF separate from React (`useRef`).",
            "status": "pending",
            "testStrategy": "Unit test seeded evaluator; manual smoke verify mesh visible."
          },
          {
            "id": 3,
            "title": "Postprocessing + HQ/LQ toggle",
            "description": "Add `EffectComposer` with `RenderPass` + `UnrealBloomPass`; wire HQ/LQ where LQ disables bloom and reduces color update frequency.",
            "dependencies": [
              2
            ],
            "details": "Expose a toggle; in LQ mode, skip per-frame color writes on alternating frames and render directly without composer.",
            "status": "pending",
            "testStrategy": "E2E verify toggle affects render; record latency differences."
          },
          {
            "id": 4,
            "title": "OrbitControls and camera presets",
            "description": "Attach `OrbitControls` and add preset buttons for front/side/isometric views.",
            "dependencies": [
              2
            ],
            "details": "Set camera positions and call `controls.update()`; preserve target at LED grid center.",
            "status": "pending",
            "testStrategy": "Unit test helper that computes expected camera vectors for presets."
          },
          {
            "id": 5,
            "title": "Screenshot via Tauri dialog+fs (web fallback)",
            "description": "Implement PNG capture with `toDataURL` and save: Tauri via `plugin-dialog.save` + `plugin-fs.writeFile`, else expose data URL for download/tests.",
            "dependencies": [
              1,
              2
            ],
            "details": "Detect Tauri like `DevicePanel`; decode base64 to `Uint8Array` for `writeFile`. In web fallback, trigger a downloadable link or expose via callback.",
            "status": "pending",
            "testStrategy": "E2E mock plugins to assert save path/write called; in web mode, assert data URL starts with `data:image/png;base64,`."
          },
          {
            "id": 6,
            "title": "Perf metrics and logging",
            "description": "Measure eval + upload + render times and log rolling averages; ensure <50ms with HQ off (Sec.5).",
            "dependencies": [
              2,
              3
            ],
            "details": "Use `performance.now()` deltas and `log('info', ...)` from `studio/src/lib/logger.ts`. Expose last-avg via a DOM data attribute for E2E assertions.",
            "status": "pending",
            "testStrategy": "E2E read metric and assert `< 50ms` (HQ off)."
          },
          {
            "id": 7,
            "title": "E2E and visual tests",
            "description": "Add `studio/e2e/preview.spec.ts` covering HQ/LQ toggle, deterministic screenshot hash, and screenshot save behavior.",
            "dependencies": [
              1,
              2,
              3,
              5,
              6
            ],
            "details": "Use Playwright to mount the component page, toggle modes, and capture screenshots. In CI, run in web fallback and mock Tauri APIs.",
            "status": "pending",
            "testStrategy": "Hash compare images within tolerance; assert latency metric; verify save invoked/mocked."
          }
        ]
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-10-16T19:39:49.283Z",
      "taskCount": 68,
      "completedCount": 49,
      "tags": [
        "master"
      ],
      "created": "2025-10-16T20:05:19.184Z",
      "description": "Tasks for master context"
    }
  }
}